{
    "id": "2601.13732v1",
    "title": "SUNSET -- A Sensor-fUsioN based semantic SegmEnTation exemplar for ROS-based self-adaptation",
    "authors": [
        "Andreas Wiedholz",
        "Rafael Paintner",
        "Julian Gleißner",
        "Alwin Hoffmann",
        "Tobias Huber"
    ],
    "abstract": "随着机器人在动态环境中部署日益频繁，其软件系统复杂度不断提升，对自适应方法的需求也日益凸显。在这些环境中，机器人软件系统越来越多地面临两种运行情境：(1) 不确定性场景——现象易于观察但根源难以追溯；(2) 多重不确定性并发场景。本文提出SUNSET——一个基于ROS2的示范系统，能够在上述条件下对基于架构的自适应机制进行严谨、可复现的评估。该系统实现了由机器学习模型驱动的传感器融合语义分割流程，通过干扰输入预处理可模拟真实的性能退化场景。该示范系统呈现五种可观测现象，每种现象可由不同根源引发，并支持涵盖自修复与自优化的并发不确定性场景。SUNSET包含语义分割流程、训练完成的机器学习模型、不确定性注入脚本、基线控制器，以及逐步集成与评估文档，为可重复研究和公平比较提供完整支持。",
    "url": "https://arxiv.org/abs/2601.13732v1",
    "html_url": "https://arxiv.org/html/2601.13732v1",
    "html_content": "SUNSET- A Sensor-fUsioN based semantic SegmEnTation exemplar for ROS-based self-adaptation\nAndreas Wiedholz\nandreas.wiedholz@xitaso.com\n1234-5678-9012\nXITASO GmbH\nAugsburg\nGermany\n,\nRafael Paintner\nrafael.paintner@dlr.de\nGerman Aerospace Center (DLR) Institute of Flight Systems\nBraunschweig\nGermany\nand\nJulian Gleißner, Alwin Hoffmann, Tobias Huber\nXITASO GmbH\nAugsburg\nGermany\n(2025)\nAbstract.\nThe fact that robots are getting deployed more often in dynamic environments, together with the increasing complexity of their software systems, raises the need for self-adaptive approaches.\nIn these environments robotic software systems increasingly operate amid (1) uncertainties, where symptoms are easy to observe but root causes are ambiguous, or (2) multiple uncertainties appear concurrently.\nWe present SUNSET\n1\n1\n1\nhttps://github.com/XITASO/sunset\n, a ROS2-based exemplar that enables rigorous, repeatable evaluation of architecture-based self-adaptation in such conditions.\nIt implements a sensor fusion semantic-segmentation pipeline driven by a trained Machine Learning (ML) model whose input preprocessing can be perturbed to induce realistic performance degradations.\nThe exemplar exposes five observable symptoms, where each can be caused by different root causes and supports concurrent uncertainties spanning self-healing and self-optimisation.\nSUNSET includes the segmentation pipeline, a trained ML model, uncertainty-injection scripts, a baseline controller, and step-by-step integration and evaluation documentation to facilitate reproducible studies and fair comparison.\nSelf-adaptation, ROS, exemplar, sensor fusion\n†\n†\ncopyright:\nacmlicensed\n†\n†\njournalyear:\n2025\n†\n†\nconference:\nPreprint; Jan 20,\n2026; Germany\n†\n†\nccs:\nComputer systems organization Reliability\n1.\nIntroduction\nRobotic systems are used commonly in dynamic environments, e.g., unmanned aerial vehicles (UAVs) that fly in unmapped dynamic areas.\nThis leads to an increased amount of runtime uncertainties faced by systems, either caused by external influences or internal software or hardware failures.\nThe research area of Robotics Software Architecture-based Self-adaptive Systems aims to deal with the challenges accompanying this development by adapting the software during runtime\n(Alberts\net al.\n,\n2025\n)\n.\nIn this work, we separate an uncertainty’s symptom, which is easy to detect, from its source, i.e., the underlying cause.\nWe focus on two challenging cases that are particularly relevant for robotic systems:\nFirst, uncertainties that do not always have a clear 1:1 mapping between the symptom and the source of uncertainty;\nsecond, the concurrent occurrence of several uncertainties.\nEither independent uncertainties occur concurrently, or one uncertainty causes ripple effects in the system leading to multiple detected symptoms.\nWhile concurrent uncertainties have been tackled by the field of general self-adaptive systems (SAS)\n(Vogel,\n2018\n)\n, such uncertainties have not yet been the focus in Robotics Software Architecture-based Self-adaptive Systems.\nTo the best of our knowledge, there is currently no exemplar that is suitable for the robotic domain and evaluates self-adaptivity approaches under concurrent uncertainties with unknown sources.\nTo fill this gap, this paper introduces SUNSET  —  an exemplar which implements a Sensor fUsioN based Semantic sEgmentaTion pipeline.\nTo make SUNSET suitable for evaluating self-adaptive approaches in robotics, we chose a common and realistic robotic use case (semantic segmentation)\n(Tzelepi and Tefas,\n2021\n)\nand implement it in the Robot Operating System\n(Macenski\net al.\n,\n2022\n)\nthe main technology used for Robotics Software Architecture-based Self-adaptive Systems\n(Alberts\net al.\n,\n2025\n)\n.\nIn particular, we use Robot Operating System2, whereas the majority of existing exemplars rely on the outdated Robot Operating System1.\nSUNSET supports external self-adaptation with a clearly separated managed and managing system\n(Kephart and Chess,\n2003\n)\n.\nThis separation simplifies the comparison of different managing systems on the same managed system\n(Weyns,\n2020\n)\nand follows common practice in robotic and Robot Operating System-based self-adaptivity exemplars\n(Askarpour\net al.\n,\n2021\n; Gil\net al.\n,\n2021\n; Silva\net al.\n,\n2023\n; Imrie\net al.\n,\n2024\n)\n.\nSUNSET is explicitly designed to contain uncertainties with unknown source.\nThis leads to a 1:n mapping between a detected symptom and possible adaptations in the system that may be valid depending on the root cause of the symptom.\nMoreover, multiple symptoms can occur at the same time in SUNSET.\nTogether, these characteristics introduce additional complexity for planning adaptations in the managing system: it must decide which symptom to prioritise and analyse the system to identify the correct underlying source of uncertainty.\nSUNSET also provides a practical, robotics-relevant workload.\nIt implements a sensor-fusion semantic-segmentation pipeline that uses a real machine-learning model whose input preprocessing can be perturbed to produce realistic degradations in performance.\nMoreover, the exemplar supports the four main types of architectural adaptations common in Robotics Software Architecture-based Self-adaptive Systems\n(Alberts\net al.\n,\n2025\n)\nwhich are aimed at either self-optimization or self-healing capabilities, i.e., handling internal component faults, in the system.\nFurthermore, it maps injected faults to established Robot Operating System diagnostic criticality levels.\nThis combination of realistic Robot Operating System2-based robotics software integration, rich adaptation capabilities, and concurrent uncertainties with unknown sources makes SUNSET a novel and challenging exemplar for evaluating robotic self-adaptivity approaches.\nTo summarize, our work offers the following contributions:\n•\nAn exemplar in which multiple uncertainties can lead to the same symptom requiring root cause analysis.\n•\nThe first Robot Operating System-based exemplar that allows all common adaptations for self-adaptive robotic applications to be performed by a managing system to resolve concurrent uncertainties.\n•\nA ML model offering realistic data for degraded performance.\n•\nAn exemplar with detailed documentation how to evaluate new managing systems with an exemplary baseline.\n2.\nRelated work\nRobotics Software Architecture-based Self-adaptive Systems research has been present for at least 15 years with Robot Operating System being the main common ground in this field.\nMany of these approaches are focused on their respective use case, causing many evaluation scenarios to be tailored to the proposed managing system itself\n(Alberts\net al.\n,\n2025\n)\n.\nTherefore, the evaluation scenario is only used in the respective study\n(Alberts\net al.\n,\n2024\n; Cheng\net al.\n,\n2020\n)\nwhich makes it difficult to compare different approaches with each other.\nThis makes it hard to prove that one approach can be implemented for multiple use cases.\nInstead, studies rather discuss whether the approach could be applied to multiple use cases in theory\n(Filippone\net al.\n,\n2024\n)\nor discuss the generalizability of their approach after evaluating on one existing benchmark\n(Silva\net al.\n,\n2025\n)\n.\nThere are a few exemplars on which multiple Robot Operating System-based self-adaptive approaches have been evaluated, which we will discuss in the following.\nA detailed overview of self-adaptive robotic exemplars is given in Robomax\n(Askarpour\net al.\n,\n2021\n)\n.\nThis artifact contains 12 exemplars of different robotic applications and details the robotic mission, the environment and what types of adaptations are present.\nWhile the artifacts have differences in the domain, robotic mission, and environmental factors, the adaptations possible in these systems focus mostly on reparametrization in the form of reconfiguring, optimising or re-organisation.\nIn 2021, the Body Sensor Network was introduced by\nGil\net al.\n(\n2021\n)\nwhich is not a robotic use case but implemented in Robot Operating System.\nThe system’s prototype is in the healthcare domain and implements a patient health status monitoring in Robot Operating System1.\nA managing system is responsible for detecting disturbances and re-parametrises the components of the Body Sensor Network accordingly.\nSilva\net al.\n(\n2023\n)\nintroduce SUAVE which simulates a Robot Operating System2-based underwater robot with the mission to detect and inspect a pipeline.\nIn the extended version, SUAVE contains 3 uncertainties, which include environmental factors, the need to recharge a battery or the failure of one of the robot’s thrusters.\nAll of the uncertainties in SUAVE have a clearly defined adaptation that resolves the uncertainty.\nWhile in theory, a failure of a thruster should be solved before adapting to other environmental factors, these uncertainties by design of the exemplar do not appear concurrently, which doesn’t necessitate a prioritisation of adaptations.\nRecently, Aloft\n(Imrie\net al.\n,\n2024\n)\nhas been published, which is an exemplar designed for drone control, implemented in Robot Operating System1.\nThe use of Gazebo allows a physically accurate simulation and contains physical concerns as well as time-related concerns raising the need for self-adaptation.\nThis can be related to failing components in the system or environmental factors necessitating changes in the plans.\nOne exemplar that encourages  —  similar to SUNSET  —  the need for prioritisation between self-healing and self-optimising adaptations is mRubis\n(Vogel,\n2018\n)\n.\nIn this exemplar, the operability of a marketplace in which users can sell or auction items has to be managed.\nSince mRubis is neither implemented in Robot Operating System nor a robotic application, it would require considerable effort to evaluate managing systems that focus on handling both critical and self-optimising adaptations concurrently in the robotics domain.\nSUNSET is the first Robot Operating System-based exemplar that supports concurrent uncertainties with unknown sources necessitating a managing system to prioritise between detected symptoms.\nIt is implemented in Robot Operating System2 instead of the majority of the Robot Operating System1-based related work\n(Askarpour\net al.\n,\n2021\n; Imrie\net al.\n,\n2024\n; Gil\net al.\n,\n2021\n)\nand enables managing systems to use all adaptations that are common in self-adaptive robotics research\n(Alberts\net al.\n,\n2025\n)\n.\nThis enables robotics research to evaluate managing systems with enhanced capabilities on an independent exemplar.\n3.\nSUNSET\nFigure 1.\nOverview SUNSET. Managed system and additional components are part of SUNSET. The managing system can be exchanged without adaptation in any of the Robot Operating System nodes.\n3.1.\nUse-Case Description\nSUNSET models the perception of an Unmanned Aerial Vehicle that must semantically understand its surroundings during the mission  —  a core capability in many modern robotic systems\n(Tzelepi and Tefas,\n2021\n)\n.\nAs data basis for our exemplar, we utilise the SynDrone Dataset (Town 01)\n(Rizzoli\net al.\n,\n2023\n)\n, which simulates a Unmanned Aerial Vehicle in a virtual environment containing both urban and rural scenes.\nThe Unmanned Aerial Vehicle is equipped with RGB and depth cameras, and the resulting data is continuously fused and interpreted to support tasks such as safe navigation and environment mapping.\n3.2.\nSystem Architecture\nThe Robot Operating System architecture of the semantic segmentation pipeline in SUNSET consists of standard components for sensor fusion (see\nFigure\n1\n).\nA\ncamera sensor\nand\ndepth sensor\nnode read RGB and depth images from a Robot Operating System bag that contains pre-recorded flight data and provide them to the rest of the pipeline.\nUsing pre-recorded data rather than live simulations improves the replicability of SUNSET experiments, as the same sensor inputs can be replayed across different runs and configurations.\nIn SUNSET there is also an\nimage enhancement\nnode that is able to reverse a degradation of RGB images.\nThe two data modalities are aligned by a\nsensor fusion\nnode that matches RGB–D pairs based on the timestamps of the received images.\nThe fused (or single-modality) images are then processed by a\nsegmentation\nnode that performs semantic segmentation.\nTo simulate how different sensing modalities influence the robustness and quality of the UAV’s scene understanding, the segmentation node can operate in three configurations: RGB-only, depth-only, and fused RGB–D.\nFor each configuration, we train a separate ML model from scratch on the SynDrone dataset\n(Rizzoli\net al.\n,\n2023\n)\n, while keeping the rest of the mission scenario unchanged.\nFor the model architecture, we use the ResNet50 based Deeplab-V3 model with the late fusion strategy tested by\nRizzoli\net al.\n(\n2023\n)\n.\nAlongside the segmentation pipeline, an\nuncertainty injector\nintroduces uncertainties (see\nSection\n3.3\n) directly into the Robot Operating System nodes.\nAdditionally, we provide a Robot Operating System node that collects information needed to detect the symptoms of the introduced uncertainties and provides it to a managing system.\nFor the managing system we propose a baseline (see\nSection\n4.2\n), which can be substituted with any other managing system with the necessary Robot Operating System interfaces.\n3.3.\nUncertainties\nFigure 2.\nThe effect of different uncertainties on the entropy of our segmentation model. This refers to symptom S4.\nThe uncertainty injector can introduce 11 uncertainties distributed between 5 symptoms that cover all of the criticality levels of the system.\nRegarding the criticality levels, we use established levels (OK, WARNING, ERROR) from Robot Operating System diagnostic tools\n2\n2\n2\nhttps://docs.ros.org/en/noetic/api/diagnostic_msgs/html/msg/DiagnosticStatus.html\n.\nEach symptom with a WARNING or ERROR criticality level is caused by one of the uncertainties and solved with the corresponding adaptations.\nResolving all injected uncertainties requires all of the adaptations our system is capable of namely redeploy, (de-)activate, communication change, and reparametrisation.\nCategorised by their symptom, the introduced uncertainties are:\nS1-3: Communication channel outage (Error)\nThis symptom can arise in the RGB camera (\nS1\n), sensor fusion node (\nS2\n), or the segmentation node (\nS3\n) and can be detected by monitoring the frequency of their respective topic.\nThese uncertainties can be introduced in two different severities, each necessitating a different adaptation.\nIn total, this results in six separate uncertainties that lead to communication channel outage symptoms.\nS4: Reduced segmentation performance (Warning)\nSince we use a trained ML model for segmentation, we are able to see real-world effects on the certainty of the model in its predictions and the resulting quality of the predictions.\nWe achieve this by calculating the mean entropy of the models’ segmentation logits.\nIf the entropy increases, i.e., the model gets uncertain about its predictions and therefore the quality of the segmentation decreases, an adaptation of the system becomes necessary.\nAs the segmentation is dependent on multiple nodes, there are four possible uncertainties with respective mitigation strategies that can lead to this symptom.\nFigure\n2\nshows the effect of different uncertainties on the entropy of the segmentation model, which we describe in the following.\nFirst, a degraded image quality is simulated by shifting the colour space of the images provided to the camera node.\nSecond, the managed system contains an\nimage enhancement\nnode that applies a reverse colour space shift to correct image degradation.\nIf this image enhancement is applied on non-degraded images, it leads again to degraded images and has the same effect on the entropy of the segmentation model.\nThird, we simulate misalignment during fusion of the RGB and depth images by shifting one of the images, which results in a spatial misalignment between RGB and depth.\nLastly, the depth node can be degraded, i.e., sending noisy depth information.\nS5: Re-focusing the camera (OK)\nAn incorrect camera focus is simulated by adding a Gaussian blur to the image.\nDuring each test run, SUNSET simultaneously introduces a combination of one uncertainty from each criticality level into the perception pipeline.\nNote that it is possible that there are more than three detected symptoms since, e.g., an outage of the camera would lead to an outage of the sensor fusion and segmentation as well.\n3.4.\nPossible adaptations\nFigure 3.\nPotential adaptations in SUNSET. Blue := Reparametrization, Green := Change of communication, Orange := Activation, Deactivation and Redeploy\nIn order to resolve uncertainties in SUNSET, we can perform the following adaptations that are common in Robotics Software Architecture-based Self-adaptive Systems\n(Alberts\net al.\n,\n2025\n)\n: Reparametrisation, change of communication, (de-)activating ROS nodes and redeploying ROS nodes .\nFigure\n3\ngives an overview of all the possible adaptations per Robot Operating System node in SUNSET that can be used to resolve the uncertainties described in\nSection\n3.3\n.\nEach Robot Operating System node in our exemplar implements the needed endpoints via a common base class to respond to adaptations from a managing subsystem.\nIn the following we detail the behaviour of the Robot Operating System nodes in SUNSET during an adaptation and which uncertainties they can resolve.\nReparametrisation\nIn order to reparametrise a Robot Operating System node, we use Robot Operating System parameters that are a standard mechanism in Robot Operating System.\nFor a node’s internal parameters, reparameterisation changes a class attribute with the exact same name as the parameter.\nThis means that the node does not need to regularly check its own parameters to receive updates.\nIn the camera, changing a parameter can resolve\nS5\n, as it triggers a refocus in this node.\nIn the sensor fusion, it triggers a recalibration between RGB and depth and potentially resolves\nS4\n.\nFurthermore, in case one of the sensors is not available, the sensor fusion and segmentation nodes can be reparametrized to use only the available modality.\nThe sensor fusion then only republishes the data from the sensor that is available, and the segmentation node uses the ML model that was trained on the available modality.\nChange of communication\nThe Robot Operating System node can change any of its subscribed topics at runtime in the following way:\nAfter the managing subsystem provides the name of the new topic, the adapted Robot Operating System node destroys its current subscription and creates a new one with the same message type.\nIn SUNSET, change of communication is used to change the input of the sensor fusion node from the camera to the image enhancement node.\nTogether with the addition of image enhancement (see next paragraph), this provides one possible solution for\nS4\n.\nAddition / removal of components\nSince our common base class inherits from the Lifecycle node class\n3\n3\n3\nhttps://foxglove.dev/blog/how-to-use-ros2-lifecycle-nodes\n, all SUNSET nodes can be within four predefined lifecycle states during runtime.\nThe possible states of each Robot Operating System node are\nUNCONFIGURED\n,\nINACTIVE\n,\nACTIVE\nand\nFINALIZED\n.\nWe consider a node added to the system if it is in the\nACTIVE\nstate and removed if it is in any other state.\nWith this adaptation we can potentially resolve\nS1-3\nin the respective nodes or\nS4\n.\nDepending on the severity level of the injected uncertainty,\nS1-3\ncan be resolved by restarting the respective node, i.e., removing and adding it to the system.\nFor\nS4\n, in case the camera publishes degraded images, adding the image enhancement node to the system provides a source of non-degraded images.\nNote that the resulting images of using image enhancement on non-degraded images have the same effect on the segmentation node as degraded images themselves.\nRedeploy\nIf a node is redeployed, the communication interfaces are destroyed, and the Robot Operating System node is completely terminated as compared to adding and removing it to the system.\nIn order to reliably terminate a Robot Operating System node, we create a timer in the respective Robot Operating System node that terminates itself as soon as the lifecycle state\nFINALIZED\nis reached.\nTo simulate the redeploy of real hardware, an artificial delay is introduced when redeploying the respective nodes (camera, depth sensor).\nThe redeploy of a node can be used in case the severity of the outage in\nS1-3\nis higher and can only be resolved by relaunching this node completely.\nRedeploying a node typically resolves all Robot Operating System node internal uncertainties; however uncertainties with external causes, e.g., image degradation remain persistent.\nSince redeploying a node in SUNSET takes longer than restarting it, redeploying a node is the least viable option when optimising on time efficiency.\n3.5.\nExpanding SUNSET\nWith the segmentation pipeline, SUNSET provides an integral part of robotic software systems.\nFurthermore, we provide a base class that extends the Robot Operating System lifecycle node class and implements the behaviour of all architectural adaptations in SUNSET.\nBy inheriting from this base class, it is straightforward to expand SUNSET with additional nodes and capabilities.\n4.\nEvaluation\nTable 1.\nBaseline results for SUNSET\nManaging system\nu\nr\n​\ne\n​\ns\n​\no\n​\nl\n​\nv\n​\ne\n​\nd\ns\ne\n​\nx\n​\ne\n​\nc\n​\nu\n​\nt\n​\ne\n​\nd\n\\frac{u_{resolved}}{s_{executed}}\nt\nr\n​\ne\n​\na\n​\nc\n​\nt\nt_{react}\n[s]\n#\nr\n​\ne\n​\nd\n​\ne\n​\np\n​\nl\n​\no\n​\ny\nu\nredeploy_{u}\nt\nd\n​\no\n​\nw\n​\nn\nt_{down}\n[s]\nIoU\nNone w/o uncertainties\nN/A\nN/A\nN/A\nN/A\n0.47\n±\n\\pm\n0.02\nNone w/ uncertainties (\nWARNING\n&\nOK\n)\nN/A\nN/A\nN/A\nN/A\n0.28\n±\n\\pm\n0.08\nBaseline\n0.86\n±\n\\pm\n0.24\n1.65\n±\n\\pm\n0.99\n1.25\n±\n\\pm\n1.36\n5.66\n±\n\\pm\n2.05\n0.40\n±\n\\pm\n0.10\n4.1.\nMetrics\nTo measure the performance of the managing system and the impact on the managed system, we provide several metrics which we calculate based on log files.\nThe performance of the managed system can be measured by the quality of the segmentation model’s predictions and the availability of the overall managed system.\nWe use the Intersection over Union which is a common way to measure the performance of segmentation models\n(Minaee\net al.\n,\n2022\n)\n.\nFor the availability of the managed system, we introduce the system downtime that accumulates the time that the segmentation algorithm didn’t send new data in the expected frequency.\nThis indicates that one of the components had an outage.\nTo put the downtime into context, one experiment runs for 20 seconds, i.e., a downtime of 5 seconds would result in a system availability of 75%.\nOther metrics we provide solely focus on the performance of the managing system:\n•\nRatio resolved uncertainties and executed adaptations\nu\nr\n​\ne\n​\ns\n​\no\n​\nl\n​\nv\n​\ne\n​\nd\na\ne\n​\nx\n​\ne\n​\nc\n​\nu\n​\nt\n​\ne\n​\nd\n\\frac{u_{resolved}}{a_{executed}}\n: How many uncertainties were resolved per executed system adaptation?\nThis metric takes into account if an executed system adaptation not only solved the uncertainty it was supposed to solve, but also other uncertainties.\n•\nReaction time\nt\nreact\nt_{\\text{react}}\n: As for each detected symptom, there are multiple uncertainties potentially being the reason for this symptom, this metric measures the time it took to detect a symptom and select the correct adaptation of the system.\n•\nNumber of unnecessary redeploys\n#redeploy\nu\n\\text{\\#redeploy}_{\\text{u}}\n: Number of redeploys that were executed even though an adaptation of the system with less impact would have sufficed.\n4.2.\nBaseline managing system\nTo evaluate that SUNSET implements valid behaviour for the defined uncertainties, we implement a managing system based on the MAPE-K loop\n(Kephart and Chess,\n2003\n)\nwith straightforward adaptations to the system and evaluate it on the metrics defined above.\nFirst, the managing system redeploys every node that sends data with a frequency lower than 1 Hz.\nSecond, it performs a recalibration in the sensor fusion node as soon as the entropy of the segmentation model is bigger than 0.06  —  one of four potential adaptations for high entropy.\nThe results of our baseline are presented in\nTable\n1\n.\nWe present the results for running SUNSET without any uncertainties and with uncertainties present the whole time (no outages) to show the best and worst possible IoU.\nThe other metrics are not applicable here since there is no downtime and no managing system present that can be evaluated.\nThe baseline ran every possible combination of uncertainties three times.\nBy design it is not able to detect three out of four\nWARNING\nuncertainties for\nS4\nwhich results in a high standard deviation for the Intersection over Union.\nAs it redeploys every node in which\nS1-3\nis detected,\n#\n​\nr\n​\ne\n​\nd\n​\ne\n​\np\n​\nl\n​\no\n​\ny\nu\n\\#redeploy_{u}\nhas a high value.\n5.\nConclusion & Future work\nIn this work, we present SUNSET an exemplar for evaluating managing systems for self-adaptive robotic systems.\nOur exemplar contains a segmentation pipeline with a real ML model and different uncertainties causing degraded performance of the model or entire system outages.\nIn SUNSET, multiple uncertainties can (1) cause the same symptom and (2) occur simultaneously, necessitating a deeper analysis of the system.\nSUNSET can easily be expanded with additional Robot Operating System nodes to create extended or customised use cases while the existing pipeline already presents a novel and challenging benchmark for evaluating Robotics Software Architecture-based Self-adaptive Systems.\nAcknowledgements.\nThe authors would like to thank the Federal Ministry of Economic Affairs and Climate Action of Germany for funding the described activities through the Federal Aviation Research Program (LuFo) VI-3, funding code 20F2201D.\nReferences\nE. Alberts, I. Gerostathopoulos, I. Malavolta, C. Hernández Corbato, and P. Lago (2025)\nSoftware architecture-based self-adaptation in robotics\n.\nJournal of Systems and Software\n219\n,\npp. 112258\n.\nExternal Links:\nISSN 0164-1212\n,\nLink\n,\nDocument\nCited by:\n§1\n,\n§1\n,\n§1\n,\n§2\n,\n§2\n,\n§3.4\n.\nE. Alberts, I. Gerostathopoulos, V. Stoico, and P. Lago (2024)\nReBeT: Architecture-based Self-adaptation of Robotic Systems through Behavior Trees\n.\nIn\n2024 IEEE International Conference on Autonomic Computing and Self-Organizing Systems (ACSOS)\n,\nExternal Links:\nLink\n,\nDocument\nCited by:\n§2\n.\nM. Askarpour, C. Tsigkanos, C. Menghi, R. Calinescu, P. Pelliccione, S. García, R. Caldas, T. J. von Oertzen, M. Wimmer, L. Berardinelli, M. Rossi, M. M. Bersani, and G. S. Rodrigues (2021)\nRoboMAX: Robotic Mission Adaptation eXemplars\n.\nIn\n2021 International Symposium on Software Engineering for Adaptive and Self-Managing Systems (SEAMS)\n,\npp. 245–251\n.\nNote:\nISSN: 2157-2321\nExternal Links:\nLink\n,\nDocument\nCited by:\n§1\n,\n§2\n,\n§2\n.\nB. H. C. Cheng, R. J. Clark, J. E. Fleck, M. A. Langford, and P. K. McKinley (2020)\nAC-ROS: assurance case driven adaptation for the robot operating system\n.\nIn\nProceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems\n,\nMODELS ’20\n,\nNew York, NY, USA\n,\npp. 102–113\n.\nExternal Links:\nISBN 978-1-4503-7019-6\n,\nLink\n,\nDocument\nCited by:\n§2\n.\nG. Filippone, J. A. Piñera García, M. Autili, and P. Pelliccione (2024)\nHandling uncertainty in the specification of autonomous multi-robot systems through mission adaptation\n.\nIn\nProceedings of the 19th International Symposium on Software Engineering for Adaptive and Self-Managing Systems\n,\nSEAMS ’24\n,\nNew York, NY, USA\n,\npp. 25–36\n.\nExternal Links:\nISBN 979-8-4007-0585-4\n,\nLink\n,\nDocument\nCited by:\n§2\n.\nE. B. Gil, R. Caldas, A. Rodrigues, G. L. G. da Silva, G. N. Rodrigues, and P. Pelliccione (2021)\nBody Sensor Network: A Self-Adaptive System Exemplar in the Healthcare Domain\n.\nIn\n2021 International Symposium on Software Engineering for Adaptive and Self-Managing Systems (SEAMS)\n,\npp. 224–230\n.\nNote:\nISSN: 2157-2321\nExternal Links:\nLink\n,\nDocument\nCited by:\n§1\n,\n§2\n,\n§2\n.\nC. Imrie, R. Howard, D. Thuremella, N. M. Proma, T. Pandey, P. Lewinska, R. Cannizzaro, R. Hawkins, C. Paterson, L. Kunze, and V. Hodge (2024)\nAloft: Self-Adaptive Drone Controller Testbed\n.\nIn\nProceedings of the 19th International Symposium on Software Engineering for Adaptive and Self-Managing Systems\n,\nSEAMS ’24\n,\nNew York, NY, USA\n,\npp. 70–76\n.\nExternal Links:\nISBN 979-8-4007-0585-4\n,\nLink\n,\nDocument\nCited by:\n§1\n,\n§2\n,\n§2\n.\nJ.O. Kephart and D.M. Chess (2003)\nThe vision of autonomic computing\n.\nComputer\n36\n(\n1\n),\npp. 41–50\n.\nExternal Links:\nISSN 1558-0814\n,\nLink\n,\nDocument\nCited by:\n§1\n,\n§4.2\n.\nS. Macenski, T. Foote, B. Gerkey, C. Lalancette, and W. Woodall (2022)\nRobot Operating System 2: Design, architecture, and uses in the wild\n.\nScience Robotics\n7\n(\n66\n),\npp. eabm6074\n.\nNote:\nPublisher: American Association for the Advancement of Science\nExternal Links:\nLink\n,\nDocument\nCited by:\n§1\n.\nS. Minaee, Y. Boykov, F. Porikli, A. Plaza, N. Kehtarnavaz, and D. Terzopoulos (2022)\nImage Segmentation Using Deep Learning: A Survey\n.\nIEEE Transactions on Pattern Analysis and Machine Intelligence\n44\n(\n7\n),\npp. 3523–3542\n.\nExternal Links:\nISSN 1939-3539\n,\nLink\n,\nDocument\nCited by:\n§4.1\n.\nG. Rizzoli, F. Barbato, M. Caligiuri, and P. Zanuttigh (2023)\nSynDrone – multi-modal UAV dataset for urban scenarios\n.\nIn\n2023 IEEE/CVF international conference on computer vision workshops (ICCVW)\n,\nLos Alamitos, CA, USA\n,\npp. 2202–2212\n.\nExternal Links:\nLink\n,\nDocument\nCited by:\n§3.1\n,\n§3.2\n.\nG. R. Silva, J. Päßler, S. L. T. Tarifa, E. B. Johnsen, and C. H. Corbato (2025)\nROSA: A Knowledge-based Solution for Robot Self-Adaptation\n.\nFrontiers in Robotics and AI\n12\n,\npp. 1531743\n.\nNote:\narXiv:2505.00733 [cs]\nExternal Links:\nISSN 2296-9144\n,\nLink\n,\nDocument\nCited by:\n§2\n.\nG. R. Silva, J. Päßler, J. Zwanepol, E. Alberts, S. L. T. Tarifa, I. Gerostathopoulos, E. B. Johnsen, and C. H. Corbato (2023)\nSUAVE: An Exemplar for Self-Adaptive Underwater Vehicles\n.\nIn\n2023 IEEE/ACM 18th Symposium on Software Engineering for Adaptive and Self-Managing Systems (SEAMS)\n,\npp. 181–187\n.\nNote:\nISSN: 2157-2321\nExternal Links:\nLink\n,\nDocument\nCited by:\n§1\n,\n§2\n.\nM. Tzelepi and A. Tefas (2021)\nSemantic Scene Segmentation for Robotics Applications\n.\nIn\n2021 12th International Conference on Information, Intelligence, Systems & Applications (IISA)\n,\npp. 1–4\n.\nExternal Links:\nLink\n,\nDocument\nCited by:\n§1\n,\n§3.1\n.\nT. Vogel (2018)\nmRUBiS: an exemplar for model-based architectural self-healing and self-optimization\n.\nIn\nProceedings of the 13th International Conference on Software Engineering for Adaptive and Self-Managing Systems\n,\nSEAMS ’18\n,\nNew York, NY, USA\n,\npp. 101–107\n.\nExternal Links:\nISBN 978-1-4503-5715-9\n,\nLink\n,\nDocument\nCited by:\n§1\n,\n§2\n.\nD. Weyns (2020)\nAn introduction to self-adaptive systems: A contemporary software engineering perspective\n.\nJohn Wiley & Sons\n.\nCited by:\n§1\n.",
    "preview_text": "The fact that robots are getting deployed more often in dynamic environments, together with the increasing complexity of their software systems, raises the need for self-adaptive approaches. In these environments robotic software systems increasingly operate amid (1) uncertainties, where symptoms are easy to observe but root causes are ambiguous, or (2) multiple uncertainties appear concurrently. We present SUNSET, a ROS2-based exemplar that enables rigorous, repeatable evaluation of architecture-based self-adaptation in such conditions. It implements a sensor fusion semantic-segmentation pipeline driven by a trained Machine Learning (ML) model whose input preprocessing can be perturbed to induce realistic performance degradations. The exemplar exposes five observable symptoms, where each can be caused by different root causes and supports concurrent uncertainties spanning self-healing and self-optimisation. SUNSET includes the segmentation pipeline, a trained ML model, uncertainty-injection scripts, a baseline controller, and step-by-step integration and evaluation documentation to facilitate reproducible studies and fair comparison.\n\nSUNSET- A Sensor-fUsioN based semantic SegmEnTation exemplar for ROS-based self-adaptation\nAndreas Wiedholz\nandreas.wiedholz@xitaso.com\n1234-5678-9012\nXITASO GmbH\nAugsburg\nGermany\n,\nRafael Paintner\nrafael.paintner@dlr.de\nGerman Aerospace Center (DLR) Institute of Flight Systems\nBraunschweig\nGermany\nand\nJulian Gleißner, Alwin Hoffmann, Tobias Huber\nXITASO GmbH\nAugsburg\nGermany\n(2025)\nAbstract.\nThe fact that robots are getting deployed more often in dynamic environments, together with the increasing complexity of their software systems, raises the need for self-adaptive approaches.\nIn these environments robotic software systems increasingly operate amid (1) uncertainties, where symptoms are easy to observe but root causes are ambiguous, or (2) multiple uncertainties appear concurrently.\nWe present SUNSET\n1\n1\n1\nhttps://github.com/XITASO/",
    "is_relevant": false,
    "relevance_score": 1.0,
    "extracted_keywords": [
        "sensor fusion",
        "semantic segmentation",
        "ROS",
        "self-adaptation",
        "machine learning"
    ],
    "one_line_summary": "SUNSET是一个基于ROS2的传感器融合语义分割示例，用于评估在动态环境中机器人软件系统的自适应性方法。",
    "detailed_summary": "",
    "qa_pairs": [],
    "is_hidden": false,
    "is_starred": false,
    "flag": true,
    "published_date": "2026-01-20T08:40:57Z",
    "created_at": "2026-01-27T15:53:09.436405",
    "updated_at": "2026-01-27T15:53:09.436412",
    "recommend": 0
}