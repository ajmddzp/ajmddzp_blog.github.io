{
    "id": "2601.06728v1",
    "title": "Robust Evacuation for Multi-Drone Failure in Drone Light Shows",
    "authors": [
        "Minhyuk Park",
        "Aloysius K. Mok",
        "Tsz-Chiu Au"
    ],
    "abstract": "è¿‘å¹´æ¥ï¼Œæ— äººæœºç¯å…‰ç§€å·²æˆä¸ºå¹¿å—æ¬¢è¿çš„å¨±ä¹å½¢å¼ã€‚ç„¶è€Œï¼Œå¤šèµ·å¤§è§„æ¨¡æ— äººæœºæ•…éšœäº‹ä»¶â€”â€”å³å¤šæ¶æ— äººæœºåŒæ—¶ä»ç©ºä¸­å è½â€”â€”å¼•å‘äº†äººä»¬å¯¹å®‰å…¨æ€§å’Œå¯é æ€§çš„æ‹…å¿§ã€‚ä¸ºç¡®ä¿ç³»ç»Ÿçš„é²æ£’æ€§ï¼Œæˆ‘ä»¬æå‡ºä¸€ç§ä¸“é—¨é’ˆå¯¹æ— äººæœºç¯å…‰ç§€ä¸­å¤šæœºæ•…éšœåœºæ™¯çš„æ— äººæœºæ³Šä½ç®—æ³•ï¼Œæ—¨åœ¨é€šè¿‡ç´§æ€¥ç–æ•£æœºåˆ¶é™ä½è¿ç¯ç¢°æ’é£é™©ï¼Œå¹¶åˆ©ç”¨é¢„å…ˆéƒ¨ç½²çš„éšè—æ— äººæœºå®ç°æ•…éšœåçš„å¿«é€Ÿæ¢å¤ã€‚è¯¥ç®—æ³•èåˆäº†æ³¨æ„åŠ›æœºåˆ¶å¢å¼ºå‹ç¤¾äº¤é•¿çŸ­æœŸè®°å¿†ç½‘ç»œæ¨¡å‹ï¼Œé€šè¿‡é¢„æµ‹æ•…éšœæ— äººæœºçš„å è½è½¨è¿¹ï¼Œè®¡ç®—å‡ºå¯æœ€å¤§é™åº¦é™ä½å¹¸å­˜æ— äººæœºè¢«æ’å‡»æ¦‚ç‡çš„è¿‘ä¼¼æœ€ä¼˜ç–æ•£è·¯å¾„ã€‚åœ¨æ¢å¤æ¨¡å—ä¸­ï¼Œç³»ç»Ÿä¼šè°ƒåº¦å¤„äºéšè”½çŠ¶æ€ï¼ˆå…³é—­LEDç¯å…‰ï¼‰çš„å¤‡ç”¨æ— äººæœºæ›¿ä»£æ•…éšœæ— äººæœºï¼Œç¡®ä¿ç¯å…‰ç§€è¡¨æ¼”æŒç»­è¿›è¡Œã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé€šè¿‡æ·±åº¦å­¦ä¹ é¢„æµ‹å è½æ— äººæœºè½¨è¿¹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½æ˜¾è‘—æå‡å¤šæ— äººæœºç³»ç»Ÿçš„é²æ£’æ€§ã€‚",
    "url": "https://arxiv.org/abs/2601.06728v1",
    "html_url": "https://arxiv.org/html/2601.06728v1",
    "html_content": "Robust Evacuation for Multi-Drone Failure in Drone Light Shows\nMinhyuk Park\n1\n,\nAloysius K. Mok\n2\n,\nTsz-Chiu Au\n1\nAbstract\nDrone light shows have emerged as a popular form of entertainment in recent years. However, several high-profile incidents involving large-scale drone failuresâ€”where multiple drones simultaneously fall from the skyâ€”have raised safety and reliability concerns. To ensure robustness, we propose a drone parking algorithm designed specifically for multiple drone failures in drone light shows, aimed at mitigating the risk of cascading collisions by drone evacuation and enabling rapid recovery from failures by leveraging strategically placed hidden drones. Our algorithm integrates a Social LSTM model with attention mechanisms to predict the trajectories of failing drones and compute near-optimal evacuation paths that minimize the likelihood of surviving drones being hit by fallen drones. In the recovery node, our system deploys hidden drones (operating with their LED lights turned off) to replace failed drones so that the drone light show can continue. Our experiments showed that our approach can greatly increase the robustness of a multi-drone system by leveraging deep learning to predict the trajectories of fallen drones.\nIntroduction\nDrone light shows have increasingly supplanted traditional fireworks as a popular form of entertainment in cultural festivals and sporting events. However, drone light shows have been subject to several large-scale operational failures. Drone dropping incidents were documented in (1) Victoria Harbor in Hong Kong in 2018\n1\n1\n1\nhttps://gpspatron.com/jamming-criminal\n, (2) Taichung City in Taiwan in 2020\n2\n2\n2\nhttps://www.taipeitimes.com/News/taiwan/archives/2020/02/24/2003731529\n, (3) SeaTac in Washington in the United States in 2024\n3\n3\n3\nhttps://www.seattletimes.com/seattle-news/seatacs-40000-fourth-of-july-fail-55-drones-drop-into-angle-lake\n, and (4) Ho Chi Minh City in Vietnam in 2025\n4\n4\n4\nhttp://youtu.be/pgIuKu7kCLY\n. While some of these failures have been attributed to intentional interference, such as jamming of communication or GPS signals, others remain of indeterminate cause. In practice, drones are programmed with\nfailure modes\n, which initiate predefined maneuvers intended to mitigate damage to the drones. For example, Figs.\n2\nand\n2\nshow the failsafe mechanisms and corresponding responses in Ardupilot, an open-source autopilot framework\n(Meier\net al.\n2015b\n)\n. However, detecting the precise onset of a failure is often challenging. Even when a drone executes a programmed failsafe response, such as a controlled descent, the base station cannot reliably predict its trajectory or coordinate evasive actions by other drones. This problem is exacerbated by the dense spatial configuration of the drone swarms, where a falling drone can collide with nearby drones, triggering cascading failures.\nFigure 1:\nArdupilotâ€™s failsafe triggers.\nFigure 2:\nArdupilotâ€™s failure responses.\nTo address these challenges, we propose a drone parking algorithm designed to evacuate drones during multi-drone failures in drone dropping incidents. This method relies on a discretization of space and time, referred to as a space-time grid. Within this framework, the algorithm estimates the probability that falling drones will impact specific grid cells and subsequently generates motion plans to reposition unaffected drones while minimizing their likelihood of collision. This optimization problem is formulated as finding a\nnearly-optimal\npath in a space-filling random graph constructed using the rapidly exploring random tree (RRT) algorithm that minimizes the collision probability. To the best of our knowledge, we are the first to consider drone evacuation during drone dropping incidents in the literature.\nRelated Work\nPopular autopilot software for hobbyist drones typically provides programmable failsafe responses, such as automated landing in response to basic triggers like low battery voltage\n(Betaflight Team\n2025\n)\n. More advanced autopilots, including Ardupilot and PX4\n(Ardupilot Team\n2025\n; Meier\net al.\n2015a\n)\n, offer sophisticated per-drone failure detection and mitigation mechanisms, such as GNSS position-loss handling, enabling greater autonomous operation. Specialized software for drone light shows, such as the open-source Skybrush platform, extends these capabilities to the swarm level by incorporating geofence enforcement, pre-flight trajectory visualization, inter-drone distance monitoring, and maximum velocity constraints\n(Team\n2025\n)\n. While these approaches can prevent many mid-flight collisions, they increase operational complexity and provide limited mitigation strategies when multiple drones fail simultaneously.\nSeveral studies have investigated methods for constructing fault-tolerant and robust multi-agent systems capable of recovering from individual drone failures. Kumar and Cohen proposed an Adaptive Agent Architecture that leverages a brokered framework and collaborative teamwork to recover from failures\n(Kumar and Cohen\n2000\n)\n. Karimadini and Lin examined fault-tolerant cooperative tasking strategies to ensure global task completion despite partial multi-agent system failures\n(Karimadini and Lin\n2011\n)\n. Jafari et al. developed an algorithm for optimal leader selection in leader-follower systems to maintain controllability under agent loss\n(Jafari\net al.\n2011\n)\n. Chen et al. introduced a leaderless distributed adaptive protocol that compensates for faults in individual agents\n(Chen\net al.\n2014\n)\n. Zhou et al. proposed a resilience evaluation framework for unmanned autonomous swarms using the Couzin-Leader model, assessing system performance following partial swarm failures\n(Zhou\net al.\n2024\n)\n.\nTrajectory Prediction of Fallen Drones\nThe drone light show is performed in a finite 3D airspace, including the platform on which drones take off or land. We call the airspace the\nstage\n. We assume there is no obstacle, such as buildings or trees, on the stage. We subdivide the stage into a 3D\ngrid\n, which consists of equally-sized grid cells, each of which is a small cubic region. The\nstage space\nğ’µ\nğ—Œğ—ğ–ºğ—€ğ–¾\n\\mathcal{Z}^{\\sf stage}\nis the set of grid cells occupied by the stage. The space-time of the drone show can be subdivided into a set of\ntiles\n, each of which is a pair\nÏ„\n=\n(\nc\n,\nt\n)\n\\tau=(c,t)\n, where\nc\nc\nis a grid cell and\nt\nt\nis a time step. The\nstage zone\nis\nâ„‹\nğ—Œğ—ğ–ºğ—€ğ–¾\n=\n{\n(\nc\n,\nt\n)\n}\nc\nâˆˆ\nğ’µ\nğ—Œğ—ğ–ºğ—€ğ–¾\n,\nt\nğ–¿ğ—‚ğ—‹ğ—Œğ—\nâ‰¤\nt\n<\nt\nğ—…ğ–ºğ—Œğ—\n\\mathcal{H}^{\\sf stage}=\\{(c,t)\\}_{c\\in\\mathcal{Z}^{\\sf stage},t_{\\sf first}\\leq t<t_{\\sf last}}\n, which is the set of all tiles between\nt\nğ–¿ğ—‚ğ—‹ğ—Œğ—\nt_{\\sf first}\nand\nt\nğ—…ğ–ºğ—Œğ—\nt_{\\sf last}\n, which are the start time and the end time of the show, respectively. In this paper, the word â€œzoneâ€ refers to a set of tiles, whereas the word â€œspaceâ€ refers to a set of grid cells. The\nfootprint\nğ’¯\nâ€‹\n(\nÏ…\n,\nt\n)\n\\mathcal{T}(\\upsilon,t)\nof a drone\nÏ…\n\\upsilon\nat time\nt\nt\nis the set of tiles whose cells are\noccupied\nby\nÏ…\n\\upsilon\nat\nt\nt\n. That is,\nğ’¯\nâ€‹\n(\nÏ…\n,\nt\n)\n\\mathcal{T}(\\upsilon,t)\nincludes any tiles that overlap with the body of\nÏ…\n\\upsilon\nat\nt\nt\n. We say two drones\nÏ…\n1\n\\upsilon_{1}\nand\nÏ…\n2\n\\upsilon_{2}\ncollide\nwith each other at time\nt\nt\nif and only if\nğ’¯\nâ€‹\n(\nÏ…\n1\n,\nt\n)\nâˆ©\nğ’¯\nâ€‹\n(\nÏ…\n2\n,\nt\n)\nâ‰ \nâˆ…\n\\mathcal{T}(\\upsilon_{1},t)\\cap\\mathcal{T}(\\upsilon_{2},t)\\neq\\emptyset\n. The\nfootprint\nğ’¯\nâ€‹\n(\nÏ€\n,\nÏ…\n,\nt\n)\n\\mathcal{T}(\\pi,\\upsilon,t)\nof a plan\nÏ€\n\\pi\nexecuted by\nÏ…\n\\upsilon\nat time\nt\nt\nis\nğ’¯\nâ€‹\n(\nÏ€\n,\nÏ…\n,\nt\n)\n=\nâ‹ƒ\nt\nâ‰¤\nt\nâ€²\nâ‰¤\nt\n+\n|\nÏ€\n|\nğ’¯\nâ€‹\n(\nÏ…\n,\nt\nâ€²\n)\n\\mathcal{T}(\\pi,\\upsilon,t)=\\bigcup_{t\\leq t^{\\prime}\\leq t+|\\pi|}\\mathcal{T}(\\upsilon,t^{\\prime})\n, which includes all tiles occupied by\nÏ…\n\\upsilon\nwhen flying on the trajectory\nğ—ğ—‹ğ–ºğ—ƒ\nâ€‹\n[\nÏ€\n]\n{\\sf traj}[\\pi]\nbetween\nt\nt\nand\nt\n+\n|\nÏ€\n|\nt+|\\pi|\n. When talking about the footprint of a plan\nÏ€\n\\pi\n, we assume we know the drone that executes\nÏ€\n\\pi\nand the time of the execution from the context. To simplify our discussion, we will simply denote the footprint of\nÏ€\n\\pi\nby\nğ’¯\nâ€‹\n(\nÏ€\n)\n\\mathcal{T}(\\pi)\n. We say two plans\nÏ€\n1\n\\pi_{1}\nand\nÏ€\n2\n\\pi_{2}\ncollide\nwith each other if and only if\nğ’¯\nâ€‹\n(\nÏ€\n1\n)\nâˆ©\nğ’¯\nâ€‹\n(\nÏ€\n2\n)\nâ‰ \nâˆ…\n\\mathcal{T}(\\pi_{1})\\cap\\mathcal{T}(\\pi_{2})\\neq\\emptyset\n. A formation plan\nÎ \n\\Pi\nis\ncollision-free\nif every pair of plans in\nÎ \n\\Pi\ndoes not collide with each other.\nWe trained a neural network to predict the trajectory of a fallen drone based on its poses in several time steps preceding\nt\n0\nt_{0}\n, the time when the incident occurs. Social LSTM\n(Alahi\net al.\n2016\n)\nis among the earliest models designed to forecast future trajectories of individuals in crowded environments using their historical positions. Vemula et al.\n(Vemula\net al.\n2018\n)\nenhanced Social LSTM with an attention mechanism to capture the relative influence of neighboring agents. Giuliari et al.\n(Giuliari\net al.\n2020\n)\nreplaced LSTMs with transformer networks for trajectory forecasting. In our experiments, we employed a Social LSTM model augmented with the attention mechanism as described in\n(Vemula\net al.\n2018\n)\n.\nThe training data were generated using a simulator developed in-house, with real drone data employed to calibrate the dronesâ€™ behavior. We implemented three failure modesâ€”(1) dropping, (2) landing, and (3) returning to the launch siteâ€”as illustrated in Fig.\n2\n. To generate the dataset, a drone was first instantiated and made to follow a trajectory representative of a typical drone light show. Next, one of the failure modes was randomly triggered during flight, and the resulting trajectory of the fallen drone was recorded. This process was repeated many times to collect a dataset of trajectories, each associated with a sequence of drone poses observed in the few time steps preceding the fall. We assume that the specific failure mode is unknown and therefore do not label the trajectories with failure mode information. Finally, a Social LSTM model was trained to predict the trajectory of a fallen drone based on the sequence of poses preceding the failure, regardless of which of the three failure modes occurred.\nOccupancy Probability\nThe\noccupancy probability\nP\nâ€‹\nr\nâ€‹\n(\nÏ„\n)\n{Pr}(\\tau)\nof a tile\nÏ„\n\\tau\nis the probability that\nÏ„\n\\tau\nis occupied by any drone. The concept of occupancy probability is similar to the occupancy grid for mapping\n(Thrun and BÃ¼cken\n1996\n; Thrun\net al.\n2005\n)\n. When there is no drone dropping incident, the occupancy probability can be derived from\nF\nğ–¿ğ—‚ğ—‹ğ—Œğ—\nF_{\\sf first}\nand the original formation plan\nÎ \nğ–ºğ—Œğ—Œğ—‚ğ—€ğ—‡ğ–¾ğ–½\n\\Pi^{\\sf assigned}\nas follows:\nP\nâ€‹\nr\nâ€‹\n(\nÏ„\n)\n=\n1\n{Pr}(\\tau)=1\nfor all\nÏ„\nâˆˆ\nâ‹ƒ\nÏ€\nğ–ºğ—Œğ—Œğ—‚ğ—€ğ—‡ğ–¾ğ–½\nâˆˆ\nÎ \nğ–ºğ—Œğ—Œğ—‚ğ—€ğ—‡ğ–¾ğ–½\nğ’¯\nâ€‹\n(\nÏ€\nğ–ºğ—Œğ—Œğ—‚ğ—€ğ—‡ğ–¾ğ–½\n)\n\\tau\\in\\bigcup_{\\pi^{\\sf assigned}\\in\\Pi^{\\sf assigned}}\\mathcal{T}(\\pi^{\\sf assigned})\nand\nP\nâ€‹\nr\nâ€‹\n(\nÏ„\n)\n=\n0\n{Pr}(\\tau)=0\nfor all other tiles in\nâ„‹\nğ—Œğ—ğ–ºğ—€ğ–¾\n\\mathcal{H}^{\\sf stage}\n. When a drone dropping incident occurs,\nP\nâ€‹\nr\nâ€‹\n(\nÏ„\n)\n{Pr}(\\tau)\nfor any tile with time after\nt\n0\nt_{0}\nmay change since (1) the fallen drones in\nğ’±\nğ–¿ğ–ºğ—…ğ—…ğ–¾ğ—‡\n\\mathcal{V}_{\\sf fallen}\nwill no longer follow their assigned plans, and (2) some active drones in\nğ’±\nğ–ºğ–¼ğ—ğ—‚ğ—ğ–¾\n\\mathcal{V}_{\\sf active}\ncan no longer follow their assigned plans in\nÎ \nğ–ºğ—Œğ—Œğ—‚ğ—€ğ—‡ğ–¾ğ–½\n\\Pi^{\\sf assigned}\n.\nGiven a fallen drone\nÏ…\nâˆˆ\nğ’±\nğ–¿ğ–ºğ—…ğ—…ğ–¾ğ—‡\n\\upsilon\\in\\mathcal{V}_{\\sf fallen}\n, we utilize the machine learning model to estimate the occupancy probability of the tiles as follows. Initially, we set the occupancy probability of any tile after\nt\n0\nt_{0}\nto zero, except the tiles in the footprints of the assigned trajectory of\nÏ…\n\\upsilon\non or before\nt\n0\nt_{0}\n, which have the occupancy probability\n1\n1\n. We perform\nN\nN\nrandom rollouts of the model to generate\nN\nN\ntrajectories starting at\nt\n0\nt_{0}\n, where\nN\nN\nis a large positive integer, given the poses before\nt\n0\nt_{0}\n. For any tile\nÏ„\n\\tau\nwhose time is greater than\nt\n0\nt_{0}\n, we count how many times\nÏ„\n\\tau\nis occupied by any trajectories. Then the occupancy probability of\nÏ„\n\\tau\nis\nP\nâ€‹\nr\nÏ…\nâ€‹\n(\nÏ„\n)\n=\nC\n/\nN\n{Pr}_{\\upsilon}(\\tau)=C/N\n, where\nC\nC\nis the count.\nThe\nfall zone\nâ„‹\nâ€‹\n(\nÏ…\n)\n\\mathcal{H}(\\upsilon)\nof a fallen drone\nÏ…\n\\upsilon\nis the set of tiles whose occupancy probability in\nP\nâ€‹\nr\nÏ…\n{Pr}_{\\upsilon}\nis non-zero. Fig.\n3\nshows the occupancy probability in the fall zone of a drone. Let\nt\nğ–¾ğ—‡ğ–½\nÏ…\nt_{\\sf end}^{\\upsilon}\nbe the largest time among all tiles with non-zero occupancy probability in\nP\nâ€‹\nr\nÏ…\n{Pr}_{\\upsilon}\n. Then the\nend time\nof the incident is\nt\nğ–¾ğ—‡ğ–½\n=\nmax\nÏ…\nâˆˆ\nğ’±\nğ–¿ğ–ºğ—…ğ—…ğ–¾ğ—‡\nâ¡\nt\nğ–¾ğ—‡ğ–½\nÏ…\nt_{\\sf end}=\\max_{\\upsilon\\in\\mathcal{V}_{\\sf fallen}}t_{\\sf end}^{\\upsilon}\n, which is the largest time at which any fallen drone occupies any tile. The\nhit zone\nfor\nğ’±\nğ–¿ğ–ºğ—…ğ—…ğ–¾ğ—‡\n\\mathcal{V}_{\\sf fallen}\nis\nâ„‹\nğ—ğ—‚ğ—\n=\nâ‹ƒ\nÏ…\nâˆˆ\nğ’±\nğ–¿ğ–ºğ—…ğ—…ğ–¾ğ—‡\nâ„‹\nâ€‹\n(\nÏ…\n)\n\\mathcal{H}^{\\sf hit}=\\bigcup_{\\upsilon\\in\\mathcal{V}_{\\sf fallen}}\\mathcal{H}(\\upsilon)\n, which is the set of tiles in the fall zones of the fallen drones. When our system is notified that a drone dropping incident occurs at time\nt\n0\nt_{0}\n, it will (1)\nevacuate\nall drones in the hit zone at time\nt\n0\nt_{0}\nby moving them out of the hit zone and parking them at some designated locations called\nparking space\n, and (2) prevent the remaining drones from entering the hit zone by\ndetouring\nthem to the parking space. The\nsafe zone\nis\nâ„‹\nğ—Œğ–ºğ–¿ğ–¾\n=\nâ„‹\nğ—Œğ—ğ–ºğ—€ğ–¾\nâˆ–\nâ„‹\nğ—ğ—‚ğ—\n\\mathcal{H}^{\\sf safe}=\\mathcal{H}^{\\sf stage}\\setminus\\mathcal{H}^{\\sf hit}\n, which is the set of tiles not in the hit zone. The\nparking space\nğ’µ\nğ—‰ğ–ºğ—‹ğ—„\n\\mathcal{Z}^{\\sf park}\nis defined as the set of grid cells such that the tiles with these grid cells are always in the safe zone\nâ„‹\nğ—Œğ–ºğ–¿ğ–¾\n\\mathcal{H}^{\\sf safe}\n.\nFigure 3:\nThe occupancy probability in the fall zone of a drone.\nThe Parking Problem\nWhen a drone dropping incident occurs, the drones in the hit zone have to migrate to the parking space\nğ’µ\nğ—‰ğ–ºğ—‹ğ—„\n\\mathcal{Z}^{\\sf park}\nand hover inside\nğ’µ\nğ—‰ğ–ºğ—‹ğ—„\n\\mathcal{Z}^{\\sf park}\nuntil the end time\nt\nğ–¾ğ—‡ğ–½\nt_{\\sf end}\nof the incident. We define the parking problem as finding a\nvalid\nformation plan for\nğ’±\nğ–¾ğ—ğ–ºğ–¼ğ—ğ–ºğ—ğ–¾\n\\mathcal{V}_{\\sf evacuate}\n, which is the set of drones that need evacuation:\nDefinition 1\nA collision-free formation plan\nÎ \n\\Pi\nfor\nğ’±\nğ–¾ğ—ğ–ºğ–¼ğ—ğ–ºğ—ğ–¾\n\\mathcal{V}_{\\sf evacuate}\nat time\nt\n0\nt_{0}\nis\nvalid\nif and only if for all\nÏ…\nâˆˆ\nğ’±\n\\upsilon\\in\\mathcal{V}\n,\nall cells of the footprint of\nÏ…\n\\upsilon\nat time\nt\nğ–¾ğ—‡ğ–½\nt_{\\sf end}\nare in\nğ’µ\nğ—‰ğ–ºğ—‹ğ—„\n\\mathcal{Z}^{\\sf park}\nwhen executing\nÎ \n\\Pi\nat\nt\n0\nt_{0}\n(i.e.,\n{\nc\n}\n(\nc\n,\nt\n)\nâˆˆ\nğ’¯\nâ€‹\n(\nÏ…\n,\nt\nğ–¾ğ—‡ğ–½\n)\nâŠ†\nğ’µ\nğ—‰ğ–ºğ—‹ğ—„\n\\{c\\}_{(c,t)\\in\\mathcal{T}(\\upsilon,t_{\\sf end})}\\subseteq\\mathcal{Z}^{\\sf park}\n).\nCollisions may occur when the drones in\nğ’±\nğ–¾ğ—ğ–ºğ–¼ğ—ğ–ºğ—ğ–¾\n\\mathcal{V}_{\\sf evacuate}\nmigrate to the parking space. Definition\n1\n, however, does not concern itself with the collisions with the fallen drones. Therefore, we need to define the parking problem as finding a valid formation plan while minimizing the probability of collisions. First, we combine the occupancy probablity of\nP\nâ€‹\nr\nÏ…\n{Pr}_{\\upsilon}\nof all fallen drones into one probability mass function:\nP\nâ€‹\nr\nâ€‹\n(\nÏ„\n)\n=\n1\nâˆ’\nâˆ\nÏ…\nâˆˆ\nğ’±\nğ–¿ğ–ºğ—…ğ—…ğ–¾ğ—‡\n(\n1\nâˆ’\nP\nâ€‹\nr\nÏ…\nâ€‹\n(\nÏ„\n)\n)\n{Pr}(\\tau)=1-\\prod_{\\upsilon\\in\\mathcal{V}_{\\sf fallen}}(1-{Pr}_{\\upsilon}(\\tau))\n. Hence,\nP\nâ€‹\nr\nâ€‹\n(\nÏ„\n)\n{Pr}(\\tau)\nis the combined occupancy probability of\nÏ„\n\\tau\nsuch that any hidden drones could occupy\nÏ„\n\\tau\n. Second, we define the\ncollision-free\nprobability of\nÏ„\n\\tau\nby\nP\nâ€‹\nr\nğ—Œğ–ºğ–¿ğ–¾\nâ€‹\n(\nÏ„\n)\n=\n1\nâˆ’\nP\nâ€‹\nr\nâ€‹\n(\nÏ„\n)\n{Pr}_{\\sf safe}(\\tau)=1-{Pr}(\\tau)\n. More generally, we define the collision-free probability of a set of tiles:\nP\nâ€‹\nr\nğ—Œğ–ºğ–¿ğ–¾\nâ€‹\n(\nğ’¯\n)\n=\nâˆ\nÏ„\nâˆˆ\nğ’¯\nP\nâ€‹\nr\nğ—Œğ–ºğ–¿ğ–¾\nâ€‹\n(\nÏ„\n)\n.\n{Pr}_{\\sf safe}(\\mathcal{T})=\\prod_{\\tau\\in\\mathcal{T}}{Pr}_{\\sf safe}(\\tau).\nGiven the footprint\nğ’¯\nâ€‹\n(\nÏ€\n)\n\\mathcal{T}(\\pi)\nof a plan\nÏ€\n\\pi\n,\nP\nâ€‹\nr\nğ—Œğ–ºğ–¿ğ–¾\nâ€‹\n(\nğ’¯\nâ€‹\n(\nÏ€\n)\n)\n{Pr}_{\\sf safe}(\\mathcal{T}(\\pi))\nis the probability that the drone will\nnot\ncollide with any fallen drone when executing\nÏ€\n\\pi\n. An optimization version of the parking problem is defined as finding a valid formation plan\nÎ \n\\Pi\nsuch that the weighted sum of the collision-free probability of the plans in\nÎ \n\\Pi\nis maximized.\nDefinition 2\nA valid formation plan\nÎ \n\\Pi\nis\noptimal\nw.r.t. the collision-free probability\nP\nâ€‹\nr\nğ—Œğ–ºğ–¿ğ–¾\n{Pr}_{\\sf safe}\nif and only if the score\nğ—Œğ–¼ğ—ˆğ—‹ğ–¾\nâ€‹\n(\nÎ \n)\n=\nâˆ‘\nÏ…\ni\nâˆˆ\nğ’±\nğ–¾ğ—ğ–ºğ–¼ğ—ğ–ºğ—ğ–¾\nÎ±\ni\nâ€‹\nP\nâ€‹\nr\nğ—Œğ–ºğ–¿ğ–¾\nâ€‹\n(\nğ’¯\nâ€‹\n(\nÏ€\ni\n)\n)\n{\\sf score}(\\Pi)=\\sum_{\\upsilon_{i}\\in\\mathcal{V}_{\\sf evacuate}}\\alpha_{i}{Pr}_{\\sf safe}(\\mathcal{T}(\\pi_{i}))\nis maximized, where (1)\nÏ€\ni\nâˆˆ\nÎ \n\\pi_{i}\\in\\Pi\nis the plan for\nÏ…\ni\n\\upsilon_{i}\n, and (2)\nÎ±\ni\nâˆˆ\nâ„\n+\n\\alpha_{i}\\in\\mathbb{R}^{+}\nis the weight of the collision-free probability of\nÏ…\ni\n\\upsilon_{i}\n.\nThe Parking Algorithm\nThe parking algorithm generates a near-optimal, valid formation plan\nÎ \n\\Pi\nthat maximizes the score function\nğ—Œğ–¼ğ—ˆğ—‹ğ–¾\nâ€‹\n(\nÎ \n)\n{\\sf score}(\\Pi)\n. The key idea is to generate the trajectories of individual drones independently and subsequently integrate these plans into a collision-free formation using an existing collision-avoidance strategy. For each drone\nÏ…\n\\upsilon\nin\nğ’±\nğ–¾ğ—ğ–ºğ–¼ğ—ğ–ºğ—ğ–¾\n\\mathcal{V}_{\\sf evacuate}\n, the algorithm constructs a random graph connecting the drone to the designated parking area and computes the shortest path to a target location within that space. The random graph is a directed acyclic graph, where vertices represent spatial positions and directed edges correspond to feasible actions that move\nÏ…\n\\upsilon\nfrom one vertex to another within a single time step. The weight of a directed edge\n(\np\n1\n,\np\n2\n)\n(p_{1},p_{2})\nassociated with an action\na\na\nis defined as\nW\nâ€‹\n(\np\n1\n,\np\n2\n)\n=\nâˆ’\nlog\nâ¡\n(\nP\nâ€‹\nr\nğ—Œğ–ºğ–¿ğ–¾\nâ€‹\n(\nğ’¯\np\n1\n,\np\n2\n)\n)\n,\nW(p_{1},p_{2})=-\\log({Pr}_{\\sf safe}(\\mathcal{T}_{p_{1},p_{2}})),\nwhere\nğ’¯\np\n1\n,\np\n2\n\\mathcal{T}_{p_{1},p_{2}}\ndenotes the set of tiles occupied by\nÏ…\n\\upsilon\nwhen executing a single-action plan\nâŸ¨\na\nâŸ©\n\\langle a\\rangle\nfrom\np\n1\np_{1}\nto\np\n2\np_{2}\n. The random graph\n(\nV\n,\nE\n)\n(V,E)\nis generated using the rapidly exploring random tree (RRT) algorithm\n(LaValle\n1998\n)\n, originating from the droneâ€™s initial position\np\n0\np_{0}\nat time\nt\n0\nt_{0}\n. The resulting graph is space-filling and progressively spans the entire stage, ensuring that some vertices reach the designated parking area\n(LaValle\n1998\n; Karaman and Frazzoli\n2011\n)\n. Once constructed, a single-source shortest path algorithm suitable for graphs with negative edge weights (e.g., Bellman-Ford) is applied to compute a shortest-path tree from\np\n0\np_{0}\n. Given that the random graph is a directed acyclic graph, an alternative approach using topological sorting with single-pass relaxation can also efficiently compute the shortest paths. Among all vertices corresponding to positions where\nÏ…\n\\upsilon\ncan be accommodated within the parking space, the algorithm selects the vertex\np\nâˆ—\np^{*}\nassociated with the shortest path\nE\nâˆ—\nE^{*}\nfrom\np\n0\np_{0}\n. The sequence of actions along\nE\nâˆ—\nE^{*}\n, from\np\n0\np_{0}\nto\np\nâˆ—\np^{*}\n, is then concatenated to form the final plan\nÏ€\nâˆ—\n\\pi^{*}\n. The total cost of this shortest path is\nC\nâˆ—\n=\nâˆ‘\n(\np\n1\n,\np\n2\n)\nâˆˆ\nE\nâˆ—\nW\nâ€‹\n(\np\n1\n,\np\n2\n)\n.\nC^{*}=\\sum_{(p_{1},p_{2})\\in E^{*}}W(p_{1},p_{2}).\nHence,\nC\nâˆ—\n=\nâˆ’\nâˆ‘\n(\np\n1\n,\np\n2\n)\nâˆˆ\nE\nâˆ—\nlog\nâ¡\n(\nP\nâ€‹\nr\nğ—Œğ–ºğ–¿ğ–¾\nâ€‹\n(\nğ’¯\np\n1\n,\np\n2\n)\n)\n=\nâˆ’\nlog\nâ¡\n(\nâˆ\n(\np\n1\n,\np\n2\n)\nâˆˆ\nE\nâˆ—\nP\nâ€‹\nr\nğ—Œğ–ºğ–¿ğ–¾\nâ€‹\n(\nğ’¯\np\n1\n,\np\n2\n)\n)\n=\nâˆ’\nlog\nâ¡\n(\nP\nâ€‹\nr\nğ—Œğ–ºğ–¿ğ–¾\nâ€‹\n(\nğ’¯\nE\nâˆ—\n)\n)\nC^{*}=-\\sum_{(p_{1},p_{2})\\in E^{*}}\\log({Pr}_{\\sf safe}(\\mathcal{T}_{p_{1},p_{2}}))=-\\log(\\prod_{(p_{1},p_{2})\\in E^{*}}{Pr}_{\\sf safe}(\\mathcal{T}_{p_{1},p_{2}}))=-\\log({Pr}_{\\sf safe}(\\mathcal{T}_{E^{*}}))\n, where\nğ’¯\nE\nâˆ—\n\\mathcal{T}_{E^{*}}\nis the set of all tiles\nÏ…\n\\upsilon\noccupies when executing\nÏ€\nâˆ—\n\\pi^{*}\n. Consequently, the collision-free probability of\nÏ…\n\\upsilon\ntraversing the path\nE\nâˆ—\nE^{*}\nis given by\nP\nâ€‹\nr\nğ—Œğ–ºğ–¿ğ–¾\nâ€‹\n(\nğ’¯\nE\nâˆ—\n)\n=\ne\nâˆ’\nC\nâˆ—\n{Pr}_{\\sf safe}(\\mathcal{T}_{E^{*}})=e^{-C^{*}}\n. Because\nC\nâˆ—\nC^{*}\nrepresents the minimum cost among all paths to the parking space within the random graph,\nP\nâ€‹\nr\nğ—Œğ–ºğ–¿ğ–¾\nâ€‹\n(\nğ’¯\nE\nâˆ—\n)\n{Pr}_{\\sf safe}(\\mathcal{T}_{E^{*}})\ncorresponds to the\nmaximum\ncollision-free probability for\nÏ…\n\\upsilon\nreaching the designated parking location.\nRecovery Mode\nAfter time\nt\nğ–¾ğ—‡ğ–½\nt_{\\sf end}\n, all fallen drones have either landed or exited the performance area, and the system transitions into recovery mode to allow the light show to proceed. Because all parked drones are hidden, the recovery mode selects a subset of hidden drones\nğ’±\nğ—ğ—‚ğ–½ğ–½ğ–¾ğ—‡\nâ€²\nâŠ†\nğ’±\nğ—ğ—‚ğ–½ğ–½ğ–¾ğ—‡\n\\mathcal{V}_{\\sf hidden}^{\\prime}\\subseteq\\mathcal{V}_{\\sf hidden}\npositioned near locations where active drones are missing. The system then computes a recovery formation plan\nÎ \nğ—‹ğ–¾ğ–¼ğ—ˆğ—ğ–¾ğ—‹ğ—’\n\\Pi_{\\sf recovery}\nto reposition the drones in\nğ’±\nğ—ğ—‚ğ–½ğ–½ğ–¾ğ—‡\nâ€²\n\\mathcal{V}_{\\sf hidden}^{\\prime}\nto these vacant locations. Upon executing\nÎ \nğ—‹ğ–¾ğ–¼ğ—ˆğ—ğ–¾ğ—‹ğ—’\n\\Pi_{\\sf recovery}\n, the drones in\nğ’±\nğ—ğ—‚ğ–½ğ–½ğ–¾ğ—‡\nâ€²\n\\mathcal{V}_{\\sf hidden}^{\\prime}\nbecome active by illuminating their LEDs and assume the assigned trajectories of the missing drones, thereby restoring the drone light show.\nSummary and Future Work\nRobustness is an important topic in embodied AI systems. Our drone parking system achieves robustness in AI-based multi-drone systems by mitigating the risks associated with multi-drone failures, which have emerged as a significant threat to the reliability of drone light shows. Our system leverages a deep learning model to estimate the occupancy probability of grid cells within a space-time grid, identifies high-risk zones requiring evacuation, and computes motion plans that maximize collision-free probability. Our preliminary experimental results showed that this approach outperforms baseline strategies, and increases the chance of recovery from multi-drone failures. We can improve our system by refining the trajectory prediction in the future.\nACKNOWLEDGMENTS\nThis work was supported by National Research Foundation of Korea RS-2022-NR069751 (or 2022R1A2C101216813).\nReferences\nA. Alahi, K. Goel, V. Ramanathan, A. Robicquet, L. Fei-Fei, and S. Savarese (2016)\nSocial LSTM: human trajectory prediction in crowded spaces\n.\nIn\nProceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\n,\nCited by:\nTrajectory Prediction of Fallen Drones\n.\nArdupilot Team (2025)\nFailsafes\n.\nNote:\nArduPilot Copter documentationDate of Access: September 15, 2025\nExternal Links:\nLink\nCited by:\nRelated Work\n.\nBetaflight Team (2025)\nFailsafe\n.\nNote:\nBetaflight WikiDate of Access: September 15, 2025\nExternal Links:\nLink\nCited by:\nRelated Work\n.\nS. Chen, D. W. Ho, L. Li, and M. Liu (2014)\nFault-tolerant consensus of multi-agent system with distributed adaptive protocol\n.\nIEEE Transactions on Cybernetics\n45\n(\n10\n),\npp.Â 2142â€“2155\n.\nCited by:\nRelated Work\n.\nF. Giuliari, I. Hasan, M. Cristani, and F. Galasso (2020)\nTransformer networks for trajectory forecasting\n.\nIn\nInternational Conference on Pattern Recognition (ICPR)\n,\npp.Â 10335â€“10342\n.\nCited by:\nTrajectory Prediction of Fallen Drones\n.\nS. Jafari, A. Ajorlou, and A. G. Aghdam (2011)\nLeader selection in multi-agent systems subject to partial failure\n.\nIn\nAmerican Control Conference\n,\npp.Â 5330â€“5335\n.\nCited by:\nRelated Work\n.\nS. Karaman and E. Frazzoli (2011)\nSampling-based algorithms for optimal motion planning\n.\nThe International Journal of Robotics Research\n30\n(\n7\n),\npp.Â 846â€“894\n.\nCited by:\nThe Parking Algorithm\n.\nM. Karimadini and H. Lin (2011)\nFault-tolerant cooperative tasking for multi-agent systems\n.\nInternational Journal of Control\n84\n(\n12\n),\npp.Â 2092â€“2107\n.\nCited by:\nRelated Work\n.\nS. Kumar and P. R. Cohen (2000)\nTowards a fault-tolerant multi-agent system architecture\n.\nIn\nInternational Conference on Autonomous Agents\n,\npp.Â 459â€“466\n.\nCited by:\nRelated Work\n.\nS. M. LaValle (1998)\nRapidly-exploring random trees: a new tool for path planning\n.\nTechnical report\nTechnical Report\nTR 98-11\n,\nComputer Science Dept, Iowa State University\n.\nCited by:\nThe Parking Algorithm\n.\nL. Meier, D. Honegger, and M. Pollefeys (2015a)\nPX4: a node-based multithreaded open source robotics framework for deeply embedded platforms\n.\nIn\nIEEE International Conference on Robotics and Automation (ICRA)\n,\npp.Â 6235â€“6240\n.\nCited by:\nRelated Work\n.\nL. Meier, P. D. T. STools,\net al.\n(2015b)\nArdupilot: a flexible open source software for autonomous vehicles\n.\nIn\n32nd Chaos Communication Congress (32C3)\n,\nCited by:\nIntroduction\n.\nS. Team (2025)\nSkybrush studio\n.\nNote:\nSkybrush Studio Description WebpageDate of Access: September 15, 2025\nExternal Links:\nLink\nCited by:\nRelated Work\n.\nS. Thrun and A. BÃ¼cken (1996)\nIntegrating grid-based and topological maps for mobile robot navigation\n.\nIn\nProceedings of the AAAI Conference on Artificial Intelligence (AAAI)\n,\npp.Â 944â€“950\n.\nCited by:\nOccupancy Probability\n.\nS. Thrun, W. Burgard, and D. Fox (2005)\nProbabilistic robotics\n.\nThe MIT Press\n.\nCited by:\nOccupancy Probability\n.\nA. Vemula, K. Muelling, and J. Oh (2018)\nSocial attention: modeling attention in human crowds\n.\nIn\nIEEE International Conference on Robotics and Automation (ICRA)\n,\npp.Â 4601â€“4607\n.\nCited by:\nTrajectory Prediction of Fallen Drones\n.\nX. Zhou, Y. Huang, G. Bai, B. Xu, and J. Tao (2024)\nThe resilience evaluation of unmanned autonomous swarm with informed agents under partial failure\n.\nReliability Engineering & System Safety\n244\n,\npp.Â 109920\n.\nCited by:\nRelated Work\n.",
    "preview_text": "Drone light shows have emerged as a popular form of entertainment in recent years. However, several high-profile incidents involving large-scale drone failures -- where multiple drones simultaneously fall from the sky -- have raised safety and reliability concerns. To ensure robustness, we propose a drone parking algorithm designed specifically for multiple drone failures in drone light shows, aimed at mitigating the risk of cascading collisions by drone evacuation and enabling rapid recovery from failures by leveraging strategically placed hidden drones. Our algorithm integrates a Social LSTM model with attention mechanisms to predict the trajectories of failing drones and compute near-optimal evacuation paths that minimize the likelihood of surviving drones being hit by fallen drones. In the recovery node, our system deploys hidden drones (operating with their LED lights turned off) to replace failed drones so that the drone light show can continue. Our experiments showed that our approach can greatly increase the robustness of a multi-drone system by leveraging deep learning to predict the trajectories of fallen drones.\n\nRobust Evacuation for Multi-Drone Failure in Drone Light Shows\nMinhyuk Park\n1\n,\nAloysius K. Mok\n2\n,\nTsz-Chiu Au\n1\nAbstract\nDrone light shows have emerged as a popular form of entertainment in recent years. However, several high-profile incidents involving large-scale drone failuresâ€”where multiple drones simultaneously fall from the skyâ€”have raised safety and reliability concerns. To ensure robustness, we propose a drone parking algorithm designed specifically for multiple drone failures in drone light shows, aimed at mitigating the risk of cascading collisions by drone evacuation and enabling rapid recovery from failures by leveraging strategically placed hidden drones. Our algorithm integrates a Social LSTM model with attention mechanisms to predict the trajectories of failing drones and compute near-optimal evacuation paths that minimize the li",
    "is_relevant": false,
    "relevance_score": 2.0,
    "extracted_keywords": [
        "drone",
        "evacuation",
        "Social LSTM",
        "attention mechanisms",
        "trajectory prediction",
        "collision avoidance",
        "recovery"
    ],
    "one_line_summary": "è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§é’ˆå¯¹æ— äººæœºç¯å…‰ç§€ä¸­å¤šæœºå¤±æ•ˆçš„é²æ£’ç–æ•£ç®—æ³•ï¼Œç»“åˆSocial LSTMå’Œæ³¨æ„åŠ›æœºåˆ¶é¢„æµ‹è½¨è¿¹ï¼Œä»¥æœ€å°åŒ–ç¢°æ’é£é™©å¹¶åˆ©ç”¨éšè—æ— äººæœºå®ç°å¿«é€Ÿæ¢å¤ã€‚",
    "detailed_summary": "",
    "qa_pairs": [],
    "is_hidden": false,
    "is_starred": false,
    "flag": true,
    "published_date": "2026-01-11T00:36:47Z",
    "created_at": "2026-01-21T12:09:04.032048",
    "updated_at": "2026-01-21T12:09:04.032055",
    "recommend": 0
}