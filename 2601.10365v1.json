{
    "id": "2601.10365v1",
    "title": "FastStair: Learning to Run Up Stairs with Humanoid Robots",
    "authors": [
        "Yan Liu",
        "Tao Yu",
        "Haolin Song",
        "Hongbo Zhu",
        "Nianzong Hu",
        "Yuzhi Hao",
        "Xiuyong Yao",
        "Xizhe Zang",
        "Hua Chen",
        "Jie Zhao"
    ],
    "abstract": "Âú®Ê•ºÊ¢Ø‰∏äÂ•îË∑ëÂØπ‰∫∫Á±ªËÄåË®ÄËΩªËÄåÊòì‰∏æÔºå‰ΩÜÂØπ‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Êù•ËØ¥Âç¥ÊûÅÂÖ∑ÊåëÊàòÔºåÂõ†‰∏∫ÂÆÉÂêåÊó∂Ë¶ÅÊ±ÇÈ´òÂ∫¶ÁöÑÁÅµÊ¥ªÊÄßÂíå‰∏•Ê†ºÁöÑÁ®≥ÂÆöÊÄß„ÄÇÊó†Ê®°ÂûãÂº∫ÂåñÂ≠¶‰π†ËÉΩÂ§üÁîüÊàêÂä®ÊÄÅËøêÂä®Ôºå‰ΩÜÈöêÂºèÁöÑÁ®≥ÂÆöÊÄßÂ•ñÂä±ÂíåÂØπ‰ªªÂä°ÁâπÂÆöÂ•ñÂä±ËÆæËÆ°ÁöÑ‰∏•Èáç‰æùËµñÂæÄÂæÄÂØºËá¥‰∏çÂÆâÂÖ®Ë°å‰∏∫ÔºåÂ∞§ÂÖ∂ÊòØÂú®Ê•ºÊ¢Ø‰∏äÔºõÁõ∏ÂèçÔºåÂü∫‰∫éÊ®°ÂûãÁöÑËêΩËÑöÁÇπËßÑÂàíÂô®ÁºñÁ†Å‰∫ÜÊé•Ëß¶ÂèØË°åÊÄßÂíåÁ®≥ÂÆöÊÄßÁªìÊûÑÔºå‰ΩÜÂº∫Âà∂ÊâßË°åÂÖ∂Á°¨Á∫¶ÊùüÂ∏∏ÂØºËá¥‰øùÂÆàËøêÂä®ÔºåÈôêÂà∂‰∫ÜÈÄüÂ∫¶„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫ÜFastStairÔºå‰∏Ä‰∏™ËßÑÂàíÂô®ÂºïÂØºÁöÑÂ§öÈò∂ÊÆµÂ≠¶‰π†Ê°ÜÊû∂ÔºåÂÆÉËûçÂêà‰∫ÜËøô‰∏§Áßç‰∫íË°•ÁöÑ‰ºòÂäøÔºåÂÆûÁé∞‰∫ÜÂø´ÈÄüÁ®≥ÂÆöÁöÑ‰∏äÊ•ºÊ¢ØËøêÂä®„ÄÇFastStairÂ∞Ü‰∏Ä‰∏™Âπ∂Ë°åÁöÑÂü∫‰∫éÊ®°ÂûãÁöÑËêΩËÑöÁÇπËßÑÂàíÂô®ÈõÜÊàêÂà∞Âº∫ÂåñÂ≠¶‰π†ËÆ≠ÁªÉÂæ™ÁéØ‰∏≠Ôºå‰ª•ÂºïÂØºÊé¢Á¥¢ÊúùÂêëÂä®ÊÄÅÂèØË°åÁöÑÊé•Ëß¶ÔºåÂπ∂È¢ÑËÆ≠ÁªÉ‰∏Ä‰∏™Ê≥®ÈáçÂÆâÂÖ®ÁöÑÂü∫Á°ÄÁ≠ñÁï•„ÄÇ‰∏∫‰∫ÜÂáèËΩªËßÑÂàíÂô®ÂØºËá¥ÁöÑ‰øùÂÆàÊÄß‰ª•Âèä‰ΩéÈÄüÂíåÈ´òÈÄüÂä®‰ΩúÂàÜÂ∏É‰πãÈó¥ÁöÑÂ∑ÆÂºÇÔºåÂü∫Á°ÄÁ≠ñÁï•Ë¢´ÂæÆË∞É‰∏∫ÈÄüÂ∫¶‰∏ìÂÆ∂ÔºåÁÑ∂ÂêéÈÄöËøá‰ΩéÁß©Ëá™ÈÄÇÂ∫îÊäÄÊúØËøõË°åÊï¥ÂêàÔºå‰ª•ÂÆûÁé∞Ë∑®Êï¥‰∏™Êåá‰ª§ÈÄüÂ∫¶ËåÉÂõ¥ÂÜÖÁöÑÂπ≥Á®≥Êìç‰Ωú„ÄÇÊàë‰ª¨Â∞ÜÂæóÂà∞ÁöÑÊéßÂà∂Âô®ÈÉ®ÁΩ≤Âú®Oli‰∫∫ÂΩ¢Êú∫Âô®‰∫∫‰∏äÔºåÂÆûÁé∞‰∫ÜÂú®Êåá‰ª§ÈÄüÂ∫¶È´òËææ1.65Á±≥/ÁßíÊó∂ÁöÑÁ®≥ÂÆö‰∏äÊ•ºÊ¢ØÔºåÂπ∂Âú®12ÁßíÂÜÖÁ©øË∂ä‰∫Ü‰∏Ä‰∏™33Á∫ßÁöÑËû∫ÊóãÊ•ºÊ¢ØÔºåÂ±ïÁ§∫‰∫ÜÂú®ÈïøÊ•ºÊ¢Ø‰∏äÁ®≥ÂÅ•ÁöÑÈ´òÈÄüÊÄßËÉΩ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®\"Â∞èËõÆËÖ∞\"Êú∫Âô®‰∫∫ÁôªÂ°îÊØîËµõ‰∏≠‰Ωú‰∏∫ÂÜ†ÂÜõËß£ÂÜ≥ÊñπÊ°àÂæóÂà∞‰∫ÜÈ™åËØÅ„ÄÇ",
    "url": "https://arxiv.org/abs/2601.10365v1",
    "html_url": "https://arxiv.org/html/2601.10365v1",
    "html_content": "FastStair: Learning to Run Up Stairs with Humanoid Robots\nYan Liu\n1,2\n,\nTao Yu\n2\n,\nHaolin Song\n4\n,\nHongbo Zhu\n2,5\n,\nNianzong Hu\n2\n,\nYuzhi Hao\n2,6\n,\nXiuyong Yao\n2\n,\nXizhe Zang\n1\n‚Äã\n‚Ä†\n{}^{1\\text{\\textdagger}}\n,\nHua Chen\n2\n,\n3\n‚Äã\n‚Ä†\n{}^{2,3\\text{\\textdagger}}\n,\nJie Zhao\n1\n* Work done at LimX Dynamics. Project lead: Tao Yu\n‚Ä†\nCorresponding author\n1\nSchool of Mechanics Engineering, Harbin Institute of Technology (HIT), Harbin Heilongjiang 150001, China. Email:\nliuyan98@stu.hit.edu.cn, zangxizhe@hit.edu.cn, jzhao@hit.edu.cn\n2\nLimX Dynamics, Shenzhen, China.\n3\nZhejiang University-University of Illinois Urbana-Champaign Institute (ZJUI), Haining, China. Email:\nhuachen@intl.zju.edu.cn\n4\nDepartment of Electronic Engineering and Information Science\n(EEIS), University of Science and Technology of China, Hefei 230027,\nChina. Email:\nhlsong@mail.ustc.edu.cn\n5\nHong Kong University of Science and Technology, Hong Kong SAR, China. Email: Email:\nhzhubi@connect.ust.hk\n6\nDepartment of Mechanical Engineering, National University of Singapore, Singapore 117575. Email:\nyuzhihao@u.nus.edu\nAbstract\nRunning up stairs is effortless for humans but remains extremely challenging for humanoid robots due to the simultaneous requirements of high agility and strict stability. Model-free reinforcement learning (RL) can generate dynamic locomotion, yet implicit stability rewards and heavy reliance on task-specific reward shaping tend to result in unsafe behaviors, especially on stairs; conversely, model-based foothold planners encode contact feasibility and stability structure, but enforcing their hard constraints often induces conservative motion that limits speed. We present FastStair, a planner-guided, multi-stage learning framework that reconciles these complementary strengths to achieve fast and stable stair ascent. FastStair integrates a parallel model-based foothold planner into the RL training loop to bias exploration toward dynamically feasible contacts and to pretrain a safety-focused base policy.\nTo mitigate planner-induced conservatism and the discrepancy between low- and high-speed action distributions, the base policy was fine-tuned into speed-specialized experts and then integrated via Low-Rank Adaptation (LoRA) to enable smooth operation across the full commanded-speed range.\nWe deploy the resulting controller on the Oli humanoid robot, achieving stable stair ascent at commanded speeds up to 1.65 m/s and traversing a 33-step spiral staircase (17 cm rise per step) in 12 s, demonstrating robust high-speed performance on long staircases. Notably, the proposed approach served as the champion solution in the Canton Tower Robot Run Up Competition. Project Page:\nhttps://npcliu.github.io/FastStair\n.\nI\nINTRODUCTION\nHumanoid robots have attracted significant interest because of their superior terrain adaptability, yet they remain far from matching human agile and stable locomotion. Staircases, a ubiquitous feature of human environments, present a particular challenge. While humans navigate them intuitively, robots face an inherent trade-off between agility and stability that remains unresolved. This trade-off has plagued state-of-the-art locomotion control methods, hindering the deployment of humanoid robots in real-world stair-climbing tasks.\nReinforcement Learning (RL) has emerged as a powerful paradigm for generating dynamic humanoid locomotion\n[\n12\n,\n13\n,\n17\n]\n. Although RL can achieve impressive speeds on flat terrain\n[\n12\n]\n, its application to challenging terrains like staircases often exposes a fragility. This vulnerability stems from the reliance on implicit stability rewards, where dynamic stability is not explicitly guaranteed but is instead encouraged through a ensemble of heuristic reward terms, such as alive, posture, and gravity-projection. On stairs, these implicit objectives frequently conflict with task-level rewards such as high-velocity tracking. This inherent contradiction forces the learning process into a trade-off where the pursuit of agility often leads the robot to sacrifice the very rewards that maintain stability. Consequently, most current stair-climbing control schemes, including both ‚Äùblind‚Äù\n[\n7\n,\n25\n]\nand perception-augmented\n[\n15\n,\n22\n,\n6\n,\n18\n]\napproaches, tend to prioritize safety by heavily weighting stability terms over speed. This prioritization effectively forfeits the potential for high-speed locomotion and results in the conservative behaviors typical of existing RL-based stair climbers.\nFigure 1:\nFull-scale humanoid robot Oli performing agile stair-climbing locomotion: (a) parallel foothold planning in IsaacLab, (b) climbing a staircase with 20‚Äâcm step height, (c) Canton Tower Run-up, and (d) high-speed ascent.\nIn contrast, model-based planner provides explicit stability guarantees by computing feasible footholds under model and environment constraints\n[\n1\n,\n16\n,\n20\n,\n2\n]\n. By enforcing hard constraints on capture regions and footstep placement, the planner ensure a high degree of safety. However, this rigorous adherence to feasibility constraints often induces conservative motion, which narrows the exploration space and limits the robot‚Äôs dynamic agility.\nA natural strategy to bridge this gap is to utilize model-based planners to guide RL exploration toward explicitly safe and feasible contacts. However, such guidance often transfers planner‚Äôs inherent conservatism to the learned policy, resulting in behaviors that are safe but lack the requisite agility for high-speed tasks. This persistent tension between planner-guided safety and learned agility motivates the development of a framework that can reconcile these complementary strengths.\nIn this work, we propose FastStair, a planner-guided, multi-stage learning framework that reconciles model-based stability with learned agility to achieve high-speed stair-climbing locomotion.\nFirst, regarding the foothold planner, compared with mainstream ALIP-based MPC methods\n[\n1\n,\n2\n]\n, planners based on the Divergent Component of Motion (DCM) admit analytical expressions\n[\n11\n]\nand permit relatively simple constraint formulations. These properties make DCM-based planners readily convertible into discrete-search formulations that are well suited for GPU-parallel computation and therefore appropriate for guiding RL training.\nSecond, to resolve the inefficiency of implicit safety exploration, we integrate a parallel DCM-based foothold planner\n[\n11\n]\ninto the RL loop. By reformulating the optimization as a parallel discrete search, we avoid reliance on parallel real-time optimization solvers and guide exploration toward dynamically feasible safety regions. This ‚Äùoptimization-as-search‚Äù approach provides the real-time guidance necessary to pretrain a safety-focused base policy with negligible computational overhead.\nFinally, to mitigate planner-induced conservatism, we adopt a multi-stage training framework. Owing to the discrepancy in action distributions between low- and high-velocity motion, a single policy struggles to track the full commanded-speed range efficiently. Accordingly, in the second stage, the base policy was fine-tuned into two speed-specialized experts via velocity-related reward reweighting. However, direct switching between these experts causes instability (e.g., chattering). To address this, in the third stage, the parameters of both experts were integrated into a single network with low-rank adaptation (LoRA) layers on their branches. The integrated model was then fine-tuned over the full commanded speed range, yielding a unified policy that transitions smoothly across full speed range and enables stable, high-speed stair climbing.\nOur main contributions can be summarized as follows:\n‚Ä¢\nTo enhance stability on challenging staircases, we introduce a DCM-based foothold planner as an explicit stability reward, which guides the reinforcement learning exploration toward dynamically feasible footholds on challenging stairs.\n‚Ä¢\nTo mitigate the prohibitive training overhead of incorporating real-time optimization into parallel RL, we reformulate the foothold optimization as a parallelized discrete search, accelerating the training speed by approximately 25 times.\n‚Ä¢\nTo mitigate planner-induced conservatism and improve velocity-tracking performance, we propose a multi-stage framework that fine-tunes high-speed and low-speed experts from a safety-focused base policy, achieving high-speed locomotion without sacrificing stability or low-speed tracking accuracy.\n‚Ä¢\nTo address instabilities arising from expert switching, the experts were merged into a single network and fine-tuned using LoRA, which enabled smooth transitions between experts and produced a unified policy that operates robustly across the full commanded-speed range.\nFigure 2:\nOverview of the FastStair framework. During the pre-training stage, a parallel DCM-based foothold optimizer generates dynamically feasible contacts to guide policy learning via a foothold-tracking reward. In the post-training stage, the pre-trained base model is fine-tuned into high- and low-speed expert policies by expanding the commanded velocity range and adjusting reward weights to mitigate planner-induced conservatism; this decomposition is motivated by the distinct action distributions at high versus low speeds. However, direct switching between experts can cause control discontinuities, so in the LoRA fine-tuning stage we merge their parameters into a single network and fine-tune it with LoRA. The resulting unified policy ensures robust tracking across the full velocity range for deployment on the physical robot.\nII\nRelated Work\nII-A\nModel-based Locomotion on Challenging Terrains\nClassical model-based methods, such as those based on the DCM\n[\n11\n]\nand Model Predictive Control (MPC), provide a rigorous mathematical foundation for foothold planning\n[\n1\n,\n20\n,\n19\n]\n. By encoding contact feasibility and balance criteria as explicit kinemodynamic constraints, these methods excel at maintaining stability on discrete terrains like stairs or stepping stones. However, ensuring real-time computational feasibility often necessitates simplifying assumptions, such as the linear inverted pendulum model, alongside the use of conservative safety margins. These constraints inevitably restrict the reachable solution space, inducing the conservative locomotion that hinder high-speed agility.\nII-B\nLearning-based Humanoid Locomotion on Stairs\nRecent advancements in deep reinforcement learning (RL) have significantly enhanced the terrain adaptability of humanoid robots. Residual-based methods\n[\n5\n,\n6\n,\n18\n]\ntypically employ a two-stage pipeline where a vision-based network provides corrective residuals to a frozen blind policy. While effective, these decoupled architectures often require complex coordination and may limit the robot‚Äôs peak agility due to the restricted search space of the residual. Conversely, end-to-end frameworks\n[\n15\n,\n22\n]\nunify perception and control, but they often struggle with the severe exploration bottlenecks of pure RL, especially when traversing discrete terrains like stairs without explicit motion priors.\nTo further enhance locomotion performance, researchers have explored specialized training strategies. For instance,\n[\n24\n]\nuses a curriculum based on scan points, while\n[\n23\n]\nleverages human motion retargeting to induce natural behaviors. However, these methods often fail to ensure strict dynamical feasibility at high speeds. Our work diverges by using a multi-stage training framework‚Äîtransitioning from safety-critical pre-training to specialized experts. By integrating these experts into a single network via LoRA\n[\n8\n]\n, we achieve high-speed stair climbing that surpasses the conservative limits of single-policy RL.\nIII\nMethod\nWe propose a multi-stage training framework, FastStair, designed to enable high-speed stair climbing while ensuring robust traversal success rates. An overview is depicted in Fig.\n2\n.\nIn the pre-training stage, we incorporate parallel DCM-based foothold planning to guide the policy via a large foothold-tracking reward.\nWhile this prioritization ensures safety, it inevitably compromises velocity tracking accuracy. To address this, the post-training stage rebalances reward weights to prioritize velocity tracking and trains separate high-speed and low-speed expert policies, initialized from the pre-trained model.\nFinally, in the fine-tuning stage, these experts are integrated into a network and fused via LoRA. This yields a single unified policy capable of reliable traversal across the full commanded velocity range. The details of this three-stage procedure are described below.\nIII-A\nParallel Foothold Planning\nTraversing complex terrain requires selecting safe, flat footholds. However, acquiring this capability is often challenging for pure RL. To bridge this gap, we incorporate a model-based planner to guide foothold selection.\nWhile conventional planning methods\n[\n4\n,\n1\n]\ndemonstrate robust performance, they typically rely on serial CPU-based optimization solvers, rendering them incompatible with massive parallel RL frameworks. Even recent advancements in parallel optimization\n[\n9\n]\noften incur non-trivial computational overhead when scaled.\nTo address this, we formulate a DCM-based foothold optimization problem and reformulate it as a parallel discrete search task. By solving this task via vectorized tensor operations, we leverage the GPU‚Äôs massive parallelism, ensuring the planner incurs negligible computational overhead during training.\nIII-A\n1\nDCM for Stair Climbing\nFollowing\n[\n3\n]\n, we model the system dynamics using the Variable-Height Inverted Pendulum (VHIP), governed by:\nx\n¬®\n=\nœâ\n2\n‚Äã\nx\n,\n\\ddot{x}=\\omega^{2}x,\nwhere\nx\n‚àà\n‚Ñù\nx\\in\\mathbb{R}\ndenotes position in the forward direction. To accommodate stair climbing, we define the Center of Mass (CoM) height trajectory\nz\n‚Äã\n(\nt\n)\nz(t)\nduring the swing phase (duration\nT\nT\n) as a linear function\nz\n‚Äã\n(\nt\n)\n=\nk\n‚Äã\nt\n+\nz\n0\nz(t)=kt+z_{0}\n, where\nz\n0\nz_{0}\nrepresents the nominal standing height and\nk\nk\ndenotes the vertical slope. Consequently, the natural frequency is given by\nœâ\n=\ng\n/\nz\n‚Äã\n(\nt\n)\n\\omega=\\sqrt{g/z(t)}\n, where\ng\ng\nis the gravitational acceleration. Fig.\n3\nillustrates this VHIP formulation applied to stair negotiation.\nFigure 3:\nInverted-pendulum stair-climbing process.\nThe DCM is defined as\nŒæ\n=\nx\n+\n1\nœâ\n‚Äã\nx\nÀô\n\\xi=x+\\frac{1}{\\omega}\\dot{x}\n. Differentiating with respect to time yields:\nŒæ\nÀô\n=\n(\n1\n‚àí\nœâ\nÀô\nœâ\n2\n)\n‚Äã\nx\nÀô\n+\n1\nœâ\n‚Äã\nx\n¬®\n.\n\\dot{\\xi}=\\left(1-\\frac{\\dot{\\omega}}{\\omega^{2}}\\right)\\dot{x}+\\frac{1}{\\omega}\\ddot{x}.\nNoting that\nœâ\nÀô\n=\n‚àí\n1\n2\n‚Äã\nœâ\n‚Äã\nk\nz\n\\dot{\\omega}=-\\frac{1}{2}\\omega\\frac{k}{z}\n, then:\nŒæ\nÀô\n\\displaystyle\\dot{\\xi}\n=\n(\n1\n+\nk\n2\n‚Äã\ng\n‚Äã\nz\n)\n‚Äã\nx\nÀô\n+\n1\nœâ\n‚Äã\nx\n¬®\n\\displaystyle=\\left(1+\\frac{k}{2\\sqrt{gz}}\\right)\\dot{x}+\\frac{1}{\\omega}\\ddot{x}\n(1)\n=\na\n‚Äã\nx\nÀô\n+\nœâ\n‚Äã\nx\n\\displaystyle=a\\dot{x}+\\omega x\n=\na\n‚Äã\nœâ\n‚Äã\nŒæ\n+\n(\n1\n‚àí\na\n)\n‚Äã\nœâ\n‚Äã\nx\n,\n\\displaystyle=a\\omega\\xi+(1-a)\\omega x,\nwhere\na\n=\n1\n+\nk\n2\n‚Äã\ng\n‚Äã\nz\na=1+\\frac{k}{2\\sqrt{gz}}\n. Considering a maximum stair incline of\n¬±\n45\n‚àò\n\\pm 45^{\\circ}\n(implying\nk\n‚àà\n[\n‚àí\n1\n,\n1\n]\nk\\in[-1,1]\n) and a nominal standing height\nz\n0\n‚âà\n1\nz_{0}\\approx 1\nm, the coefficient\na\na\nremains within the range\n[\n0.84\n,\n1.16\n]\n[0.84,1.16]\n. Given that\na\na\nis close to unity, we approximate\na\n‚âà\n1\na\\approx 1\nto simplify the optimization. This yields the dynamics\nŒæ\nÀô\n‚âà\nœâ\n‚Äã\nŒæ\n\\dot{\\xi}\\approx\\omega\\xi\nwith a time-varying\nœâ\n\\omega\n. Consequently, the DCM evolution for stair climbing at time\nt\n‚àà\n[\n0\n,\nT\n]\nt\\in[0,T]\nis given by:\nŒæ\n‚Äã\n(\nt\n)\n=\nŒæ\n0\n‚Äã\ne\n‚à´\n0\nt\nœâ\n‚Äã\n(\nœÑ\n)\n‚Äã\nùëë\nœÑ\n.\n\\xi(t)=\\xi_{0}e^{\\int_{0}^{t}\\omega(\\tau)d\\tau}.\nIII-A\n2\nDCM-based Foothold Optimization\nLeveraging the structural similarity between our derived dynamics and the standard planar DCM model, we adapt the optimization formulation from\n[\n11\n]\n:\nmin\nu\nT\n,\nb\n\\displaystyle\\min_{u_{T},b}\\quad\nŒ±\n1\n‚Äã\n‚Äñ\nu\nT\n‚àí\n[\nL\nnom\nW\nnom\n]\n‚Äñ\n2\n+\nŒ±\n2\n‚Äã\n‚Äñ\nb\n‚àí\nb\nnom\n‚Äñ\n2\n+\nŒ±\n3\n‚Äã\nS\n‚Äã\n(\nu\nT\n)\n\\displaystyle\\alpha_{1}\\left\\|u_{T}-\\begin{bmatrix}L_{\\text{nom}}\\\\\nW_{\\text{nom}}\\end{bmatrix}\\right\\|^{2}+\\alpha_{2}\\|b-b_{\\text{nom}}\\|^{2}+\\alpha_{3}S(u_{T})\n(2)\ns.t.\nu\nT\n+\nb\n=\nŒæ\nt\n‚Äã\ne\nœÉ\n‚Äã\n(\nT\n)\n‚àí\nœÉ\n‚Äã\n(\nt\n)\n,\n\\displaystyle u_{T}+b=\\xi_{t}e^{\\sigma(T)-\\sigma(t)},\n(3)\nu\nT\n‚àà\nùí´\n,\n\\displaystyle u_{T}\\in\\mathcal{P},\n(4)\nThe integrated natural frequency is explicitly given by:\nœÉ\n‚Äã\n(\nt\n)\n=\n‚à´\n0\nt\nœâ\n‚Äã\n(\nœÑ\n)\n‚Äã\nùëë\nœÑ\n=\n2\n‚Äã\ng\n‚Äã\n(\nk\n‚Äã\nt\n+\nz\n0\n‚àí\nz\n0\n)\nk\n.\n\\sigma(t)=\\int_{0}^{t}\\omega(\\tau)d\\tau=\\frac{2\\sqrt{g}\\left(\\sqrt{kt+z_{0}}-\\sqrt{z_{0}}\\right)}{k}.\nThe decision variable\nu\nT\n‚àà\n‚Ñù\n2\nu_{T}\\in\\mathbb{R}^{2}\nrepresents the planar projection of the candidate foothold, while\nb\nb\ndenotes the DCM offset\n[\n11\n]\n. The nominal step targets are defined as\nL\nnom\n=\nv\nx\nd\n‚Äã\nT\nL_{\\text{nom}}=v_{x}^{d}T\nand\nW\nnom\n=\nv\ny\nd\n‚Äã\nT\n+\n(\n‚àí\n1\n)\ni\n‚Äã\nl\nW_{\\text{nom}}=v_{y}^{d}T+(-1)^{i}l\n, where\n(\nv\nx\nd\n,\nv\ny\nd\n)\n(v_{x}^{d},v_{y}^{d})\nis the desired commanded velocity,\ni\ni\nis the leg index (left/right), and\nl\nl\ndenotes the nominal lateral inter-foot distance. Accordingly, the nominal DCM offset is formulated as\nb\nnom\n=\n[\nL\ne\nœÉ\n‚Äã\n(\nT\n)\n‚àí\n1\n,\n(\n‚àí\n1\n)\ni\n‚Äã\nl\np\n1\n+\ne\nœÉ\n‚Äã\n(\nT\n)\n‚àí\nW\n1\n‚àí\ne\nœÉ\n‚Äã\n(\nT\n)\n]\nb_{\\text{nom}}=[\\frac{L}{e^{\\sigma(T)}-1},(-1)^{i}\\frac{l_{p}}{1+e^{\\sigma(T)}}-\\frac{W}{1-e^{\\sigma(T)}}]\n. The feasible foothold set\nùí´\n\\mathcal{P}\nis derived from a local elevation map (spanning\n1.8\n‚Äã\nm\n√ó\n1.2\n‚Äã\nm\n1.8\\,\\text{m}\\times 1.2\\,\\text{m}\n) centered on the robot, as visualized by the blue points in Fig.\n4\n. The term\nS\n‚Äã\n(\nu\nT\n)\nS(u_{T})\nquantifies the terrain steepness cost (indicated by light-blue points in Fig.\n4\n).\nFigure 4:\nTerrain-perception information. Blue markers show terrain scandots, green the averaged gradient map, light blue the local averaged gradient map, and red the optimal footholds.\nIII-A\n3\nSteepness Score Calculation\nThe steepness score\nS\n‚Äã\n(\nu\nT\n)\nS(u_{T})\nevaluates local terrain gradients to identify feasible contact patches. Upon acquiring the elevation map, we compute the spatial gradient using a Sobel operator, implemented efficiently as a GPU-parallelized convolution. To account for the robot‚Äôs planar foot morphology, we apply a subsequent local neighborhood aggregation step (also via convolution) over a kernel matching the foot dimensions. In the resulting cost map, higher values correspond to steeper terrain, indicating reduced suitability for foothold placement.\nIII-A\n4\nOptimization-to-Search Reformulation\nDirectly solving large-scale optimization problems in real-time typically incurs prohibitive computational overhead, creating a bottleneck for parallel RL. To overcome this, we reformulate the optimization into a parallel discrete search.\nWe observe that the feasible foothold set\nùí´\n\\mathcal{P}\n(blue points in Fig.\n4\n) is naturally discretized by the elevation map resolution and can be encoded as a tensor on the GPU. Leveraging the equality constraint in Eq.¬†(\n3\n), we analytically map each candidate foothold\nu\nT\n‚àà\nùí´\nu_{T}\\in\\mathcal{P}\nto its corresponding DCM offset\nb\nb\n. Consequently, the cost function in Eq.¬†(\n2\n) can be evaluated in parallel across the entire batch of candidate footholds using efficient vectorized tensor operations. The optimal foothold is then identified via a simple\nargmin\nreduction.\nTo further accelerate the query, we constrain the search window to a\n0.6\n‚Äã\nm\n√ó\n0.6\n‚Äã\nm\n0.6\\,\\text{m}\\times 0.6\\,\\text{m}\nregion of interest centered on the nominal target\n[\nL\nnom\n,\nW\nnom\n]\n‚ä§\n[L_{\\text{nom}},W_{\\text{nom}}]^{\\top}\n, as indicated by the light-blue region in Fig.\n4\n.\nWhile this formulation relies on simplified dynamics (approximating\na\n‚âà\n1\na\\approx 1\n), it provides a computationally lightweight yet effective heuristic sufficient to guide the RL policy. Moreover, this\noptimization-to-search\nparadigm offers a generalizable strategy for tightly coupling model-based planners with massive parallel RL environments without sacrificing training speed.\nIII-B\nThree-Stage Reinforcement Learning Framework\nIII-B\n1\nObservation Space\nThe policy‚Äôs state space is partitioned into proprioceptive observations (available during both training and deployment) and privileged observations (restricted to the training phase).\nThe proprioceptive observations primarily comprise the user command vector\nùíÑ\nt\n=\n[\nv\nx\nd\n,\nv\ny\nd\n,\nw\nyaw\nd\n]\n‚ä§\n\\boldsymbol{c}_{t}=[v_{x}^{d},v_{y}^{d},w_{\\mathrm{yaw}}^{d}]^{\\top}\n, base angular velocity, projected gravity vector, joint positions, joint velocities, and the previous action history. To encode timing, we include gait clock signals\n{\nsin\n‚Å°\n(\n2\n‚Äã\nœÄ\n‚Äã\nf\n‚Äã\nt\n)\n,\ncos\n‚Å°\n(\n2\n‚Äã\nœÄ\n‚Äã\nf\n‚Äã\nt\n)\n}\n\\{\\sin(2\\pi ft),\\cos(2\\pi ft)\\}\n, where\nf\nf\ndenotes the stepping frequency. Crucially, the robot also perceives the terrain via elevation map centered on the robot.\nThe privileged observations augment this set with ground-truth states and explicit model-based guidance. These include the base linear velocity, base height, external contact forces, joint accelerations, and joint torques. Importantly, to guide the learning process, we incorporate the optimal foothold computed by the parallel planner described in Sec.\nIII-A\n.\nIII-B\n2\nReward Function and Network Architecture\nSince our primary contribution lies in the multi-stage framework, we adopt the actor-critic network architecture and the baseline reward formulation from\n[\n21\n]\n. However, to drive stage-specific behaviors, we adjust specific reward scalars across the three training stages, as detailed in Table\nI\n.\nCrucially, to enforce the guidance provided by the parallel planner, we introduce a specific foothold-tracking reward not present in\n[\n21\n]\n:\nr\nfoot\n=\nexp\n‚Å°\n(\n‚àí\n10\n‚Äã\n‚Äñ\nùê©\nf\n‚àí\nùê©\nf\nd\n‚Äñ\n)\n,\nr_{\\text{foot}}=\\exp\\!\\left(-10\\|\\mathbf{p}_{f}-\\mathbf{p}_{f}^{d}\\|\\right),\nwhere\nùê©\nf\n‚àà\n‚Ñù\n3\n\\mathbf{p}_{f}\\in\\mathbb{R}^{3}\ndenotes the current swing-foot position and\nùê©\nf\nd\n‚àà\n‚Ñù\n3\n\\mathbf{p}_{f}^{d}\\in\\mathbb{R}^{3}\nrepresents the desired instantaneous position for the next time step. The desired trajectory\nùê©\nf\nd\n\\mathbf{p}_{f}^{d}\nis generated via interpolation (e.g., B√©zier curves) defined by three keyframes: the lift-off position, the swing apex, and the target landing position\n[\nu\nT\n‚ä§\n,\nh\nz\n]\n‚ä§\n[u_{T}^{\\top},h_{z}]^{\\top}\n. Here,\nu\nT\nu_{T}\nis the optimal planar foothold derived in Sec.\nIII-A\n, and\nh\nz\nh_{z}\nis the corresponding terrain height retrieved directly from the elevation map. To prevent tripping, the swing apex is configured to ensure sufficient clearance above the maximum height difference between the lift-off and landing points.\nIII-B\n3\nPre-training Stage\nIn the Pre-training Stage, we prioritize traversal stability over precise velocity tracking. Accordingly, we assign a dominant weight to the foothold-tracking reward defined above. This constraint compels the policy to target safe contact regions‚Äîspecifically the centers of stair treads‚Äîrather than risky edge placements, thereby maximizing the probability of successful traversal. Through this process, the policy effectively encodes the geometric intuition of the model-based planner. However, the emphasis on foothold accuracy leads to increased speed-tracking error.\nIII-B\n4\nPost-training Stage\nTo recover velocity-tracking precision and increase climbing speed, the reward weights were adjusted by increasing the weight of the speed-tracking term and reducing the foothold-tracking weight.\nWe partition the command space into two distinct regimes: a high-velocity band (\n[\n0.8\n,\n1.6\n]\n‚Äã\nm/s\n[0.8,1.6]\\,\\text{m/s}\n) and a low-velocity band (\n[\n‚àí\n0.3\n,\n0.8\n]\n‚Äã\nm/s\n[-0.3,0.8]\\,\\text{m/s}\n). Initialized from the pre-trained policy, two separate expert model are trained to master each specific regime. This divide-and-conquer strategy is essential; empirical results indicate that training a single policy directly over the full union of ranges (\n[\n‚àí\n0.3\n,\n1.6\n]\n‚Äã\nm/s\n[-0.3,1.6]\\,\\text{m/s}\n) leads to mode collapse towards moderate velocities, significantly degrading tracking accuracy at the operational extremes (i.e., very slow or very fast motion).\nIII-B\n5\nLoRA Fine-tuning Stage\nBecause joint-action distributions differ between high- and low-speed locomotion, directly switching between discrete expert policies induces control discontinuities and physical instability during deployment. To resolve this, we integrate the parameters of both the high-speed and low-speed experts into a unified network (see Fig.\n2\n). We then fine-tune the model using LoRA to smooth the transition boundaries and ensure robust performance across the full command spectrum.\nWithin the unified network, we employ a rule-based switcher driven by the user command: the high-speed expert is activated to generate joint actions when the commanded forward velocity\nv\nx\nd\n>\n0.8\n‚Äã\nm/s\nv_{x}^{d}>0.8\\,\\text{m/s}\n, while the low-speed expert governs the regime below this threshold.\nTABLE I:\nThe reward weights for the three stages\nReward Term\nStage 1 Weights\nStage 2 Weights\nStage 3 Weights\nLin. velocity track\n1.0\n1.35\n1.1\nBase height\n(w.r.t. feet)\n0.4\n0.3\n0.4\nAction smoothness\n‚àí\n2.5\n-2.5\ne-03\n‚àí\n2\n-2\ne-03\n‚àí\n2\n-2\ne-03\nJoint accel. L2\n‚àí\n5\n-5\ne-07\n‚àí\n4\n-4\ne-07\n‚àí\n4\n-4\ne-07\nJoint torque L2\n‚àí\n4\n-4\ne-07\n‚àí\n3\n-3\ne-07\n‚àí\n3\n-3\ne-07\nTorque rate\n‚àí\n1.5\n-1.5\ne-07\n‚àí\n2\n-2\ne-08\n‚àí\n2\n-2\ne-08\nJoint power\n‚àí\n2.5\n-2.5\ne-07\n‚àí\n2\n-2\ne-07\n‚àí\n2\n-2\ne-07\nLin. accel. L2\n‚àí\n2\n-2\ne-03\n‚àí\n1.5\n-1.5\ne-03\n‚àí\n1.5\n-1.5\ne-03\nProj. gravity L2\n‚àí\n0.15\n-0.15\n‚àí\n0.1\n-0.1\n‚àí\n0.1\n-0.1\nFeet stumble\n‚àí\n1.5\n-1.5\n‚àí\n1.5\n-1.5\n‚àí\n2\n-2\nFoothold\n0.6\n0.6\n0.5\n0.5\n0.4\n0.4\nIII-C\nElevation Maps Reconstruction\nThe locomotion policy relies on egocentric local elevation maps (visualized as blue markers in Fig.\n4\n) for terrain awareness. During simulation training, we extract ground-truth height samples directly from the IsaacLab interface.\nFor physical deployment, we implement the perception pipeline proposed in\n[\n21\n]\nusing an Intel RealSense D435i depth camera. This module processes raw depth frames in real-time to reconstruct a local terrain grid covering a\n1.8\n‚Äã\nm\n√ó\n1.2\n‚Äã\nm\n1.8\\,\\text{m}\\times 1.2\\,\\text{m}\narea centered on the robot, with a spatial resolution of\n5\n‚Äã\ncm\n5\\,\\text{cm}\n. The resulting terrain scandots serves as the primary exteroceptive input for the onboard policy.\nIV\nEXPERIMENTS\nIV-A\nRobot Platform\nWe conduct all experiments using the full-scale humanoid robot LimX Oli\n[\n14\n]\n(Fig.\n5\n). The robot weighs 55‚Äâkg and stands 1.65‚Äâm tall, featuring 31 actuated degrees of freedom (DoF): 6 per leg, 7 per arm, 3 in the waist, and 2 in the head. In this study, all 31 joints are actively controlled. For onboard computing, the system integrates an NVIDIA Jetson Orin NX and a Rockchip RK3588-based single-board computer to handle real-time perception and policy inference.\nFigure 5:\nRobot Platform Limx Oli.\nIV-B\nTraning and Deployment\nFollowing\n[\n21\n]\n, we utilize IsaacLab to construct a diverse training curriculum featuring flat ground, rough terrain, and pyramid-shaped stairs (both ascent and descent). To facilitate agile maneuvers, we constrain the gait frequency to\n[\n1.0\n,\n1.5\n]\n[1.0,1.5]\nHz. We simulate 4096 environments in parallel, randomizing the robot‚Äôs base pose upon each reset and resampling command velocities every 10 seconds. While the forward velocity range varies across the three training stages (as detailed in Sec.\nIII-B\n4\n), the lateral velocity and yaw rate are fixed at\nv\ny\nd\n‚àà\n[\n‚àí\n0.3\n,\n0.3\n]\nv_{y}^{d}\\in[-0.3,0.3]\nm/s and\nw\nyaw\nd\n‚àà\n[\n‚àí\n1.0\n,\n1.0\n]\nw_{\\text{yaw}}^{d}\\in[-1.0,1.0]\nrad/s, respectively.\nTo bridge the sim-to-real gap, we apply domain randomization. Randomized parameters include the mass and inertia of links (base, waist, legs), contact friction, restitution coefficients, and joint PD gains. Additionally, we inject random external force and impulse perturbations. For the final LoRA fine-tuning stage we configure the LoRA hyperparameters as\nŒ±\n=\n16\n\\alpha=16\nand\nŒ≥\n=\n8\n\\gamma=8\n.\nFor real-world deployment, we employ a distributed computing architecture. The Intel RealSense D435i captures depth frames, which are processed by the perception pipeline on the NVIDIA Jetson Orin NX to generate local elevation maps. These maps are transmitted to the Rockchip RK3588-based computer, which executes the final unified policy. This decoupling of perception and control workloads ensures efficient onboard processing and maintains the strict control loop timing required for stable agile locomotion.\nIV-C\nFoothold Tracking and Computational Efficiency\nIV-C\n1\nFoothold Tracking\nIn our framework, planned footholds serve as supervisory signals within the reward function, guiding the policy toward safe contact regions. Fig.\n6\nillustrates the optimal footholds (red point in the figure) generated via Eq.\n2\nduring ascent; notably, the planner concentrates targets near the centers of the stair treads. By minimizing the tracking error against these targets, the robot implicitly learns to identify and exploit safe, planar contact surfaces.\nTo evaluate this guidance, both the pre-trained and the final unified policies were deployed in IsaacLab and data were collected at commanded forward velocities of\n{\n0.4\n,\n0.6\n,\n0.8\n,\n1.0\n}\n‚Äã\nm/s\n\\{0.4,\\,0.6,\\,0.8,\\,1.0\\}\\,\\text{m/s}\n. Performance was quantified by the mean planar Euclidean distance between executed and planned footholds. As illustrated in Fig.\n6\n, simulation screenshots show that the swing foot generally lands near the desired foothold; nevertheless, the foothold-tracking error of the final unified policy is larger than that of the pre-trained policy. By contrast, the velocity-tracking analysis in Fig.\n9\nindicates that the final unified policy attains lower velocity error. This pattern is explained by the training design: during pre-training a larger weight is placed on foothold accuracy to prioritize safety, and only after a safe baseline has been learned is post-training used to explore more agile behaviors. The results therefore reflect the intended trade-off between safety and agility embodied by the proposed multi-stage framework.\nIV-C\n2\nComputational Efficiency\nThe complete planning pipeline‚Äîincluding elevation map processing and the parallel discrete search‚Äîincurs a latency of approximately 4‚Äâms per step for a batch of 4096 environments on an NVIDIA RTX 4090. This represents an approximate\n25\n√ó\n25\\times\nspeedup compared to recent parallel MPC implementations using CusADi\n[\n10\n]\nunder similar hardware conditions, highlighting the scalability of our approach for large-scale RL.\nFigure 6:\nFoothold screenshots and Foothold-tracking error. For each commanded speed, the error was computed by averaging the absolute foothold-position errors recorded over a time window.\nIV-D\nFull-Range Velocity-Tracking Experiments\nTo assess policy robustness beyond the training simulator, we conduct validation in MuJoCo on a staircase with a step height of\n15\n‚Äã\ncm\n15\\,\\text{cm}\n. Fig.\n7\npresents both a simulation snapshot and a time-series plot of the forward velocity response during a stair descent maneuver.\nExperimental results demonstrate that the unified policy effectively tracks velocity commands across the entire operational range. Notably, the robot maintains stability and tracking accuracy from a stationary stance (\n0\n‚Äã\nm/s\n0\\,\\text{m/s}\n) up to the maximum commanded velocity of\n1.6\n‚Äã\nm/s\n1.6\\,\\text{m/s}\n, validating the effectiveness of the multi-stage training framework.\nFigure 7:\nMuJoCo simulation snapshot and velocity-tracking performance during stair descent. The plot shows commanded and measured forward velocities over time.\nIV-E\nTraining Framework Evaluation\nWe evaluated the following methods in terms of terrain traversal success ratio and velocity-tracking mean absolute error (MAE):\n‚Ä¢\nBaseline\n[\n21\n]\n:\nA standard end-to-end RL policy trained without model-based foothold guidance, which has twice the parameters of a velocity expert policy.\n‚Ä¢\nPre-trained (Ablation):\nAn intermediate variant (Stage 1 only) incorporates DCM-based foothold guidance and uses twice the parameters of a velocity expert, but lacks the velocity-specific split and LoRA integration.\n‚Ä¢\nAMP\n[\n23\n]\n:\nA policy trained using Adversarial Motion Priors (AMP), where exploration is guided by retargeted human reference motions rather than terrain-aware geometric planning.\n‚Ä¢\nFastStair (ours):\nThe complete proposed framework (see Fig.\n2\n).\nIV-E\n1\nTerrain Traversal Success Ratio\nThe traversal success ratio was evaluated on a staircase with 25‚Äâcm step height at commanded forward speeds of 0.5, 1.0, 1.5, and 2.0‚Äâm/s. In IsaacSim we initialized 500 robots around the center of a pyramidal staircase with randomized headings and commanded them to traverse in all directions. The success ratio is defined as the fraction of environments in which the robot reached the far edge of the terrain within an episode without falling. Results are presented in Fig.\n8\n.\nAs illustrated, FastStair achieves the highest success rate across all tested velocities. The Pre-trained policy also significantly outperforms the baselines, a result we attribute to the parallel foothold planning incorporated during pre-training. This explicitly imparts geometric guidance, enabling the robot to identify optimal contact regions on the stair treads.\nIn contrast, while the AMP method performs well at lower velocities (\n‚â§\n1.0\n‚Äã\nm/s\n\\leq 1.0\\,\\text{m/s}\n), its performance degrades sharply at higher speeds, eventually underperforming even the unguided Baseline. In simulation, we observed that the AMP policy exhibited a tendency to stall at the base of the stairs when commanded above\n1.0\n‚Äã\nm/s\n1.0\\,\\text{m/s}\n. We hypothesize this stems from two factors: the lack of high-speed climbing examples in the reference dataset (distributional shift) and a conservative reward structure that penalizes the deviations required for aggressive maneuvers.\nAlthough all policies were trained with a maximum commanded velocity of\n1.6\n‚Äã\nm/s\n1.6\\,\\text{m/s}\n, we extended the evaluation to\n2.0\n‚Äã\nm/s\n2.0\\,\\text{m/s}\nto assess robustness. Notably, FastStair maintains a success rate exceeding\n70\n%\n70\\%\neven in this out-of-distribution regime, demonstrating superior generalization of the learned agile locomotion skills.\nFigure 8:\nSuccess-rate comparison for traversing a staircase with 25‚Äâcm step height at various commanded speeds.\nIV-E\n2\nVelocity-Tracking Evaluation\nWe evaluate the velocity-tracking fidelity of the four methods on a staircase with a\n25\n‚Äã\ncm\n25\\,\\text{cm}\nstep height. forward velocity commands are sampled uniformly from\n[\n‚àí\n0.3\n,\n1.6\n]\n‚Äã\nm/s\n[-0.3,1.6]\\,\\text{m/s}\nat\n3\n‚Äã\ns\n3\\,\\text{s}\nintervals. For each trial, we compute the Mean Absolute Error (MAE) between the commanded and actual velocities. The resulting error distributions are presented in Fig.\n9\n.\nAs illustrated, FastStair achieves the lowest MAE (approximately\n0.5\n‚Äã\nm/s\n0.5\\,\\text{m/s}\n), validating the effectiveness of the full training pipeline. Notably, the Pre-trained policy exhibits a slightly higher MAE than the Baseline. This result is consistent with our design intent: the heavy weighting of the foothold-tracking reward during pre-training biases the policy toward precise, safe foot placement (as evidenced in Fig.\n6\n) at the expense of velocity-tracking performance. This safety-versus-agility trade-off explicitly justifies the necessity of the subsequent post-training stage to recover velocity-tracking precision while retaining the learned foothold priors.\nConversely, the AMP method yields the largest MAE. As noted in Sec.\nIV-E\n1\n, the AMP policy frequently exhibits stagnation behavior at the stair base under high-velocity commands, leading to significant tracking deviations. Finally, we note that the maximum error values across all methods are inflated by velocity measurements recorded immediately prior to falls; therefore, maximum error is not a reliable indicator of tracking quality.\nFigure 9:\nMean absolute error (MAE) of velocity tracking for four methods on a staircase with 25‚Äâcm step height.\nFigure 10:\nOutdoor experiments of perception-enabled agile stair climbing, including high-speed ascent and descent and turning maneuvers on stairs.\nIV-F\nReal-World Deployment\nWe deploy the final policy on the full-scale humanoid robot ‚ÄúLimX Oli,‚Äù executing directly on the onboard RK3588-based computer at a control frequency of\n100\n‚Äã\nHz\n100\\,\\text{Hz}\n, without any additional task-level fine-tuning. We conduct a series of outdoor experiments to validate performance (see Fig.\n1\nand Fig.\n10\n). Detailed video recordings are provided in the supplementary material\n1\n1\n1\nhttps://youtu.be/SoLBK7VEGDo\n.\nWe perform comprehensive stair-climbing tests covering the full velocity range (0 to 1.5 m/s) on an outdoor staircase with a 15 cm step height (Fig.\n10\n). The robot successfully executes both ascent and descent across the full commanded velocity range, achieving ascent velocities up to 1.5 m/s. To accommodate such high-speed motion, the robot exhibits an emergent step-skipping behavior, clearing two steps in a single stride to maximize forward progress. Notably, the robot successfully negotiated 33 stairs (17 cm/step) at the Canton Tower within 12 seconds, reaching a peak velocity of 1.65 m/s during the final steps of the ascent.\nFurther validation includes the continuous negotiation of steeper staircases (\n20\n‚Äã\ncm\n20\\,\\text{cm}\nstep height, Fig.\n1\n) and dynamic turning maneuvers between flight segments. All tasks were completed successfully, demonstrating that FastStair enables stable, perception-aware agile locomotion in challenging real-world environments.\nV\nConclusion\nIn this paper, we presented FastStair, a multi-stage learning framework that reconciles model-based stability with learned agility for high-speed stair climbing. By reformulating DCM-based foothold optimization into a GPU-parallel discrete search, we provided real-time guidance within the RL loop with negligible computational overhead. To mitigate planner-induced conservatism and improve velocity-tracking performance, the base policy was fine-tuned into separate low- and high-speed experts to accommodate differing action distributions. To eliminate instabilities associated with hard switching, the experts were merged into a single network and consolidated via LoRA fine-tuning, yielding a unified policy that operates robustly across the full commanded-speed range. Experimental results on the Oli robot demonstrate robust performance, achieving agile stair ascent at speeds up to 1.65 m/s. The successful navigation of a 33-step spiral staircase in 12 seconds underscores the efficiency and high-speed capabilities of FastStair in challenging real-world environments.\nFor future work, we aim to extend the parallel planning paradigm to a broader spectrum of challenging terrains. Furthermore, we plan to investigate generalized methodologies for tightly coupling model-based geometric priors with large-scale RL, ultimately enabling reliable deployment in complex, unstructured field environments.\nReferences\n[1]\nB. Acosta and M. Posa\n(2023)\nBipedal walking on constrained footholds with mpc footstep control\n.\nIn\n2023 IEEE-RAS 22nd International Conference on Humanoid Robots (Humanoids)\n,\npp.¬†1‚Äì8\n.\nCited by:\n¬ßI\n,\n¬ßI\n,\n¬ß\nII-A\n,\n¬ß\nIII-A\n.\n[2]\nB. Acosta and M. Posa\n(2025)\nPerceptive mixed-integer footstep control for underactuated bipedal walking on rough terrain\n.\narXiv preprint arXiv:2501.19391\n.\nCited by:\n¬ßI\n,\n¬ßI\n.\n[3]\nS. Caron, A. Escande, L. Lanari, and B. Mallein\n(2019)\nCapturability-based pattern generation for walking with variable height\n.\nIEEE Transactions on Robotics\n36\n(\n2\n),\npp.¬†517‚Äì536\n.\nCited by:\n¬ß\nIII-A\n1\n.\n[4]\nO. Dosunmu-Ogunbi, A. Shrivastava, G. Gibson, and J. W. Grizzle\n(2023)\nStair climbing using the angular momentum linear inverted pendulum model and model predictive control\n.\nIn\n2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\n,\npp.¬†8558‚Äì8565\n.\nCited by:\n¬ß\nIII-A\n.\n[5]\nH. Duan, B. Pandit, M. S. Gadde, B. Van Marum, J. Dao, C. Kim, and A. Fern\n(2024)\nLearning vision-based bipedal locomotion for challenging terrain\n.\nIn\n2024 IEEE International Conference on Robotics and Automation (ICRA)\n,\npp.¬†56‚Äì62\n.\nCited by:\n¬ß\nII-B\n.\n[6]\nM. S. Gadde, P. Dugar, A. Malik, and A. Fern\n(2025)\nNo more blind spots: learning vision-based omnidirectional bipedal locomotion for challenging terrain\n.\nIn\n2025 IEEE-RAS 24th International Conference on Humanoid Robots (Humanoids)\n,\npp.¬†601‚Äì608\n.\nCited by:\n¬ßI\n,\n¬ß\nII-B\n.\n[7]\nX. Gu, Y. Wang, and J. Chen\n(2024)\nHumanoid-gym: reinforcement learning for humanoid robot with zero-shot sim2real transfer\n.\narXiv preprint arXiv:2404.05695\n.\nCited by:\n¬ßI\n.\n[8]\nE. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, W. Chen,\net al.\n(2022)\nLora: low-rank adaptation of large language models.\n.\nICLR\n1\n(\n2\n),\npp.¬†3\n.\nCited by:\n¬ß\nII-B\n.\n[9]\nS. H. Jeon, S. Hong, H. J. Lee, C. Khazoom, and S. Kim\n(2024)\nCusadi: a gpu parallelization framework for symbolic expressions and optimal control\n.\nIEEE Robotics and Automation Letters\n.\nCited by:\n¬ß\nIII-A\n.\n[10]\nJ. Kamohara, F. Wu, C. Wamorkar, S. Hutchinson, and Y. Zhao\n(2025)\nRL-augmented adaptive model predictive control for bipedal locomotion over challenging terrain\n.\narXiv preprint arXiv:2509.18466\n.\nCited by:\n¬ß\nIV-C\n2\n.\n[11]\nM. Khadiv, A. Herzog, S. A. A. Moosavian, and L. Righetti\n(2020)\nWalking control based on step timing adaptation\n.\nIEEE Transactions on Robotics\n36\n(\n3\n),\npp.¬†629‚Äì643\n.\nCited by:\n¬ßI\n,\n¬ßI\n,\n¬ß\nII-A\n,\n¬ß\nIII-A\n2\n,\n¬ß\nIII-A\n2\n.\n[12]\nZ. Li, X. B. Peng, P. Abbeel, S. Levine, G. Berseth, and K. Sreenath\n(2025)\nReinforcement learning for versatile, dynamic, and robust bipedal locomotion control\n.\nThe International Journal of Robotics Research\n44\n(\n5\n),\npp.¬†840‚Äì888\n.\nCited by:\n¬ßI\n.\n[13]\nQ. Liao, T. E. Truong, X. Huang, G. Tevet, K. Sreenath, and C. K. Liu\n(2025)\nBeyondmimic: from motion tracking to versatile humanoid control via guided diffusion\n.\narXiv preprint arXiv:2508.08241\n.\nCited by:\n¬ßI\n.\n[14]\n(\n2025\n)\nLimx Oli\n.\nNote:\nhttps://www.limxdynamics.com/en/oli\nAccessed: July 30, 2025\nCited by:\n¬ß\nIV-A\n.\n[15]\nJ. Long, J. Ren, M. Shi, Z. Wang, T. Huang, P. Luo, and J. Pang\n(2025)\nLearning humanoid locomotion with perceptive internal model\n.\nIn\n2025 IEEE International Conference on Robotics and Automation (ICRA)\n,\npp.¬†9997‚Äì10003\n.\nCited by:\n¬ßI\n,\n¬ß\nII-B\n.\n[16]\nL. Penco, B. Park, S. Fasano, N. Poddar, S. McCrory, N. Kitchel, T. Bialek, D. Anderson, D. Calvert, and R. Griffin\n(2025)\nAnticipatory and adaptive footstep streaming for teleoperated bipedal robots\n.\nIn\n2025 IEEE-RAS 24th International Conference on Humanoid Robots (Humanoids)\n,\npp.¬†1‚Äì8\n.\nCited by:\n¬ßI\n.\n[17]\nT. Peng, L. Bao, and C. Zhou\n(2025)\nGait-conditioned reinforcement learning with multi-phase curriculum for humanoid locomotion\n.\narXiv preprint arXiv:2505.20619\n.\nCited by:\n¬ßI\n.\n[18]\nJ. Ren, T. Huang, H. Wang, Z. Wang, Q. Ben, J. Long, Y. Yang, J. Pang, and P. Luo\n(2025)\nVb-com: learning vision-blind composite humanoid locomotion against deficient perception\n.\narXiv preprint arXiv:2502.14814\n.\nCited by:\n¬ßI\n,\n¬ß\nII-B\n.\n[19]\nA. Shamsah, Z. Gu, J. Warnke, S. Hutchinson, and Y. Zhao\n(2023)\nIntegrated task and motion planning for safe legged navigation in partially observable environments\n.\nIEEE Transactions on Robotics\n39\n(\n6\n),\npp.¬†4913‚Äì4934\n.\nCited by:\n¬ß\nII-A\n.\n[20]\nY. Shi, S. Li, Y. Wu, J. Liu, X. Leng, X. Zang, and S. Piao\n(2025)\nBipedal robust walking on uneven footholds: piecewise slope lipm with discrete model predictive control\n.\narXiv preprint arXiv:2504.02255\n.\nCited by:\n¬ßI\n,\n¬ß\nII-A\n.\n[21]\nH. Song, H. Zhu, T. Yu, Y. Liu, M. Yuan, W. Zhou, H. Chen, and H. Li\n(2025)\nGait-adaptive perceptive humanoid locomotion with real-time under-base terrain reconstruction\n.\narXiv preprint arXiv:2512.07464\n.\nExternal Links:\nLink\nCited by:\n¬ß\nIII-B\n2\n,\n¬ß\nIII-B\n2\n,\n¬ß\nIII-C\n,\n1st item\n,\n¬ß\nIV-B\n.\n[22]\nW. Sun, B. Cao, L. Chen, Y. Su, Y. Liu, Z. Xie, and H. Liu\n(2025)\nLearning perceptive humanoid locomotion over challenging terrain\n.\narXiv preprint arXiv:2503.00692\n.\nCited by:\n¬ßI\n,\n¬ß\nII-B\n.\n[23]\nD. Wang, X. Wang, X. Liu, J. Shi, Y. Zhao, C. Bai, and X. Li\n(2025)\nMoRE: mixture of residual experts for humanoid lifelike gaits learning on complex terrains\n.\narXiv preprint arXiv:2506.08840\n.\nCited by:\n¬ß\nII-B\n,\n3rd item\n.\n[24]\nH. Wang, Z. Wang, J. Ren, Q. Ben, T. Huang, W. Zhang, and J. Pang\n(2025)\nBeamdojo: learning agile humanoid locomotion on sparse footholds\n.\narXiv preprint arXiv:2502.10363\n.\nCited by:\n¬ß\nII-B\n.\n[25]\nZ. Wang, W. Wei, R. Yu, J. Wu, and Q. Zhu\n(2024)\nToward understanding key estimation in learning robust humanoid locomotion\n.\nIn\n2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\n,\npp.¬†11232‚Äì11239\n.\nCited by:\n¬ßI\n.",
    "preview_text": "Running up stairs is effortless for humans but remains extremely challenging for humanoid robots due to the simultaneous requirements of high agility and strict stability. Model-free reinforcement learning (RL) can generate dynamic locomotion, yet implicit stability rewards and heavy reliance on task-specific reward shaping tend to result in unsafe behaviors, especially on stairs; conversely, model-based foothold planners encode contact feasibility and stability structure, but enforcing their hard constraints often induces conservative motion that limits speed. We present FastStair, a planner-guided, multi-stage learning framework that reconciles these complementary strengths to achieve fast and stable stair ascent. FastStair integrates a parallel model-based foothold planner into the RL training loop to bias exploration toward dynamically feasible contacts and to pretrain a safety-focused base policy. To mitigate planner-induced conservatism and the discrepancy between low- and high-speed action distributions, the base policy was fine-tuned into speed-specialized experts and then integrated via Low-Rank Adaptation (LoRA) to enable smooth operation across the full commanded-speed range. We deploy the resulting controller on the Oli humanoid robot, achieving stable stair ascent at commanded speeds up to 1.65 m/s and traversing a 33-step spiral staircase (17 cm rise per step) in 12 s, demonstrating robust high-speed performance on long staircases. Notably, the proposed approach served as the champion solution in the Canton Tower Robot Run Up Competition.\n\nFastStair: Learning to Run Up Stairs with Humanoid Robots\nYan Liu\n1,2\n,\nTao Yu\n2\n,\nHaolin Song\n4\n,\nHongbo Zhu\n2,5\n,\nNianzong Hu\n2\n,\nYuzhi Hao\n2,6\n,\nXiuyong Yao\n2\n,\nXizhe Zang\n1\n‚Äã\n‚Ä†\n{}^{1\\text{\\textdagger}}\n,\nHua Chen\n2\n,\n3\n‚Äã\n‚Ä†\n{}^{2,3\\text{\\textdagger}}\n,\nJie Zhao\n1\n* Work done at LimX Dynamics. Project lead: Tao Yu\n‚Ä†\nCorresponding author\n1\nSchool of Mechanics Engineering, Harbin Institute of Technology (HIT), Harbin",
    "is_relevant": true,
    "relevance_score": 8.0,
    "extracted_keywords": [
        "Reinforcement Learning",
        "locomotion",
        "whole body control"
    ],
    "one_line_summary": "FastStairÊòØ‰∏Ä‰∏™ÁªìÂêàÊ®°ÂûãËßÑÂàí‰∏éÂº∫ÂåñÂ≠¶‰π†ÁöÑÊ°ÜÊû∂ÔºåÁî®‰∫éÂÆûÁé∞‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Âø´ÈÄüÁ®≥ÂÆö‰∏äÊ•ºÊ¢ØÔºåÈÄöËøáÂ§öÈò∂ÊÆµÂ≠¶‰π†ÂíåLoRAÈõÜÊàê‰ºòÂåñËøêÂä®ÊéßÂà∂„ÄÇ",
    "detailed_summary": "## FastStairÔºöÂèåË∂≥Êú∫Âô®‰∫∫Ê•ºÊ¢ØÂ•îË∑ëÂ≠¶‰π†Ê°ÜÊû∂ËØ¶ÁªÜÊëòË¶Å\n\n### 1. Á†îÁ©∂ËÉåÊôØÂíåÂä®Êú∫\nÂèåË∂≥Êú∫Âô®‰∫∫Âú®Ê•ºÊ¢ØÁ≠âÈùûÁªìÊûÑÂåñÂú∞ÂΩ¢‰∏äÁöÑ**È´òÈÄü„ÄÅÁ®≥ÂÆöËøêÂä®**ÊòØ‰∏Ä‰∏™ÈïøÊúüÊåëÊàò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂ≠òÂú®ÊòéÊòæÂ±ÄÈôêÔºöÂü∫‰∫éÊ®°ÂûãÁöÑËßÑÂàíÂô®ÔºàÂ¶ÇDCM„ÄÅMPCÔºâËôΩËÉΩ‰øùËØÅÁ®≥ÂÆöÊÄßÔºå‰ΩÜÂæÄÂæÄÂØºËá¥**‰øùÂÆà„ÄÅ‰ΩéÈÄü**ÁöÑËøêÂä®ÔºõËÄåÂü∫‰∫éÊó†Ê®°ÂûãÂº∫ÂåñÂ≠¶‰π†ÔºàRLÔºâÁöÑÊñπÊ≥ïËôΩËÉΩÁîüÊàêÂä®ÊÄÅÊ≠•ÊÄÅÔºå‰ΩÜ‰æùËµñÈöêÂºèÁ®≥ÂÆöÊÄßÂ•ñÂä±ÔºåÂú®Ê•ºÊ¢ØÁ≠âÂ§çÊùÇÂú∞ÂΩ¢‰∏äÂÆπÊòì‰∫ßÁîü**‰∏çÂÆâÂÖ®Ë°å‰∏∫**Ôºå‰∏îÈöæ‰ª•ÂÆûÁé∞È´òÈÄü„ÄÇÂõ†Ê≠§Ôºå‰∫üÈúÄ‰∏ÄÁßçËÉΩ**ËûçÂêàÊ®°ÂûãÂÆâÂÖ®ÊÄß**‰∏é**Â≠¶‰π†ÊïèÊç∑ÊÄß**‰ºòÂäøÁöÑÊñ∞Ê°ÜÊû∂„ÄÇ\n\n### 2. Ê†∏ÂøÉÊñπÊ≥ïÂíåÊäÄÊúØÂàõÊñ∞\nÊú¨ÊñáÊèêÂá∫ **FastStair**Ôºå‰∏Ä‰∏™**ËßÑÂàíÂô®ÂºïÂØºÁöÑÂ§öÈò∂ÊÆµÂ≠¶‰π†Ê°ÜÊû∂**ÔºåÂÖ∂Ê†∏ÂøÉÂàõÊñ∞ÁÇπÂåÖÊã¨Ôºö\n- **Âü∫‰∫éDCMÁöÑÂπ∂Ë°åËêΩËÑöÁÇπËßÑÂàíÂô®**ÔºöÂ∞ÜËêΩËÑöÁÇπ‰ºòÂåñÈóÆÈ¢òÈáçÊûÑ‰∏∫**GPUÂπ∂Ë°åÁöÑÁ¶ªÊï£ÊêúÁ¥¢**ÔºåËÆ°ÁÆóÂºÄÈîÄÊûÅ‰ΩéÔºàÊØèÊ≠•Á∫¶4msÔºâÔºåËÉΩÂú®RLËÆ≠ÁªÉÂæ™ÁéØ‰∏≠ÂÆûÊó∂Êèê‰æõÂä®ÊÄÅÂèØË°åÁöÑËêΩËÑöÁÇπÂºïÂØºÔºå‰Ωú‰∏∫ÊòæÂºèÂÆâÂÖ®Â•ñÂä±„ÄÇ\n- **‰∏âÈò∂ÊÆµËÆ≠ÁªÉÁ≠ñÁï•**Ôºö\n    1.  **È¢ÑËÆ≠ÁªÉÈò∂ÊÆµ**ÔºöÂà©Áî®ËßÑÂàíÂô®ÂºïÂØºÔºåËÆ≠ÁªÉ‰∏Ä‰∏™**ÂÆâÂÖ®‰ºòÂÖà**ÁöÑÂü∫Á°ÄÁ≠ñÁï•ÔºåÂ≠¶‰π†Âú®Ê•ºÊ¢ØË∏èÈù¢‰∏≠ÂøÉËêΩËÑö„ÄÇ\n    2.  **ÂêéËÆ≠ÁªÉÈò∂ÊÆµ**ÔºöÈíàÂØπ‰ΩéÈÄüÔºà[-0.3, 0.8] m/sÔºâÂíåÈ´òÈÄüÔºà[0.8, 1.6] m/sÔºâÂä®‰ΩúÂàÜÂ∏ÉÂ∑ÆÂºÇÂ§ßÁöÑÈóÆÈ¢òÔºåÂ∞ÜÂü∫Á°ÄÁ≠ñÁï•ÂæÆË∞ÉÊàê**‰∏§‰∏™ÈÄüÂ∫¶‰∏ìÂÆ∂Á≠ñÁï•**Ôºå‰ª•ÊèêÂçáÈÄüÂ∫¶Ë∑üË∏™Á≤æÂ∫¶„ÄÇ\n    3.  **LoRAÂæÆË∞ÉÈò∂ÊÆµ**ÔºöÂ∞Ü‰∏§‰∏™‰∏ìÂÆ∂Á≠ñÁï•ÁöÑÂèÇÊï∞**Êï¥ÂêàÂà∞Âçï‰∏ÄÁΩëÁªú**‰∏≠ÔºåÂπ∂Âà©Áî®**‰ΩéÁß©ÈÄÇÂ∫îÔºàLoRAÔºâ** ÊäÄÊúØËøõË°åÂæÆË∞ÉÔºåÊ∂àÈô§Áõ¥Êé•ÂàáÊç¢ÂØºËá¥ÁöÑ‰∏çÁ®≥ÂÆöÔºåÊúÄÁªàÂæóÂà∞‰∏Ä‰∏™ËÉΩÂú®ÂÖ®ÈÄüÂ∫¶ËåÉÂõ¥ÂÜÖÂπ≥Êªë„ÄÅÈ≤ÅÊ£íËøêË°åÁöÑ**Áªü‰∏ÄÁ≠ñÁï•**„ÄÇ\n\n### 3. ‰∏ªË¶ÅÂÆûÈ™åÁªìÊûú\nÂú®‰ªøÁúü‰∏éÂÆûÁâ©Êú∫Âô®‰∫∫ÔºàLimX OliÔºâ‰∏äËøõË°å‰∫ÜÂÖ®Èù¢È™åËØÅÔºö\n- **ÊàêÂäüÁéá‰∏éÈÄüÂ∫¶Ë∑üË∏™**ÔºöÂú®25ÂéòÁ±≥È´òÂè∞Èò∂ÁöÑÊ•ºÊ¢Ø‰∏äÔºåFastStairÁöÑ**ÈÅçÂéÜÊàêÂäüÁéáÊúÄÈ´ò**Ôºå‰∏î**ÈÄüÂ∫¶Ë∑üË∏™Âπ≥ÂùáÁªùÂØπËØØÂ∑ÆÊúÄ‰Ωé**ÔºàÁ∫¶0.5 m/sÔºâÔºåÊòæËëó‰ºò‰∫éÂü∫Á∫øÊñπÊ≥ïÂíåAMPÊñπÊ≥ï„ÄÇ\n- **ÂÆûÁâ©ÈÉ®ÁΩ≤ÊÄßËÉΩ**ÔºöÊú∫Âô®‰∫∫ÊàêÂäüÂú®Êà∑Â§ñÊ•ºÊ¢ØÔºà15-20ÂéòÁ±≥Âè∞Èò∂Ôºâ‰∏äÂÆûÁé∞‰∫Ü**ÂÖ®ÈÄüÂ∫¶ËåÉÂõ¥Ôºà0-1.5 m/sÔºâÁöÑÁ®≥ÂÆö‰∏ä‰∏ãÊ•º**ÔºåÂπ∂Â±ïÁé∞Âá∫**Ë∑®Ê≠•Ôºà‰∏ÄÊ≠•Ë∑®‰∏§Èò∂Ôºâ** ÁöÑÊïèÊç∑Ë°å‰∏∫„ÄÇÂú®‚ÄúÂ∞èËõÆËÖ∞‚ÄùÁôªÈ´òËµõ‰∏≠Ôºå‰ª•**1.65 m/sÁöÑÂ≥∞ÂÄºÈÄüÂ∫¶**Âú®12ÁßíÂÜÖÊàêÂäüÊîÄÁà¨33Á∫ßËû∫ÊóãÊ•ºÊ¢ØÔºà17ÂéòÁ±≥/Èò∂ÔºâÔºåËµ¢ÂæóÂÜ†ÂÜõ„ÄÇ\n- **ËÆ°ÁÆóÊïàÁéá**ÔºöÂπ∂Ë°åËßÑÂàíÂô®Áõ∏ÊØî‰º†ÁªüÂπ∂Ë°åMPCÂÆûÁé∞ÔºåÂ∏¶Êù•Á∫¶**25ÂÄçÁöÑËÆ≠ÁªÉÂä†ÈÄü**„ÄÇ\n\n### 4. Á†îÁ©∂ÊÑè‰πâÂíå‰ª∑ÂÄº\nFastStairÊàêÂäü**Ë∞ÉÂíå‰∫ÜÊ®°ÂûãËßÑÂàíÁöÑÂÆâÂÖ®ÊÄß‰∏éÂº∫ÂåñÂ≠¶‰π†ÁöÑÊïèÊç∑ÊÄß**‰πãÈó¥ÁöÑÂõ∫ÊúâÁüõÁõæÔºå‰∏∫ÂèåË∂≥Êú∫Âô®‰∫∫Âú®Â§çÊùÇÂú∞ÂΩ¢‰∏äÁöÑ**È´òÈÄüÂä®ÊÄÅËøêÂä®**Êèê‰æõ‰∫ÜÂàáÂÆûÂèØË°åÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇÂÖ∂ÊèêÂá∫ÁöÑ**‚Äú‰ºòÂåñÂç≥ÊêúÁ¥¢‚ÄùÂπ∂Ë°åËßÑÂàíËåÉÂºè**Âíå**Âü∫‰∫éLoRAÁöÑÂ§ö‰∏ìÂÆ∂Á≠ñÁï•ËûçÂêàÊñπÊ≥ï**Ôºå‰∏ç‰ªÖÂÆûÁé∞‰∫ÜÂΩìÂâçÊúÄÂø´ÁöÑÂèåË∂≥Êú∫Âô®‰∫∫Ê•ºÊ¢ØÊîÄÁà¨ÈÄüÂ∫¶Ôºå‰πü‰∏∫**Â∞ÜÊ®°ÂûãÂÖàÈ™åÁ¥ßÂØÜËÄ¶ÂêàÂà∞Â§ßËßÑÊ®°‰ªøÁúüÂ≠¶‰π†**Êèê‰æõ‰∫ÜÈÄöÁî®ÊÄßÊÄùË∑ØÔºåÊé®Âä®‰∫ÜÂèåË∂≥Êú∫Âô®‰∫∫Ëµ∞ÂêëÊõ¥Â§çÊùÇ„ÄÅÂÆûÁî®ÁöÑÁúüÂÆû‰∏ñÁïåÈÉ®ÁΩ≤„ÄÇ",
    "qa_pairs": [
        {
            "question": "ËøôÁØáËÆ∫ÊñáÁöÑÊ†∏ÂøÉÂàõÊñ∞ÁÇπÊòØ‰ªÄ‰πàÔºå‰ªñÊÉ≥Ëß£ÂÜ≥‰ªÄ‰πàÈóÆÈ¢òÔºåÊÄé‰πàËß£ÂÜ≥ÁöÑÔºü",
            "answer": "## ËÆ∫ÊñáÊ†∏ÂøÉÂàÜÊûêÔºöFastStair\n\n### **‰∏Ä„ÄÅ ÊãüËß£ÂÜ≥ÁöÑÊ†∏ÂøÉÈóÆÈ¢ò**\nËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥**‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Âú®Ê•ºÊ¢Ø‰∏äÂÆûÁé∞È´òÈÄü„ÄÅÁ®≥ÂÆöÊîÄÁà¨**Ëøô‰∏ÄÈïøÊúüÂ≠òÂú®ÁöÑÊåëÊàò„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÂÆÉËØïÂõæË∞ÉÂíå‰º†ÁªüÊñπÊ≥ï‰∏≠Â≠òÂú®ÁöÑ‰∏§‰∏™ÂÖ≥ÈîÆÁüõÁõæÔºö\n1.  **ÊïèÊç∑ÊÄß‰∏éÁ®≥ÂÆöÊÄßÁöÑÊùÉË°°**Ôºö\n    - **Á∫ØÂº∫ÂåñÂ≠¶‰π†ÔºàRLÔºâÊñπÊ≥ï**ÔºöËÉΩÁîüÊàêÂä®ÊÄÅËøêÂä®Ôºå‰ΩÜ‰æùËµñÈöêÂºèÁöÑÁ®≥ÂÆöÊÄßÂ•ñÂä±ÔºåÂú®Ê•ºÊ¢ØÁ≠âÂ§çÊùÇÂú∞ÂΩ¢‰∏äÂÆπÊòì‰∫ßÁîü‰∏çÂÆâÂÖ®Ë°å‰∏∫ÔºåÈöæ‰ª•‰øùËØÅÈ´òÈÄü‰∏ãÁöÑÁ®≥ÂÆö„ÄÇ\n    - **Âü∫‰∫éÊ®°ÂûãÁöÑËßÑÂàíÂô®ÊñπÊ≥ï**ÔºöÈÄöËøáÁ°¨Á∫¶ÊùüÔºàÂ¶ÇËêΩËÑöÁÇπÂèØË°åÊÄß„ÄÅÊçïËé∑Âå∫ÂüüÔºâÊèê‰æõÊòéÁ°ÆÁöÑÁ®≥ÂÆöÊÄß‰øùËØÅÔºå‰ΩÜÂæÄÂæÄÂØºËá¥**‰øùÂÆàÁöÑËøêÂä®Ê®°Âºè**ÔºåÈôêÂà∂‰∫ÜÊú∫Âô®‰∫∫ÁöÑÈÄüÂ∫¶ÂíåÂä®ÊÄÅÊïèÊç∑ÊÄß„ÄÇ\n\n2.  **ËÆ≠ÁªÉÊïàÁéá‰∏éÂÆûÊó∂ÊÄßÁöÑÁüõÁõæ**ÔºöÂ∞ÜÂ§çÊùÇÁöÑÊ®°Âûã‰ºòÂåñÂô®Áõ¥Êé•ÈõÜÊàêÂà∞Â§ßËßÑÊ®°Âπ∂Ë°åRLËÆ≠ÁªÉÂæ™ÁéØ‰∏≠Ôºå‰ºö‰∫ßÁîü**Èöæ‰ª•ÊâøÂèóÁöÑËÆ°ÁÆóÂºÄÈîÄ**„ÄÇ\n\n### **‰∫å„ÄÅ Ê†∏ÂøÉÂàõÊñ∞ÁÇπ**\nËÆ∫ÊñáÊèêÂá∫‰∫Ü‰∏Ä‰∏™Âêç‰∏∫ **FastStair** ÁöÑ**ËßÑÂàíÂô®ÂºïÂØº„ÄÅÂ§öÈò∂ÊÆµÂ≠¶‰π†Ê°ÜÊû∂**ÔºåÂÖ∂ÂàõÊñ∞ÊÄß‰∏ªË¶Å‰ΩìÁé∞Âú®‰ª•‰∏ãÂõõ‰∏™Â±ÇÈù¢Ôºö\n\n1.  **Âü∫‰∫éDCMÁöÑÂπ∂Ë°åËêΩËÑöÁÇπËßÑÂàíÂô®‰Ωú‰∏∫ÊòæÂºèÁ®≥ÂÆöÊÄßÂºïÂØº**\n    - **ÊäÄÊúØÂàõÊñ∞**ÔºöÈááÁî®**ÂèëÊï£ËøêÂä®ÂàÜÈáèÔºàDCMÔºâÊ®°Âûã**ËøõË°åËêΩËÑöÁÇπËßÑÂàí„ÄÇÁõ∏ÊØî‰∏ªÊµÅÊñπÊ≥ïÔºàÂ¶ÇALIP-MPCÔºâÔºåDCMÊ®°ÂûãÂÖÅËÆ∏Ëß£ÊûêË°®ËææÂíåÊõ¥ÁÆÄÂçïÁöÑÁ∫¶ÊùüÂÖ¨Âºè„ÄÇ\n    - **ÂÖ≥ÈîÆÊîπËøõ**ÔºöÂ∞Ü‰º†ÁªüÁöÑËøûÁª≠‰ºòÂåñÈóÆÈ¢ò**ÈáçÊûÑ‰∏∫Âπ∂Ë°åÁ¶ªÊï£ÊêúÁ¥¢ÈóÆÈ¢ò**„ÄÇÈÄöËøáÂêëÈáèÂåñÂº†ÈáèÊìç‰ΩúÂú®GPU‰∏äÊâßË°åÔºåÂÆûÁé∞‰∫Ü**Á∫¶25ÂÄçÁöÑËÆ≠ÁªÉÂä†ÈÄü**Ôºå‰ΩøÂÖ∂ËÉΩÂ§ü‰ª•ÂèØÂøΩÁï•ÁöÑËÆ°ÁÆóÂºÄÈîÄÂÆûÊó∂ÈõÜÊàêÂà∞RLËÆ≠ÁªÉÂæ™ÁéØ‰∏≠„ÄÇ\n    - **‰ΩúÁî®**ÔºöÂú®È¢ÑËÆ≠ÁªÉÈò∂ÊÆµÔºåÈÄöËøá‰∏Ä‰∏™È´òÊùÉÈáçÁöÑ‚ÄúËêΩËÑöÁÇπË∑üË∏™Â•ñÂä±‚ÄùÔºåÂºïÂØºRLÁ≠ñÁï•Êé¢Á¥¢**Âä®ÊÄÅÂèØË°åÁöÑÂÆâÂÖ®ËêΩËÑöÂå∫Âüü**ÔºàÂ¶ÇÊ•ºÊ¢ØË∏èÈù¢‰∏≠ÂøÉÔºâÔºå‰ªéËÄåÁºñÁ†Å‰∫ÜÊ®°ÂûãËßÑÂàíÂô®ÁöÑÂá†‰ΩïÂÖàÈ™åÁü•ËØÜÔºåÂ•†ÂÆö‰∫ÜÂÆâÂÖ®Âü∫Á°Ä„ÄÇ\n\n2.  **Â§öÈò∂ÊÆµËÆ≠ÁªÉÊ°ÜÊû∂‰ª•ÂÖãÊúçËßÑÂàíÂô®‰øùÂÆàÊÄß**\n    - **ÈóÆÈ¢òËØÜÂà´**ÔºöÂçï‰∏ÄÁ≠ñÁï•Èöæ‰ª•Âú®ÂÖ®ÈÄüÂ∫¶ËåÉÂõ¥Ôºà‰ΩéÈÄüÂà∞È´òÈÄüÔºâÂÜÖÈ´òÊïàË∑üË∏™Êåá‰ª§ÔºåÂõ†‰∏∫‰∏çÂêåÈÄüÂ∫¶‰∏ãÁöÑÂä®‰ΩúÂàÜÂ∏ÉÂ∑ÆÂºÇÂ∑®Â§ß„ÄÇ\n    - **Ëß£ÂÜ≥ÊñπÊ°à**Ôºö\n        - **Èò∂ÊÆµ‰∏ÄÔºàÈ¢ÑËÆ≠ÁªÉÔºâ**Ôºö‰ΩøÁî®ËßÑÂàíÂô®ÂºïÂØºÔºåËÆ≠ÁªÉ‰∏Ä‰∏™**ÂÆâÂÖ®‰ºòÂÖàÁöÑÂü∫Á°ÄÁ≠ñÁï•**„ÄÇ\n        - **Èò∂ÊÆµ‰∫åÔºàÂêéËÆ≠ÁªÉÔºâ**ÔºöÈÄöËøáË∞ÉÊï¥Â•ñÂä±ÊùÉÈáçÔºàÈôç‰ΩéËêΩËÑöÁÇπË∑üË∏™ÊùÉÈáçÔºåÊèêÈ´òÈÄüÂ∫¶Ë∑üË∏™ÊùÉÈáçÔºâÔºåÂ∞ÜÂü∫Á°ÄÁ≠ñÁï•**ÂæÆË∞ÉÊàê‰∏§‰∏™ÈÄüÂ∫¶‰∏ìÂÆ∂**Ôºö**‰ΩéÈÄü‰∏ìÂÆ∂**Ôºà-0.3 Ëá≥ 0.8 m/sÔºâÂíå**È´òÈÄü‰∏ìÂÆ∂**Ôºà0.8 Ëá≥ 1.6 m/sÔºâ„ÄÇËøôÁßç‚ÄúÂàÜËÄåÊ≤ª‰πã‚ÄùÁöÑÁ≠ñÁï•ÈÅøÂÖç‰∫ÜÂçï‰∏ÄÁ≠ñÁï•Âú®ÂÖ®ËåÉÂõ¥ËÆ≠ÁªÉÊó∂ÁöÑÊ®°ÂºèÂ¥©Ê∫É„ÄÇ\n        - **Èò∂ÊÆµ‰∏âÔºàLoRAÂæÆË∞ÉÔºâ**Ôºö‰∏∫Ëß£ÂÜ≥‰∏§‰∏™‰∏ìÂÆ∂Á≠ñÁï•Áõ¥Êé•ÂàáÊç¢Êó∂‰∫ßÁîüÁöÑÊéßÂà∂‰∏çËøûÁª≠Âíå‰∏çÁ®≥ÂÆöÈóÆÈ¢òÔºåÂàõÊñ∞ÊÄßÂú∞Â∞Ü‰∏§‰∏™‰∏ìÂÆ∂ÁöÑÂèÇÊï∞**ÂêàÂπ∂Âà∞‰∏Ä‰∏™Áªü‰∏ÄÁΩëÁªú‰∏≠**ÔºåÂπ∂Âà©Áî®**‰ΩéÁß©Ëá™ÈÄÇÂ∫îÔºàLoRAÔºâÊäÄÊúØ**ËøõË°åÂæÆË∞É„ÄÇ\n\n3.  **Âà©Áî®LoRAÂÆûÁé∞‰∏ìÂÆ∂ËûçÂêà‰∏éÂπ≥ÊªëËøáÊ∏°**\n    - **ÊäÄÊúØÂàõÊñ∞**ÔºöÂ∞ÜËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÈ¢ÜÂüüÁöÑ**LoRAÊäÄÊúØ**ÂºïÂÖ•Êú∫Âô®‰∫∫ÊéßÂà∂„ÄÇÂú®Áªü‰∏ÄÁΩëÁªú‰∏≠ÔºåÊ†πÊçÆÈÄüÂ∫¶Êåá‰ª§ÊøÄÊ¥ªÂØπÂ∫î‰∏ìÂÆ∂ÁöÑLoRAÂàÜÊîØËøõË°åÊé®ÁêÜ„ÄÇ\n    - **‰ΩúÁî®**ÔºöLoRAÂæÆË∞ÉÂπ≥Êªë‰∫ÜÈ´ò‰ΩéÈÄü‰∏ìÂÆ∂‰πãÈó¥ÁöÑËøáÊ∏°ËæπÁïåÔºåÊúÄÁªà‰∫ßÁîü‰∏Ä‰∏™**Âçï‰∏ÄÁöÑ„ÄÅÁªü‰∏ÄÁöÑÁ≠ñÁï•**ÔºåËÉΩÂ§üÂú®**ÂÖ®Êåá‰ª§ÈÄüÂ∫¶ËåÉÂõ¥ÂÜÖÂÆûÁé∞È≤ÅÊ£í„ÄÅÂπ≥ÊªëÁöÑÊéßÂà∂**ÔºåÊ∂àÈô§‰∫ÜÂàáÊç¢ÊäñÂä®„ÄÇ\n\n4.  **ÂÆåÊï¥ÁöÑÁ≥ªÁªüÈõÜÊàê‰∏éÁúüÂÆû‰∏ñÁïåÈ™åËØÅ**\n    - **ÊäÄÊúØÊï¥Âêà**ÔºöÂ∞Ü‰∏äËø∞Â≠¶‰π†Ê°ÜÊû∂‰∏é**ÂÆûÊó∂ÊÑüÁü•ÔºàÂü∫‰∫éÊ∑±Â∫¶Áõ∏Êú∫ÁöÑÂ±ÄÈÉ®È´òÁ®ãÂú∞ÂõæÈáçÂª∫Ôºâ**„ÄÅ**‰ªøÁúüÂà∞Áé∞ÂÆûËøÅÁßªÊäÄÊúØÔºàÂüüÈöèÊú∫ÂåñÔºâ** Áõ∏ÁªìÂêà„ÄÇ\n    - **ÂÆûÈôÖ‰ª∑ÂÄº**ÔºöÂú®‚ÄúOli‚ÄùÂÖ®Â∞∫ÂØ∏‰∫∫ÂΩ¢Êú∫Âô®‰∫∫‰∏äÊàêÂäüÈÉ®ÁΩ≤ÔºåÊó†ÈúÄÈ¢ùÂ§ñË∞É‰ºò„ÄÇÂÆûÁé∞‰∫ÜÔºö\n        - È´òËææ **1.65 m/s** ÁöÑÊ•ºÊ¢ØÊîÄÁà¨ÈÄüÂ∫¶„ÄÇ\n        - Âú®12ÁßíÂÜÖÁ®≥ÂÅ•ÊîÄÁà¨**33Á∫ßËû∫ÊóãÊ•ºÊ¢Ø**ÔºàÊØèÁ∫ßÈ´ò17ÂéòÁ±≥Ôºâ„ÄÇ\n        - Âú®‚ÄúÂπøÂ∑ûÂ°îÊú∫Âô®‰∫∫ÁôªÈ´òÊØîËµõ‚Äù‰∏≠Â§∫ÂÜ†ÔºåËØÅÊòé‰∫ÜÂÖ∂**Âú®Â§çÊùÇ„ÄÅÈïøË∑ùÁ¶ªÁúüÂÆûÂú∫ÊôØ‰∏≠ÁöÑÈ´òÊÄßËÉΩÂíåÈ≤ÅÊ£íÊÄß**„ÄÇ\n\n### **‰∏â„ÄÅ Ëß£ÂÜ≥ÊñπÊ°àÊÄªÁªì**\n**FastStairÈÄöËøá‚ÄúËßÑÂàíÂô®ÂºïÂØºÂÆâÂÖ® + Â§öÈò∂ÊÆµÂ≠¶‰π†ÊïèÊç∑ + LoRAËûçÂêàÁªü‰∏Ä‚ÄùÁöÑ‰∏âÊ≠•Ëµ∞Á≠ñÁï•ÔºåÁ≥ªÁªüÊÄßÂú∞Ëß£ÂÜ≥‰∫Ü‰∫∫ÂΩ¢Êú∫Âô®‰∫∫È´òÈÄü‰∏äÊ•ºÊ¢ØÁöÑÈöæÈ¢ò„ÄÇ**\n\n1.  **Áî®Ê®°ÂûãËßÑÂàíÂô®Ëß£ÂÜ≥‚ÄúÊé¢Á¥¢‰∏çÂÆâÂÖ®‚ÄùÈóÆÈ¢ò**ÔºöÂ∞ÜDCMËßÑÂàíÂô®ÈáçÊûÑ‰∏∫GPUÂπ∂Ë°åÊêúÁ¥¢ÔºåÈ´òÊïàÂú∞‰∏∫RLÊèê‰æõÊòéÁ°ÆÁöÑÂä®ÊÄÅÂèØË°åÊÄßÊåáÂØºÔºåÁ°Æ‰øùÁ≠ñÁï•Â≠¶‰π†ÂÆâÂÖ®ÁöÑËêΩËÑöË°å‰∏∫„ÄÇ\n2.  **Áî®Â§öÈò∂ÊÆµ‰∏ìÂÆ∂Á≠ñÁï•Ëß£ÂÜ≥‚ÄúËßÑÂàíÂ§™‰øùÂÆà‚ÄùÈóÆÈ¢ò**ÔºöÂÖàÂ≠¶ÂÆâÂÖ®ÔºåÂÜçÈíàÂØπÈÄüÂ∫¶ÂàÜÂåñÂ≠¶‰π†ÔºåÊâìÁ†¥Âçï‰∏ÄÁ≠ñÁï•ÁöÑÊÄßËÉΩÁì∂È¢àÔºåËß£ÈîÅÈ´òÈÄüÊïèÊç∑ÊÄß„ÄÇ\n3.  **Áî®LoRAËûçÂêàËß£ÂÜ≥‚Äú‰∏ìÂÆ∂ÂàáÊç¢‰∏çÁ®≥ÂÆö‚ÄùÈóÆÈ¢ò**ÔºöÂ∞ÜÂ§ö‰∏™‰∏ìÂÆ∂Êô∫ËÉΩ‰Ωì‚ÄúËΩØÂåñ‚Äù‰∏∫‰∏Ä‰∏™ÂèØËá™ÈÄÇÂ∫îË∞ÉÊï¥ÁöÑÁªü‰∏ÄÁΩëÁªúÔºå‰øùËØÅÂÖ®ÈÄüÂüüÊéßÂà∂ÁöÑÂπ≥Êªë‰∏éÁ®≥ÂÆö„ÄÇ\n\nËøôÈ°πÂ∑•‰ΩúÁöÑÊ†∏ÂøÉ‰ª∑ÂÄºÂú®‰∫éÔºåÂÆÉ**‰∏çÊòØÁÆÄÂçïÂú∞ÁªìÂêàÊ®°Âûã‰∏éÂ≠¶‰π†ÔºåËÄåÊòØËÆæËÆ°‰∫Ü‰∏Ä‰∏™Á≤æÂ∑ßÁöÑÊ°ÜÊû∂ÔºåËÆ©‰∏§ËÄÖ‰ºòÂäø‰∫íË°•**ÔºöÊ®°ÂûãËßÑÂàíÂô®Êèê‰æõ‰∫ÜRLÂàùÊúüÊé¢Á¥¢ÊâÄÈúÄÁöÑÂÖ≥ÈîÆÂÆâÂÖ®ÂºïÂØºÔºåËÄåRLÂèàÈÄöËøáÂ≠¶‰π†ÂíåÂæÆË∞ÉÔºåÁ™ÅÁ†¥‰∫ÜÊ®°ÂûãËßÑÂàíÂô®Âõ∫ÊúâÁöÑ‰øùÂÆàÊÄßÊûÅÈôêÔºåÊúÄÁªàÂÆûÁé∞‰∫ÜË∂ÖË∂ä‰ªª‰ΩïÂçï‰∏ÄÊñπÊ≥ïÁöÑÊÄßËÉΩ„ÄÇ",
            "timestamp": "2026-01-20T17:57:49.007446",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "Âü∫‰∫é‰ªñÁöÑÂâç‰ΩúÔºåÊ¢≥ÁêÜËøô‰∏™ÊñπÂêëÁöÑÊï¥‰∏™ÂèëÂ±ïËÑâÁªúÔºåÊØè‰∏ÄÊ≠•Áõ∏ÊØî‰∫é‰πãÂâçÁöÑÂ∑•‰ΩúÈÉΩÊîπËøõ‰∫Ü‰ªÄ‰πàÔºåÁùÄÈáç‰∫éÂá†‰∏™‰∏çÂêåÁöÑÂèëÂ±ïÊñπÂêë„ÄÇ",
            "answer": "## Âü∫‰∫éÂâç‰ΩúÁöÑFastStairÂèëÂ±ïËÑâÁªúÂàÜÊûê\n\nÊú¨ÊñáÊèêÂá∫ÁöÑFastStairÊ°ÜÊû∂Âπ∂ÈùûÂ≠§Á´ãÂ≠òÂú®ÔºåËÄåÊòØÂª∫Á´ãÂú®ËøëÂπ¥Êù•‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Ê•ºÊ¢ØË°åËµ∞Á†îÁ©∂ÁöÑ‰∏ÄÁ≥ªÂàóÂÖ≥ÈîÆÂ∑•‰Ωú‰πã‰∏ä„ÄÇÂÖ∂ÂèëÂ±ïËÑâÁªúÊ∏ÖÊô∞Âú∞Ê≤øÁùÄÂá†‰∏™‰∫íË°•ÁöÑÊñπÂêëÊºîËøõÔºö**‰ªéÁ∫ØÊ®°ÂûãÊñπÊ≥ïÂà∞Á∫ØÂ≠¶‰π†ÊñπÊ≥ïÁöÑÊé¢Á¥¢ÔºåÂÜçÂà∞‰∏§ËÄÖÁªìÂêàÁöÑÂ∞ùËØïÔºåÊúÄÁªàËÅöÁÑ¶‰∫éËß£ÂÜ≥ÁªìÂêàÂêé‰∫ßÁîüÁöÑ‚Äú‰øùÂÆàÊÄß‚Äù‰∏é‚ÄúÊïèÊç∑ÊÄß‚ÄùÁüõÁõæ**„ÄÇ‰ª•‰∏ãÊòØÂü∫‰∫éËÆ∫ÊñáÂÜÖÂÆπÂèäÁõ∏ÂÖ≥ÂºïÊñáÁöÑÊ¢≥ÁêÜÔºö\n\n### ÂèëÂ±ïËÑâÁªú‰∏éÊ†∏ÂøÉÊîπËøõ\n\nÊï¥‰∏™ÊñπÂêëÁöÑÂèëÂ±ïÂèØ‰ª•Ê¶ÇÊã¨‰∏∫‰∏â‰∏™Èò∂ÊÆµÔºåÊØè‰∏™Èò∂ÊÆµÈÉΩËØïÂõæËß£ÂÜ≥Ââç‰∏Ä‰∏™Èò∂ÊÆµÁöÑÊ†∏ÂøÉÁì∂È¢à„ÄÇ\n\n#### Á¨¨‰∏ÄÈò∂ÊÆµÔºöÊ®°Âûã‰∏ªÂØºÔºåÂÆâÂÖ®‰ΩÜ‰øùÂÆà\n*   **‰ª£Ë°®Â∑•‰Ωú**ÔºöÂü∫‰∫éDCMÔºàÂèëÊï£ËøêÂä®ÂàÜÈáèÔºâ[11] ÊàñALIPÔºàËßíÂä®ÈáèÁ∫øÊÄßÂÄíÁ´ãÊëÜÔºâ[1, 2, 20] ÁöÑÊ®°ÂûãÈ¢ÑÊµãÊéßÂà∂ÔºàMPCÔºâÊ≠•ÊÄÅËßÑÂàíÂô®„ÄÇ\n*   **Ê†∏ÂøÉÊÄùÊÉ≥**ÔºöÂ∞ÜÊé•Ëß¶ÂèØË°åÊÄß„ÄÅÂπ≥Ë°°ÂáÜÂàôÁ≠âÁºñÁ†Å‰∏∫ÊòéÁ°ÆÁöÑËøêÂä®Â≠¶/Âä®ÂäõÂ≠¶Á∫¶ÊùüÔºåÈÄöËøáÊ±ÇËß£‰ºòÂåñÈóÆÈ¢òÊù•ËßÑÂàíËêΩËÑöÁÇπ„ÄÇ\n*   **‰ºòÁÇπ**ÔºöÊèê‰æõ**ÊòéÁ°ÆÁöÑÁ®≥ÂÆöÊÄß‰øùËØÅ**ÔºåÂú®Á¶ªÊï£Âú∞ÂΩ¢ÔºàÂ¶ÇÊ•ºÊ¢ØÔºâ‰∏äÂÆâÂÖ®ÊÄßÈ´ò„ÄÇ\n*   **Â±ÄÈôêÊÄßÔºàÂç≥ÂæÖÊîπËøõÁÇπÔºâ**Ôºö\n    1.  **‰øùÂÆàÊÄß**Ôºö‰∏∫Á°Æ‰øùÂÆûÊó∂ËÆ°ÁÆóÂèØË°åÔºåÂ∏∏ÈááÁî®ÁÆÄÂåñÊ®°ÂûãÔºàÂ¶ÇÁ∫øÊÄßÂÄíÁ´ãÊëÜÔºâÂíå‰øùÂÆàÁöÑÂÆâÂÖ®ËæπÁïåÔºåËøô**ÈôêÂà∂‰∫ÜÂèØËææËß£Á©∫Èó¥**ÔºåÂØºËá¥Âä®‰Ωú‰øùÂÆàÔºåÊó†Ê≥ïÂÆûÁé∞È´òÈÄüÊïèÊç∑ËøêÂä®„ÄÇ\n    2.  **ËÆ°ÁÆó‰∏éÈõÜÊàêÁì∂È¢à**Ôºö‰º†ÁªüÁöÑÂ∫èÂàóÂåñCPU‰ºòÂåñÊ±ÇËß£Âô®Êó†Ê≥ï‰∏éÂ§ßËßÑÊ®°Âπ∂Ë°åRLËÆ≠ÁªÉÊ°ÜÊû∂ÂÖºÂÆπÔºåÈôêÂà∂‰∫ÜÂÖ∂Âú®Â≠¶‰π†Ê°ÜÊû∂‰∏≠ÁöÑÂ∫îÁî®„ÄÇ\n\n#### Á¨¨‰∫åÈò∂ÊÆµÔºöÂ≠¶‰π†‰∏ªÂØºÔºåÊïèÊç∑‰ΩÜËÑÜÂº±\n*   **‰ª£Ë°®Â∑•‰Ωú**ÔºöÂü∫‰∫éÊ∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†ÔºàRLÔºâÁöÑÁ´ØÂà∞Á´Ø[15, 22] ÊàñÊÆãÂ∑ÆÂ≠¶‰π†[5, 6, 18] ÊñπÊ≥ï„ÄÇ\n*   **Ê†∏ÂøÉÊÄùÊÉ≥**ÔºöÂà©Áî®RLÁõ¥Êé•‰ªé‰º†ÊÑüÂô®ËæìÂÖ•Â≠¶‰π†ÊéßÂà∂Á≠ñÁï•ÔºåÊúÄÂ§ßÂåñÂåÖÂê´‰ªªÂä°Â•ñÂä±ÔºàÂ¶ÇÈÄüÂ∫¶Ë∑üË∏™ÔºâÂíåÈöêÂºèÁ®≥ÂÆöÊÄßÂ•ñÂä±ÔºàÂ¶ÇÂ≠òÊ¥ª„ÄÅÂßøÊÄÅÔºâÁöÑÂõûÊä•ÂáΩÊï∞„ÄÇ\n*   **‰ºòÁÇπ**ÔºöÂú®Âπ≥Âù¶Âú∞ÂΩ¢‰∏äËÉΩÂ±ïÁé∞Âá∫**ÊÉä‰∫∫ÁöÑÂä®ÊÄÅÊÄßÂíåÊïèÊç∑ÊÄß**[12]„ÄÇ\n*   **Â±ÄÈôêÊÄßÔºàÂç≥ÂæÖÊîπËøõÁÇπÔºâ**Ôºö\n    1.  **ÈöêÂºèÂÆâÂÖ®ÁöÑ‰∏çÁ°ÆÂÆöÊÄß**ÔºöÁ®≥ÂÆöÊÄß‰æùËµñ‰∫éÂêØÂèëÂºèÂ•ñÂä±È°πÁöÑ‚ÄúÈºìÂä±‚ÄùËÄåÈùû‚Äú‰øùËØÅ‚Äù„ÄÇÂú®Ê•ºÊ¢ØÁ≠âÂ§çÊùÇÂú∞ÂΩ¢‰∏äÔºå**‰ªªÂä°Â•ñÂä±ÔºàÈ´òÈÄüÔºâ‰∏éÁ®≥ÂÆöÊÄßÂ•ñÂä±Â∏∏ÂèëÁîüÂÜ≤Á™Å**ÔºåÂØºËá¥Á≠ñÁï•‰∏∫ËøΩÊ±ÇÈÄüÂ∫¶ËÄåÁâ∫Áâ≤ÂÆâÂÖ®ÔºåË°å‰∏∫ËÑÜÂº±„ÄÇ\n    2.  **Êé¢Á¥¢Áì∂È¢à**ÔºöÂú®Á¶ªÊï£Âú∞ÂΩ¢‰∏äÔºåÁ∫ØRLÈù¢‰∏¥‰∏•ÈáçÁöÑÊé¢Á¥¢Âõ∞ÈöæÔºåÈöæ‰ª•Ëá™ÂèëÂ≠¶‰ºöÂØªÊâæÂÆâÂÖ®ËêΩËÑöÁÇπ„ÄÇ\n    3.  **ÊÄßËÉΩÂ§©Ëä±Êùø**ÔºöËÆ∏Â§öÂ∑•‰Ωú[7, 15, 22] ‰∏∫‰øùÂÆâÂÖ®ËÄåËøáÂ∫¶Âä†ÊùÉÁ®≥ÂÆöÊÄßÈ°πÔºå**‰∏ªÂä®ÊîæÂºÉ‰∫ÜÈ´òÈÄüËøêÂä®ÁöÑÊΩúÂäõ**„ÄÇ\n\n#### Á¨¨‰∏âÈò∂ÊÆµÔºöÊ®°Âûã‰∏éÂ≠¶‰π†ÁªìÂêàÔºåÂØªÊ±ÇÂπ≥Ë°°\nËøôÊòØÂΩìÂâçÁöÑ‰∏ªÊµÅÊñπÂêëÔºåFastStairÊòØÂÖ∂‰∏≠ÁöÑÊù∞Âá∫‰ª£Ë°®„ÄÇËØ•Èò∂ÊÆµËá¥Âäõ‰∫éËûçÂêàÂâç‰∏§Èò∂ÊÆµÁöÑ‰ºòÁÇπÔºå‰ΩÜ‰∏çÂêåÁ†îÁ©∂‰æßÈáçÁÇπ‰∏çÂêåÔºö\n\n1.  **ÊñπÂêë‰∏ÄÔºöÁî®Ê®°ÂûãÊåáÂØºÂ≠¶‰π†ÔºåÊèêÂçáÂÆâÂÖ®ÊÄß**\n    *   **Ê†∏ÂøÉÊîπËøõ**ÔºöÂºïÂÖ•Ê®°ÂûãËßÑÂàíÂô®‰∏∫RLÊèê‰æõ**ÊòéÁ°ÆÁöÑ„ÄÅÂü∫‰∫éÂá†‰ΩïÁöÑÂºïÂØº**ÔºåÂ∞ÜÊé¢Á¥¢ÂÅèÂêëÂä®ÊÄÅÂèØË°åÁöÑÂÆâÂÖ®Âå∫Âüü„ÄÇ\n    *   **FastStairÁöÑË¥°ÁåÆ**Ôºö\n        *   **ÁÆóÊ≥ïÈÄâÊã©**ÔºöÈááÁî®**Âü∫‰∫éDCMÁöÑËßÑÂàíÂô®**ÔºåÂõ†ÂÖ∂ÊúâËß£ÊûêËß£Ôºå‰æø‰∫éÁ∫¶ÊùüË°®Ëø∞ÔºåÊõ¥ÂÆπÊòìËΩ¨Âåñ‰∏∫Á¶ªÊï£ÊêúÁ¥¢ÈóÆÈ¢ò„ÄÇ\n        *   **ËÆ°ÁÆóËåÉÂºèÈù©Êñ∞**ÔºöÂ∞ÜËßÑÂàíÂô®ÁöÑ‰ºòÂåñÈóÆÈ¢ò**ÈáçÊûÑ‰∏∫GPUÂπ∂Ë°åÁöÑÁ¶ªÊï£ÊêúÁ¥¢**ÔºåÈÄöËøáÂêëÈáèÂåñÂº†ÈáèÊìç‰ΩúÂÆûÁé∞„ÄÇÁõ∏ÊØî‰º†ÁªüÁöÑÂπ∂Ë°å‰ºòÂåñÊ±ÇËß£Âô®[9, 10]Ôºå**ËÆ≠ÁªÉÈÄüÂ∫¶ÊèêÂçáÁ∫¶25ÂÄç**ÔºåËß£ÂÜ≥‰∫ÜÊ®°ÂûãÊñπÊ≥ïÈõÜÊàêÂà∞Âπ∂Ë°åRL‰∏≠ÁöÑËÆ°ÁÆóÂºÄÈîÄÁì∂È¢à„ÄÇ\n        *   **ÂºïÂØºÊñπÂºè**ÔºöÂ∞ÜËßÑÂàíÂá∫ÁöÑÊúÄ‰ºòËêΩËÑöÁÇπ‰Ωú‰∏∫ÁâπÊùÉ‰ø°ÊÅØÂºïÂÖ•ËßÇÂØüÁ©∫Èó¥ÔºåÂπ∂ËÆæËÆ°‰∏ìÈó®ÁöÑ**ËêΩËÑöÁÇπË∑üË∏™Â•ñÂä±**ÔºåÂú®È¢ÑËÆ≠ÁªÉÈò∂ÊÆµÂº∫Âà∂Á≠ñÁï•Â≠¶‰π†ÂÆâÂÖ®Êé•Ëß¶Ê®°Âºè„ÄÇ\n\n2.  **ÊñπÂêë‰∫åÔºöÂ§öÈò∂ÊÆµËÆ≠ÁªÉ‰∏é‰∏ìÂÆ∂Á≠ñÁï•ÔºåÂÖãÊúç‰øùÂÆàÊÄßÂπ∂ÊèêÂçáÊÄßËÉΩ**\n    *   **ÈóÆÈ¢òÊÑèËØÜ**ÔºöÂçïÁ∫ØÁöÑÊ®°ÂûãÂºïÂØº‰ºöÂ∞ÜËßÑÂàíÂô®ÁöÑ**‰øùÂÆàÊÄß‰º†ÈÄíÁªôÂ≠¶‰π†Á≠ñÁï•**ÔºåÂØºËá¥Á≠ñÁï•ÂÆâÂÖ®‰ΩÜ‰∏çÂ§üÊïèÊç∑ÔºåÈÄüÂ∫¶Ë∑üË∏™ÊÄßËÉΩÂ∑Æ„ÄÇ\n    *   **FastStairÁöÑË¥°ÁåÆ**Ôºö\n        *   **ÂàÜËÄåÊ≤ª‰πã**ÔºöËßÇÂØüÂà∞È´òÈÄü‰∏é‰ΩéÈÄüËøêÂä®‰∏ãÁöÑÂä®‰ΩúÂàÜÂ∏ÉÂ≠òÂú®ÊòæËëóÂ∑ÆÂºÇ„ÄÇÊèêÂá∫**Â§öÈò∂ÊÆµÊ°ÜÊû∂**ÔºöÂÖàÈ¢ÑËÆ≠ÁªÉ‰∏Ä‰∏™**ÂÆâÂÖ®‰ºòÂÖàÁöÑÂü∫Á≠ñÁï•**ÔºõÁÑ∂ÂêéÂ∞ÜÂÖ∂ÂæÆË∞ÉÊàê**È´òÈÄü‰∏ìÂÆ∂**Âíå**‰ΩéÈÄü‰∏ìÂÆ∂**ÔºåÂàÜÂà´‰ºòÂåñ‰∏çÂêåÈÄüÂ∫¶Âå∫Èó¥ÁöÑÊÄßËÉΩ„ÄÇ\n        *   **ÊÄßËÉΩÈ™åËØÅ**ÔºöÂÆûÈ™åË°®ÊòéÔºåÁõ¥Êé•ËÆ≠ÁªÉÂçï‰∏ÄÁ≠ñÁï•Ë¶ÜÁõñÂÖ®ÈÄüÂ∫¶ËåÉÂõ¥‰ºöÂØºËá¥Ê®°ÂºèÂ¥©Ê∫ÉÔºåÊÄßËÉΩ‰∏ãÈôç„ÄÇËÄå‰∏ìÂÆ∂Á≠ñÁï•ËÉΩÊòæËëóÊèêÂçáÂú®ÂêÑËá™Âå∫Èó¥ÁöÑÈÄüÂ∫¶Ë∑üË∏™Á≤æÂ∫¶ÂíåÊàêÂäüÁéá„ÄÇ\n\n3.  **ÊñπÂêë‰∏âÔºöÁ≠ñÁï•ÈõÜÊàê‰∏éÂπ≥ÊªëÔºåÂÆûÁé∞È≤ÅÊ£íÈÉ®ÁΩ≤**\n    *   **ÈóÆÈ¢òÊÑèËØÜ**ÔºöÂú®ÈÉ®ÁΩ≤‰∏≠Áõ¥Êé•Ê†πÊçÆÈÄüÂ∫¶ÂëΩ‰ª§ÂàáÊç¢‰∏§‰∏™‰∏ìÂÆ∂Á≠ñÁï•‰ºöÂØºËá¥**ÊéßÂà∂‰∏çËøûÁª≠ÂíåÊäñÂä®**ÔºåÂºïÂèëÁâ©ÁêÜ‰∏çÁ®≥ÂÆö„ÄÇ\n    *   **FastStairÁöÑË¥°ÁåÆ**Ôºö\n        *   **ÂàõÊñ∞ÊÄßÈõÜÊàêÊñπÊ≥ï**ÔºöÂºïÂÖ•**‰ΩéÁß©Ëá™ÈÄÇÂ∫îÔºàLoRAÔºâ** ÊäÄÊúØ„ÄÇÂ∞Ü‰∏§‰∏™‰∏ìÂÆ∂ÁΩëÁªúÁöÑÂèÇÊï∞ÂêàÂπ∂Âà∞‰∏Ä‰∏™Áªü‰∏ÄÁΩëÁªú‰∏≠ÔºåÂπ∂Âú®ÂÖ∂ÂàÜÊîØ‰∏äÊ∑ªÂä†LoRAÂ±ÇËøõË°åÂæÆË∞É„ÄÇ\n        *   **ÊïàÊûú**ÔºöËøô‰∫ßÁîü‰∫Ü‰∏Ä‰∏™**Âçï‰∏Ä„ÄÅÁªü‰∏ÄÁöÑÁ≠ñÁï•**ÔºåËÉΩÂ§ü**Âú®ÂÖ®Êåá‰ª§ÈÄüÂ∫¶ËåÉÂõ¥ÂÜÖÂπ≥ÊªëËøáÊ∏°**ÔºåÊ∂àÈô§‰∫ÜÂàáÊç¢‰∏çÁ®≥ÂÆöÔºåÂêåÊó∂‰øùÁïô‰∫Ü‰∏ìÂÆ∂ÂêÑËá™ÁöÑÊÄßËÉΩ‰ºòÂäø„ÄÇ\n\n4.  **ÊñπÂêëÂõõÔºö‰∏éÂü∫‰∫éÂÖàÈ™åÁöÑÊñπÊ≥ïÂØπÊØîÔºåÂá∏ÊòæÂá†‰ΩïÂºïÂØºÁöÑ‰ºòÂäø**\n    *   **ÂØπÊØîÂØπË±°**ÔºöÂ¶ÇAMPÔºàÂØπÊäóÊÄßËøêÂä®ÂÖàÈ™åÔºâ[23] Á≠âÊñπÊ≥ïÔºå‰ΩøÁî®**‰∫∫‰ΩìËøêÂä®ÈáçÂÆöÂêë**‰Ωú‰∏∫ÂèÇËÄÉÊù•ÂºïÂØºRLÔºå‰ª•ÁîüÊàêÊõ¥Ëá™ÁÑ∂ÁöÑÊ≠•ÊÄÅ„ÄÇ\n    *   **FastStairÁöÑÂ∑ÆÂºÇÂåñ‰ºòÂäø**Ôºö\n        *   **ÂéüÁêÜ‰∏çÂêå**ÔºöFastStair‰æùËµñÁöÑÊòØ**Âü∫‰∫éÁâ©ÁêÜÊ®°ÂûãÁöÑÂá†‰ΩïÂèØË°åÊÄßÂÖàÈ™å**ÔºåËÄåÈùû‰∫∫‰ΩìËøêÂä®Êï∞ÊçÆÂÖàÈ™å„ÄÇ\n        *   **ÊÄßËÉΩË°®Áé∞**ÔºöÂÆûÈ™åË°®ÊòéÔºåÂú®È´òÈÄüÔºà>1.0 m/sÔºâÊ•ºÊ¢ØÁà¨Âçá‰ªªÂä°‰∏≠ÔºåAMPÊñπÊ≥ïÊÄßËÉΩÊÄ•Ââß‰∏ãÈôçÔºåÁîöËá≥‰∏çÂ¶ÇÊó†ÂºïÂØºÁöÑÂü∫Á∫ø„ÄÇÂéüÂõ†ÊòØ‰∫∫‰ΩìÊï∞ÊçÆÈõÜ‰∏≠Áº∫‰πèÈ´òÈÄüÁà¨Ê•ºÊ†∑Êú¨ÔºàÂàÜÂ∏ÉÂÅèÁßªÔºâÔºå‰∏îÂÖ∂Â•ñÂä±ÁªìÊûÑÂØπÂÅèÁ¶ªÂèÇËÄÉÂä®‰ΩúÁöÑÊÉ©ÁΩöÈôêÂà∂‰∫ÜÊøÄËøõÊú∫Âä®„ÄÇËÄåFastStairÁöÑ**Ê®°ÂûãÂºïÂØº‰∏éÈÄüÂ∫¶‰∏ìÂÆ∂ËÆæËÆ°‰ΩøÂÖ∂Âú®È´òÈÄüÂíåË∂ÖÂàÜÂ∏ÉÔºà2.0 m/sÔºâÂú∫ÊôØ‰∏ã‰ªç‰øùÊåÅÈ´òÊàêÂäüÁéá**„ÄÇ\n\n### ÊÄªÁªì\nFastStairÁöÑÂèëÂ±ïËÑâÁªúÊ∏ÖÊô∞Âú∞Â±ïÁ§∫‰∫Ü‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Â§çÊùÇÂú∞ÂΩ¢ locomotion Á†îÁ©∂ÁöÑÊºîËøõÈÄªËæëÔºö‰ªé**Ê®°Âûã‰∏éÂ≠¶‰π†ÂêÑËá™‰∏∫Êîø**ÔºåÂà∞**ÁÆÄÂçïÁªìÂêà**ÔºåÂÜçÂà∞**Ê∑±Â∫¶„ÄÅÈ´òÊïà„ÄÅÁ≤æÂ∑ßÁöÑËûçÂêà**„ÄÇÂÖ∂Ê†∏ÂøÉÊîπËøõÂú®‰∫éÔºö\n1.  **ËÆ°ÁÆóÂ±ÇÈù¢**ÔºöÈÄöËøá‚Äú‰ºòÂåñÂç≥ÊêúÁ¥¢‚ÄùËåÉÂºèÔºåÂÆûÁé∞‰∫ÜÊ®°ÂûãÂºïÂØº‰∏éÂ§ßËßÑÊ®°Âπ∂Ë°åRLÁöÑ**È´òÊïàÁ¥ßËÄ¶Âêà**„ÄÇ\n2.  **ÁÆóÊ≥ïÂ±ÇÈù¢**ÔºöÈÄöËøá**Â§öÈò∂ÊÆµËÆ≠ÁªÉ‰∏éLoRAÈõÜÊàê**ÔºåÁ≥ªÁªüÊÄßÂú∞Ëß£ÂÜ≥‰∫Ü‚ÄúÂºïÂØºÂØºËá¥‰øùÂÆà‚ÄùÂíå‚Äú‰∏ìÂÆ∂ÂàáÊç¢‰∏çÁ®≥‚ÄùËøô‰∏§‰∏™ÁªìÂêàËåÉÂºè‰∏≠ÁöÑÂÖ≥ÈîÆÈöæÈ¢ò„ÄÇ\n3.  **ÊÄßËÉΩÂ±ÇÈù¢**ÔºöÂú®ÁúüÂÆûÊú∫Âô®‰∫∫‰∏äÂÆûÁé∞‰∫Ü**È´òËææ1.65 m/sÁöÑÁ®≥ÂÆöÊ•ºÊ¢ØÂ•îË∑ë**ÔºåÂπ∂Âú®ÂõΩÈôÖÁ´ûËµõ‰∏≠È™åËØÅ‰∫ÜÂÖ∂‰ºòË∂äÊÄßÔºåÊ†áÂøóÁùÄËØ•ÊñπÂêë‰ªéÁêÜËÆ∫ÊñπÊ≥ïÂà∞È´òÊÄßËÉΩÂ∑•Á®ãÂÆûÁé∞ÁöÑÈáçÂ§ßËøõÊ≠•„ÄÇ\n\nÊú™Êù•ÁöÑÂèëÂ±ïÊñπÂêëÔºåÊ≠£Â¶ÇÊñá‰∏≠ÊâÄÊåáÔºåÊòØÂ∞ÜËøôÁßç**Âπ∂Ë°åËßÑÂàíËåÉÂºèÊé®ÂπøÂà∞Êõ¥ÂπøÊ≥õÁöÑÊåëÊàòÊÄßÂú∞ÂΩ¢**ÔºåÂπ∂Êé¢Á¥¢**ËÄ¶ÂêàÊ®°ÂûãÂÖàÈ™å‰∏éÂ§ßËßÑÊ®°RLÁöÑÈÄöÁî®ÊñπÊ≥ïËÆ∫**Ôºå‰ª•ÂÆûÁé∞Âú®Â§çÊùÇÈùûÁªìÊûÑÂåñÁéØÂ¢É‰∏≠ÁöÑÂèØÈù†ÈÉ®ÁΩ≤„ÄÇ",
            "timestamp": "2026-01-20T17:58:43.978867",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "‰ªñÁöÑÂâç‰ΩúÊúâÂì™‰∫õÔºü‰ΩøÁî®Ë°®Ê†º‰ªîÁªÜËÆ≤ËÆ≤‰ªñÁöÑÊØèÁØáÂâç‰ΩúÔºå‰ªñÂíåÂâç‰ΩúÁöÑÂå∫Âà´ÊòØ‰ªÄ‰πàÔºå‰∏ªË¶ÅÊîπÂñÑÊòØ‰ªÄ‰πàÔºüÁùÄÈáç‰∫éÂÖ∑‰ΩìÁõ∏ÊØî‰∫é‰πãÂâçÊñáÁ´†ÁöÑÊîπÂä®",
            "answer": "## FastStair ËÆ∫ÊñáÁöÑÂâç‰ΩúÂàÜÊûê\n\nÊ†πÊçÆËÆ∫ÊñáÂÜÖÂÆπÔºåFastStair Ê°ÜÊû∂Âª∫Á´ãÂú®‰ΩúËÄÖÂõ¢ÈòüÂÖàÂâçÁöÑÁ†îÁ©∂Â∑•‰Ωú‰πã‰∏äÔºåÁâπÂà´ÊòØÂºïÁî®‰∫Ü `[21]` ‰Ωú‰∏∫ÂÖ∂ÁΩëÁªúÊû∂ÊûÑÂíåÈÉ®ÂàÜÊñπÊ≥ïÁöÑÂü∫Á°Ä„ÄÇ‰ª•‰∏ãÊòØÂØπÂÖ∂Ê†∏ÂøÉÂâç‰ΩúÁöÑËØ¶ÁªÜÂàÜÊûê„ÄÇ\n\n### Ââç‰ΩúÊ†∏ÂøÉËÆ∫ÊñáÔºö`[21]` Gait-adaptive Perceptive Humanoid Locomotion with Real-time Under-base Terrain Reconstruction\n\n| ÁâπÂæÅÁª¥Â∫¶ | Ââç‰Ωú `[21]` ÁöÑÂÜÖÂÆπ‰∏éÁâπÁÇπ | FastStair ÁöÑÊîπËøõ‰∏éÂå∫Âà´ | ‰∏ªË¶ÅÊîπÂñÑÁÇπ |\n| :--- | :--- | :--- | :--- |\n| **Ê†∏ÂøÉÁõÆÊ†á** | ÂÆûÁé∞**ÈÄÇÂ∫îÊÄßÂú∞ÂΩ¢ÁöÑÊÑüÁü•ËøêÂä®**ÔºåÈáçÁÇπÂú®‰∫éÂà©Áî®ÂÆûÊó∂ÈáçÂª∫ÁöÑÂú∞ÂΩ¢ÂõæËøõË°åÁ®≥ÂÅ•ÁöÑË°åËµ∞ÔºåÈÄÇÁî®‰∫éÁ≤óÁ≥ô„ÄÅ‰∏çÂπ≥Âù¶ÁöÑÂú∞Èù¢„ÄÇ | ‰∏ìÈó®ÈíàÂØπ**È´òÈÄü‰∏ä‰∏ãÊ•ºÊ¢Ø**Ëøô‰∏ÄÊûÅÂÖ∑ÊåëÊàòÊÄßÁöÑ‰ªªÂä°ËøõË°å‰ºòÂåñÔºåËøΩÊ±ÇÂú®‰∏•Ê†ºÁ®≥ÂÆöÊÄß‰∏ãÁöÑÈ´òÊïèÊç∑ÊÄß„ÄÇ | **‰ªªÂä°ËÅöÁÑ¶**Ôºö‰ªéÈÄöÁî®ÁöÑÂú∞ÂΩ¢ÈÄÇÂ∫îËΩ¨ÂêëËß£ÂÜ≥Ê•ºÊ¢ØÂú∫ÊôØ‰∏≠ÈÄüÂ∫¶‰∏éÁ®≥ÂÆöÊÄßÁöÑÂõ∫ÊúâÁüõÁõæ„ÄÇ |\n| **ÊñπÊ≥ïÊ°ÜÊû∂** | **Á´ØÂà∞Á´ØÂº∫ÂåñÂ≠¶‰π† (RL)**„ÄÇÈááÁî® Actor-Critic Êû∂ÊûÑÔºåÂ•ñÂä±ÂáΩÊï∞ËÆæËÆ°Áî®‰∫éÈºìÂä±ÈÄüÂ∫¶Ë∑üË∏™„ÄÅÂπ≥Ë°°„ÄÅÂä®‰ΩúÂπ≥ÊªëÁ≠â„ÄÇ‰æùËµñ**ÈöêÂºèÁöÑÁ®≥ÂÆöÊÄßÂ•ñÂä±**ÔºàÂ¶ÇÂßøÊÄÅ„ÄÅÈáçÂäõÊäïÂΩ±Ôºâ„ÄÇ | **ËßÑÂàíÂô®ÂºïÂØºÁöÑÂ§öÈò∂ÊÆµÂ≠¶‰π†Ê°ÜÊû∂**„ÄÇÂú®RLÂæ™ÁéØ‰∏≠ÈõÜÊàê‰∫Ü**Âü∫‰∫éDCMÁöÑÂπ∂Ë°åËêΩËÑöÁÇπËßÑÂàíÂô®**Ôºå‰∏∫Â≠¶‰π†Êèê‰æõ**ÊòæÂºèÁöÑÁ®≥ÂÆöÊÄßÊåáÂØº**„ÄÇ | **Êû∂ÊûÑÈù©Êñ∞**ÔºöÂºïÂÖ•‰∫Ü**Ê®°ÂûãËßÑÂàíÂô®**‰Ωú‰∏∫Â≠¶‰π†ËøáÁ®ãÁöÑÂÖàÈ™åÂíåÂºïÂØºÔºåÂ∞ÜÊòæÂºèÁöÑÂä®ÊÄÅÂèØË°åÊÄßÁ∫¶Êùü‰∏éÊï∞ÊçÆÈ©±Âä®ÁöÑÁ≠ñÁï•Â≠¶‰π†Áõ∏ÁªìÂêà„ÄÇ |\n| **Á®≥ÂÆöÊÄß‰øùÈöú** | ÂÆåÂÖ®‰æùËµñRLÁ≠ñÁï•ÈÄöËøáÂ•ñÂä±ÂáΩÊï∞Â≠¶‰π†Âà∞ÁöÑÈöêÂºèÂπ≥Ë°°ËÉΩÂäõ„ÄÇÂú®ÊûÅÁ´ØÂú∞ÂΩ¢ÔºàÂ¶ÇÈ´òÂè∞Èò∂Ôºâ‰∏äÔºåÈöêÂºèÂ•ñÂä±ÂèØËÉΩ‰∏éÈÄüÂ∫¶ÁõÆÊ†áÂÜ≤Á™ÅÔºåÂØºËá¥Á≠ñÁï•ËÑÜÂº±Êàñ‰∏çÂÆâÂÖ®„ÄÇ | ÈÄöËøá**Âπ∂Ë°åËêΩËÑöÁÇπËßÑÂàíÂô®**Êèê‰æõÊòæÂºèÊåáÂØº„ÄÇËßÑÂàíÂô®Âü∫‰∫éÁÆÄÂåñÂä®ÂäõÂ≠¶Ê®°ÂûãÔºàVHIP/DCMÔºâËÆ°ÁÆóÂä®ÊÄÅÂèØË°åÁöÑËêΩËÑöÂå∫ÂüüÔºåÂπ∂ÈÄöËøá‰∏Ä‰∏™‰∏ìÈó®ÁöÑ**ËêΩËÑöÁÇπË∑üË∏™Â•ñÂä±** (`r_foot`) Âº∫ÁÉàÂºïÂØºÁ≠ñÁï•ÊúùÂêëÂÆâÂÖ®Âå∫ÂüüÊé¢Á¥¢„ÄÇ | **ÂÆâÂÖ®ÊÄßÊèêÂçá**ÔºöÂ∞ÜÊ®°ÂûãÈ¢ÑÊµãÁöÑ‚ÄúÁ°¨‚ÄùÁ∫¶ÊùüËΩ¨Âåñ‰∏∫RLÁöÑ‚ÄúËΩØ‚ÄùÂºïÂØºÔºåÊòæËëóÊèêÈ´ò‰∫ÜÂú®Á¶ªÊï£„ÄÅÈ´òÈ£éÈô©Âú∞ÂΩ¢ÔºàÊ•ºÊ¢ØËæπÁºòÔºâ‰∏äÁöÑÊé¢Á¥¢ÊïàÁéáÂíåÊúÄÁªàÁ≠ñÁï•ÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ |\n| **ËÆ≠ÁªÉÁ≠ñÁï•** | ÂçïÈò∂ÊÆµËÆ≠ÁªÉ„ÄÇÂú®ÂåÖÂê´Â§öÁßçÂú∞ÂΩ¢ÁöÑËØæÁ®ã‰∏≠ËÆ≠ÁªÉ‰∏Ä‰∏™Áªü‰∏ÄÁöÑÁ≠ñÁï•„ÄÇ | **‰∏âÈò∂ÊÆµËÆ≠ÁªÉÊµÅÁ®ã**Ôºö<br>1. **È¢ÑËÆ≠ÁªÉ**ÔºöÁî®È´òÊùÉÈáçÁöÑËêΩËÑöÁÇπË∑üË∏™Â•ñÂä±ËÆ≠ÁªÉ‰∏Ä‰∏™**ÂÆâÂÖ®‰ºòÂÖàÁöÑÂü∫Á°ÄÁ≠ñÁï•**„ÄÇ<br>2. **ÂêéËÆ≠ÁªÉ**ÔºöÂ∞ÜÂü∫Á°ÄÁ≠ñÁï•ÂæÆË∞É‰∏∫**È´òÈÄü**Âíå**‰ΩéÈÄü**‰∏§‰∏™‰∏ìÂÆ∂Á≠ñÁï•Ôºå‰ª•Ëß£ÂÜ≥Âçï‰∏ÄÁ≠ñÁï•Âú®ÂÖ®ÈÄüÂ∫¶ËåÉÂõ¥Ë∑üË∏™‰∏äÁöÑÂàÜÂ∏ÉÂ∑ÆÂºÇÈóÆÈ¢ò„ÄÇ<br>3. **LoRAÂæÆË∞É**ÔºöÂ∞Ü‰∏§‰∏™‰∏ìÂÆ∂ÈõÜÊàêÂà∞‰∏Ä‰∏™ÁΩëÁªú‰∏≠Ôºå‰ΩøÁî®LoRAËøõË°åÂæÆË∞ÉÔºåÂæóÂà∞**Âπ≥ÊªëËøáÊ∏°ÁöÑÁªü‰∏ÄÁ≠ñÁï•**ÔºåÊ∂àÈô§Áõ¥Êé•ÂàáÊç¢Â∏¶Êù•ÁöÑÊéßÂà∂‰∏çËøûÁª≠ÊÄß„ÄÇ | **ÊÄßËÉΩ‰ºòÂåñ**Ôºö<br>1. **Ëß£ËÄ¶Â≠¶‰π†ÁõÆÊ†á**ÔºöÂÖàÂ≠¶ÂÆâÂÖ®ÔºåÂÜçÂ≠¶ÈÄüÂ∫¶ÔºåÈÅøÂÖç‰∫ÜÁõÆÊ†áÂÜ≤Á™Å„ÄÇ<br>2. **‰∏ìÂÆ∂ÂàÜÂ∑•**ÔºöÈíàÂØπ‰∏çÂêåÈÄüÂ∫¶Âå∫Èó¥ÁöÑÂä®ÂäõÂ≠¶ÁâπÊÄßËøõË°å‰∏ìÈó®‰ºòÂåñ„ÄÇ<br>3. **Á≠ñÁï•ËûçÂêà**ÔºöÂà©Áî®LoRAÂÆûÁé∞‰∏ìÂÆ∂Áü•ËØÜÁöÑÊó†ÁºùÊï¥ÂêàÔºåËé∑ÂæóÂÖ®ÈÄüÂüüÂπ≥Êªë„ÄÅÈ´òÊÄßËÉΩÁöÑÊúÄÁªàÁ≠ñÁï•„ÄÇ |\n| **ËÆ°ÁÆó‰∏éËßÑÂàí** | ÊÑüÁü•ÈÉ®ÂàÜÂÆûÊó∂ÈáçÂª∫Êú∫Âô®‰∫∫‰∏ãÊñπÁöÑÂú∞ÂΩ¢È´òÁ®ãÂõæ„ÄÇ**Ê≤°ÊúâÈõÜÊàêÊ®°ÂûãÈ¢ÑÊµãÊéßÂà∂Âô®(MPC)**ÔºåËßÑÂàíÂÆåÂÖ®Áî±Â≠¶‰π†Á≠ñÁï•ÈöêÂºèÂÆåÊàê„ÄÇ | **ÂàõÊñ∞ÊÄßÂú∞Â∞ÜËßÑÂàíÂô®Âπ∂Ë°åÂåñÂπ∂ÂµåÂÖ•RLËÆ≠ÁªÉÂæ™ÁéØ**„ÄÇÂ∞ÜDCMËêΩËÑöÁÇπ‰ºòÂåñÈóÆÈ¢ò**ÈáçÊûÑ‰∏∫Âπ∂Ë°åÁ¶ªÊï£ÊêúÁ¥¢**ÔºåÂà©Áî®GPUÂº†ÈáèÊìç‰ΩúÂÆûÁé∞ÔºåËÆ°ÁÆóÂºÄÈîÄÊûÅ‰ΩéÔºàÊØèÊ≠•~4msÔºâÔºåÁõ∏ÊØî‰º†ÁªüÂπ∂Ë°åMPCÂÆûÁé∞ÊèêÈÄüÁ∫¶**25ÂÄç**„ÄÇ | **ËÆ≠ÁªÉÊïàÁéá**ÔºöËß£ÂÜ≥‰∫ÜÂú®Âπ∂Ë°åRLÁéØÂ¢É‰∏≠ÈõÜÊàêÂÆûÊó∂‰ºòÂåñÁöÑËÆ°ÁÆóÁì∂È¢àÈóÆÈ¢òÔºå‰ΩøÂæó‚ÄúËßÑÂàíÂºïÂØºRL‚ÄùÁöÑÊ®°ÂºèÂú®Â§ßËßÑÊ®°ËÆ≠ÁªÉ‰∏≠ÂèòÂæóÂèØË°å„ÄÇ |\n| **ÂÆûÈ™åÈ™åËØÅ** | Âú®‰ªøÁúüÂíåÂÆûÁâ©Êú∫Âô®‰∫∫‰∏äÂ±ïÁ§∫‰∫ÜÂú®Á≤óÁ≥ôÂú∞Èù¢„ÄÅÊñúÂù°„ÄÅ‰ΩéÂè∞Èò∂Á≠âÂ§çÊùÇÂú∞ÂΩ¢‰∏äÁöÑÁ®≥ÂÅ•Ë°åËµ∞ÂíåÈÄüÂ∫¶Ë∑üË∏™ËÉΩÂäõ„ÄÇ | **‰∏ìÊ≥®‰∫éÊ•ºÊ¢ØÊÄßËÉΩ**ÔºöÂú®‰ªøÁúüÂíåÂÆûÁâ©‰∏äÁ≥ªÁªüÈ™åËØÅ‰∫ÜÈ´òÈÄüÔºàÈ´òËææ1.65 m/sÔºâ‰∏ä‰∏ãÊ•ºÊ¢ØÁöÑËÉΩÂäõÔºåÊàêÂäüÊåëÊàò‰∫Ü33Á∫ßËû∫ÊóãÊ•ºÊ¢Ø„ÄÇÂú®**ÂπøÂ∑ûÂ°îÊú∫Âô®‰∫∫ÁôªÊ•ºÊØîËµõ**‰∏≠Â§∫ÂÜ†„ÄÇÂÆöÈáèÂÆûÈ™åË°®ÊòéÔºåÂÖ∂**Âú∞ÂΩ¢Á©øË∂äÊàêÂäüÁéáÂíåÈÄüÂ∫¶Ë∑üË∏™ËØØÂ∑ÆÂùáÊòæËëó‰ºò‰∫éÂâç‰ΩúÂèäAMPÁ≠âÂü∫Á∫øÊñπÊ≥ï**„ÄÇ | **‰ªªÂä°ÊÄßËÉΩÁ™ÅÁ†¥**ÔºöÂÆûÁé∞‰∫Ü‰∫∫ÂΩ¢Êú∫Âô®‰∫∫È´òÈÄü„ÄÅÁ®≥ÂÆöÁà¨Ê•ºÊ¢ØËøô‰∏ÄÊ†áÂøóÊÄßËøõÂ±ïÔºåËØÅÊòé‰∫ÜÊâÄÊèêÊ°ÜÊû∂Âú®Ëß£ÂÜ≥ÁâπÂÆöÈ´òÈöæÂ∫¶‰ªªÂä°‰∏äÁöÑ‰ºòË∂äÊÄß„ÄÇ |\n\n### ÊÄªÁªìÔºöFastStair Áõ∏ÂØπ‰∫éÂâç‰ΩúÁöÑÊ†∏ÂøÉÊîπÂä®‰∏éÊèêÂçá\n\n1.  **ÈóÆÈ¢òÂÆö‰πâÂçáÁ∫ß**Ôºö‰ªéÂâç‰ΩúÁöÑ‚ÄúÂ§çÊùÇÂú∞ÂΩ¢Á®≥ÂÅ•Ë°åËµ∞‚ÄùËÅöÁÑ¶Âà∞Êõ¥ÂÖ∑ÊåëÊàòÊÄßÁöÑ‚Äú**È´òÈÄüÊ•ºÊ¢ØËøêÂä®**‚ÄùÔºåÁõ¥Èù¢ÊïèÊç∑ÊÄß‰∏éÁ®≥ÂÆöÊÄßÁöÑÊ†∏ÂøÉÁüõÁõæ„ÄÇ\n2.  **ÊñπÊ≥ïËÆ∫ËûçÂêà**Ôºö‰ªé‚ÄúÁ∫ØÂ≠¶‰π†‚ÄùËΩ¨Âêë‚Äú**ËßÑÂàíÂºïÂØºÂ≠¶‰π†**‚Äù„ÄÇÂÖ≥ÈîÆÂàõÊñ∞ÊòØÂºïÂÖ•‰∫Ü**Âü∫‰∫éDCMÁöÑÂπ∂Ë°åËêΩËÑöÁÇπËßÑÂàíÂô®**‰Ωú‰∏∫ÊòæÂºèÂÆâÂÖ®ÂÖàÈ™åÔºåÂπ∂ÈÄöËøá**‰ºòÂåñËΩ¨ÊêúÁ¥¢**ÊäÄÊúØ‰ΩøÂÖ∂‰∏éÂ§ßËßÑÊ®°Âπ∂Ë°åRLËÆ≠ÁªÉÂÖºÂÆπ„ÄÇ\n3.  **ËÆ≠ÁªÉÊµÅÁ®ãÁ≤æÁªÜÂåñ**ÔºöËÆæËÆ°‰∫Ü**‰∏âÈò∂ÊÆµËÆ≠ÁªÉÊ°ÜÊû∂**ÔºàÂÆâÂÖ®È¢ÑËÆ≠ÁªÉ -> ÈÄüÂ∫¶‰∏ìÂÆ∂Âåñ -> LoRAÁªü‰∏ÄÔºâÔºåÁ≥ªÁªüÂåñÂú∞Ëß£ÂÜ≥‰∫ÜÂçï‰∏ÄÁ≠ñÁï•Âú®ÂÖºÈ°æÂÆâÂÖ®‰∏éÈ´òÈÄüÊó∂ÁöÑÂ±ÄÈôêÊÄßÔºå‰ª•Âèä‰∏ìÂÆ∂ÂàáÊç¢ÁöÑÁ®≥ÂÆöÊÄßÈóÆÈ¢ò„ÄÇ\n4.  **ÊÄßËÉΩÊòæËëóÊèêÂçá**ÔºöÂú®Ê•ºÊ¢Ø‰ªªÂä°‰∏äÔºåÊó†ËÆ∫ÊòØÊàêÂäüÁéá„ÄÅÈÄüÂ∫¶‰∏äÈôêËøòÊòØÈÄüÂ∫¶Ë∑üË∏™Á≤æÂ∫¶ÔºåÈÉΩÂÆûÁé∞‰∫ÜÂØπÂâç‰ΩúÂèä‰∏ªÊµÅÊñπÊ≥ïÁöÑË∂ÖË∂äÔºåÂπ∂ÈÄöËøáÂÆûÁâ©ÈÉ®ÁΩ≤È™åËØÅ‰∫ÜÂÖ∂ÂÆûÈôÖÂ∫îÁî®‰ª∑ÂÄº„ÄÇ\n\n**Êú¨Ë¥®Âå∫Âà´**ÔºöÂâç‰Ωú `[21]` ‰ª£Ë°®‰∫ÜÂà©Áî®ÊÑüÁü•ÂÆûÁé∞Á®≥ÂÅ•Âú∞ÂΩ¢ÈÄÇÂ∫îÁöÑÂÖàËøõÁ∫ØRLÊñπÊ≥ïÔºõËÄå **FastStair ÊòØ‰∏ì‰∏∫Á™ÅÁ†¥ÊûÅÈôêÊÄßËÉΩ‰ªªÂä°ÔºàÈ´òÈÄüÁà¨Ê•ºÔºâËÆæËÆ°ÁöÑ„ÄÅËûçÂêàÊ®°Âûã‰∏éÂ≠¶‰π†‰ºòÂäøÁöÑ‰∏ã‰∏Ä‰ª£Ê°ÜÊû∂**ÔºåÂÖ∂ÊîπËøõÊòØÁ≥ªÁªüÊÄßÂíåÊ†πÊú¨ÊÄßÁöÑ„ÄÇ",
            "timestamp": "2026-01-20T17:59:27.409056",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "ËÆ∫ÊñáÊèêÂá∫‰∫ÜÂì™‰∫õÂÖ≥ÈîÆÊäÄÊúØÊñπÊ≥ïÔºåËØ∑ÂàóË°®Ê†ºÂÖ∑‰ΩìËØ¶ÁªÜËØ¥ÊòéÊäÄÊúØÁªÜËäÇÔºåÈúÄË¶ÅÂåÖÂê´ÂÖ∑‰ΩìÁöÑÊï∞Â≠¶ÂéüÁêÜÊé®ÂØºÔºå‰ª•ÂèäÂÖ∑‰ΩìÂèÇÊï∞„ÄÇ",
            "answer": "## FastStair ÂÖ≥ÈîÆÊäÄÊúØÊñπÊ≥ïÂàÜÊûê\n\nËØ•ËÆ∫ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫ **FastStair** ÁöÑËßÑÂàíÂºïÂØº„ÄÅÂ§öÈò∂ÊÆµÂ≠¶‰π†Ê°ÜÊû∂ÔºåÊó®Âú®Ëß£ÂÜ≥‰∫∫ÂΩ¢Êú∫Âô®‰∫∫È´òÈÄü‰∏äÊ•ºÊ¢ØÊó∂Èù¢‰∏¥ÁöÑ**ÊïèÊç∑ÊÄß‰∏éÁ®≥ÂÆöÊÄß**ÁöÑÊ†∏ÂøÉÁüõÁõæ„ÄÇÂÖ∂ÂÖ≥ÈîÆÊäÄÊúØÊñπÊ≥ïÈÄöËøáÊï¥ÂêàÊ®°ÂûãËßÑÂàí‰∏éÂº∫ÂåñÂ≠¶‰π†ÔºåÂπ∂ÈááÁî®ÂàÜÈò∂ÊÆµËÆ≠ÁªÉ‰∏éÊ®°ÂûãËûçÂêàÁ≠ñÁï•Êù•ÂÆûÁé∞„ÄÇ\n\n‰ª•‰∏ãÊòØÂÖ≥ÈîÆÊäÄÊúØÊñπÊ≥ïÁöÑËØ¶ÁªÜËØ¥ÊòéË°®Ê†ºÔºö\n\n| ÊäÄÊúØÊñπÊ≥ï | Ê†∏ÂøÉÁõÆÊ†á | ÊäÄÊúØÁªÜËäÇ‰∏éÊï∞Â≠¶ÂéüÁêÜ | ÂÖ∑‰ΩìÂèÇÊï∞/ÂÆûÁé∞ |\n| :--- | :--- | :--- | :--- |\n| **1. Âü∫‰∫éDCMÁöÑÂπ∂Ë°åËêΩËÑöÁÇπËßÑÂàíÂô®** | ‰∏∫RLËÆ≠ÁªÉÊèê‰æõ**ÊòæÂºèÁöÑÂä®ÊÄÅÂèØË°åÊÄß‰∏éÁ®≥ÂÆöÊÄßÂºïÂØº**ÔºåÂ∞Ü‰ºòÂåñÈóÆÈ¢òËΩ¨Âåñ‰∏∫È´òÊïàÁöÑGPUÂπ∂Ë°åÊêúÁ¥¢„ÄÇ | **a. Âä®ÂäõÂ≠¶Ê®°ÂûãÔºö** ÈááÁî®**ÂèòÈ´òÂ∫¶ÂÄíÁ´ãÊëÜÔºàVHIPÔºâ** Ê®°Âûã‰ª•ÈÄÇÂ∫îÊ•ºÊ¢ØÂú∞ÂΩ¢„ÄÇÂä®ÂäõÂ≠¶ÊñπÁ®ã‰∏∫Ôºö<br> `\\ddot{x} = \\omega^2 x`Ôºå ÂÖ∂‰∏≠ `x` ‰∏∫Ë¥®ÂøÉ(CoM)Ê∞¥Âπ≥‰ΩçÁΩÆÔºå `\\omega = \\sqrt{g / z(t)}` ‰∏∫Êó∂ÂèòËá™ÁÑ∂È¢ëÁéáÔºå `z(t) = kt + z_0` ‰∏∫Á∫øÊÄßÂèòÂåñÁöÑCoMÈ´òÂ∫¶„ÄÇ<br>**b. DCMÂÆö‰πâ‰∏éËøë‰ººÔºö** ÂèëÊï£ËøêÂä®ÂàÜÈáèÂÆö‰πâ‰∏∫ `\\xi = x + \\dot{x}/\\omega`„ÄÇÂØπÂÖ∂Ê±ÇÂØºÂπ∂‰ª£ÂÖ•Âä®ÂäõÂ≠¶ÊñπÁ®ãÔºåÂæóÂà∞Á≤æÁ°ÆÊºîÂåñÔºö<br> `\\dot{\\xi} = a\\omega\\xi + (1-a)\\omega x`Ôºå ÂÖ∂‰∏≠ `a = 1 + k/(2\\sqrt{gz})`„ÄÇ<br> Áî±‰∫éÊ•ºÊ¢ØÂù°Â∫¶ÈÄöÂ∏∏ `k ‚àà [-1, 1]`Ôºå `a ‚âà 1`ÔºåÂõ†Ê≠§ÂèØÁÆÄÂåñ‰∏∫Ëøë‰ººÁ∫øÊÄßÊó∂ÂèòÁ≥ªÁªüÔºö<br> `\\dot{\\xi} ‚âà \\omega\\xi`Ôºå ÂÖ∂Ëß£‰∏∫ `\\xi(t) = \\xi_0 e^{\\int_0^t \\omega(\\tau)d\\tau} = \\xi_0 e^{\\sigma(t)}`„ÄÇ<br>**c. ‰ºòÂåñÈóÆÈ¢òËΩ¨Âåñ‰∏∫ÊêúÁ¥¢Ôºö** Âü∫‰∫éÁÆÄÂåñDCMÂä®ÂäõÂ≠¶ÔºåËêΩËÑöÁÇπËßÑÂàíË¢´Ë°®Ëø∞‰∏∫‰∏Ä‰∏™Â∏¶Á∫¶ÊùüÁöÑ‰ºòÂåñÈóÆÈ¢òÔºàÂºè2-4ÔºâÔºåÁõÆÊ†áÊòØÊâæÂà∞ÊúÄ‰ºòËêΩËÑöÁÇπ `u_T` ÂíåDCMÂÅèÁßª `b`ÔºåÊúÄÂ∞èÂåñ‰∏éÊ†áÁß∞ÁõÆÊ†áÁöÑË∑ùÁ¶ªÂèäÂú∞ÂΩ¢Èô°Â∫¶‰ª£‰ª∑ `S(u_T)`„ÄÇ**ÂÖ≥ÈîÆÂàõÊñ∞**Âú®‰∫éÂà©Áî®Á≠âÂºèÁ∫¶Êùü `u_T + b = \\xi_t e^{\\sigma(T)-\\sigma(t)}`Ôºå‰∏∫Á¶ªÊï£ÂÄôÈÄâÁÇπÈõÜ `P` ‰∏≠ÁöÑÊØè‰∏™ÁÇπËß£ÊûêËÆ°ÁÆóÂØπÂ∫îÁöÑ `b`Ôºå‰ªéËÄåÂ∞ÜÊï¥‰∏™‰ºòÂåñËØÑ‰º∞ËΩ¨Âåñ‰∏∫Âú®GPU‰∏äÂØπÂÄôÈÄâÁÇπÊàêÊú¨ÂáΩÊï∞ÁöÑ**Âπ∂Ë°åÂêëÈáèÂåñËÆ°ÁÆó**ÔºåÊúÄÂêéÈÄöËøá `argmin` ÈÄâÂèñÊúÄ‰ºòÁÇπ„ÄÇ | - **Âú∞ÂΩ¢ÊÑüÁü•ËåÉÂõ¥Ôºö** `1.8m √ó 1.2m` ÁöÑÂ±ÄÈÉ®È´òÁ®ãÂõæÔºåÂàÜËæ®Áéá `5cm`„ÄÇ<br>- **ÊêúÁ¥¢Á™óÂè£Ôºö** ‰ª•Ê†áÁß∞ËêΩËÑöÁÇπ `[L_nom, W_nom]^T` ‰∏∫‰∏≠ÂøÉÁöÑ `0.6m √ó 0.6m` Âå∫Âüü„ÄÇ<br>- **Èô°Â∫¶ËØÑÂàÜ `S(u_T)`Ôºö** ‰ΩøÁî®SobelÁÆóÂ≠êËÆ°ÁÆóÈ´òÁ®ãÂõæÊ¢ØÂ∫¶ÔºåÂÜçÈÄöËøáÂç∑ÁßØÊ†∏Ôºà‰∏éËÑöÊéåÂ∞∫ÂØ∏ÂåπÈÖçÔºâËøõË°åÂ±ÄÈÉ®ËÅöÂêàÔºåÂæóÂà∞Âú∞ÂΩ¢Èô°Â∫¶ÊàêÊú¨Âõæ„ÄÇ<br>- **ËÆ°ÁÆóÊïàÁéáÔºö** Âú®NVIDIA RTX 4090‰∏äÔºåÂØπ4096‰∏™Âπ∂Ë°åÁéØÂ¢ÉËøõË°åÂçïÊ≠•ËßÑÂàíÂª∂ËøüÁ∫¶ **4ms**ÔºåÁõ∏ÊØî‰º†ÁªüÂπ∂Ë°åMPCÂÆûÁé∞Âä†ÈÄüÁ∫¶ **25ÂÄç**„ÄÇ |\n| **2. Â§öÈò∂ÊÆµÂº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂** | ÂàÜÈò∂ÊÆµËß£ÂÜ≥**ÂÆâÂÖ®ÊÄßÂºïÂØº„ÄÅÈÄüÂ∫¶ËøΩË∏™Á≤æÂ∫¶ÊèêÂçá„ÄÅÂÖ®ÈÄüÂüüÂπ≥ÊªëÊéßÂà∂**ÁöÑÈóÆÈ¢òÔºåÈÅøÂÖçÂçï‰∏ÄÁ≠ñÁï•ÁöÑÂ±ÄÈôêÊÄß„ÄÇ | **a. È¢ÑËÆ≠ÁªÉÈò∂ÊÆµÔºàÂÆâÂÖ®Âü∫Á°ÄÁ≠ñÁï•ÔºâÔºö** <br>   - **ÁõÆÊ†áÔºö** ‰ºòÂÖà‰øùËØÅÁ©øË∂äÊ•ºÊ¢ØÁöÑ**Á®≥ÂÆöÊÄß**„ÄÇ<br>   - **ÊñπÊ≥ïÔºö** Âú®Â•ñÂä±ÂáΩÊï∞‰∏≠Ëµã‰∫à**ËêΩËÑöÁÇπË∑üË∏™Â•ñÂä±** `r_foot = exp(-10 * ||p_f - p_f^d||)` ÊûÅÈ´òÁöÑÊùÉÈáçÔºà0.6Ôºâ„ÄÇÂÖ∂‰∏≠ `p_f^d` ÊòØÂü∫‰∫éËßÑÂàíÂô®ËæìÂá∫ËêΩËÑöÁÇπ `u_T` ÂíåÂú∞ÂΩ¢È´òÂ∫¶ `h_z` ÈÄöËøáË¥ùÂ°ûÂ∞îÊõ≤Á∫øÊèíÂÄºÁîüÊàêÁöÑÊúüÊúõÊëÜÂä®ËÑöËΩ®Ëøπ„ÄÇ<br>   - **ÊïàÊûúÔºö** Á≠ñÁï•Â≠¶‰ºöÂ∞ÜËÑöÊîæÁΩÆÂú®Ê•ºÊ¢ØË∏èÈù¢‰∏≠ÂøÉÁ≠âÂÆâÂÖ®Âå∫ÂüüÔºå‰ΩÜÈÄüÂ∫¶Ë∑üË∏™Á≤æÂ∫¶ËæÉÂ∑Æ„ÄÇ<br><br>**b. ÂêéËÆ≠ÁªÉÈò∂ÊÆµÔºàÈÄüÂ∫¶‰∏ìÂÆ∂Á≠ñÁï•ÔºâÔºö** <br>   - **ÁõÆÊ†áÔºö** Âú®ÂÆâÂÖ®Âü∫Á°Ä‰∏äÔºåÊèêÂçá**ÈÄüÂ∫¶Ë∑üË∏™Á≤æÂ∫¶**Âíå**È´òÈÄüËøêÂä®ËÉΩÂäõ**„ÄÇ<br>   - **ÊñπÊ≥ïÔºö** Ë∞ÉÊï¥Â•ñÂä±ÊùÉÈáçÔºàËßÅË°®IÔºâÔºåÈôç‰ΩéËêΩËÑöÁÇπË∑üË∏™ÊùÉÈáçÔºà0.5‚Üí0.4ÔºâÔºåÊèêÈ´òÁ∫øÈÄüÂ∫¶Ë∑üË∏™ÊùÉÈáçÔºà1.0‚Üí1.35Ôºâ„ÄÇÂ∞ÜÊåá‰ª§ÈÄüÂ∫¶Á©∫Èó¥ÂàíÂàÜ‰∏∫**‰ΩéÈÄüÂå∫** `[-0.3, 0.8] m/s` Âíå**È´òÈÄüÂå∫** `[0.8, 1.6] m/s`ÔºåÂàÜÂà´‰ªéÈ¢ÑËÆ≠ÁªÉÁ≠ñÁï•ÂæÆË∞ÉÂá∫‰∏§‰∏™**‰∏ìÂÆ∂Á≠ñÁï•**„ÄÇËøôÊòØÂõ†‰∏∫È´òÈÄü‰∏é‰ΩéÈÄüËøêÂä®ÂØπÂ∫îÁöÑÂÖ≥ËäÇÂä®‰ΩúÂàÜÂ∏ÉÂ∑ÆÂºÇÊòæËëóÔºåÂçï‰∏ÄÁ≠ñÁï•ÊòìÂØºËá¥Ê®°ÂºèÂùçÁº©„ÄÇ<br><br>**c. LoRAÂæÆË∞ÉÈò∂ÊÆµÔºàÁªü‰∏ÄÁ≠ñÁï•ÔºâÔºö** <br>   - **ÁõÆÊ†áÔºö** Ê∂àÈô§‰∏§‰∏™‰∏ìÂÆ∂Á≠ñÁï•Áõ¥Êé•ÂàáÊç¢ÂØºËá¥ÁöÑ**ÊéßÂà∂‰∏çËøûÁª≠**Âíå**ÊäñÂä®**„ÄÇ<br>   - **ÊñπÊ≥ïÔºö** Â∞Ü‰∏§‰∏™‰∏ìÂÆ∂ÁΩëÁªúÁöÑÂèÇÊï∞ÂêàÂπ∂Âà∞‰∏Ä‰∏™Áªü‰∏ÄÁΩëÁªú‰∏≠ÔºåÂπ∂Âú®ÂÖ∂ÂàÜÊîØ‰∏äÊ∑ªÂä†**‰ΩéÁß©ÈÄÇÂ∫îÔºàLoRAÔºâÂ±Ç**„ÄÇÁÑ∂Âêé‰ΩøÁî®Ë¶ÜÁõñÂÖ®ÈÄüÂüü `[-0.3, 1.6] m/s` ÁöÑÊåá‰ª§ÂØπËØ•Áªü‰∏ÄÁΩëÁªúËøõË°åÂæÆË∞É„ÄÇLoRAÂÖÅËÆ∏È´òÊïàÂú∞Ë∞ÉÊï¥ÂêàÂπ∂ÂêéÁöÑÊ®°ÂûãÔºåÂπ≥Êªë‰∏çÂêåÈÄüÂ∫¶Âå∫Èó¥ÁöÑËøáÊ∏°„ÄÇÈÉ®ÁΩ≤Êó∂ÔºåÊ†πÊçÆÊåá‰ª§ÈÄüÂ∫¶ `v_x^d` ÊòØÂê¶Â§ß‰∫é `0.8 m/s` Êù•ÊøÄÊ¥ªÁõ∏Â∫î‰∏ìÂÆ∂ÂàÜÊîØ„ÄÇ | - **ÁΩëÁªúÊû∂ÊûÑÔºö** Ê≤øÁî®Actor-CriticÊû∂ÊûÑÔºåËßÇÊµãÁ©∫Èó¥ÂåÖÂê´Êú¨‰ΩìÊÑüÁü•„ÄÅÁâπÊùÉ‰ø°ÊÅØÔºàÂ¶ÇËßÑÂàíÂô®ËæìÂá∫ÁöÑÊúÄ‰ºòËêΩËÑöÁÇπÔºâÂíå‰ª•Êú∫Âô®‰∫∫‰∏∫‰∏≠ÂøÉÁöÑÂ±ÄÈÉ®È´òÁ®ãÂõæ„ÄÇ<br>- **ËÆ≠ÁªÉËßÑÊ®°Ôºö** Âú®IsaacLab‰∏≠Âπ∂Ë°å4096‰∏™ÁéØÂ¢ÉÔºåÊ≠•È¢ë `[1.0, 1.5] Hz`ÔºåÊåá‰ª§ÊØè10ÁßíÈáçÈááÊ†∑„ÄÇ<br>- **Â•ñÂä±ÊùÉÈáçÔºö** ÂÖ≥ÈîÆÊùÉÈáçÂèòÂåñËßÅËÆ∫ÊñáË°®IÔºàÂ¶ÇÁ∫øÈÄüÂ∫¶Ë∑üË∏™„ÄÅËêΩËÑöÁÇπË∑üË∏™„ÄÅÊäïÂΩ±ÈáçÂäõÁ≠âÊùÉÈáçÁöÑÈò∂ÊÆµÊÄßË∞ÉÊï¥Ôºâ„ÄÇ<br>- **LoRAÂèÇÊï∞Ôºö** ÂæÆË∞ÉÊó∂ËÆæÁΩÆ `Œ±=16`, `Œ≥=8`„ÄÇ |\n| **3. ÊÑüÁü•‰∏éÈÉ®ÁΩ≤ÊµÅÊ∞¥Á∫ø** | ÂÆûÁé∞‰ªé‰ªøÁúüÂà∞ÂÆûÁâ©ÁöÑ**Èõ∂Ê¨°ËøÅÁßªÔºàZero-Shot Sim2RealÔºâ**Ôºå‰∏∫Á≠ñÁï•Êèê‰æõÂÆûÊó∂ÁöÑÂú∞ÂΩ¢ÊÑüÁü•„ÄÇ | **a. È´òÁ®ãÂõæÈáçÂª∫Ôºö** <br>   - **‰ªøÁúü‰∏≠Ôºö** Áõ¥Êé•‰ªéIsaacLabÊé•Âè£Ëé∑ÂèñÁúüÂÆûÂú∞ÂΩ¢È´òÂ∫¶Ê†∑Êú¨„ÄÇ<br>   - **ÂÆûÁâ©‰∏äÔºö** ‰ΩøÁî®Intel RealSense D435iÊ∑±Â∫¶Áõ∏Êú∫„ÄÇÂÆûÊó∂Â§ÑÁêÜÊ∑±Â∫¶Â∏ßÔºåÈáçÂª∫‰ª•Êú∫Âô®‰∫∫‰∏∫‰∏≠ÂøÉÁöÑ `1.8m √ó 1.2m` Â±ÄÈÉ®Âú∞ÂΩ¢ÁΩëÊ†ºÔºàÂàÜËæ®Áéá5cmÔºâÔºåÁîüÊàê‚ÄúÂú∞ÂΩ¢Êï£ÁÇπ‚Äù‰Ωú‰∏∫Á≠ñÁï•ÁöÑÊÑüÁü•ËæìÂÖ•„ÄÇ<br><br>**b. ÂàÜÂ∏ÉÂºèËÆ°ÁÆóÈÉ®ÁΩ≤Ôºö** <br>   - **ÊÑüÁü•Ê®°ÂùóÔºö** Âú®NVIDIA Jetson Orin NX‰∏äËøêË°åÔºåÂ§ÑÁêÜÊ∑±Â∫¶ÂõæÂÉèÂπ∂ÁîüÊàêÈ´òÁ®ãÂõæ„ÄÇ<br>   - **ÊéßÂà∂Ê®°ÂùóÔºö** Âú®Rockchip RK3588ÂçïÊùøËÆ°ÁÆóÊú∫‰∏äËøêË°åÔºåÊé•Êî∂È´òÁ®ãÂõæÂπ∂ÊâßË°åÁªü‰∏ÄÁ≠ñÁï•ÔºåÊéßÂà∂È¢ëÁéá‰∏∫ **100 Hz**„ÄÇ | - **Êú∫Âô®‰∫∫Âπ≥Âè∞Ôºö** LimX Oli‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ÔºåË∫´È´ò1.65mÔºå‰ΩìÈáç55kgÔºå31‰∏™È©±Âä®Ëá™Áî±Â∫¶„ÄÇ<br>- **ÊéßÂà∂È¢ëÁéáÔºö** 100 Hz„ÄÇ<br>- **ÊÑüÁü•Á°¨‰ª∂Ôºö** Intel RealSense D435i Ê∑±Â∫¶Áõ∏Êú∫„ÄÇ |\n\n### **ÊäÄÊúØÂàõÊñ∞‰∏éÂÆûÈôÖ‰ª∑ÂÄºÊÄªÁªì**\n\n1.  **ËßÑÂàí‰∏éÂ≠¶‰π†ÁöÑÊ∑±Â∫¶ËûçÂêà**Ôºö Â∞Ü**Ê®°ÂûãÂåñDCMËßÑÂàíÂô®**ÁöÑÊòæÂºèÁ®≥ÂÆöÊÄß‰øùËØÅÔºåÈÄöËøá‚Äú‰ºòÂåñÂç≥ÊêúÁ¥¢‚ÄùÁöÑÂπ∂Ë°åÂåñÂΩ¢ÂºèÔºåÊó†ÁºùÂµåÂÖ•**Ê®°ÂûãÊó†ÂÖ≥RL**ÁöÑËÆ≠ÁªÉÂæ™ÁéØ‰∏≠‰Ωú‰∏∫ÂºïÂØº‰ø°Âè∑„ÄÇËøôËß£ÂÜ≥‰∫ÜÁ∫ØRLÂú®Â§çÊùÇÂú∞ÂΩ¢‰∏äÊé¢Á¥¢ÊïàÁéá‰Ωé„ÄÅÂÆâÂÖ®ÊÄßÂ∑ÆÁöÑÈóÆÈ¢ò„ÄÇ\n2.  **Ëß£ÂÜ≥‚ÄúÂºïÂØºÂç≥‰øùÂÆà‚ÄùÁöÑÊÇñËÆ∫**Ôºö ÈÄöËøá**Â§öÈò∂ÊÆµËÆ≠ÁªÉ**Á≠ñÁï•ÔºåÂÖàÂà©Áî®ËßÑÂàíÂô®Â≠¶Âæó‚ÄúÂÆâÂÖ®Âü∫Á°Ä‚ÄùÔºåÂÜçÈÄöËøá**Â•ñÂä±ÈáçÂä†ÊùÉ**Âíå**ÈÄüÂ∫¶Âå∫Èó¥ÂàíÂàÜ**ÂüπÂÖª‚ÄúÈ´òÈÄü‰∏ìÂÆ∂‚ÄùÔºåÊúÄÂêéÁî®**LoRAÊäÄÊúØ**Â∞Ü‰∏ìÂÆ∂Âπ≥ÊªëËûçÂêà„ÄÇËøôÊâìÁ†¥‰∫Ü‰º†ÁªüËßÑÂàíÂºïÂØºRLÂØºËá¥ÁöÑÊïèÊç∑ÊÄß‰∏äÈôêÔºåÂÆûÁé∞‰∫ÜÂÆâÂÖ®‰∏éÈÄüÂ∫¶ÁöÑÂÖºÂæó„ÄÇ\n3.  **ÊûÅÈ´òÁöÑÁ≥ªÁªüÊïàÁéá‰∏éÂ∑•Á®ãÂèØË°åÊÄß**Ôºö ËßÑÂàíÂô®GPUÂπ∂Ë°åÂåñÂ∏¶Êù•25ÂÄçÂä†ÈÄüÔºå‰ΩøÂú®Á∫øÂºïÂØºËÆ≠ÁªÉÊàê‰∏∫ÂèØËÉΩÔºõÂ§ö‰∏ìÂÆ∂LoRAËûçÂêàÊñπÊ°àËÆ°ÁÆóÈáèÂ∞èÔºåÈÄÇÂêàÂú®**ÂµåÂÖ•ÂºèÂπ≥Âè∞ÔºàRK3588Ôºâ** ‰∏äÂÆûÊó∂ËøêË°åÔºåÊúÄÁªàÂú®ÂÆûÁâ©Êú∫Âô®‰∫∫‰∏äÂÆûÁé∞‰∫ÜÈ´òËææ **1.65 m/s** ÁöÑÁ®≥ÂÆö‰∏äÊ•ºÊ¢ØÈÄüÂ∫¶ÔºåÂπ∂Âú®ÂπøÂ∑ûÂ°îÁà¨Ê•ºÊØîËµõ‰∏≠Ëé∑ËÉúÔºåËØÅÊòé‰∫ÜÂÖ∂Âº∫Â§ßÁöÑÂÆûÈôÖÂ∫îÁî®‰ª∑ÂÄº„ÄÇ",
            "timestamp": "2026-01-20T18:00:30.152359",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "‰ªñ‰ΩøÁî®‰∫ÜÂì™‰∫õËØÑ‰ª∑ÊåáÊ†á‰∏éÊï∞ÊçÆÈõÜÔºåÂàóË°®Ê†ºÂÖ∑‰ΩìËÆ≤ËÆ≤‰ªñÁöÑËØÑ‰ª∑ÊåáÊ†áÁöÑÁªÜËäÇ‰∏éÊï∞ÊçÆÈõÜÁöÑÁªÜËäÇ",
            "answer": "## ËÆ∫Êñá„ÄäFastStair: Learning to Run Up Stairs with Humanoid Robots„ÄãÁöÑËØÑ‰ª∑ÊåáÊ†á‰∏éÊï∞ÊçÆÈõÜÂàÜÊûê\n\nÊú¨ÊñáÈÄöËøá**‰ªøÁúüÂÆûÈ™å**Âíå**ÁúüÂÆû‰∏ñÁïåÈÉ®ÁΩ≤**Êù•ËØÑ‰º∞ÊâÄÊèêÂá∫ÁöÑFastStairÊ°ÜÊû∂„ÄÇÂÖ∂ËØÑ‰ª∑ÊåáÊ†á‰∏ªË¶ÅÂõ¥Áªï**‰ªªÂä°ÊàêÂäüÁéá**„ÄÅ**ËøêÂä®ÊéßÂà∂Á≤æÂ∫¶**Âíå**ËÆ°ÁÆóÊïàÁéá**‰∏â‰∏™ÊñπÈù¢„ÄÇÊï∞ÊçÆÈõÜÂàô‰∏ªË¶ÅÊòØÂú®‰ªøÁúüÁéØÂ¢É‰∏≠ÊûÑÂª∫ÁöÑ**Â§öÊ†∑ÂåñËÆ≠ÁªÉËØæÁ®ã**ÂíåÁî®‰∫éËØÑ‰º∞ÁöÑ**ÁâπÂÆöÊµãËØïÂú∫ÊôØ**„ÄÇ\n\n### ‰∏Ä„ÄÅ ‰∏ªË¶ÅËØÑ‰ª∑ÊåáÊ†á\n\n| ÊåáÊ†áÁ±ªÂà´ | ÂÖ∑‰ΩìÊåáÊ†á | ËÆ°ÁÆóÊñπÂºè / ÂÆö‰πâ | ËØÑ‰º∞ÁõÆÁöÑ‰∏éÁªÜËäÇ |\n| :--- | :--- | :--- | :--- |\n| **‰ªªÂä°ÊàêÂäüÁéá** | Âú∞ÂΩ¢Á©øË∂äÊàêÂäüÁéá (Terrain Traversal Success Ratio) | `ÊàêÂäüÁéØÂ¢ÉÊï∞ / ÊÄªÁéØÂ¢ÉÊï∞`„ÄÇÂú®‰ªøÁúü‰∏≠ÔºåÂàùÂßãÂåñÂ§ßÈáèÊú∫Âô®‰∫∫ÔºåÂëΩ‰ª§ÂÖ∂Á©øË∂äÂú∞ÂΩ¢„ÄÇÊàêÂäüÂÆö‰πâ‰∏∫ÔºöÂú® episode ÂÜÖÂà∞ËææÂú∞ÂΩ¢ËøúÁ´Ø‰∏îÊú™ÊëîÂÄí„ÄÇ | **Ê†∏ÂøÉÊÄßËÉΩÊåáÊ†á**„ÄÇÁî®‰∫éË°°ÈáèÁ≠ñÁï•Âú®**È´òÈöæÂ∫¶Ê•ºÊ¢Ø**Ôºà25cmÈò∂È´òÔºâ‰∏äÔºåÂú®‰∏çÂêåÊåá‰ª§ÈÄüÂ∫¶Ôºà0.5, 1.0, 1.5, 2.0 m/sÔºâ‰∏ãÁöÑ**Êï¥‰ΩìÈ≤ÅÊ£íÊÄß**„ÄÇËØ•ÊåáÊ†áÁõ¥Êé•ÂèçÊò†‰∫ÜÊñπÊ≥ïÂú®ÂÆâÂÖ®ÊÄß‰∏éÊïèÊç∑ÊÄß‰πãÈó¥ÁöÑÂπ≥Ë°°ËÉΩÂäõ„ÄÇ |\n| **ËøêÂä®ÊéßÂà∂Á≤æÂ∫¶** | 1. ÈÄüÂ∫¶Ë∑üË∏™Âπ≥ÂùáÁªùÂØπËØØÂ∑Æ (Velocity-Tracking MAE) | `MAE = mean( | ÂÆûÈôÖÂâçÂêëÈÄüÂ∫¶ - Êåá‰ª§ÂâçÂêëÈÄüÂ∫¶ | )`„ÄÇÂú®Âõ∫ÂÆöÊ•ºÊ¢Ø‰∏äÔºåÊåá‰ª§ÈÄüÂ∫¶Âë®ÊúüÊÄßÂèòÂåñÔºåËÆ°ÁÆóÊï¥‰∏™ËøáÁ®ãÁöÑË∑üË∏™ËØØÂ∑Æ„ÄÇ | ËØÑ‰º∞Á≠ñÁï•**Á≤æÁ°ÆÊâßË°åÈÄüÂ∫¶ÂëΩ‰ª§**ÁöÑËÉΩÂäõ„ÄÇËæÉ‰ΩéÁöÑMAEË°®ÊòéÁ≠ñÁï•ËÉΩÊõ¥Â•ΩÂú∞ÂìçÂ∫îÁî®Êà∑Êåá‰ª§ÔºåÊòØÂÆûÁé∞**È´òÈÄü„ÄÅÂèØÊéß**Áà¨Ê•ºÊ¢ØÁöÑÂÖ≥ÈîÆ„ÄÇËÆ∫ÊñáÁâπÂà´ÂØπÊØî‰∫Ü‰∏çÂêåÊñπÊ≥ïÂú®Ê≠§ÊåáÊ†á‰∏äÁöÑÂ∑ÆÂºÇ„ÄÇ |\n| | 2. ËêΩËÑöÁÇπË∑üË∏™ËØØÂ∑Æ (Foothold-Tracking Error) | ËÆ°ÁÆó**ÊâßË°åËêΩËÑöÁÇπ**‰∏é**ËßÑÂàíÂô®ÁîüÊàêÁöÑÊúüÊúõËêΩËÑöÁÇπ**‰πãÈó¥ÁöÑ**Âπ≥ÂùáÂπ≥Èù¢Ê¨ßÊ∞èË∑ùÁ¶ª**„ÄÇ | Áî®‰∫éÈáèÂåñ**Ê®°ÂûãËßÑÂàíÂô®ÂØπRLÁ≠ñÁï•ÁöÑÂºïÂØºÊïàÊûú**„ÄÇÂú®È¢ÑËÆ≠ÁªÉÈò∂ÊÆµÔºåÊ≠§ËØØÂ∑ÆËæÉÂ∞èÔºåË°®ÊòéÁ≠ñÁï•Â≠¶‰ºö‰∫ÜË∑üÈöèÂÆâÂÖ®ËêΩËÑöÁÇπÔºõÂú®ÊúÄÁªàÁ≠ñÁï•‰∏≠ÔºåÊ≠§ËØØÂ∑ÆÂèØËÉΩÂ¢ûÂ§ßÔºå‰ª•Êç¢ÂèñÊõ¥È´òÁöÑÈÄüÂ∫¶Ë∑üË∏™Á≤æÂ∫¶Ôºå‰ΩìÁé∞‰∫ÜËÆæËÆ°‰∏≠ÁöÑÊùÉË°°„ÄÇ |\n| **ËÆ°ÁÆóÊïàÁéá** | 1. ËßÑÂàíÂô®ËÆ°ÁÆóÂª∂Ëøü (Planner Latency) | ÊµãÈáèÂÆåÊï¥ËßÑÂàíÁÆ°Á∫øÔºàÂåÖÊã¨È´òÁ®ãÂõæÂ§ÑÁêÜÂíåÂπ∂Ë°åÁ¶ªÊï£ÊêúÁ¥¢ÔºâÂ§ÑÁêÜ**‰∏Ä‰∏™ÊâπÊ¨°Ôºà4096‰∏™ÁéØÂ¢ÉÔºâ** ÊâÄÈúÄÁöÑÊó∂Èó¥ÔºàÁ∫¶4msÔºâ„ÄÇ | ËØÅÊòéÊâÄÊèêÂá∫ÁöÑ **‚Äú‰ºòÂåñËΩ¨ÊêúÁ¥¢‚Äù** ÊîπÈù©ÁöÑÊúâÊïàÊÄß„ÄÇËØ•ÊåáÊ†áË°®ÊòéÔºåÂ∞ÜÂü∫‰∫éDCMÁöÑ‰ºòÂåñÈóÆÈ¢òÈáçÊûÑ‰∏∫GPUÂπ∂Ë°åÁöÑÁ¶ªÊï£ÊêúÁ¥¢ÔºåËÉΩÂÆûÁé∞**ËøëÂÆûÊó∂**ÁöÑËßÑÂàíÊåáÂØºÔºå‰∏îÂØπÂ§ßËßÑÊ®°Âπ∂Ë°åRLËÆ≠ÁªÉ**ÂºÄÈîÄÂèØÂøΩÁï•**„ÄÇ |\n| | 2. ËÆ≠ÁªÉÂä†ÈÄüÊØî (Training Speedup) | ‰∏é‰ΩøÁî®‰º†ÁªüÂπ∂Ë°åMPCÊ±ÇËß£Âô®ÔºàÂ¶ÇCusADiÔºâÁöÑÊñπÊ≥ïËøõË°åÂØπÊØîÔºåËé∑ÂæóÁ∫¶ **25ÂÄçÁöÑÂä†ÈÄü**„ÄÇ | Âº∫Ë∞ÉÊñπÊ≥ïÂú®**Â∑•Á®ãÂÆûË∑µ‰∏äÁöÑ‰ºòÂäø**Ôºå‰ΩøÂæóÂ∞ÜÂ§çÊùÇÁöÑÊ®°ÂûãËßÑÂàíÂô®ÈõÜÊàêÂà∞RLËÆ≠ÁªÉÂæ™ÁéØ‰∏≠ÂèòÂæóÂèØË°åÔºåËß£ÂÜ≥‰∫Ü‰º†ÁªüÊñπÊ≥ïËÆ°ÁÆóÂºÄÈîÄËøáÂ§ßÁöÑÁì∂È¢à„ÄÇ |\n| **ÁúüÂÆû‰∏ñÁïåÊÄßËÉΩ** | 1. ËææÊàêÈÄüÂ∫¶ (Achieved Speed) | Âú®ÁúüÂÆûÊú∫Âô®‰∫∫‰∏äÊàêÂäüÊâßË°åÁà¨Ê•ºÊ¢Ø‰ªªÂä°Êó∂ÁöÑ**ÂÆûÊµãÊúÄÈ´òÈÄüÂ∫¶**ÔºàÂ¶Ç1.65 m/sÔºâ„ÄÇ | **ÊúÄÁªàÈ™åËØÅÊåáÊ†á**„ÄÇËØÅÊòé‰ªøÁúüËÆ≠ÁªÉÁöÑÁ≠ñÁï•ËÉΩÁõ¥Êé•ËøÅÁßªÂà∞ÁúüÂÆûÂ§çÊùÇÁéØÂ¢ÉÔºàÂ¶ÇÂπøÂ∑ûÂ°îËû∫ÊóãÊ•ºÊ¢ØÔºâÔºåÂπ∂ÂÆûÁé∞**‰∫∫Á±ªÁ∫ßÂà´ÁöÑÊïèÊç∑ÈÄüÂ∫¶**ÔºåÂÖ∑ÊúâÊûÅÈ´òÁöÑÂÆûÈôÖÂ∫îÁî®‰ª∑ÂÄº„ÄÇ |\n| | 2. ‰ªªÂä°ÂÆåÊàêÊó∂Èó¥ (Task Completion Time) | ÂÆåÊàêÁâπÂÆöÊ•ºÊ¢ØÊåëÊàòÁöÑ**ÊÄªËÄóÊó∂**ÔºàÂ¶Ç33Á∫ßÊ•ºÊ¢ØÁî®Êó∂12ÁßíÔºâ„ÄÇ | Áõ¥ËßÇÂ±ïÁ§∫ÊñπÊ≥ïÂú®**ÈïøË∑ùÁ¶ª„ÄÅËøûÁª≠Ê•ºÊ¢Ø**ÁéØÂ¢É‰∏ãÁöÑ**È´òÊïàÊÄßÂíåËÄêÂäõ**ÔºåÁªºÂêàÂèçÊò†‰∫ÜÈÄüÂ∫¶„ÄÅÁ®≥ÂÆöÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇ |\n\n### ‰∫å„ÄÅ ‰ΩøÁî®ÁöÑÊï∞ÊçÆÈõÜ/ËÆ≠ÁªÉÁéØÂ¢É\n\nÊú¨ÊñáÊ≤°Êúâ‰ΩøÁî®ÈùôÊÄÅÁöÑÁ¶ªÁ∫øÊï∞ÊçÆÈõÜÔºåËÄåÊòØ‰æùËµñ‰∫éÂú®‰ªøÁúüÂô®‰∏≠Âä®ÊÄÅÁîüÊàêÁöÑ**ËÆ≠ÁªÉËØæÁ®ã**Âíå**ËØÑ‰º∞Âú∫ÊôØ**„ÄÇ\n\n| ÁéØÂ¢ÉÁ±ªÂûã | ÂÖ∑‰ΩìÊûÑÊàê | ÁõÆÁöÑ‰∏éÁªÜËäÇ |\n| :--- | :--- | :--- |\n| **ËÆ≠ÁªÉËØæÁ®ã (Training Curriculum)** | Âú® **IsaacLab** ‰ªøÁúüÂô®‰∏≠ÊûÑÂª∫ÔºåÂåÖÂê´Ôºö<br>1. **Âπ≥Âù¶Âú∞Èù¢**<br>2. **Â¥éÂ≤ñÂú∞ÂΩ¢**<br>3. **ÈáëÂ≠óÂ°îÂΩ¢Ê•ºÊ¢Ø**ÔºàÂåÖÂê´‰∏äË°åÂíå‰∏ãË°åÔºâ | **Áî®‰∫éÁ≠ñÁï•ÁöÑÂ§öÈò∂ÊÆµËÆ≠ÁªÉ**„ÄÇ<br>- **Â§öÊ†∑ÊÄß**ÔºöÁ°Æ‰øùÁ≠ñÁï•ËÉΩÊ≥õÂåñÂà∞‰∏çÂêåÂú∞ÂΩ¢ÔºåËÄå‰∏ç‰ªÖ‰ªÖÊòØÊ•ºÊ¢Ø„ÄÇ<br>- **ËØæÁ®ãÂ≠¶‰π†**Ôºö‰ªéÁÆÄÂçïÂú∞ÂΩ¢ÂºÄÂßãÔºåÈÄêÊ≠•Â¢ûÂä†ÈöæÂ∫¶Ôºå‰øÉËøõÁ®≥ÂÆöÂ≠¶‰π†„ÄÇ<br>- **ÂüüÈöèÊú∫Âåñ**ÔºöÂØπÊú∫Âô®‰∫∫Ë¥®Èáè„ÄÅÊÉØÊÄß„ÄÅÊë©Êì¶„ÄÅÂÖ≥ËäÇÂ¢ûÁõä„ÄÅÂ§ñÈÉ®Êâ∞Âä®Á≠âËøõË°åÈöèÊú∫ÂåñÔºå‰ª•**Áº©Â∞è‰ªøÁúü‰∏éÁé∞ÂÆûÂ∑ÆË∑ù**„ÄÇ |\n| **ËØÑ‰º∞ÊµãËØïÈõÜ (Evaluation Testbeds)** | 1. **‰ªøÁúüÊµãËØïÊ•ºÊ¢Ø**Ôºö<br>   - **25cmÈò∂È´òÊ•ºÊ¢Ø**ÔºöÁî®‰∫éÁ≥ªÁªüÊÄßÁöÑÊàêÂäüÁéá‰∏éÈÄüÂ∫¶Ë∑üË∏™ËØØÂ∑ÆËØÑ‰º∞„ÄÇ<br>   - **15cmÈò∂È´òÊ•ºÊ¢Ø**ÔºöÂú®MuJoCo‰∏≠Áî®‰∫éÈ™åËØÅÂÖ®ÈÄüÂ∫¶ËåÉÂõ¥ÁöÑË∑üË∏™ÊÄßËÉΩ„ÄÇ<br>2. **ÁúüÂÆû‰∏ñÁïåÊµãËØïÂú∫**Ôºö<br>   - **15cmÈò∂È´òÊà∑Â§ñÊ•ºÊ¢Ø**ÔºöËøõË°åÂÖ®ÈÄüÂ∫¶ËåÉÂõ¥Ôºà0-1.5 m/sÔºâÁöÑÁà¨Âçá/‰∏ãÈôçÊµãËØï„ÄÇ<br>   - **20cmÈò∂È´òÊ•ºÊ¢Ø**ÔºöÊµãËØïÊõ¥Èô°Â≥≠Âú∞ÂΩ¢ÁöÑÊÄßËÉΩ„ÄÇ<br>   - **ÂπøÂ∑ûÂ°îËû∫ÊóãÊ•ºÊ¢Ø**Ôºö33Á∫ßÔºå17cmÈò∂È´òÔºå‰Ωú‰∏∫ÁªàÊûÅÊåëÊàò„ÄÇ | **Áî®‰∫éÂÆöÈáè‰∏éÂÆöÊÄßËØÑ‰º∞**„ÄÇ<br>- **‰ªøÁúüÊµãËØï**ÔºöÊèê‰æõÂèØÊéß„ÄÅÂèØÈáçÂ§çÁöÑÂÆöÈáèÊØîËæÉÂü∫ÂáÜÔºåÁî®‰∫é**Ê∂àËûçÂÆûÈ™å**Âíå‰∏éÂü∫Á∫øÊñπÊ≥ïÔºàÂ¶ÇÁ∫ØRLÂü∫Á∫ø„ÄÅAMPÊñπÊ≥ïÔºâÁöÑÂÖ¨Âπ≥ÂØπÊØî„ÄÇ<br>- **ÁúüÂÆû‰∏ñÁïåÊµãËØï**ÔºöÊúÄÁªàÈ™åËØÅÁ≠ñÁï•ÁöÑ**ÂÆûÈôÖÈÉ®ÁΩ≤ËÉΩÂäõ**„ÄÅ**ÊÑüÁü•Á≥ªÁªü**ÔºàRealSense D435iÊ∑±Â∫¶Áõ∏Êú∫ÔºâÁöÑÂèØÈù†ÊÄß‰ª•ÂèäÊï¥Â•óÁ≥ªÁªüÁöÑ**Â∑•Á®ãÂÆåÂ§áÊÄß**„ÄÇËØÅÊòéÊñπÊ≥ïËß£ÂÜ≥‰∫Üsim-to-realËΩ¨ÁßªÈóÆÈ¢ò„ÄÇ |\n\n### ÊÄªÁªì\nFastStair ÁöÑËØÑ‰ª∑‰ΩìÁ≥ªÈùûÂ∏∏ÂÖ®Èù¢Ôºå**ÂÖºÈ°æ‰∫ÜÂ≠¶ÊúØÁ†îÁ©∂ÁöÑ‰∏•Ë∞®ÊÄß‰∏éÂ∑•Á®ãÂ∫îÁî®ÁöÑÂÆûÁî®ÊÄß**Ôºö\n- **ÊåáÊ†á‰∏ä**Ôºå‰∏ç‰ªÖÊúâÂÖ≥ÈîÆÁöÑ**ÊàêÂäüÁéá**Âíå**ÊéßÂà∂Á≤æÂ∫¶**ÊåáÊ†áÔºåËøòÂàõÊñ∞ÊÄßÂú∞ÂºïÂÖ•‰∫Ü**ËßÑÂàíÂô®ËÆ°ÁÆóÊïàÁéá**ÊåáÊ†áÔºåÂá∏Êòæ‰∫ÜÂÖ∂ÊñπÊ≥ïÂú®ÂÆûÁé∞‚ÄúËßÑÂàíÂºïÂØºRL‚ÄùÊó∂ÁöÑÊ†∏ÂøÉÊäÄÊúØË¥°ÁåÆ„ÄÇ\n- **Êï∞ÊçÆ/ÁéØÂ¢É‰∏ä**ÔºåÈÄöËøáÁ≤æÂøÉËÆæËÆ°ÁöÑ**‰ªøÁúüËØæÁ®ã**Âíå**Â§öÁª¥Â∫¶ÊµãËØïÈõÜ**ÔºåÁ°Æ‰øù‰∫ÜÁ≠ñÁï•ÁöÑÊ≥õÂåñËÉΩÂäõÂíåËØÑ‰º∞ÁªìÊûúÁöÑÂèØÈù†ÊÄßÔºåÊúÄÁªàÈÄöËøá**ÊûÅÂÖ∑ÊåëÊàòÊÄßÁöÑÁúüÂÆû‰∏ñÁïåÊºîÁ§∫**ËØÅÊòé‰∫ÜÂÖ∂ÂçìË∂äÁöÑÂÆûÈôÖ‰ª∑ÂÄº„ÄÇ",
            "timestamp": "2026-01-20T18:01:17.251390",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "ËÆ∫ÊñáÂú®Âì™‰∫õÊï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜÂÆûÈ™åÔºü‰∏ªË¶ÅÁöÑËØÑ‰º∞ÊåáÊ†áÂíåÊÄßËÉΩÊèêÂçáÊòØÂ§öÂ∞ëÔºü",
            "answer": "## ËÆ∫ÊñáÂÆûÈ™åÊï∞ÊçÆÈõÜ„ÄÅËØÑ‰º∞ÊåáÊ†á‰∏éÊÄßËÉΩÊèêÂçáÂàÜÊûê\n\n### ‰∏Ä„ÄÅ ÂÆûÈ™åÊï∞ÊçÆÈõÜ‰∏éÂπ≥Âè∞\nËÆ∫Êñá‰∏ªË¶ÅÂú®**‰ªøÁúüÁéØÂ¢É**Âíå**ÁúüÂÆûÊú∫Âô®‰∫∫Âπ≥Âè∞**‰∏äËøõË°åÂÆûÈ™åÔºåÊú™‰ΩøÁî®‰º†ÁªüÊÑè‰πâ‰∏äÁöÑ‚ÄúÊï∞ÊçÆÈõÜ‚ÄùÔºåËÄåÊòØÊûÑÂª∫‰∫ÜÂ§öÊ†∑ÂåñÁöÑËÆ≠ÁªÉ‰∏éÊµãËØïÂú∫ÊôØ„ÄÇ\n\n#### 1. ‰ªøÁúüËÆ≠ÁªÉÁéØÂ¢É (IsaacLab)\n- **ËÆ≠ÁªÉÂú∞ÂΩ¢**ÔºöÊûÑÂª∫‰∫ÜÂåÖÂê´**Âπ≥Âú∞„ÄÅÂ¥éÂ≤ñÂú∞ÂΩ¢„ÄÅÈáëÂ≠óÂ°îÂΩ¢Ê•ºÊ¢ØÔºà‰∏ä‰∏ãË°åÔºâ** ÁöÑËØæÁ®ãÂåñËÆ≠ÁªÉÂú∫ÊôØ„ÄÇ\n- **ÂÖ≥ÈîÆÂèÇÊï∞**Ôºö\n    - Âπ∂Ë°å4096‰∏™ÁéØÂ¢É„ÄÇ\n    - Ê≠•ÊÄÅÈ¢ëÁéáÁ∫¶ÊùüÂú® `[1.0, 1.5]` Hz„ÄÇ\n    - Êåá‰ª§ÈÄüÂ∫¶ËåÉÂõ¥Ê†πÊçÆËÆ≠ÁªÉÈò∂ÊÆµË∞ÉÊï¥ÔºàËØ¶ËßÅ‰∏ãÊñáÔºâ„ÄÇ\n    - Â∫îÁî®‰∫ÜÂπøÊ≥õÁöÑ**ÂüüÈöèÊú∫Âåñ**ÔºàË¥®Èáè„ÄÅÊÉØÊÄß„ÄÅÊë©Êì¶„ÄÅÊÅ¢Â§çÁ≥ªÊï∞„ÄÅÂÖ≥ËäÇPDÂ¢ûÁõä„ÄÅÂ§ñÈÉ®Êâ∞Âä®Á≠âÔºâ‰ª•Áº©Â∞è‰ªøÁúü‰∏éÁé∞ÂÆûÂ∑ÆË∑ù„ÄÇ\n\n#### 2. ‰ªøÁúüËØÑ‰º∞ÁéØÂ¢É\n- **IsaacLab / IsaacSim**ÔºöÁî®‰∫é**ÊàêÂäüÁéá**Âíå**Ë∂≥ÈÉ®ËêΩÁÇπË∑üË∏™**ËØÑ‰º∞„ÄÇ\n    - **ÊµãËØïÊ•ºÊ¢Ø**Ôºö25 cmÂè∞Èò∂È´òÂ∫¶ÁöÑÈáëÂ≠óÂ°îÂΩ¢Ê•ºÊ¢Ø„ÄÇ\n- **MuJoCo**ÔºöÁî®‰∫é**ÂÖ®ËåÉÂõ¥ÈÄüÂ∫¶Ë∑üË∏™**È™åËØÅ„ÄÇ\n    - **ÊµãËØïÊ•ºÊ¢Ø**Ôºö15 cmÂè∞Èò∂È´òÂ∫¶ÁöÑÊ•ºÊ¢Ø„ÄÇ\n\n#### 3. ÁúüÂÆû‰∏ñÁïåÈÉ®ÁΩ≤Âπ≥Âè∞\n- **Êú∫Âô®‰∫∫**ÔºöÂÖ®Â∞∫ÂØ∏‰∫∫ÂΩ¢Êú∫Âô®‰∫∫ **LimX Oli** (È´ò1.65mÔºåÈáç55kgÔºå31‰∏™Ëá™Áî±Â∫¶)„ÄÇ\n- **ÊµãËØïÊ•ºÊ¢Ø**Ôºö\n    - 15 cmÂè∞Èò∂È´òÂ∫¶ÁöÑÊà∑Â§ñÊ•ºÊ¢ØÔºàÁî®‰∫éÂÖ®ÈÄüÂ∫¶ËåÉÂõ¥Áà¨Âçá/‰∏ãÈôçÊµãËØïÔºâ„ÄÇ\n    - 20 cmÂè∞Èò∂È´òÂ∫¶ÁöÑÊ•ºÊ¢ØÔºàÁî®‰∫éËøûÁª≠Áà¨ÂçáÊµãËØïÔºâ„ÄÇ\n    - **ÂπøÂ∑ûÂ°îËû∫ÊóãÊ•ºÊ¢Ø**Ôºö33Á∫ßÔºåÊØèÁ∫ßÈ´ò17 cmÔºàÁî®‰∫éÈïøË∑ùÁ¶ª„ÄÅÈ´òÈÄüÊÄßËÉΩÂ±ïÁ§∫Ôºâ„ÄÇ\n- **ÊÑüÁü•Á≥ªÁªü**Ôºö‰ΩøÁî®Intel RealSense D435iÊ∑±Â∫¶Áõ∏Êú∫ÂÆûÊó∂ÈáçÂª∫‰ª•Êú∫Âô®‰∫∫‰∏∫‰∏≠ÂøÉÁöÑ**Â±ÄÈÉ®È´òÁ®ãÂõæ**Ôºà1.8m √ó 1.2mÔºåÂàÜËæ®Áéá5cmÔºâ„ÄÇ\n\n### ‰∫å„ÄÅ ‰∏ªË¶ÅËØÑ‰º∞ÊåáÊ†á\nËÆ∫ÊñáÈááÁî®‰∫Ü‰ª•‰∏ãÊ†∏ÂøÉÊåáÊ†áÊù•ÈáèÂåñÊÄßËÉΩÔºö\n\n1.  **Âú∞ÂΩ¢Á©øË∂äÊàêÂäüÁéá**ÔºöÂú®ÊåáÂÆöÈÄüÂ∫¶Êåá‰ª§‰∏ãÔºåÊú∫Âô®‰∫∫ÊàêÂäüÂà∞ËææÂú∞ÂΩ¢ËøúÁ´Ø‰∏îÊú™Ë∑åÂÄíÁöÑÁéØÂ¢ÉÊØî‰æã„ÄÇËøôÊòØË°°Èáè**Á®≥ÂÆöÊÄß‰∏éÈ≤ÅÊ£íÊÄß**ÁöÑÊ†∏ÂøÉÊåáÊ†á„ÄÇ\n2.  **ÈÄüÂ∫¶Ë∑üË∏™Âπ≥ÂùáÁªùÂØπËØØÂ∑Æ**ÔºöÊåá‰ª§ÈÄüÂ∫¶‰∏éÂÆûÈôÖÈÄüÂ∫¶‰πãÈó¥ÁöÑMAE„ÄÇÁî®‰∫éËØÑ‰º∞**ÊéßÂà∂Á≤æÂ∫¶‰∏éÊïèÊç∑ÊÄß**„ÄÇ\n3.  **Ë∂≥ÈÉ®ËêΩÁÇπË∑üË∏™ËØØÂ∑Æ**ÔºöËßÑÂàíÁöÑÁêÜÊÉ≥ËêΩÁÇπ‰∏éÁ≠ñÁï•ÂÆûÈôÖÊâßË°åËêΩÁÇπ‰πãÈó¥ÁöÑÂπ≥ÂùáÂπ≥Èù¢Ê¨ßÊ∞èË∑ùÁ¶ª„ÄÇÁî®‰∫éÈ™åËØÅ**Ê®°ÂûãÂºïÂØºÁöÑÊúâÊïàÊÄß**„ÄÇ\n4.  **ËÆ°ÁÆóÊïàÁéá**ÔºöËßÑÂàíÊ®°ÂùóÁöÑÂª∂ËøüÔºåÁî®‰∫éËØÑ‰º∞Ê°ÜÊû∂ÁöÑ**ÂÆûÊó∂ÊÄß‰∏éÂèØÊâ©Â±ïÊÄß**„ÄÇ\n5.  **ÂÆûÈôÖË°®Áé∞**ÔºöÂú®ÁúüÂÆûÊú∫Âô®‰∫∫‰∏äËææÂà∞ÁöÑ**ÊúÄÈ´òÁà¨ÂçáÈÄüÂ∫¶**Âíå**Á©øË∂äÈïøÊ•ºÊ¢ØÊâÄÈúÄÊó∂Èó¥**„ÄÇ\n\n### ‰∏â„ÄÅ ÊÄßËÉΩÊèêÂçá‰∏éÂÆûÈ™åÁªìÊûú\nFastStairÊ°ÜÊû∂Áõ∏ÊØîÂü∫Á∫øÊñπÊ≥ïÂú®Â§ö‰∏™Áª¥Â∫¶‰∏äÂèñÂæó‰∫ÜÊòæËëóÊèêÂçá„ÄÇ\n\n#### 1. ÊàêÂäüÁéá‰∏éÁ®≥ÂÆöÊÄßÔºàÊ†∏ÂøÉ‰ºòÂäøÔºâ\n- **ÂØπÊØîÊñπÊ≥ï**Ôºö\n    - **Baseline**ÔºöÊó†Ê®°ÂûãÂºïÂØºÁöÑÁ´ØÂà∞Á´ØRLÁ≠ñÁï•„ÄÇ\n    - **Pre-trained (Ablation)**Ôºö‰ªÖ‰ΩøÁî®DCMÂºïÂØºÈ¢ÑËÆ≠ÁªÉÁöÑÁ≠ñÁï•ÔºàÈò∂ÊÆµ1Ôºâ„ÄÇ\n    - **AMP**Ôºö‰ΩøÁî®ÂØπÊäóËøêÂä®ÂÖàÈ™åÔºà‰∫∫Á±ªËøêÂä®ÈáçÂÆöÂêëÔºâÂºïÂØºÁöÑÁ≠ñÁï•„ÄÇ\n    - **FastStair (Ours)**ÔºöÂÆåÊï¥ÁöÑ‰∏âÈò∂ÊÆµÊ°ÜÊû∂„ÄÇ\n- **ÁªìÊûú**ÔºàÂú®25cmÂè∞Èò∂„ÄÅ‰∏çÂêåÊåá‰ª§ÈÄüÂ∫¶‰∏ãÔºâÔºö\n    - **FastStairÂú®ÊâÄÊúâÊµãËØïÈÄüÂ∫¶‰∏ãÂùáÂèñÂæóÊúÄÈ´òÊàêÂäüÁéá**„ÄÇ\n    - Âç≥‰ΩøÂú®**Ë∂ÖÂá∫ËÆ≠ÁªÉËåÉÂõ¥**ÁöÑ `2.0 m/s` Êåá‰ª§‰∏ãÔºåÊàêÂäüÁéá‰ªçË∂ÖËøá **70%**ÔºåÂ±ïÁé∞‰∫ÜÂá∫Ëâ≤ÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ\n    - **Pre-trained**Á≠ñÁï•‰πüÊòæËëó‰ºò‰∫éBaselineÔºåËØÅÊòé‰∫ÜÊ®°ÂûãÂºïÂØºÂØπÂÆâÂÖ®ÊÄßÁöÑÊèêÂçá„ÄÇ\n    - **AMP**Âú®‰ΩéÈÄü(`‚â§1.0 m/s`)Ë°®Áé∞Â∞öÂèØÔºå‰ΩÜÂú®È´òÈÄü‰∏ãÊÄßËÉΩÊÄ•Ââß‰∏ãÈôçÔºåÁîöËá≥‰∏çÂ¶ÇBaselineÔºåË°®ÊòéÂÖ∂Âú®È´òÈÄüÊïèÊç∑ËøêÂä®‰∏äÂ≠òÂú®Â±ÄÈôêÊÄß„ÄÇ\n\n#### 2. ÈÄüÂ∫¶Ë∑üË∏™Á≤æÂ∫¶\n- **ÁªìÊûú**ÔºöFastStairÂÆûÁé∞‰∫Ü**ÊúÄ‰ΩéÁöÑÈÄüÂ∫¶Ë∑üË∏™MAEÔºàÁ∫¶0.5 m/sÔºâ**„ÄÇ\n- **ÂàÜÊûê**Ôºö\n    - **Pre-trained**Á≠ñÁï•ÁöÑMAEÁï•È´ò‰∫éBaselineÔºåËøôÁ¨¶ÂêàËÆæËÆ°È¢ÑÊúüÔºöÈ¢ÑËÆ≠ÁªÉÈò∂ÊÆµ‰∏∫‰øùÈöúÂÆâÂÖ®ÔºàÂº∫Ë∞ÉË∂≥ÈÉ®Ë∑üË∏™ÔºâÁâ∫Áâ≤‰∫ÜÈÉ®ÂàÜÈÄüÂ∫¶Ë∑üË∏™Á≤æÂ∫¶„ÄÇ\n    - ÂêéÁª≠ÁöÑ‰∏ìÂÆ∂ÂæÆË∞ÉÂíåLoRAËûçÂêàÈò∂ÊÆµÊàêÂäü**ÊÅ¢Â§ç‰∫ÜÈÄüÂ∫¶Ë∑üË∏™Á≤æÂ∫¶**ÔºåÂêåÊó∂‰øùÊåÅ‰∫ÜÂÆâÂÖ®ÊÄßÔºåÈ™åËØÅ‰∫ÜÂ§öÈò∂ÊÆµÊ°ÜÊû∂ÁöÑÂøÖË¶ÅÊÄß„ÄÇ\n    - **AMP**ÁöÑMAEÊúÄÂ§ßÔºåÂõ†ÂÖ∂Âú®È´òÈÄüÊåá‰ª§‰∏ãÊòìÂá∫Áé∞ÂÅúÊªûË°å‰∏∫„ÄÇ\n\n#### 3. ËÆ°ÁÆóÊïàÁéá\n- **Âπ∂Ë°åË∂≥ÈÉ®ËßÑÂàíÂô®**Â∞Ü‰ºòÂåñÈóÆÈ¢òÈáçÊûÑ‰∏∫Âπ∂Ë°åÁ¶ªÊï£ÊêúÁ¥¢ÔºåÂà©Áî®GPUÂº†ÈáèÊìç‰Ωú„ÄÇ\n- **ÊÄßËÉΩ**ÔºöÂú®NVIDIA RTX 4090‰∏äÔºåÂ§ÑÁêÜ4096‰∏™ÁéØÂ¢ÉÁöÑÊâπÈáèËßÑÂàíÔºåÂª∂Ëøü‰ªÖÁ∫¶ **4 ms/Ê≠•**„ÄÇ\n- **ÊèêÂçá**ÔºöÁõ∏ÊØî‰ΩøÁî®CusADiÁöÑÂπ∂Ë°åMPCÂÆûÁé∞ÔºåËé∑Âæó‰∫ÜÁ∫¶ **25ÂÄçÁöÑÂä†ÈÄü**Ôºå‰ΩøÂæóÂú®RLËÆ≠ÁªÉÂæ™ÁéØ‰∏≠ÈõÜÊàêÂÆûÊó∂ËßÑÂàíÊåáÂØºÊàê‰∏∫ÂèØËÉΩÔºå‰∏îÂºÄÈîÄÂèØÂøΩÁï•‰∏çËÆ°„ÄÇ\n\n#### 4. ÁúüÂÆû‰∏ñÁïåÈÉ®ÁΩ≤ÊÄßËÉΩÔºàÂÆûÈôÖ‰ª∑ÂÄº‰ΩìÁé∞Ôºâ\n- **È´òÈÄüÁà¨Âçá**ÔºöÂú®15cmÂè∞Èò∂‰∏äÂÆûÁé∞Á®≥ÂÆöÁà¨ÂçáÔºåÈÄüÂ∫¶È´òËææ **1.5 m/s**ÔºõÂú®ÂπøÂ∑ûÂ°îÊ•ºÊ¢Ø‰∏äÂ≥∞ÂÄºÈÄüÂ∫¶Ëææ **1.65 m/s**„ÄÇ\n- **ÈïøË∑ùÁ¶ªÁ©øË∂ä**ÔºöÂú® **12ÁßíÂÜÖ** ÊàêÂäüÁ©øË∂ä **33Á∫ß** Ëû∫ÊóãÊ•ºÊ¢ØÔºåÂ±ïÁ§∫‰∫ÜÂú®ÈïøÊ•ºÊ¢ØÂú∫ÊôØ‰∏ãÁöÑ**È´òÊïàÊÄß‰∏éËÄê‰πÖÊÄß**„ÄÇ\n- **Â§çÊùÇÊú∫Âä®**ÔºöÊàêÂäüÂÆåÊàê‰∫ÜÊ•ºÊ¢Ø‰∏äÁöÑ**Âä®ÊÄÅËΩ¨Âêë**Âíå**20cmÈ´òÂè∞Èò∂ÁöÑËøûÁª≠Áà¨Âçá**„ÄÇ\n- **ÈÉ®ÁΩ≤ÊïàÁéá**ÔºöÁ≠ñÁï•Âú®ÊùøËΩΩËÆ°ÁÆóÊú∫(RK3588)‰∏ä‰ª• **100 Hz** È¢ëÁéáÂÆûÊó∂ËøêË°åÔºåÊó†ÈúÄÈíàÂØπÁúüÂÆû‰∏ñÁïåËøõË°åÈ¢ùÂ§ñÁöÑ‰ªªÂä°Á∫ßÂæÆË∞ÉÔºåËØÅÊòé‰∫Ü‰ºòÁßÄÁöÑ**Sim2RealËøÅÁßªËÉΩÂäõ**„ÄÇ\n\n### ÊÄªÁªì\nFastStairÈÄöËøáÂàõÊñ∞ÁöÑ**Â§öÈò∂ÊÆµÂ≠¶‰π†Ê°ÜÊû∂**Âíå**GPUÂπ∂Ë°åÁöÑÊ®°ÂûãÂºïÂØº**ÔºåÂú®**‰ªøÁúü**Âíå**ÁúüÂÆû‰∏ñÁïå**ÁöÑÊ•ºÊ¢ØÂú∞ÂΩ¢‰∏äÔºåÂÖ®Èù¢Ë∂ÖË∂ä‰∫ÜÁé∞ÊúâÊñπÊ≥ï„ÄÇÂÖ∂Ê†∏ÂøÉÊÄßËÉΩÊèêÂçá‰ΩìÁé∞Âú®Ôºö\n- **Á®≥ÂÆöÊÄß**ÔºöÁ©øË∂äÊàêÂäüÁéáÊúÄÈ´ò„ÄÇ\n- **ÊïèÊç∑ÊÄß**ÔºöÈÄüÂ∫¶Ë∑üË∏™ÊúÄÁ≤æÂáÜÔºåÂÆûÁé∞È´òÈÄüËøêÂä®Ôºà>1.5 m/sÔºâ„ÄÇ\n- **ÊïàÁéá**ÔºöËßÑÂàíËÆ°ÁÆóÂä†ÈÄü25ÂÄçÔºåÁé∞ÂÆû‰ªªÂä°ÂÆåÊàêÊó∂Èó¥Áü≠Ôºà33Á∫ß/12ÁßíÔºâ„ÄÇ\n- **ÂÆûÁî®ÊÄß**ÔºöÂú®Â§çÊùÇ„ÄÅÈïøË∑ùÁ¶ªÁöÑÁúüÂÆûÊ•ºÊ¢ØÂú∫ÊôØ‰∏≠Ë°®Áé∞Á®≥ÂÅ•ÔºåËé∑Âæó‰∫Ü**ÂπøÂ∑ûÂ°îÊú∫Âô®‰∫∫Áà¨Ê•ºÊØîËµõÁöÑÂÜ†ÂÜõ**ÔºåÂá∏Êòæ‰∫ÜÂÖ∂Á™ÅÂá∫ÁöÑÂÆûÈôÖÂ∫îÁî®‰ª∑ÂÄº„ÄÇ",
            "timestamp": "2026-01-20T18:02:02.451837",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "ËÆ∫ÊñáÁöÑ‰∏ªË¶ÅÂ±ÄÈôêÊÄßÊúâÂì™‰∫õÔºüÊú™Êù•ÂèØËÉΩÁöÑÊîπËøõÊñπÂêëÊòØ‰ªÄ‰πàÔºü",
            "answer": "## ËÆ∫Êñá„ÄäFastStair„ÄãÁöÑ‰∏ªË¶ÅÂ±ÄÈôêÊÄßÂèäÊú™Êù•ÊîπËøõÊñπÂêëÂàÜÊûê\n\n### ‰∏Ä„ÄÅ‰∏ªË¶ÅÂ±ÄÈôêÊÄß\n\n1.  **Ê®°ÂûãÁÆÄÂåñÂ∏¶Êù•ÁöÑËøë‰ººËØØÂ∑Æ**Ôºö\n    - Âú®Âü∫‰∫é**ÂèëÊï£ËøêÂä®ÂàÜÈáèÔºàDCMÔºâ**ÁöÑÁ´ãË∂≥ÁÇπËßÑÂàíÂô®‰∏≠Ôºå‰∏∫‰∫ÜÂ∞Ü‰ºòÂåñÈóÆÈ¢òËΩ¨Âåñ‰∏∫È´òÊïàÁöÑÂπ∂Ë°åÁ¶ªÊï£ÊêúÁ¥¢ÔºåÂØπÂä®ÂäõÂ≠¶Ê®°ÂûãËøõË°å‰∫ÜÂÖ≥ÈîÆÁÆÄÂåñÔºàÂÅáËÆæÁ≥ªÊï∞ `a ‚âà 1`Ôºâ„ÄÇËøôËôΩÁÑ∂Â§ßÂπÖÊèêÂçá‰∫ÜËÆ°ÁÆóÊïàÁéáÔºå‰ΩÜÊú¨Ë¥®‰∏äÊòØ‰∏ÄÁßç**ÂêØÂèëÂºèËøë‰ºº**ÔºåÂèØËÉΩÂú®È´òÂä®ÊÄÅ„ÄÅÂ§ßÂù°Â∫¶ÊàñÈùûÊ†áÂáÜÊ•ºÊ¢ØÂú∫ÊôØ‰∏ãÂºïÂÖ•ËßÑÂàíËØØÂ∑ÆÔºåÂΩ±ÂìçÁêÜËÆ∫‰∏äÁöÑÊúÄ‰ºòÊÄßÊàñÈ≤ÅÊ£íÊÄßËæπÁïå„ÄÇ\n\n2.  **ÊÑüÁü•Á≥ªÁªüÁöÑ‰æùËµñ‰∏éÊΩúÂú®Áì∂È¢à**Ôºö\n    - Êï¥‰∏™Ê°ÜÊû∂‰∏•Èáç‰æùËµñ**ÂÆûÊó∂Â±ÄÈÉ®È´òÁ®ãÂõæ**ÁöÑÁ≤æÁ°ÆÈáçÂª∫„ÄÇËÆ∫Êñá‰∏≠‰ΩøÁî®ÁöÑIntel RealSense D435iÊ∑±Â∫¶Áõ∏Êú∫Âú®Âº∫ÂÖâ„ÄÅÂèçÂÖâ„ÄÅÈÄèÊòéÊàñÁ∫πÁêÜÁº∫Â§±ÁöÑÊ•ºÊ¢ØË°®Èù¢ÂèØËÉΩÂ§±ÊïàÔºå‰∏îÊÑüÁü•Âª∂ËøüÔºàÂ∞ΩÁÆ°Êñá‰∏≠ÊèêÂà∞Á∫¶4msÔºâÂú®ÊûÅÁ´ØÈ´òÈÄüÔºàÂ¶ÇÊé•Ëøë1.65 m/sÔºâ‰∏ãÂèØËÉΩÊàê‰∏∫Á≥ªÁªüÁ®≥ÂÆöÊÄßÁöÑÊΩúÂú®Áì∂È¢à„ÄÇÊÑüÁü•ËØØÂ∑Æ‰ºöÁõ¥Êé•‰º†ÂØºËá≥ËßÑÂàíÂô®ÂíåÁ≠ñÁï•„ÄÇ\n\n3.  **‰∏ìÂÆ∂Á≠ñÁï•ÂàáÊç¢ÁöÑÈÄªËæë‰æùËµñ**Ôºö\n    - ÊúÄÁªàÁöÑÁªü‰∏ÄÁ≠ñÁï•ËôΩÁÑ∂ÈÄöËøáLoRAÂÆûÁé∞‰∫ÜÂπ≥ÊªëËøáÊ∏°Ôºå‰ΩÜÂÖ∂Â∫ïÂ±Ç‰ªç‰æùËµñ‰∫é‰∏Ä‰∏™**Âü∫‰∫éËßÑÂàôÁöÑÈÄüÂ∫¶ÂàáÊç¢Âô®**Ôºà‰ª•0.8 m/s‰∏∫ÈòàÂÄºÔºâ„ÄÇËøôÁßçÁ°¨ÁºñÁ†ÅÁöÑÂàáÊç¢ÈÄªËæëÂèØËÉΩÊó†Ê≥ïÊúÄ‰ºòÂú∞Â§ÑÁêÜÊâÄÊúâËøáÊ∏°Áä∂ÊÄÅÔºåÂ∞§ÂÖ∂ÊòØÂú®ÈùûÂπ≥Á®≥ËøêÂä®ÊàñÂø´ÈÄüÂèòÈÄüÂ∫¶Êåá‰ª§‰∏ãÔºåÂèØËÉΩ‰ªçÂ≠òÂú®ÁªÜÂæÆÁöÑ‰∏çËøûÁª≠ÊÄßÈ£éÈô©„ÄÇ\n\n4.  **ËÆ≠ÁªÉÂú∫ÊôØ‰∏éÊ≥õÂåñËÉΩÂäõÈôêÂà∂**Ôºö\n    - ËÆ≠ÁªÉ‰∏ªË¶ÅÂú®‰ªøÁúüÁéØÂ¢É‰∏≠ËøõË°åÔºåÂ∞ΩÁÆ°‰ΩøÁî®‰∫ÜÂüüÈöèÊú∫ÂåñÔºå‰ΩÜËØæÁ®ãËÆæÁΩÆÈõÜ‰∏≠‰∫é**ÈáëÂ≠óÂ°îÂΩ¢Ê•ºÊ¢ØÂíåÁâπÂÆöÂèÇÊï∞ËåÉÂõ¥**„ÄÇÂØπ‰∫éÊõ¥ÊûÅÁ´ØÊàñÊõ¥‰∏çËßÑÂàôÁöÑÊ•ºÊ¢ØÔºàÂ¶ÇËû∫ÊóãÊ•ºÊ¢Ø„ÄÅÂè∞Èò∂È´òÂ∫¶/Ê∑±Â∫¶ÂèòÂåñÊûÅÂ§ß„ÄÅÂ∏¶ÊúâÂπ≥Âè∞ÊàñÁ†¥ÊçüÁöÑÊ•ºÊ¢ØÔºâÔºåÁ≠ñÁï•ÁöÑÊ≥õÂåñËÉΩÂäõÊú™ÁªèÂÖÖÂàÜÈ™åËØÅ„ÄÇËÆ∫Êñá‰∏≠Âú®Ëû∫ÊóãÊ•ºÊ¢ØÁöÑÊàêÂäüÊºîÁ§∫Êõ¥Â§öÊòØÁªìÊûúÈ™åËØÅÔºåËÄåÈùûÁ≥ªÁªüÊÄßÊ≥õÂåñËÉΩÂäõËØÅÊòé„ÄÇ\n\n5.  **ËÆ°ÁÆóÊû∂ÊûÑÁöÑÂ§çÊùÇÊÄß**Ôºö\n    - Ê°ÜÊû∂ÂåÖÂê´**Â§öÈò∂ÊÆµËÆ≠ÁªÉ**ÔºàÈ¢ÑËÆ≠ÁªÉ„ÄÅ‰∏ìÂÆ∂ËÆ≠ÁªÉ„ÄÅLoRAÂæÆË∞ÉÔºâÂíå**ÂºÇÊûÑËÆ°ÁÆóÂπ≥Âè∞**ÔºàGPUÁî®‰∫éËÆ≠ÁªÉ/ËßÑÂàíÔºåJetson OrinÁî®‰∫éÊÑüÁü•ÔºåRK3588Áî®‰∫éÊéßÂà∂Ôºâ„ÄÇËøôÁßçÂ§çÊùÇÊÄßÂ¢ûÂä†‰∫ÜÁ≥ªÁªüÈõÜÊàê„ÄÅË∞ÉËØïÂíåÁª¥Êä§ÁöÑÈöæÂ∫¶ÔºåÂèØËÉΩ‰∏çÂà©‰∫éÂø´ÈÄüÈÉ®ÁΩ≤Âà∞ÂÖ∂‰ªñÊú∫Âô®‰∫∫Âπ≥Âè∞„ÄÇ\n\n### ‰∫å„ÄÅÊú™Êù•ÂèØËÉΩÁöÑÊîπËøõÊñπÂêë\n\n1.  **ËßÑÂàíÂô®Ê®°ÂûãÁöÑÂ¢ûÂº∫‰∏éÊ≥õÂåñ**Ôºö\n    - **ÂºÄÂèëÊõ¥Á≤æÁ°ÆÁöÑÂπ∂Ë°å‰ºòÂåñÂô®**ÔºöÊé¢Á¥¢Âú®‰øùÊåÅGPUÂπ∂Ë°åÊïàÁéáÁöÑÂâçÊèê‰∏ãÔºåÂáèÂ∞ëÂä®ÂäõÂ≠¶Ëøë‰ººËØØÂ∑ÆÁöÑÊñπÊ≥ïÔºå‰æãÂ¶ÇÈááÁî®Ëø≠‰ª£‰øÆÊ≠£ÊàñÂ≠¶‰π†ÂûãÊ†°Ê≠£È°π„ÄÇ\n    - **Êâ©Â±ïËá≥Êõ¥Â§çÊùÇÂú∞ÂΩ¢**ÔºöÂ∞Ü‚Äú‰ºòÂåñÂç≥ÊêúÁ¥¢‚ÄùËåÉÂºèÊé®ÂπøÂà∞**ÊñúÂù°„ÄÅÁ¢éÁü≥Âú∞„ÄÅÈùûÁªìÊûÑÂåñÁéØÂ¢É**Á≠âÔºåÁ†îÁ©∂Â¶Ç‰ΩïÂ∞ÜÂú∞ÂΩ¢ÁâπÂæÅÔºàÂ¶ÇÊë©Êì¶Á≥ªÊï∞„ÄÅÂèØÂèòÂΩ¢ÊÄßÔºâÁ∫≥ÂÖ•Âπ∂Ë°å‰ª£‰ª∑ËÆ°ÁÆó‰∏≠„ÄÇ\n\n2.  **ÊÑüÁü•‰∏éÊéßÂà∂ÁöÑÁ¥ßËÄ¶Âêà‰∏éÈ≤ÅÊ£íÊÄßÊèêÂçá**Ôºö\n    - **Â§ö‰º†ÊÑüÂô®ËûçÂêà**ÔºöÁªìÂêà**ËßÜËßâÊÉØÊÄßÈáåÁ®ãËÆ°ÔºàVIOÔºâ„ÄÅÊøÄÂÖâÈõ∑ËææÊàñ‰∫ã‰ª∂Áõ∏Êú∫**Ôºå‰ª•Ë°•ÂÅøÁ∫ØËßÜËßâÊ∑±Â∫¶ÊÑüÁü•ÁöÑÁº∫Èô∑ÔºåÊèêÈ´òÂú®ÊåëÊàòÊÄßÂÖâÁÖßÂíåÁ∫πÁêÜÊù°‰ª∂‰∏ãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ\n    - **ÊÑüÁü•‰∏çÁ°ÆÂÆöÊÄßÂª∫Ê®°**ÔºöÂú®Á≠ñÁï•ÁöÑËßÇÂØüÁ©∫Èó¥‰∏≠ÊòæÂºèÂºïÂÖ•**ÊÑüÁü•ÁΩÆ‰ø°Â∫¶Êàñ‰∏çÁ°ÆÂÆöÊÄß‰º∞ËÆ°**Ôºå‰ΩøÁ≠ñÁï•ËÉΩÂ§üÊ†πÊçÆÊÑüÁü•Ë¥®ÈáèËá™ÈÄÇÂ∫îË∞ÉÊï¥ÂÖ∂Ë°å‰∏∫ÔºàÂ¶ÇËøõÂÖ•Êõ¥Ë∞®ÊÖéÁöÑÊ®°ÂºèÔºâ„ÄÇ\n\n3.  **Á≠ñÁï•Êû∂ÊûÑ‰∏éÂ≠¶‰π†ËåÉÂºèÁöÑËøõÂåñ**Ôºö\n    - **Á´ØÂà∞Á´ØÁöÑËá™ÈÄÇÂ∫îÂàáÊç¢**ÔºöÁî®**ÂèØÂ≠¶‰π†ÁöÑÈó®ÊéßÁΩëÁªúÊàñÊ∑∑Âêà‰∏ìÂÆ∂ÔºàMoEÔºâ** Êõø‰ª£Âü∫‰∫éËßÑÂàôÁöÑÈÄüÂ∫¶ÂàáÊç¢Âô®ÔºåÂÆûÁé∞Êõ¥Âπ≥Êªë„ÄÅÊõ¥Âü∫‰∫é‰∏ä‰∏ãÊñáÁöÑÈÄüÂ∫¶Ê®°ÂºèËøáÊ∏°„ÄÇ\n    - **ÂÖÉÂ≠¶‰π†ÊàñÁªàË∫´Â≠¶‰π†**Ôºö‰ΩøÁ≠ñÁï•ÂÖ∑Â§áÂú®Â∞ëÈáèÁúüÂÆû‰∏ñÁïå‰∫§‰∫íÂêé**Âú®Á∫øÈÄÇÂ∫î**Êñ∞Ê•ºÊ¢ØÂá†‰ΩïÁâπÂæÅÁöÑËÉΩÂäõÔºåÂáèÂ∞ëÂØπ‰ªøÁúüÁ≤æÁ°ÆÂª∫Ê®°ÁöÑ‰æùËµñ„ÄÇ\n\n4.  **Á≥ªÁªüÈõÜÊàê‰∏éÊïàÁéá‰ºòÂåñ**Ôºö\n    - **ËΩªÈáèÂåñ‰∏éÁªü‰∏ÄÈÉ®ÁΩ≤**ÔºöÁ†îÁ©∂Â∞ÜÊÑüÁü•„ÄÅËßÑÂàí„ÄÅÊéßÂà∂Ê®°ÂùóËøõ‰∏ÄÊ≠•ÂéãÁº©Âíå‰ºòÂåñÔºåÂÆûÁé∞Âú®**Âçï‰∏ÄËæπÁºòËÆ°ÁÆóÂπ≥Âè∞**‰∏äÁöÑÈ´òÊïàËøêË°åÔºåÈôç‰ΩéÁ≥ªÁªüÂ§çÊùÇÊÄßÂíåÂäüËÄó„ÄÇ\n    - **‰ªøÁúüÂà∞ÁúüÂÆûËøÅÁßªÁöÑÂº∫Âåñ**ÔºöÂºÄÂèëÊõ¥ÂÖàËøõÁöÑ**ÂüüËá™ÈÄÇÂ∫îÊäÄÊúØ**Âíå**Á≥ªÁªüËæ®ËØÜÊñπÊ≥ï**Ôºå‰ª•Ëøõ‰∏ÄÊ≠•Áº©Â∞è‰ªøÁúü‰∏éÁúüÂÆûÊú∫Âô®‰∫∫Âä®ÂäõÂ≠¶‰πãÈó¥ÁöÑÂ∑ÆË∑ù„ÄÇ\n\n5.  **ÊÄßËÉΩËæπÁïåÊé¢Á¥¢‰∏éÁêÜËÆ∫ÂàÜÊûê**Ôºö\n    - **ÂÆâÂÖ®ÊÄß‰∏éÊïèÊç∑ÊÄßÁöÑÁêÜËÆ∫ÊùÉË°°**ÔºöÂØπÊ°ÜÊû∂ËøõË°åÊõ¥ÂΩ¢ÂºèÂåñÁöÑÂàÜÊûêÔºåÈáèÂåñÂºïÂÖ•Ê®°ÂûãÂºïÂØºÊâÄÂ∏¶Êù•ÁöÑ**Á®≥ÂÆöÊÄß‰øùÈöúËæπÁïå**Ôºå‰ª•Âèä‰∏∫ËøΩÊ±ÇÈÄüÂ∫¶ÊâÄÊâøÊãÖÁöÑ**È£éÈô©Ê∞¥Âπ≥**„ÄÇ\n    - **ÊûÅÈôêÊÄßËÉΩÊµãËØï**ÔºöÂú®Êõ¥‰∏•ËãõÁöÑÊù°‰ª∂‰∏ãÔºàÂ¶ÇÊπøÊªëÊ•ºÊ¢Ø„ÄÅË¥üÈáç„ÄÅÂ§ñÂäõÊâ∞Âä®ÔºâÁ≥ªÁªüÊÄßÂú∞ÊµãËØïÁ≠ñÁï•ÁöÑÂ§±ÊïàÊ®°ÂºèÔºå‰∏∫‰∏ã‰∏Ä‰ª£ÊîπËøõÊèê‰æõÊòéÁ°ÆÊñπÂêë„ÄÇ\n\n**ÊÄªÁªì**ÔºöFastStairÁöÑÊ†∏ÂøÉÂ±ÄÈôêÊÄßÊ∫ê‰∫éÂÖ∂‰∏∫‰∫ÜÂú®**ÊïàÁéá„ÄÅÂÆâÂÖ®ÊÄß‰∏éÊïèÊç∑ÊÄß**‰πãÈó¥ÂèñÂæóÂπ≥Ë°°ËÄåÂÅöÂá∫ÁöÑÂ∑•Á®ãÊäòË°∑ÔºàÊ®°ÂûãÁÆÄÂåñ„ÄÅËßÑÂàôÂàáÊç¢Ôºâ‰ª•ÂèäÂØπÁâπÂÆöÊÑüÁü•ÁÆ°ÈÅìÁöÑ‰æùËµñ„ÄÇÊú™Êù•ÁöÑÊîπËøõÂ∞ÜÊ≤øÁùÄ **‚ÄúÊõ¥Á≤æÁ°ÆÁöÑÊ®°Âûã‚Äù„ÄÅ‚ÄúÊõ¥È≤ÅÊ£íÁöÑÊÑüÁü•‚Äù„ÄÅ‚ÄúÊõ¥Êô∫ËÉΩÁöÑÁ≠ñÁï•‚ÄùÂíå‚ÄúÊõ¥È´òÊïàÁöÑÁ≥ªÁªü‚Äù** Âõõ‰∏™‰∏ªË¶ÅÊñπÂêëÊé®ËøõÔºåÊó®Âú®ÂÆûÁé∞‰∫∫ÂΩ¢Êú∫Âô®‰∫∫Âú®Êõ¥Â§çÊùÇ„ÄÅÊú™Áü•ÁöÑÁúüÂÆûÁéØÂ¢É‰∏≠ÁúüÊ≠£Á±ª‰∫∫ÁöÑÈ´òÈÄü„ÄÅÁ®≥ÂÅ•ËøêÂä®ËÉΩÂäõ„ÄÇ",
            "timestamp": "2026-01-20T18:02:39.704826",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        }
    ],
    "is_hidden": false,
    "is_starred": false,
    "flag": true,
    "published_date": "2026-01-15T13:14:59Z",
    "created_at": "2026-01-20T17:49:55.254225",
    "updated_at": "2026-01-20T17:49:55.254246",
    "recommend": 0
}