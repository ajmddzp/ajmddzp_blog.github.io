{
    "id": "2601.14945v1",
    "title": "TIDAL: Temporally Interleaved Diffusion and Action Loop for High-Frequency VLA Control",
    "authors": [
        "Yuteng Sun",
        "Haoran Wang",
        "Ruofei Bai",
        "Zhengguo Li",
        "Jun Li",
        "Meng Yee",
        "Chuah",
        "Wei Yun Yau"
    ],
    "abstract": "å¤§è§„æ¨¡è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹å…·å¤‡è¯­ä¹‰æ³›åŒ–èƒ½åŠ›ï¼Œä½†å…¶é«˜æ¨ç†å»¶è¿Ÿé™åˆ¶äº†å®ƒä»¬åªèƒ½é‡‡ç”¨ä½é¢‘çš„æ‰¹é‡æ‰§è¡ŒèŒƒå¼ã€‚è¿™ç§é¢‘ç‡ä¸åŒ¹é…é€ æˆäº†æ‰§è¡Œç›²åŒºï¼Œå¯¼è‡´åœ¨åŠ¨æ€ç¯å¢ƒä¸­ï¼ˆç›®æ ‡åœ¨å¼€ç¯æ‰§è¡Œçª—å£æœŸé—´ç§»åŠ¨ï¼‰ä»»åŠ¡å¤±è´¥ã€‚æˆ‘ä»¬æå‡ºTIDALï¼ˆæ—¶åºäº¤é”™æ‰©æ•£ä¸åŠ¨ä½œå¾ªç¯ï¼‰â€”â€”ä¸€ç§å°†è¯­ä¹‰æ¨ç†ä¸é«˜é¢‘é©±åŠ¨è§£è€¦çš„åˆ†å±‚æ¡†æ¶ã€‚TIDALä½œä¸ºåŸºäºæ‰©æ•£çš„VLAæ¨¡å‹ä¸­ä¸ä¸»å¹²ç½‘ç»œæ— å…³çš„æ¨¡å—ï¼Œé‡‡ç”¨åŒé¢‘æ¶æ„é‡æ–°åˆ†é…è®¡ç®—èµ„æºï¼šä½é¢‘å®è§‚æ„å›¾å¾ªç¯ç¼“å­˜è¯­ä¹‰åµŒå…¥ï¼Œè€Œé«˜é¢‘å¾®è§‚æ§åˆ¶å¾ªç¯åˆ™å°†å•æ­¥æµç§¯åˆ†ä¸æ‰§è¡Œè¿‡ç¨‹äº¤é”™è¿›è¡Œã€‚è¯¥è®¾è®¡ä½¿å¾—è¾¹ç¼˜ç¡¬ä»¶ä¸Šçš„æ§åˆ¶æ›´æ–°é¢‘ç‡æå‡è‡³çº¦9èµ«å…¹ï¼ˆåŸºçº¿çº¦ä¸º2.4èµ«å…¹ï¼‰ï¼Œä¸”ä¸å¢åŠ è¾¹é™…å¼€é”€ã€‚ä¸ºåº”å¯¹ç”±æ­¤äº§ç”Ÿçš„å»¶è¿Ÿåç§»ï¼Œæˆ‘ä»¬å¼•å…¥æ—¶åºé”™ä½è®­ç»ƒç­–ç•¥ï¼Œä½¿ç­–ç•¥èƒ½ç»“åˆå®æ—¶æœ¬ä½“æ„ŸçŸ¥ä¸æ»åçš„è¯­ä¹‰æ„å›¾å­¦ä¹ é¢„æµ‹æ€§è¡¥å¿ã€‚æ­¤å¤–ï¼Œé’ˆå¯¹é™æ€è§†è§‰ç¼–ç å™¨å¯¹é€Ÿåº¦ä¸æ•æ„Ÿçš„é—®é¢˜ï¼Œæˆ‘ä»¬æ•´åˆäº†å·®åˆ†è¿åŠ¨é¢„æµ‹å™¨ã€‚TIDALä½œä¸ºæ¶æ„çº§æ–¹æ¡ˆï¼Œä¸ç³»ç»Ÿçº§ä¼˜åŒ–å½¢æˆæ­£äº¤äº’è¡¥ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨åŠ¨æ€æ‹¦æˆªä»»åŠ¡ä¸­ï¼Œæœ¬æ–¹æ³•è¾ƒå¼€ç¯åŸºçº¿çš„æ€§èƒ½æå‡è¾¾2å€ã€‚å°½ç®¡é™æ€æˆåŠŸç‡ç•¥æœ‰ä¸‹é™ï¼Œä½†æˆ‘ä»¬çš„æ–¹æ³•å°†åé¦ˆé¢‘ç‡æé«˜4å€ï¼Œå¹¶å°†è¯­ä¹‰åµŒå…¥çš„æœ‰æ•ˆä½œç”¨èŒƒå›´æ‰©å±•è‡³åŸç”ŸåŠ¨ä½œå—å°ºå¯¸ä¹‹å¤–ã€‚åœ¨éæš‚åœæ¨ç†åè®®ä¸‹ï¼Œå½“æ ‡å‡†åŸºçº¿å› å»¶è¿Ÿè€Œå¤±æ•ˆæ—¶ï¼ŒTIDALä»èƒ½ä¿æŒé²æ£’æ€§ã€‚",
    "url": "https://arxiv.org/abs/2601.14945v1",
    "html_url": "https://arxiv.org/html/2601.14945v1",
    "html_content": "TIDAL: Temporally Interleaved Diffusion and Action Loop for High-Frequency VLA Control\nYuteng Sun\n1,2\n,\nHaoran Wang\n1,3\n,\nRuofei Bai\n1,3\n,\nZhengguo Li\n1\n,\nJun Li\n1\n,\nMeng Yee (Michael) Chuah\n1\nand\nWei Yun Yau\n1\nAbstract\nLarge-scale Vision-Language-Action (VLA) models offer semantic generalization but suffer from high inference latency, limiting them to low-frequency batch-and-execute paradigm. This frequency mismatch creates an execution blind spot, causing failures in dynamic environments where targets move during the open-loop execution window. We propose TIDAL (Temporally Interleaved Diffusion and Action Loop), a hierarchical framework that decouples semantic reasoning from high-frequency actuation. TIDAL operates as a backbone-agnostic module for diffusion-based VLAs, using a dual-frequency architecture to redistribute the computational budget. Specifically, a low-frequency macro-intent loop caches semantic embeddings, while a high-frequency micro-control loop interleaves single-step flow integration with execution. This design enables approximately 9 Hz control updates on edge hardware (vs. approximately 2.4 Hz baselines) without increasing marginal overhead. To handle the resulting latency shift, we introduce a temporally misaligned training strategy where the policy learns predictive compensation using stale semantic intent alongside real-time proprioception. Additionally, we address the insensitivity of static vision encoders to velocity by incorporating a differential motion predictor. TIDAL is architectural, making it orthogonal to system-level optimizations. Experiments show a 2x performance gain over open-loop baselines in dynamic interception tasks. Despite a marginal regression in static success rates, our approach yields a 4x increase in feedback frequency and extends the effective horizon of semantic embeddings beyond the native action chunk size. Under non-paused inference protocols, TIDAL remains robust where standard baselines fail due to latency.\nI\nIntroduction\nFigure 1:\nDynamic Interception Task Execution.\nA complete rollout where TIDAL (1) intercepts a moving can, (2) places it into the drawer, and (3) closes the drawer.\nUnlike open-loop baselines, TIDALâ€™s high-frequency micro-control loop enables the robot to reactively track the moving target and robustly complete the long-horizon sequence.\nThe pursuit of generalist embodied agents has been accelerated by Vision-Language-Action models, exemplified by systems like GR00T\n[\n1\n]\nand\nÏ€\n0\n\\pi_{0}\n[\n2\n]\n. These state-of-the-art models increasingly adopt hierarchical architectures that integrate large Vision-Language-Model backbones with continuous diffusion or flow-matching heads. While these models offer strong semantic grounding by internet-scale pre-training, their architectural scale creates a severe computational bottleneck. Current VLAs typically operate on a batch-and-execute paradigm: the system pauses to process observations and computes an entire long-horizon action chunk, which is then executed open-loop. This introduces a fundamental frequency mismatch. Dynamic manipulation requires high-frequency control, yet large-scale VLM inference is often bound to 2â€“5â€‰Hz\n[\n3\n,\n4\n]\n. In real-world deployment, this bottleneck is worsened by the mandatory execution time of the generated action chunk\n[\n5\n,\n6\n]\n. The combination of inference latency and open-loop execution creates an execution blind spot, where the robot remains unresponsive to environmental changes, leading to failures in dynamic interception tasks.\nExisting latency mitigation strategies incur significant trade-offs. System-level optimizations, such as quantization (e.g., BitVLA\n[\n7\n]\n) or token pruning (e.g., FlashVLA\n[\n8\n]\n), provide speedups but remain bounded by the sequential attention mechanism. Distilling small-scale policies like TinyVLA\n[\n9\n]\ntrades rich semantic priors for throughput. More recently, asynchronous scheduling\n[\n5\n]\nand dual-system architectures\n[\n10\n,\n11\n]\nhave attempted to decouple execution from reasoning. However, these methods often require complex stream management or separate policy networks. We argue that high-frequency control should not require losing the semantic intelligence of large foundation models, nor should it require training distinct policies.\nWe propose TIDAL (Temporally Interleaved Diffusion and Action Loop), a backbone-agnostic framework that bridges this frequency gap via compute-efficient interleaved scheduling. Our core insight is that semantic intent exhibits high temporal persistence, whereas physical state is highly transient. Consequently, the expensive VLM backbone need not be queried synchronously at every step. Instead of discarding the semantic context, we extend its lifespan by fusing it with high-frequency, real-time proprioceptive updates. TIDAL employs a hierarchical dual-frequency Architecture: a low-frequency macro-loop caches semantic embeddings, while a high-frequency micro-loop interleaves single-step flow integration with execution. By algorithmically compressing action chunk generation to negligible levels via single-step flow integration, we achieve the responsiveness of parallel systems without their hardware cost. This redistributes the computational budget, refreshing the action chunk every\nâˆ¼\n\\sim\n110â€‰ms (\nâ‰ˆ\n9\n\\approx 9\nHz) compared to the standard\nâˆ¼\n\\sim\n400â€‰ms baseline cycle, yielding a\n4\nÃ—\n4\\times\nincrease in feedback frequency. Although this imposes a higher optimization burden that slightly impacts static task convergence, it provides the critical reactivity required for dynamic interaction and extends the lifespan of semantic embeddings beyond the native action chunk size.\nDeploying this decoupled architecture introduces a temporal misalignment between the stale semantic condition and the current physical state. To address this, we introduce a temporally misaligned training strategy where the policy learns predictive compensation, using current proprioception to correct for outdated visual intent. Additionally, we resolve the velocity insensitivity of static vision encoders by incorporating a Differential Motion Predictor with contact-gated injection.\nOur primary contributions are:\n1.\nA dual-loop framework that densifies the control updates of heavy VLA backbones by decoupling intent generation from actuation.\n2.\nA training paradigm that enables the policy to robustly compensate for variable VLM latencies and stale semantic cues.\n3.\nAn optimized flow matching inference strategy leveraging source-biased sampling training to compress action chunk generation into a single execution step, facilitating high-frequency interleaving.\n4.\nTIDAL achieves a\n2\nÃ—\n2\\times\nperformance gain in dynamic interception tasks and maintains robustness under non-paused inference evaluation.\nII\nRelated Work\nII-A\nEvolution of VLA: Towards Hierarchical Flow\nEarly VLM-as-a-policy approaches, such as RT-2\n[\n12\n]\nand OpenVLA\n[\n13\n]\n, adopt a VLM + discrete action token architecture. They map natural language directly to quantized actions via large-scale pre-training. To enable continuous control, recent works moved to diffusion and flow matching policies. Models like Octo\n[\n14\n]\nand\nÏ€\n0\n\\pi_{0}\n[\n2\n]\nreplace discrete heads with diffusion processes\n[\n15\n]\nor flow matching experts.\nMore recently, hierarchical architectures have become standard. Systems like GR00T\n[\n1\n]\nand\nÏ€\n0\nâ€‹\n.5\n\\pi_{0}.5\n[\n16\n]\ncombine a heavy VLM backbone for reasoning with a separate Diffusion Transformer (DiT) for action generation. Despite this decoupling, the main inference strategy remains the batch-and-execute paradigm. Even hierarchical systems typically query the VLM and action head synchronously at the start of a cycle. The computational cost of the VLM limits the control frequency to 2â€“5â€‰Hz\n[\n3\n]\n. This creates an execution blind spot: a window where high-frequency motor control freezes or runs open-loop while waiting for the next update. TIDAL targets this specific inefficiency in hierarchical flow-based architectures.\nII-B\nLatency Mitigation and Real-Time Inference\nCurrent methods bridge the inference-actuation gap through model simplification, adaptive computation, or parallel scheduling.\nII-B\n1\nModel Distillation and Architectural Simplification\nOne strategy is to train smaller policies or replace heavy Transformer backbones. Mobile ALOHA\n[\n17\n]\nand TinyVLA\n[\n9\n]\nshow that compact models achieve high throughput. SmolVLA\n[\n18\n]\nuses parameter-efficient fine-tuning on consumer hardware and RoboMamba\n[\n19\n]\nuses state-space models to reduce complexity. These methods gain speed by losing the rich semantic priors and reasoning of large foundation models. Consistency Policy\n[\n20\n]\naccelerates inference by distilling diffusion heads into single-step solvers. This only addresses action head latency, leaving the VLM backbone bottleneck unresolved. TIDAL retains the full backbone, achieving small-model speed without losing large-model intelligence.\nII-B\n2\nStatic Compression and Adaptive Inference\nMany works optimize the backbone directly. Static techniques like quantization (e.g., BitVLA\n[\n7\n]\n, AWQ\n[\n21\n]\n) and token pruning (e.g., FlashVLA\n[\n8\n]\n, EfficientVLA\n[\n22\n]\n) reduce memory and compute density. Dynamic inference mechanisms such as DeeR-VLA\n[\n23\n]\nand CEED-VLA\n[\n24\n]\nuse early exit strategies to stop the forward pass when confidence is high. MoLe-VLA\n[\n25\n]\noptimizes compute via dynamic layer routing, while EdgeVLA\n[\n26\n]\nand PD-VLA\n[\n27\n]\nremove autoregressive dependencies via parallel decoding or specialized heads. System-level optimizations\n[\n28\n]\nalso enable real-time throughput via kernel fusion. Although these methods reduce computation per step, they remain bound by the sequential observe-then-act bottleneck. TIDAL is orthogonal to these optimizations; it acts as a temporal scheduler that uses these accelerated backbones to further densify replanning cycles.\nII-B\n3\nAsynchronous Pipeline and Future Awareness\nRecent works optimize the inference pipeline via asynchronous execution to break sequential dependencies. Real-Time Chunking\n[\n5\n]\ninpaints future actions during execution, while VLASH\n[\n6\n]\nuses a future-state-aware paradigm. VLASH trains the policy to compensate for latency by conditioning on predicted future states. Similarly, Spec-VLA\n[\n29\n]\naccelerates decoding via speculative sampling.\nTIDAL shares the insight of training with temporal misalignment but diverges in execution. Pipelined approaches require high VLM throughput to minimize the prediction horizon. In contrast, TIDALâ€™s lightweight micro-loop reduces effective calculation time to minimal levels. This allows TIDAL to condition directly on the current fused state, avoiding the complexity and uncertainty of predicting future system states.\nII-B\n4\nDecoupled and Dual-System Architectures\nA recent paradigm decouples semantic reasoning from motor control into separate processes. Concurrent frameworks like DuoCore-FS\n[\n30\n]\nand Fast-in-Slow\n[\n10\n]\nimplement a parallel architecture: a slow VLM updates a latent buffer in the background, while a fast policy queries this buffer at high frequency. Although this enables asynchronous execution, it imposes a heavy hardware burden, requiring sufficient memory bandwidth and compute to sustain two active models simultaneously.\nTIDAL achieves similar decoupling via an\nInterleaved\nrather than Parallel strategy. By treating the VLM and Action Head as serial but temporally multiplexed components, TIDAL maximizes compute utilization on edge devices. Unlike DuoCore-FS, which relies on hardware parallelism, TIDAL uses a single-step flow integration mechanism. This algorithmically compresses micro-loop latency, ensuring high-frequency reactivity within a serial execution budget. We validate this responsiveness through dynamic simulation benchmarks, providing quantitative analysis of interception performance under realistic non-paused inference constraints.\nII-C\nTemporal Redundancy and Action Generation\nRecent works on VLA efficiency\n[\n31\n]\nleverage the insight that physical states change rapidly, but high-level semantic intent persists. This insight drives techniques like VLA-Cache\n[\n32\n]\n, which reuses attention KV-caches for static patches, and Fast ECoT\n[\n33\n]\n, which caches high-level language plans. TIDAL extends this philosophy from feature-level to semantic embedding level. We freeze the heavy semantic embedding while querying the lightweight flow policy, exploiting the redundancy in the task intention.\nII-D\nAction Chunking and Execution Strategies\nAction chunking\n[\n34\n]\nis the standard execution paradigm for VLA models like OpenVLA\n[\n13\n]\nand A0\n[\n35\n]\n. Predicting a fixed-horizon action chunk distributes the computational cost of the backbone. But the prevailing execution strategy remains open-loop, the robot executes the chunk blindly while the planner freezes for the next cycle. This causes temporal discontinuities at chunk boundaries and makes the system unresponsive to dynamic disturbances during the long execution window.\nRecent efforts reduce these artifacts through advanced scheduling. Real-Time Chunking (RTC)\n[\n5\n]\ntreats asynchronous execution as inference-time inpainting, generating the next chunk while executing the previous one. Training-Time Action Conditioning (TTAC)\n[\n36\n]\noptimizes this by simulating latency to condition on executing prefixes. Bidirectional Decoding\n[\n37\n]\nuses rejection sampling to splice chunks. Although these asynchronous methods improve throughput, they fundamentally condition actions on stale observations captured at the start of the inference delay.\nTIDAL moves away from this predict-then-execute. Leveraging the vector field properties of Flow Matching\n[\n38\n]\n, we treat the action chunk not as a rigid chunk, but as a flexible manifold. Our\nInterleaved Single-Step Integration\ninjects the latest proprioceptive state into the solver at every step. This transforms the chunk from a static plan into a dynamic vector field query, enabling high frequency reactivity without the complexity of asynchronous stream management or the latency of full sequence regeneration.\nIII\nMethodology\nFigure 2:\nComparison of Inference Paradigms in Dynamic Interception.\n(Top) Standard Baseline:\nUnder the batch-and-execute model, the system performs a blocking inference at the start. It generates a fixed 16-step action chunk conditioned on the static initial state\ns\n0\ns_{0}\n. The resulting open-loop execution forces the robot to follow a stale trajectory, missing the moving target.\n(Bottom) TIDAL (Ours):\nOur Hierarchical Dual-Frequency Architecture.\nThe macro-loop queries the VLM once to generate a Cached Intent\nâ„°\n\\mathcal{E}\n(grey bar), decoupling expensive reasoning from high-frequency actuation.\nThe micro-loop performs interleaved flow integration. At each update, the DiT combines the frozen intent with the real-time fused state\ns\n~\nt\n\\tilde{s}_{t}\nto generate a fresh trajectory.\nThe policy executes only the immediate chunk (\nN\n=\n4\nN=4\n) and discards the tail (fading blocks). This sliding-window execution refreshes the control signal at\nâˆ¼\n\\sim\n9â€‰Hz, enabling the robot to robustly intercept dynamic objects.\nIII-A\nHierarchical Dual-Frequency Architecture\nTIDAL splits VLA inference into two nested processes: a low-frequency macro-intent loop for semantic reasoning and a high-frequency micro-control loop for closed-loop refinement. This decomposition allows 3B parameter backbones to run at high control frequencies by caching semantic embeddings and interleaving flow matching integration steps.\nIII-A\n1\nMacro-Intent Loop (Semantic Caching)\nThe macro loop extracts high-level intent from visual observations. Let\nl\ninstr\nl_{\\text{instr}}\ndenote the natural language instruction and\nI\nt\nk\nI_{t_{k}}\ndenote the RGB observation at macro-step\nk\nk\n. We use a pre-trained VLM backbone\nÎ¦\nVLM\n\\Phi_{\\text{VLM}}\nto map these inputs to a dense intent embedding\nâ„°\nk\n\\mathcal{E}_{k}\n:\nâ„°\nk\n=\nÎ¦\nVLM\nâ€‹\n(\nI\nt\nk\n,\nl\ninstr\n)\n\\mathcal{E}_{k}=\\Phi_{\\text{VLM}}(I_{t_{k}},l_{\\text{instr}})\n(1)\nThe embedding\nâ„°\nk\n\\mathcal{E}_{k}\nis stored in a latent intent and remains frozen for the macro-cycle (horizon\nH\n=\n16\nH=16\n). This caching strategy isolates the control loop from the high latency of\nÎ¦\nVLM\n\\Phi_{\\text{VLM}}\n, exploiting the fact that semantic intent persists over short execution horizons.\nIII-A\n2\nMicro-Control Loop (Interleaved Flow Execution)\nThe micro loop functions as a stateless policy that queries the action head at high frequency. To align with the standard execution horizon (\nH\n=\n16\nH=16\n) while maximizing feedback density, we structure the inference as a cascade of\nK\n=\n4\nK=4\ninteractions per macro-cycle.\nGiven a cached intent\nâ„°\n\\mathcal{E}\n, the loop iterates through latency stages\nk\nâˆˆ\n{\n0\n,\nâ€¦\n,\nK\nâˆ’\n1\n}\nk\\in\\{0,\\dots,K-1\\}\n. At each stage, it observes the current fused state\ns\n~\nk\nâ‹…\nN\n\\tilde{s}_{k\\cdot N}\nand performs a single-step Euler integration to generate the action chunk\na\n^\n\\hat{a}\n:\na\n^\n=\nx\n0\n+\nv\nÎ¸\nâ€‹\n(\nx\n0\n,\n0\n,\ns\n~\nk\nâ‹…\nN\n,\nâ„°\n)\n\\hat{a}=x_{0}+v_{\\theta}(x_{0},0,\\tilde{s}_{k\\cdot N},\\mathcal{E})\n(2)\nwhere\nx\n0\nâˆ¼\nğ’©\nâ€‹\n(\n0\n,\nI\n)\nx_{0}\\sim\\mathcal{N}(0,I)\nrepresents the source noise at flow time\nt\n=\n0\nt=0\n, and\nv\nÎ¸\nv_{\\theta}\npredicts the vector field pointing towards the data manifold.\nAfter chunk generation, we execute only the first\nN\nN\nsteps (\na\n^\n[\n0\n:\nN\n]\n\\hat{a}[0:N]\n) on the robot hardware, discarding the rest.\nStandard baselines exhaust the entire integration budget (e.g.,\nK\n=\n4\nK=4\nsolver steps) at\nt\n=\n0\nt=0\n. In contrast, TIDAL distributes this budget across the timeline. Building on streaming execution paradigms\n[\n39\n,\n40\n]\n, we use a single integration step, which yields a sufficiently accurate vector direction for closed-loop stability. By executing a single Euler stepâ€”effectively a local flow updateâ€”at every chunk boundary, we maintain a Backbone-Iso-Compute footprint while increasing the action chunk update frequency by\n4\nÃ—\n4\\times\n. While standard baselines suffer from a long update cycle (\nâˆ¼\n\\sim\n400â€‰ms), TIDAL reduces this local control cycle to\nâˆ¼\n\\sim\n100ms. This acts as a local vector field query, correcting action chunk drift via updated\ns\nt\ni\ns_{t_{i}}\nrather than expensive long-horizon replanning.\nAlgorithm 1\nTIDAL Hierarchical Inference Logic\n0:\nVLM Backbone\nÎ¦\n\\Phi\n, Policy Vector Field\nv\nÎ¸\nv_{\\theta}\n, Prediction Horizon\nH\n=\n16\nH=16\n, Execution Chunk\nN\n=\n4\nN=4\n, Latency Stages\nK\n=\n4\nK=4\n1:\nloop\n2:\n{\nMacro-Intent Loop\n}\n3:\nCapture high-res image\nI\nm\nâ€‹\na\nâ€‹\nc\nâ€‹\nr\nâ€‹\no\nI_{macro}\n4:\nâ„°\nâ†\nÎ¦\nâ€‹\n(\nI\nm\nâ€‹\na\nâ€‹\nc\nâ€‹\nr\nâ€‹\no\n,\nl\ni\nâ€‹\nn\nâ€‹\ns\nâ€‹\nt\nâ€‹\nr\n)\n\\mathcal{E}\\leftarrow\\Phi(I_{macro},l_{instr})\n{Blocking Inference (\nâˆ¼\n\\sim\n41â€‰ms), updates intent}\n5:\n{\nMicro-Control Loop\n}\n6:\nfor\nk\n=\n0\nk=0\nto\nK\nâˆ’\n1\nK-1\ndo\n7:\nCapture proprioception\ns\np\nâ€‹\nr\nâ€‹\no\nâ€‹\np\ns_{prop}\nand micro-cam\nI\nm\nâ€‹\ni\nâ€‹\nc\nâ€‹\nr\nâ€‹\no\nI_{micro}\n8:\nm\nk\nâ‹…\nN\nâ†\nMotionPredictor\nâ€‹\n(\nI\nm\nâ€‹\ni\nâ€‹\nc\nâ€‹\nr\nâ€‹\no\n)\nm_{k\\cdot N}\\leftarrow\\text{MotionPredictor}(I_{micro})\n9:\ns\n~\nk\nâ‹…\nN\nâ†\nFuse\nâ€‹\n(\ns\np\nâ€‹\nr\nâ€‹\no\nâ€‹\np\n,\nm\nk\nâ‹…\nN\n)\n\\tilde{s}_{k\\cdot N}\\leftarrow\\text{Fuse}(s_{prop},m_{k\\cdot N})\n{Dynamic state fusion (Eq. 7)}\n10:\nx\n0\nâˆ¼\nğ’©\nâ€‹\n(\n0\n,\nI\n)\nx_{0}\\sim\\mathcal{N}(0,I)\n{Sample fresh noise}\n11:\nv\n^\nâ†\nv\nÎ¸\nâ€‹\n(\nx\n0\n,\n0\n,\ns\n~\nk\nâ‹…\nN\n,\nâ„°\n)\n\\hat{v}\\leftarrow v_{\\theta}(x_{0},0,\\tilde{s}_{k\\cdot N},\\mathcal{E})\n{Inference (\nâˆ¼\n\\sim\n19â€‰ms), condition on\ns\n~\nk\nâ‹…\nN\n\\tilde{s}_{k\\cdot N}\n}\n12:\na\n^\nr\nâ€‹\na\nâ€‹\nw\nâ†\nx\n0\n+\nv\n^\n\\hat{a}_{raw}\\leftarrow x_{0}+\\hat{v}\n{Generate full trajectory\nH\nH\n}\n13:\nExecute\na\n^\nr\nâ€‹\na\nâ€‹\nw\n[\n0\n:\nN\n]\n\\hat{a}_{raw}[0:N]\n{Run\nN\nN\nsteps, discard tail\nH\nâˆ’\nN\nH-N\n}\n14:\nWait\nfor execution (\nâˆ¼\n\\sim\n80â€‰ms @ 50â€‰Hz)\n15:\nend\nfor\n16:\nend\nloop\nIII-B\nTemporally Misaligned Training\nFigure 3:\nTemporally Misaligned Training Strategy.\nWe decouple the timestamps of visual and physical inputs to handle latency between the macro-Loop and micro-Loop.\nLatency Injection (Vertical Axis):\nA single frozen semantic intent (encoded from image\nI\n0\nI_{0}\n) is reused across multiple latency stages (\nk\n=\n0\n,\nâ€¦\n,\n3\nk=0,\\dots,3\n). Training pairs this stale intent with progressively later proprioceptive states (\ns\n0\n,\ns\n4\n,\ns\n8\n,\ns\n12\ns_{0},s_{4},s_{8},s_{12}\n), enabling the policy to learn predictive compensation for VLM lag.\nOptimization Objectives:\nWe use a Horizon-Weighted Loss (Dark vs. Light Green bars) with weight\nw\n=\n2.0\nw=2.0\nfor the immediate execution chunk (\nN\n=\n4\nN=4\n) to to emphasize execution stability.\nThe Time-Biased Sampling inset (\nt\nâˆ¼\nP\nâ€‹\n(\nt\n)\nt\\sim P(t)\n) shows that we bias flow timestep sampling towards the noise source (\nt\nâ‰ˆ\n0\nt\\approx 0\n) to optimize the vector field for single-step integration.\nSynchronous training creates a distribution shift in our architecture because semantic conditions\nâ„°\n\\mathcal{E}\n(\nI\nt\nâˆ’\nÎ”\nI_{t-\\Delta}\n) lag behind the physical state\ns\nt\ns_{t}\n. We address this with a temporally misaligned training strategy that explicitly decouples visual and physical input timestamps. This aligns with recent findings in asynchronous control\n[\n6\n,\n30\n]\n, confirming that conditioning policies on latency-matched proprioception enables convergence despite semantic lag.\nIII-B\n1\nDynamic Latency Injection\nWe simulate variable inference latencies by creating training samples with randomized time-lags. Instead of fixed windows\nH\nH\n, we sample extended trajectory segments of length\nL\nL\n:\nL\n=\nH\n+\n(\nK\nâˆ’\n1\n)\nÃ—\nN\nL=H+(K-1)\\times N\n(3)\nwhere\nH\n=\n16\nH=16\nis the prediction horizon,\nN\n=\n4\nN=4\nis the execution chunk size, and\nK\n=\n4\nK=4\nis the number of latency stages. We set\nL\n=\n28\nL=28\n.\nDuring training, we discretize the potential delay into fixed stages, sampling a latency index\nk\nâˆ¼\nğ’°\nâ€‹\n{\n0\n,\nK\nâˆ’\n1\n}\nk\\sim\\mathcal{U}\\{0,K-1\\}\nfor each iteration. The policy input tuple consists of:\nâ€¢\nFrozen Intent (\nt\n=\n0\nt=0\n): Visual backbone input\nI\n0\nI_{0}\n.\nâ€¢\nCurrent State (\nt\n=\nk\nâ‹…\nN\nt=k\\cdot N\n): Proprioceptive state\ns\nk\nâ‹…\nN\ns_{k\\cdot N}\n.\nâ€¢\nAction Target (\nt\n=\nk\nâ‹…\nN\nt=k\\cdot N\n): Ground truth sequence\na\nk\nâ‹…\nN\n:\nk\nâ‹…\nN\n+\nH\na_{k\\cdot N:k\\cdot N+H}\n.\nRestricting latency to a fixed set of discrete multiples of\nN\nN\n, rather than sampling from a continuous interval, reduces the variance of the learning objective. This simplifies the optimization landscape, allowing the model to converge to distinct compensation modes for each stage of intent staleness, rather than fitting an infinite spectrum of delays.\nIII-B\n2\nHorizon-Weighted & Time-Biased Flow Matching\nThe action chunk generator is implemented using Conditional Flow Matching (CFM)\n[\n41\n]\n, which regresses a time-dependent vector field\nv\nÎ¸\nv_{\\theta}\n. We define the optimal transport path\nÏˆ\nt\nâ€‹\n(\nx\n0\n,\nx\n1\n)\n=\n(\n1\nâˆ’\nt\n)\nâ€‹\nx\n0\n+\nt\nâ€‹\nx\n1\n\\psi_{t}(x_{0},x_{1})=(1-t)x_{0}+tx_{1}\nbetween the Gaussian noise source\nx\n0\nâˆ¼\nğ’©\nâ€‹\n(\n0\n,\nI\n)\nx_{0}\\sim\\mathcal{N}(0,I)\nand the target action sequence\nx\n1\nx_{1}\n. The objective minimizes the expected flow matching error:\nâ„’\n(\nÎ¸\n)\n=\nğ”¼\nk\n,\nt\n,\nx\n0\n,\nx\n1\n[\nâˆ‘\ni\n=\n0\nH\nâˆ’\n1\nw\ni\nâ‹…\nâˆ¥\nv\nÎ¸\nâ€‹\n(\nÏˆ\nt\nâ€‹\n(\nx\n0\n,\nx\n1\n)\n,\nt\n,\ns\nk\nâ‹…\nN\n,\nâ„°\n0\n)\n(\ni\n)\nâˆ’\n(\nx\n1\n(\ni\n)\nâˆ’\nx\n0\n(\ni\n)\n)\nâˆ¥\n2\n]\n\\begin{split}\\mathcal{L}(\\theta)=\\mathbb{E}_{k,t,x_{0},x_{1}}\\Bigg[\\sum_{i=0}^{H-1}w_{i}\\cdot\\Big\\|&v_{\\theta}(\\psi_{t}(x_{0},x_{1}),t,s_{k\\cdot N},\\mathcal{E}_{0})^{(i)}\\\\\n&-(x_{1}^{(i)}-x_{0}^{(i)})\\Big\\|^{2}\\Bigg]\\end{split}\n(4)\nwhere\nt\nt\nis the continuous flow time,\nk\nâˆˆ\n{\n0\n,\n1\n,\n2\n,\n3\n}\nk\\in\\{0,1,2,3\\}\nrepresents the sampled latency stage, and\ni\ni\nindexes the action horizon steps.\ns\nk\nâ‹…\nN\ns_{k\\cdot N}\nand\nâ„°\n0\n\\mathcal{E}_{0}\ndenote the time-misaligned proprioception and frozen semantic intent, respectively.\nThe micro-loop executes only the initial chunk of length\nN\n=\n4\nN=4\nbefore the next update. So we apply a horizon-aware mask\nw\ni\nw_{i}\n, setting\nw\ni\n=\n2.0\nw_{i}=2.0\nfor\ni\n<\nN\ni<N\nand\n1.0\n1.0\notherwise. This asymmetry forces the vector field to prioritize precision in the imminent execution window (\ni\n<\nN\ni<N\n) over distal trajectory smoothness.\nStandard Flow Matching samples the flow timestep\nt\nt\nuniformly (\nt\nâˆ¼\nğ’°\nâ€‹\n[\n0\n,\n1\n]\nt\\sim\\mathcal{U}[0,1]\n), allocating equal capacity across the probability path. However, our micro-loop relies exclusively on single-step Euler integration starting from pure noise (\nt\n=\n0\nt=0\n). The policy is only queried at the source frontier. Training capacity spent minimizing error at intermediate flow times (e.g.,\nt\n=\n0.5\nt=0.5\n) is therefore wasted, as these states are never visited during inference. To align the objective with our architecture, we bias the sampling distribution\np\nâ€‹\n(\nt\n)\np(t)\nheavily towards the noise source. We sample an auxiliary variable\ns\nâˆ¼\nBeta\nâ€‹\n(\nÎ±\n,\nÎ²\n)\ns\\sim\\text{Beta}(\\alpha,\\beta)\nand set\nt\n=\n1\nâˆ’\ns\nt=1-s\n. With\nÎ±\n=\n5.0\n\\alpha=5.0\nand\nÎ²\n=\n1.0\n\\beta=1.0\n, the probability mass concentrates near\nt\nâ‰ˆ\n0\nt\\approx 0\n. This ensures the vector field is most accurate exactly where the single-step solver queries it, maximizing the efficiency of the limited inference budget.\nIII-C\nDynamic Perception via Motion Injection\nWe introduce a Differential Motion Predictor (\nÏˆ\nmotion\n\\psi_{\\text{motion}}\n) to inject high-frequency kinematic features directly into the policy, enabling reactivity to moving targets without re-querying the VLM.\nWe extract motion cues using temporal difference tensors. The input\nÎ”\nâ€‹\nI\nt\n\\Delta I_{t}\nis the normalized pixel-wise difference between the current frame and a history frame with lag\nk\n=\n4\nk=4\n:\nÎ”\nâ€‹\nI\nt\n=\nğ’¯\nâ€‹\n(\nI\nt\n)\nâˆ’\nğ’¯\nâ€‹\n(\nI\nt\nâˆ’\nk\n)\n\\Delta I_{t}=\\mathcal{T}(I_{t})-\\mathcal{T}(I_{t-k})\n.\nA custom 7-layer CNN processes this input to minimize latency, followed by an MLP bottleneck that produces a low-dimensional embedding\nm\nt\nâˆˆ\nâ„\n64\nm_{t}\\in\\mathbb{R}^{64}\n. We pretrain\nÏˆ\nmotion\n\\psi_{\\text{motion}}\nusing an auxiliary regression loss to predict the end-effectorâ€™s future position\np\np\nand velocity\nv\nv\n, forcing\nm\nt\nm_{t}\nto encode physical dynamics:\nâ„’\naux\n=\nÎ»\n1\nâ€‹\nâ€–\np\n^\nt\nâˆ’\np\nt\nâ€–\n2\n+\nÎ»\n2\nâ€‹\nâ€–\nv\n^\nt\nâˆ’\nv\nt\nâ€–\n2\n+\nÎ»\n3\nâ€‹\nâ€–\np\n^\nt\n+\nk\nâˆ’\np\nt\n+\nk\nâ€–\n2\n\\mathcal{L}_{\\text{aux}}=\\lambda_{1}\\|\\hat{p}_{t}-p_{t}\\|^{2}+\\lambda_{2}\\|\\hat{v}_{t}-v_{t}\\|^{2}+\\lambda_{3}\\|\\hat{p}_{t+k}-p_{t+k}\\|^{2}\n(5)\nPredicting the future position\np\nt\n+\nk\np_{t+k}\nimplicitly encodes momentum, enabling predictive interception.\nTo prevent control instability during manipulation where relative motion is zero, we use a hard contact-gating mechanism. Based on a binary contact state\nc\nt\nâˆˆ\n{\n0\n,\n1\n}\nc_{t}\\in\\{0,1\\}\nderived from gripper sensors, and the robotâ€™s proprioceptive joint state\ns\nprop\ns_{\\text{prop}}\n, we construct the fused policy state\ns\n~\nt\n\\tilde{s}_{t}\nvia concatenation:\ns\n~\nt\n=\nConcat\nâ€‹\n(\ns\nprop\n,\n(\n1\nâˆ’\nc\nt\n)\nâ‹…\nm\nt\n)\n\\tilde{s}_{t}=\\text{Concat}(s_{\\text{prop}},\\;(1-c_{t})\\cdot m_{t})\n(6)\nwhere\nm\nt\nâˆˆ\nâ„\n64\nm_{t}\\in\\mathbb{R}^{64}\nis the motion embedding and\ns\nprop\ns_{\\text{prop}}\nis the robotâ€™s joint state. This formulation enforces a modal switch: the policy attends to the full motion vector during the approach phase (\nc\nt\n=\n0\nc_{t}=0\n) and receives a zero-masked vector during manipulation (\nc\nt\n=\n1\nc_{t}=1\n), falling back to proprioceptive control upon contact.\nIV\nExperiments\nWe evaluate whether TIDALâ€™s hierarchical decoupling enables robust dynamic manipulation without losing generalist capabilities.\nIV-A\nExperimental Setup\nIV-A\n1\nEnvironments\nWe evaluate TIDAL on two benchmarks in the RoboCasa (MuJoCo) suite:\nWe use 8 tasks from the official â€˜RoboCasa-GR1â€˜ benchmark\n[\n42\n,\n1\n]\n. These long-horizon tasks feature stationary targets and serve as a control group to verify that our architecture maintains generalist capabilities.\nWe construct a Dynamic Interception benchmark requiring the robot to intercept a moving target, place it in a drawer, and close it. We initialize the target with a random velocity (\n0.04\n0.04\nâ€“\n0.06\n0.06\nm/s) along a cardinal direction. To increase stochasticity, the object executes a random 90-degree turn at boundaries, creating non-deterministic trajectories. We stratify this into Easy and Hard tiers. Since we use the left hand, targets moving right or up are kinematically favorable (â€œEasyâ€). Conversely, the Hard tier involves targets moving away or into occlusion zones, requiring complex reach-around maneuvers.\nIV-A\n2\nData Collection\nFor the dynamic task, we collect a fine-tuning dataset of 2,000 successful episodes using a paused-sim oracle strategy. This oracle operates by pausing the physics simulation at every time step (\nN\n=\n1\nN=1\n) to run the full VLA inference, thereby generating ideal closed-loop trajectories that perfectly track environmental changesâ€”a behavior achievable only when computational latency is ignored. This automated pipeline allows for the scalable generation of high-quality expert data, avoiding the prohibitive time and labor costs associated with human VR teleoperation.\nIV-A\n3\nBaselines and Configuration\nWe use GR00T-N1.5-3B as the VLA backbone. We compare TIDAL against a standard Open-Loop Baseline under a strict Backbone-Iso-Compute protocol:\nâ€¢\nOpen-Loop Baseline: Follows the batch-and-execute paradigm. It queries the VLM backbone and Diffusion Head once at\nt\n=\n0\nt=0\n, generating a full action chunk (\nH\n=\n16\nH=16\n), then executes the sequence open-loop (\nâˆ¼\n\\sim\n2.4â€‰Hz control frequency).\nâ€¢\nTIDAL (Ours): Splits the compute budget. It queries the VLM once every 16 steps to cache the intent. Then, at every chunk of\nN\n=\n4\nN=4\nsteps, it queries the flow matching head for a single Euler integration step, updating the action chunk based on the latest observation.\nIV-A\n4\nComputational Protocols & Baseline Selection\nWe strictly control the budget of the heavy Backbone components (VLM encoder and Diffusion Transformer). We fix the prediction horizon at\nH\n=\n16\nH=16\nfor all methods. Reducing the horizon (e.g., to\nH\n=\n8\nH=8\n) would require doubling the backbone query frequency to maintain continuous control. Given the latency of 3B models, such high-frequency re-planning is intractable for real-time deployment and would cause severe execution freezing.\nWe therefore enforce a backbone-iso-compute constraint. Both TIDAL and the baseline are limited to one VLM pass and an equivalent number of DiT passes per macro-cycle. The distinction is topological, which is the baseline batches computations at\nt\n=\n0\nt=0\n, whereas TIDAL distributes them temporally. While TIDAL incurs marginal overhead from lightweight MLP adapters(state encoding/action encoding and decoding) and the tiny custom 7-layer CNN motion predictor, these are negligible compared to the backbone latency. This ensures that performance gains come from hierarchical scheduling rather than increased backbone throughput.\nWe quantify latency using the performance of NVIDIA Jetson AGX Orin (Max-N mode, TensorRT from official performance profiles\n[\n1\n]\n). We define Effective Update Frequency based on total cycle time\nT\nc\nâ€‹\ny\nâ€‹\nc\nâ€‹\nl\nâ€‹\ne\n=\nT\ni\nâ€‹\nn\nâ€‹\nf\nâ€‹\ne\nâ€‹\nr\nâ€‹\ne\nâ€‹\nn\nâ€‹\nc\nâ€‹\ne\n+\nT\ne\nâ€‹\nx\nâ€‹\ne\nâ€‹\nc\nâ€‹\nu\nâ€‹\nt\nâ€‹\ni\nâ€‹\no\nâ€‹\nn\nT_{cycle}=T_{inference}+T_{execution}\n, assuming a 50â€‰Hz control rate (\n20\nâ€‹\nms/step\n20\\text{ms/step}\n):\nâ€¢\nBaseline: Full inference (\n93\n93\nms) + 16-step execution (\n320\n320\nms)\nâ†’\n\\rightarrow\nâˆ¼\n\\sim\n2.4â€‰Hz update rate.\nâ€¢\nTIDAL (Effective): Weighted average inference (\nâˆ¼\n30\n\\sim 30\nms, including amortized VLM) + 4-step execution (\n80\n80\nms)\nâ†’\n\\rightarrow\nâˆ¼\n\\sim\n9â€‰Hz effective update rate.\nâ€¢\nTIDAL (Peak): Micro inference (\nâˆ¼\n19\n\\sim 19\nms) + execution (\n80\n80\nms)\nâ†’\n\\rightarrow\nâˆ¼\n\\sim\n10â€‰Hz peak rate.\nIV-B\nMain Results\nTable\nI\nsummarizes the performance across standard static tasks and our dynamic interception benchmarks.\nTABLE I:\nSuccess Rate Comparison on Static and Dynamic Benchmarks\nMethod\nStatic (Official)\nDynamic (Easy)\nDynamic (Hard)\nBaseline\n0.5925\n0.31\n0.16\nTIDAL (Ours)\n0.5094\n0.61\n0.36\nIV-B\n1\nDynamic Interception\nIn dynamic environments, the Open-Loop Baseline fails, scoring only 0.31 on the Easy tier and dropping to 0.16 on Hard. Its long inference latency prevents action chunk updates once execution begins. TIDAL doubles performance, reaching\n0.61\n(Easy) and\n0.36\n(Hard). This gap confirms our hypothesis: high-frequency correction is a prerequisite for interception, regardless of the semantic plannerâ€™s quality.\nIV-B\n2\nStatic Generalization\nOn the official RoboCasa benchmark, the Baseline outperforms TIDAL (59.25% vs 50.94%). This gap comes from two factors. First, the VLM backbone was pre-trained with standard open-loop objectives, giving the Baseline an architectural advantage in static settings. Second, TIDALâ€™s hierarchical structure increases optimization complexity, likely requiring more training steps to converge. However, TIDAL retains strong generalist capabilities (\nâˆ¼\n\\sim\n50.94%), showing that optimizing inference for speed does not cause a severe loss of reasoning. We explicitly trade static precision for reactivityâ€”a critical capability that baseline lacks.\nIV-C\nAblation Study\nWe isolate the contributions of TIDALâ€™s two core components: hierarchical architecture (high-frequency updates) and differential motion Predictor (velocity perception). Table\nII\nshows results on the Dynamic (Easy) task.\nThe TIDAL architecture without motion features yields a success rate of 0.33, marginally better than the Baseline (0.31). Although operating at\nâˆ¼\n\\sim\n9â€‰Hz, it lacks explicit velocity data. The policy acts as a high-frequency position servo that lags behind the moving target, confirming that control frequency is insufficient if perception remains motion-blind.\nInjecting motion features into the Open-Loop Baseline improves performance to 0.44. Motion embeddings provide initial velocity cues, allowing the planner to estimate a better intercept trajectory at\nt\n=\n0\nt=0\n. However, this setup remains bound by the batch-and-execute paradigm; it cannot react to target changes during the long execution window.\nTIDAL (Full) achieves 0.61, outperforming both variants. This highlights a critical synergy: the motion predictor provides the signal to track dynamics, while the hierarchical architecture provides the computational opportunity to act on that signal reactively.\nTABLE II:\nAblation Analysis on Dynamic (Easy) Tasks.\nConfiguration\nSuccess\nKey Limitation\nBaseline\n0.31\nHigh Latency + Static Features\nTIDAL w/o Motion\n0.33\nMotion Blindness\nBase + Motion\n0.44\nExecution Blind Spot\nTIDAL (Full)\n0.61\n-\nIV-D\nHyperparameter Exploration\nWe analyze TIDALâ€™s training objective sensitivity on a single representative task from the official suite, focusing on the horizon-weighting factor\nw\nw\n(biasing the loss towards the immediate execution chunk) and the Beta distribution parameter\nÎ±\n\\alpha\n(biasing time sampling towards the noise source).\nWe sweep\nw\nâˆˆ\n[\n1.0\n,\n3.0\n]\nw\\in[1.0,3.0]\nwith\nÎ±\n=\n1.5\n\\alpha=1.5\n. Table\nIII\n(Left) shows performance peaks at\nw\n=\n2.0\nw=2.0\n(76.95%).\nIncreasing\nw\nw\nto 2.0 improves success, confirming that prioritizing the first\nN\n=\n4\nN=4\nsteps is crucial for micro-loop stability. Higher weights (\nw\n>\n2.0\nw>2.0\n) degrade performance. Over-weighting likely causes the optimization to neglect trajectory continuity, creating disjointed flow predictions at chunk boundaries.\nWith\nw\n=\n2.0\nw=2.0\n, we vary\nÎ±\n\\alpha\n. Since TIDALâ€™s micro-loop queries the flow network only from pure noise (\nt\n=\n0\nt=0\n), the training distribution should match this pattern.\nTable\nIII\n(Right) validates this. Increasing\nÎ±\n\\alpha\nto 5.0 shifts focus towards\nt\nâ‰ˆ\n0\nt\\approx 0\n, yielding the highest success rate (78.91%). This confirms that for single-step architectures, the capacity spent modeling mid-trajectory flow (e.g.,\nt\nâˆˆ\n[\n0.2\n,\n0.8\n]\nt\\in[0.2,0.8]\n) is largely wasted. However, pushing\nÎ±\n\\alpha\ntoo far (e.g., 7.0) reduces sample diversity, causing a performance drop.\nTABLE III:\nHyperparameter Exploration: Horizon Weight (\nw\nw\n) and Time Sampling (\nÎ±\n\\alpha\n)\nLoss Weight (\nw\nw\n)\nTime Sampling (\nÎ±\n\\alpha\n)\nWeight\nSuccess Rate\nAlpha\nSuccess Rate\n1.0\n70.31%\n3.0\n78.12%\n1.5\n73.83%\n5.0\n78.91%\n2.0\n76.95%\n7.0\n71.10%\n2.5\n71.48%\n-\n-\n3.0\n70.70%\n-\n-\nIV-E\nSemantic Intent Lifespan and Efficiency\nWe analyze the temporal validity of the cached semantic intent\nâ„°\n\\mathcal{E}\non a single static task from official suite. By artificially increasing the latency parameter\nl\nl\n, we force the micro-loop to execute more physical steps before refreshing the semantic goal, testing the policyâ€™s tolerance for staleness.\nTable\nIV\nshows a stable profile. Extending intent lifespan from the standard\nl\n=\n28\nl=28\n(0.72) to\nl\n=\n56\nl=56\n(0.60) causes minimal degradation. This suggests that in TIDAL, there is a window where the semantic embedding remains valid if the policy receives real-time proprioceptive updates.\nThis finding challenges the native action chunk limit. While the GR00T backbone is trained to predict a fixed 16-step chunk, TIDALâ€™s hierarchical architecture extends the useful horizon of a single intent query to\nâˆ¼\n\\sim\n44 steps. The policy uses the old intent to condition new, locally correct flows. A sharp performance cliff appears at\nl\n=\n64\nl=64\n(0.38), indicating where the robotâ€™s state diverges too far from the initial snapshot. Although variance increases at extreme latencies (\nl\n>\n60\nl>60\n), the trend confirms that control authority degrades as semantic lag exceeds the physical correlation window.\nTABLE IV:\nAnalysis of Semantic Intent Lifespan (\nl\nl\n) and Performance Retention\nLag Parameter (\nl\nl\n)\nEffective Steps\nSuccess Rate\nRetention\n28 (Standard)\n16 steps\n0.72\n100%\n32\n20 steps\n0.68\n94.4%\n36\n24 steps\n0.61\n84.7%\n40\n28 steps\n0.66\n91.7%\n44\n32 steps\n0.69\n95.8%\n48\n36 steps\n0.69\n95.8%\n52\n40 steps\n0.66\n91.7%\n56\n44 steps\n0.60\n83.3%\n60\n48 steps\n0.48\n66.7%\n64\n52 steps\n0.38\n52.8%\n68\n56 steps\n0.51\n70.8%\n72\n60 steps\n0.32\n44.4%\n80\n68 steps\n0.24\n33.3%\n100\n88 steps\n0.20\n27.8%\nTABLE V:\nComparison of Inference Stability: Paused vs. Non-Paused Protocols\nMethod\nPaused\nNon-Paused\nRetention Rate\nBaseline\n0.31\n0.09\nâˆ¼\n\\sim\n29%\nTIDAL (Ours)\n0.61\n0.30\nâˆ¼\n\\sim\n49%\nIV-F\nSim-to-Real Potential: Non-Paused Inference\nStandard benchmarks pause physics during inference, cutting the delay between observation and actuation off. To approximate real-world deployment, we use a non-paused evaluation where the simulation advances target dynamics during policy computation.\nTable\nV\nreveals a contrast:\nâ€¢\nBaseline Collapse: The Open-Loop Baseline fails, dropping from 0.31 to 0.09. Suffering from a\nâˆ¼\n\\sim\n400â€‰ms blind window (93â€‰ms compute + 320â€‰ms execution), the target moves away from the planned trajectory before the robot moves. A 9% success rate makes the system unusable for real-time dynamic interception.\nâ€¢\nTIDAL Resilience: TIDAL sustains a success rate of 0.30. By shrinking the update cycle to\nâˆ¼\n\\sim\n100ms, TIDAL reduces the blind window by\n4\nÃ—\n4\\times\n. Although performance drops compared to the idealized paused setting (0.61), it retains nearly half its performance and remains\n3\nÃ—\n3\\times\nmore effective than the baseline. This resilience comes from our distributed compute strategy: interleaving computation with actuation minimizes reaction delay and continuously corrects for drift, bridging the reality gap where standard baselines fail.\nV\nConclusion\nWe presented TIDAL, a framework designed to enable high-frequency control with large VLA models. By interleaving single-step flow generation with action execution, our approach achieves a 4x increase in update frequency on edge hardware while maintaining the same backbone computational budget. This significantly reduces the execution blind spot found in standard batch-and-execute baselines.\nWe rely on temporally misaligned training to compensate for stale semantics, while single-step flow integration minimizes latency. This results in a 2x performance gain on dynamic interception tasks. Our analysis reveals that updating the policy with real-time proprioception effectively extends the lifespan of cached semantic embeddings beyond their native horizon. Since TIDAL is backbone-agnostic, it remains orthogonal to system-level accelerations. The sustained performance under non-paused protocols suggests strong potential for future sim-to-real transfer. We are currently deploying TIDAL on physical robot hardware to further validate its robustness in real-world dynamic environments.\nReferences\n[1]\nJ.Â Bjorck, F.Â CastaÃ±eda, N.Â Cherniadev, X.Â Da, R.Â Ding, L.Â Fan, Y.Â Fang, D.Â Fox, F.Â Hu, S.Â Huang\netÂ al.\n, â€œGr00t n1: An open foundation model for generalist humanoid robots,â€\narXiv preprint arXiv:2503.14734\n, 2025.\n[2]\nK.Â Black, N.Â Brown, D.Â Driess, A.Â Esmail, M.Â Equi, C.Â Finn, N.Â Fusai, L.Â Groom, K.Â Hausman, B.Â Ichter\netÂ al.\n, â€œ\nÏ€\n0\n\\pi_{0}\n: A vision-language-action flow model for general robot control,â€\narXiv preprint arXiv:2410.24164\n, 2024.\n[3]\nK.Â Kawaharazuka, J.Â Oh, J.Â Yamada, I.Â Posner, and Y.Â Zhu, â€œVision-language-action models for robotics: A review towards real-world applications,â€\nIEEE Access\n, 2025.\n[4]\nR.Â Shao, W.Â Li, L.Â Zhang, R.Â Zhang, Z.Â Liu, R.Â Chen, and L.Â Nie, â€œLarge vlm-based vision-language-action models for robotic manipulation: A survey,â€\narXiv preprint arXiv:2508.13073\n, 2025.\n[5]\nK.Â Black, M.Â Y. Galliker, and S.Â Levine, â€œReal-time execution of action chunking flow policies,â€\narXiv preprint arXiv:2506.07339\n, 2025.\n[6]\nJ.Â Tang, Y.Â Sun, Y.Â Zhao, S.Â Yang, Y.Â Lin, Z.Â Zhang, J.Â Hou, Y.Â Lu, Z.Â Liu, and S.Â Han, â€œVlash: Real-time vlas via future-state-aware asynchronous inference,â€\narXiv preprint arXiv:2512.01031\n, 2025.\n[7]\nH.Â Wang, C.Â Xiong, R.Â Wang, and X.Â Chen, â€œBitvla: 1-bit vision-language-action models for robotics manipulation,â€\narXiv preprint arXiv:2506.07530\n, 2025.\n[8]\nX.Â Tan, Y.Â Yang, P.Â Ye, J.Â Zheng, B.Â Bai, X.Â Wang, J.Â Hao, and T.Â Chen, â€œThink twice, act once: Token-aware compression and action reuse for efficient inference in vision-language-action models,â€\narXiv preprint arXiv:2505.21200\n, 2025.\n[9]\nJ.Â Wen, Y.Â Zhu, J.Â Li, M.Â Zhu, Z.Â Tang, K.Â Wu, Z.Â Xu, N.Â Liu, R.Â Cheng, C.Â Shen\netÂ al.\n, â€œTinyvla: Towards fast, data-efficient vision-language-action models for robotic manipulation,â€\nIEEE Robotics and Automation Letters\n, 2025.\n[10]\nH.Â Chen, J.Â Liu, C.Â Gu, Z.Â Liu, R.Â Zhang, X.Â Li, X.Â He, Y.Â Guo, C.-W. Fu, S.Â Zhang\netÂ al.\n, â€œFast-in-slow: A dual-system foundation model unifying fast manipulation within slow reasoning,â€\narXiv preprint arXiv:2506.01953\n, 2025.\n[11]\nJ.Â Liu, H.Â Chen, P.Â An, Z.Â Liu, R.Â Zhang, C.Â Gu, X.Â Li, Z.Â Guo, S.Â Chen, M.Â Liu\netÂ al.\n, â€œHybridvla: Collaborative diffusion and autoregression in a unified vision-language-action model,â€\narXiv preprint arXiv:2503.10631\n, 2025.\n[12]\nB.Â Zitkovich, T.Â Yu, S.Â Xu, P.Â Xu, T.Â Xiao, F.Â Xia, J.Â Wu, P.Â Wohlhart, S.Â Welker, A.Â Wahid\netÂ al.\n, â€œRt-2: Vision-language-action models transfer web knowledge to robotic control,â€ in\nConference on Robot Learning\n.â€ƒPMLR, 2023, pp. 2165â€“2183.\n[13]\nM.Â J. Kim, K.Â Pertsch, S.Â Karamcheti, T.Â Xiao, A.Â Balakrishna, S.Â Nair, R.Â Rafailov, E.Â Foster, G.Â Lam, P.Â Sanketi\netÂ al.\n, â€œOpenvla: An open-source vision-language-action model,â€\narXiv preprint arXiv:2406.09246\n, 2024.\n[14]\nO.Â Mees, D.Â Ghosh, K.Â Pertsch, K.Â Black, H.Â R. Walke, S.Â Dasari, J.Â Hejna, T.Â Kreiman, C.Â Xu, J.Â Luo\netÂ al.\n, â€œOcto: An open-source generalist robot policy,â€ in\nFirst Workshop on Vision-Language Models for Navigation and Manipulation at ICRA 2024\n, 2024.\n[15]\nC.Â Chi, Z.Â Xu, S.Â Feng, E.Â Cousineau, Y.Â Du, B.Â Burchfiel, R.Â Tedrake, and S.Â Song, â€œDiffusion policy: Visuomotor policy learning via action diffusion,â€\nThe International Journal of Robotics Research\n, vol.Â 44, no. 10-11, pp. 1684â€“1704, 2025.\n[16]\nK.Â Black, N.Â Brown, J.Â Darpinian, K.Â Dhabalia, D.Â Driess, A.Â Esmail, M.Â R. Equi, C.Â Finn, N.Â Fusai, M.Â Y. Galliker\netÂ al.\n, â€œ\nÏ€\n0.5\n\\pi_{0.5}\n: A vision-language-action model with open-world generalization,â€ in\n9th Annual Conference on Robot Learning\n, 2025.\n[17]\nZ.Â Fu, T.Â Z. Zhao, and C.Â Finn, â€œMobile aloha: Learning bimanual mobile manipulation using low-cost whole-body teleoperation,â€ in\n8th Annual Conference on Robot Learning\n, 2024.\n[18]\nM.Â Shukor, D.Â Aubakirova, F.Â Capuano, P.Â Kooijmans, S.Â Palma, A.Â Zouitine, M.Â Aractingi, C.Â Pascal, M.Â Russi, A.Â Marafioti\netÂ al.\n, â€œSmolvla: A vision-language-action model for affordable and efficient robotics,â€\narXiv preprint arXiv:2506.01844\n, 2025.\n[19]\nJ.Â Liu, M.Â Liu, Z.Â Wang, L.Â Lee, K.Â Zhou, P.Â An, S.Â Yang, R.Â Zhang, Y.Â Guo, and S.Â Zhang, â€œRobomamba: Multimodal state space model for efficient robot reasoning and manipulation,â€\narXiv e-prints\n, pp. arXivâ€“2406, 2024.\n[20]\nA.Â Prasad, K.Â Lin, J.Â Wu, L.Â Zhou, and J.Â Bohg, â€œConsistency policy: Accelerated visuomotor policies via consistency distillation,â€\narXiv preprint arXiv:2405.07503\n, 2024.\n[21]\nJ.Â Lin, J.Â Tang, H.Â Tang, S.Â Yang, G.Â Xiao, and S.Â Han, â€œAwq: Activation-aware weight quantization for on-device llm compression and acceleration,â€\nGetMobile: Mobile Computing and Communications\n, vol.Â 28, no.Â 4, pp. 12â€“17, 2025.\n[22]\nY.Â Yang, Y.Â Wang, Z.Â Wen, L.Â Zhongwei, C.Â Zou, Z.Â Zhang, C.Â Wen, and L.Â Zhang, â€œEfficientvla: Training-free acceleration and compression for vision-language-action models,â€\narXiv preprint arXiv:2506.10100\n, 2025.\n[23]\nY.Â Yue, Y.Â Wang, B.Â Kang, Y.Â Han, S.Â Wang, S.Â Song, J.Â Feng, and G.Â Huang, â€œDeer-vla: Dynamic inference of multimodal large language models for efficient robot execution,â€\nAdvances in Neural Information Processing Systems\n, vol.Â 37, pp. 56â€‰619â€“56â€‰643, 2024.\n[24]\nW.Â Song, J.Â Chen, P.Â Ding, Y.Â Huang, H.Â Zhao, D.Â Wang, and H.Â Li, â€œCeed-vla: Consistency vision-language-action model with early-exit decoding,â€\narXiv preprint arXiv:2506.13725\n, 2025.\n[25]\nR.Â Zhang, M.Â Dong, Y.Â Zhang, L.Â Heng, X.Â Chi, G.Â Dai, L.Â Du, Y.Â Du, and S.Â Zhang, â€œMole-vla: Dynamic layer-skipping vision language action model via mixture-of-layers for efficient robot manipulation,â€\narXiv preprint arXiv:2503.20384\n, 2025.\n[26]\nP.Â Budzianowski, W.Â Maa, M.Â Freed, J.Â Mo, W.Â Hsiao, A.Â Xie, T.Â MÅ‚oduchowski, V.Â Tipnis, and B.Â Bolte, â€œEdgevla: Efficient vision-language-action models,â€\narXiv preprint arXiv:2507.14049\n, 2025.\n[27]\nW.Â Song, J.Â Chen, P.Â Ding, H.Â Zhao, W.Â Zhao, Z.Â Zhong, Z.Â Ge, J.Â Ma, and H.Â Li, â€œAccelerating vision-language-action model integrated with action chunking via parallel decoding,â€\narXiv preprint arXiv:2503.02310\n, 2025.\n[28]\nY.Â Ma, Y.Â Zhou, Y.Â Yang, T.Â Wang, and H.Â Fan, â€œRunning vlas at real-time speed,â€\narXiv preprint arXiv:2510.26742\n, 2025.\n[29]\nS.Â Wang, R.Â Yu, Z.Â Yuan, C.Â Yu, F.Â Gao, Y.Â Wang, and D.Â F. Wong, â€œSpec-vla: speculative decoding for vision-language-action models with relaxed acceptance,â€ in\nProceedings of the 2025 Conference on Empirical Methods in Natural Language Processing\n, 2025, pp. 26â€‰916â€“26â€‰928.\n[30]\nT.Â Zou, H.Â Zeng, Y.Â Nong, Y.Â Li, K.Â Liu, H.Â Yang, X.Â Ling, X.Â Li, and L.Â Ma, â€œAsynchronous fast-slow vision-language-action policies for whole-body robotic manipulation,â€\narXiv preprint arXiv:2512.20188\n, 2025.\n[31]\nW.Â Guan, Q.Â Hu, A.Â Li, and J.Â Cheng, â€œEfficient vision-language-action models for embodied manipulation: A systematic survey,â€\narXiv preprint arXiv:2510.17111\n, 2025.\n[32]\nS.Â Xu, Y.Â Wang, C.Â Xia, D.Â Zhu, T.Â Huang, and C.Â Xu, â€œVla-cache: Towards efficient vision-language-action model via adaptive token caching in robotic manipulation,â€\narXiv preprint arXiv:2502.02175\n, 2025.\n[33]\nZ.Â Duan, Y.Â Zhang, S.Â Geng, G.Â Liu, J.Â Boedecker, and C.Â X. Lu, â€œFast ecot: Efficient embodied chain-of-thought via thoughts reuse,â€\narXiv preprint arXiv:2506.07639\n, 2025.\n[34]\nT.Â Z. Zhao, V.Â Kumar, S.Â Levine, and C.Â Finn, â€œLearning fine-grained bimanual manipulation with low-cost hardware,â€\narXiv preprint arXiv:2304.13705\n, 2023.\n[35]\nR.Â Xu, J.Â Zhang, M.Â Guo, Y.Â Wen, H.Â Yang, M.Â Lin, J.Â Huang, Z.Â Li, K.Â Zhang, L.Â Wang\netÂ al.\n, â€œA0: An affordance-aware hierarchical model for general robotic manipulation,â€\narXiv preprint arXiv:2504.12636\n, 2025.\n[36]\nK.Â Black, A.Â Z. Ren, M.Â Equi, and S.Â Levine, â€œTraining-time action conditioning for efficient real-time chunking,â€\narXiv preprint arXiv:2512.05964\n, 2025.\n[37]\nY.Â Liu, J.Â I. Hamid, A.Â Xie, Y.Â Lee, M.Â Du, and C.Â Finn, â€œBidirectional decoding: Improving action chunking via closed-loop resampling,â€\narXiv preprint arXiv:2408.17355\n, 2024.\n[38]\nX.Â Liu, C.Â Gong, and Q.Â Liu, â€œFlow straight and fast: Learning to generate and transfer data with rectified flow,â€\narXiv preprint arXiv:2209.03003\n, 2022.\n[39]\nS.Â Jiang, X.Â Fang, N.Â Roy, T.Â Lozano-PÃ©rez, L.Â P. Kaelbling, and S.Â Ancha, â€œStreaming flow policy: Simplifying diffusion\n/\n/\nflow-matching policies by treating action trajectories as flow trajectories,â€\narXiv preprint arXiv:2505.21851\n, 2025.\n[40]\nS.Â H. HÃ¸eg, Y.Â Du, and O.Â Egeland, â€œStreaming diffusion policy: Fast policy synthesis with variable noise diffusion models,â€\narXiv preprint arXiv:2406.04806\n, 2024.\n[41]\nY.Â Lipman, R.Â T. Chen, H.Â Ben-Hamu, M.Â Nickel, and M.Â Le, â€œFlow matching for generative modeling,â€\narXiv preprint arXiv:2210.02747\n, 2022.\n[42]\nS.Â Nasiriany, A.Â Maddukuri, L.Â Zhang, A.Â Parikh, A.Â Lo, A.Â Joshi, A.Â Mandlekar, and Y.Â Zhu, â€œRobocasa: Large-scale simulation of everyday tasks for generalist robots,â€\narXiv preprint arXiv:2406.02523\n, 2024.",
    "preview_text": "Large-scale Vision-Language-Action (VLA) models offer semantic generalization but suffer from high inference latency, limiting them to low-frequency batch-and-execute paradigm. This frequency mismatch creates an execution blind spot, causing failures in dynamic environments where targets move during the open-loop execution window. We propose TIDAL (Temporally Interleaved Diffusion and Action Loop), a hierarchical framework that decouples semantic reasoning from high-frequency actuation. TIDAL operates as a backbone-agnostic module for diffusion-based VLAs, using a dual-frequency architecture to redistribute the computational budget. Specifically, a low-frequency macro-intent loop caches semantic embeddings, while a high-frequency micro-control loop interleaves single-step flow integration with execution. This design enables approximately 9 Hz control updates on edge hardware (vs. approximately 2.4 Hz baselines) without increasing marginal overhead. To handle the resulting latency shift, we introduce a temporally misaligned training strategy where the policy learns predictive compensation using stale semantic intent alongside real-time proprioception. Additionally, we address the insensitivity of static vision encoders to velocity by incorporating a differential motion predictor. TIDAL is architectural, making it orthogonal to system-level optimizations. Experiments show a 2x performance gain over open-loop baselines in dynamic interception tasks. Despite a marginal regression in static success rates, our approach yields a 4x increase in feedback frequency and extends the effective horizon of semantic embeddings beyond the native action chunk size. Under non-paused inference protocols, TIDAL remains robust where standard baselines fail due to latency.\n\nTIDAL: Temporally Interleaved Diffusion and Action Loop for High-Frequency VLA Control\nYuteng Sun\n1,2\n,\nHaoran Wang\n1,3\n,\nRuofei Bai\n1,3\n,\nZhengguo Li\n1\n,\nJun Li\n1\n,\nMeng Yee (Michael) Chuah\n1\nand\nWei Yun Yau\n1\nAbstrac",
    "is_relevant": true,
    "relevance_score": 9.0,
    "extracted_keywords": [
        "Reinforcement Learning",
        "VLA",
        "diffusion",
        "Flow Matching",
        "locomotion",
        "VLM",
        "whole body control"
    ],
    "one_line_summary": "TIDAL æ˜¯ä¸€ä¸ªç”¨äºæé«˜åŸºäºæ‰©æ•£çš„ VLA æ¨¡å‹æ§åˆ¶é¢‘ç‡çš„åˆ†å±‚æ¡†æ¶ï¼Œé€šè¿‡è§£è€¦è¯­ä¹‰æ¨ç†ä¸é«˜é¢‘é©±åŠ¨ï¼Œåœ¨åŠ¨æ€ç¯å¢ƒä¸­å®ç°æ›´å¿«çš„å“åº”ã€‚",
    "detailed_summary": "## è®ºæ–‡æ‘˜è¦ï¼šTIDAL: Temporally Interleaved Diffusion and Action Loop for High-Frequency VLA Control\n\n**1. ç ”ç©¶èƒŒæ™¯å’ŒåŠ¨æœº**\nå½“å‰ï¼Œå¤§è§„æ¨¡è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹åœ¨æœºå™¨äººæ§åˆ¶ä¸­å±•ç°å‡ºå¼ºå¤§çš„è¯­ä¹‰æ³›åŒ–èƒ½åŠ›ï¼Œä½†å…¶é«˜æ˜‚çš„æ¨ç†å»¶è¿Ÿä½¿å…¶é€šå¸¸åªèƒ½åœ¨ä½é¢‘ç‡ï¼ˆçº¦2-5 Hzï¼‰ä¸‹ä»¥â€œæ‰¹é‡è®¡ç®—-å¼€ç¯æ‰§è¡Œâ€çš„æ¨¡å¼è¿è¡Œã€‚è¿™ç§é¢‘ç‡ä¸åŒ¹é…åœ¨åŠ¨æ€ç¯å¢ƒä¸­ï¼ˆå¦‚ç›®æ ‡ç‰©ä½“åœ¨æœºå™¨äººæ‰§è¡Œè¿‡ç¨‹ä¸­ç§»åŠ¨ï¼‰é€ æˆäº†â€œæ‰§è¡Œç›²åŒºâ€ï¼Œå¯¼è‡´ä»»åŠ¡å¤±è´¥ã€‚ç°æœ‰æ–¹æ³•ï¼ˆå¦‚æ¨¡å‹å‹ç¼©ã€å¼‚æ­¥è°ƒåº¦ï¼‰å¾€å¾€éœ€è¦åœ¨æ€§èƒ½ã€è¯­ä¹‰æ™ºèƒ½æˆ–ç¡¬ä»¶æˆæœ¬ä¸Šåšå‡ºå¦¥åã€‚\n\n**2. æ ¸å¿ƒæ–¹æ³•å’ŒæŠ€æœ¯åˆ›æ–°**\næœ¬æ–‡æå‡ºäº† **TIDAL**ï¼Œä¸€ä¸ªç”¨äºæ‰©æ•£åŸºVLAæ¨¡å‹çš„ã€ä¸ä¸»å¹²ç½‘ç»œæ— å…³çš„å±‚æ¬¡åŒ–åŒé¢‘æ¡†æ¶ï¼Œæ—¨åœ¨è§£è€¦è¯­ä¹‰æ¨ç†ä¸é«˜é¢‘é©±åŠ¨ã€‚\n- **åŒé¢‘æ¶æ„**ï¼šåŒ…å«ä¸€ä¸ª**ä½é¢‘å®æ„å›¾å¾ªç¯**ï¼ˆç¼“å­˜è¯­ä¹‰åµŒå…¥ï¼‰å’Œä¸€ä¸ª**é«˜é¢‘å¾®æ§åˆ¶å¾ªç¯**ï¼ˆäº¤é”™æ‰§è¡Œå•æ­¥æµåŒ¹é…ç§¯åˆ†ä¸åŠ¨ä½œæ‰§è¡Œï¼‰ã€‚é€šè¿‡å°†è®¡ç®—é¢„ç®—é‡æ–°åˆ†é…ï¼Œå°†æ§åˆ¶æ›´æ–°é¢‘ç‡ä»çº¦2.4 Hzæå‡è‡³çº¦9 Hzã€‚\n- **æ—¶é—´é”™ä½è®­ç»ƒ**ï¼šé€šè¿‡æ³¨å…¥å¯å˜å»¶è¿Ÿï¼Œè®­ç»ƒç­–ç•¥æ¨¡å‹åˆ©ç”¨**è¿‡æ—¶çš„è¯­ä¹‰æ„å›¾**ä¸**å®æ—¶çš„æœ¬ä½“æ„ŸçŸ¥**è¿›è¡Œé¢„æµ‹æ€§è¡¥å¿ï¼Œä»¥åº”å¯¹è¯­ä¹‰ç¼“å­˜å¸¦æ¥çš„æ—¶é—´é”™ä½ã€‚\n- **åŠ¨æ€æ„ŸçŸ¥æ³¨å…¥**ï¼šå¼•å…¥ä¸€ä¸ª**å·®åˆ†è¿åŠ¨é¢„æµ‹å™¨**ï¼Œé€šè¿‡æ¥è§¦é—¨æ§æœºåˆ¶å°†ç›®æ ‡é€Ÿåº¦ä¿¡æ¯æ³¨å…¥ç­–ç•¥çŠ¶æ€ï¼Œå¼¥è¡¥é™æ€è§†è§‰ç¼–ç å™¨å¯¹é€Ÿåº¦ä¸æ•æ„Ÿçš„ç¼ºé™·ã€‚\n- **å•æ­¥æµç§¯åˆ†**ï¼šé‡‡ç”¨æºåç½®é‡‡æ ·è®­ç»ƒï¼Œå°†åŠ¨ä½œå—ç”Ÿæˆå‹ç¼©ä¸ºå•æ­¥æ¬§æ‹‰ç§¯åˆ†ï¼Œæå¤§å‡å°‘äº†å¾®å¾ªç¯çš„æ¨ç†å»¶è¿Ÿã€‚\n\n**3. ä¸»è¦å®éªŒç»“æœ**\nåœ¨åŠ¨æ€æ‹¦æˆªä»»åŠ¡ä¸­ï¼ŒTIDALç›¸æ¯”å¼€ç¯åŸºçº¿å®ç°äº†**2å€çš„æ€§èƒ½æå‡**ï¼ˆæˆåŠŸç‡ä»0.31æå‡è‡³0.61ï¼‰ã€‚åœ¨é™æ€ä»»åŠ¡ä¸Šï¼Œæ€§èƒ½æœ‰è½»å¾®å›å½’ï¼ˆä»59.25%é™è‡³50.94%ï¼‰ï¼Œè¿™æ˜¯ä¸ºæ¢å–åŠ¨æ€ååº”æ€§æ‰€åšçš„åˆç†æƒè¡¡ã€‚æ¶ˆèå®éªŒè¯å®äº†é«˜é¢‘æ¶æ„ä¸è¿åŠ¨é¢„æµ‹å™¨çš„ååŒä½œç”¨ã€‚åœ¨æ›´è´´è¿‘çœŸå®ä¸–ç•Œçš„â€œéæš‚åœæ¨ç†â€è¯„ä¼°åè®®ä¸‹ï¼ŒTIDALä¿æŒäº†çº¦49%çš„æ€§èƒ½ç•™å­˜ç‡ï¼Œè€ŒåŸºçº¿åˆ™å´©æºƒè‡³çº¦29%ï¼Œè¯æ˜äº†å…¶åº”å¯¹å®é™…å»¶è¿Ÿçš„é²æ£’æ€§ã€‚\n\n**4. ç ”ç©¶æ„ä¹‰å’Œä»·å€¼**\nTIDALçš„æ ¸å¿ƒä»·å€¼åœ¨äºï¼Œ**åœ¨ä¸å¢åŠ ä¸»å¹²ç½‘ç»œè®¡ç®—è´Ÿæ‹…ã€ä¸ç‰ºç‰²å¤§æ¨¡å‹è¯­ä¹‰æ™ºèƒ½çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡äº†VLAæ¨¡å‹åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„é«˜é¢‘ååº”ä¸æ§åˆ¶èƒ½åŠ›**ã€‚å®ƒæå‡ºäº†ä¸€ç§ç®—æ³•å±‚é¢çš„æ—¶é—´è°ƒåº¦æ–¹æ¡ˆï¼Œä¸ç³»ç»Ÿçº§ä¼˜åŒ–æ­£äº¤ï¼Œå…·æœ‰å¾ˆå¥½çš„é€šç”¨æ€§ã€‚è¯¥å·¥ä½œä¸ºå°†å¤§æ¨¡å‹é«˜æ•ˆéƒ¨ç½²äºéœ€è¦å®æ—¶äº¤äº’çš„æœºå™¨äººåœºæ™¯ï¼ˆå¦‚åŠ¨æ€æŠ“å–ã€äººæœºåä½œï¼‰æä¾›äº†é‡è¦çš„æ¡†æ¶æ€è·¯ï¼Œå¹¶å±•ç¤ºäº†é€šè¿‡æ—¶é—´é”™ä½è®­ç»ƒæ‰©å±•è¯­ä¹‰åµŒå…¥æœ‰æ•ˆç”Ÿå‘½å‘¨æœŸçš„æ½œåŠ›ã€‚",
    "qa_pairs": [
        {
            "question": "è¿™ç¯‡è®ºæ–‡çš„æ ¸å¿ƒåˆ›æ–°ç‚¹æ˜¯ä»€ä¹ˆï¼Œä»–æƒ³è§£å†³ä»€ä¹ˆé—®é¢˜ï¼Œæ€ä¹ˆè§£å†³çš„ï¼Ÿ",
            "answer": "## è®ºæ–‡æ ¸å¿ƒåˆ†æï¼šTIDAL\n\n### **ä¸€ã€ æ ¸å¿ƒè¦è§£å†³çš„é—®é¢˜**\nè®ºæ–‡æ—¨åœ¨è§£å†³**å¤§è§„æ¨¡è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹åœ¨åŠ¨æ€ç¯å¢ƒä¸­å› é«˜æ¨ç†å»¶è¿Ÿå¯¼è‡´çš„â€œæ‰§è¡Œç›²åŒºâ€é—®é¢˜**ã€‚\n- **é—®é¢˜æ ¹æº**ï¼šå½“å‰å…ˆè¿›çš„VLAæ¨¡å‹ï¼ˆå¦‚GR00T, Ï€â‚€ï¼‰è™½ç„¶å…·å¤‡å¼ºå¤§çš„è¯­ä¹‰æ³›åŒ–èƒ½åŠ›ï¼Œä½†å› å…¶åºå¤§çš„è®¡ç®—é‡ï¼Œæ¨ç†é€Ÿåº¦æ…¢ï¼ˆé€šå¸¸2-5 Hzï¼‰ã€‚å®ƒä»¬æ™®éé‡‡ç”¨ **â€œæ‰¹é‡è®¡ç®—-å¼€ç¯æ‰§è¡Œâ€** èŒƒå¼ï¼šæœºå™¨äººæš‚åœè§‚å¯Ÿã€è®¡ç®—ä¸€æ•´æ®µé•¿æ—¶é—´è·¨åº¦çš„åŠ¨ä½œåºåˆ—ï¼Œç„¶åç›²ç›®æ‰§è¡Œã€‚åœ¨æ‰§è¡Œçª—å£æœŸå†…ï¼Œæœºå™¨äººæ— æ³•å“åº”ç¯å¢ƒå˜åŒ–ã€‚\n- **ä¸¥é‡åæœ**ï¼šåœ¨**åŠ¨æ€ç¯å¢ƒ**ï¼ˆå¦‚æ‹¦æˆªç§»åŠ¨ç‰©ä½“ï¼‰ä¸­ï¼Œç”±äºç›®æ ‡åœ¨æœºå™¨äººæ‰§è¡Œâ€œé™ˆæ—§â€è®¡åˆ’æ—¶å·²ç»ç§»åŠ¨ï¼Œå¯¼è‡´ä»»åŠ¡å¤±è´¥ã€‚æ ‡å‡†åŸºå‡†æµ‹è¯•é€šå¸¸â€œæš‚åœâ€ç‰©ç†æ¨¡æ‹Ÿä»¥å¿½ç•¥å»¶è¿Ÿï¼Œä½†è¿™ä¸çœŸå®éƒ¨ç½²åœºæ™¯ä¸¥é‡ä¸ç¬¦ã€‚\n\n### **äºŒã€ æ ¸å¿ƒåˆ›æ–°ç‚¹**\nTIDALæå‡ºäº†ä¸€ç§**ä¸ä¸»å¹²æ¨¡å‹æ— å…³çš„å±‚æ¬¡åŒ–åŒé¢‘ç‡æ¡†æ¶**ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯**å°†è¯­ä¹‰æ¨ç†ä¸é«˜é¢‘é©±åŠ¨è§£è€¦**ã€‚å…¶åˆ›æ–°å¹¶éåˆ›é€ æ–°æ¨¡å‹ï¼Œè€Œæ˜¯è®¾è®¡äº†ä¸€ç§æ–°çš„**æ¨ç†è°ƒåº¦æ¶æ„å’Œè®­ç»ƒèŒƒå¼**ã€‚\n\n**ä¸»è¦åˆ›æ–°ä½“ç°åœ¨ä»¥ä¸‹å››ä¸ªæ–¹é¢ï¼š**\n\n1.  **åŒå¾ªç¯å±‚æ¬¡åŒ–æ¶æ„**ï¼š\n    - **å®æ„å›¾å¾ªç¯**ï¼š**ä½é¢‘**è¿è¡Œï¼ˆå¦‚æ¯16æ­¥ä¸€æ¬¡ï¼‰ï¼Œè°ƒç”¨æ˜‚è´µçš„VLMä¸»å¹²ï¼Œä»è§†è§‰å’Œè¯­è¨€æŒ‡ä»¤ä¸­æå–å¹¶**ç¼“å­˜è¯­ä¹‰åµŒå…¥**ã€‚åˆ©ç”¨è¯­ä¹‰æ„å›¾åœ¨çŸ­æ—¶é—´å†…çš„æŒä¹…æ€§ã€‚\n    - **å¾®æ§åˆ¶å¾ªç¯**ï¼š**é«˜é¢‘**è¿è¡Œï¼ˆå¦‚æ¯4æ­¥ä¸€æ¬¡ï¼Œçº¦9 Hzï¼‰ã€‚å®ƒ**å°†å•æ­¥æµåŒ¹é…ç§¯åˆ†ä¸åŠ¨ä½œæ‰§è¡Œäº¤é”™è¿›è¡Œ**ã€‚æ¯æ¬¡åªæ ¹æ®æœ€æ–°çš„èåˆçŠ¶æ€å’Œç¼“å­˜çš„è¯­ä¹‰æ„å›¾ï¼Œé€šè¿‡ä¸€æ¬¡æ¬§æ‹‰ç§¯åˆ†ç”Ÿæˆæ–°çš„åŠ¨ä½œè½¨è¿¹ï¼Œå¹¶ç«‹å³æ‰§è¡Œå…¶å¼€å¤´éƒ¨åˆ†ã€‚\n    - **æ•ˆæœ**ï¼šåœ¨**ä¸å¢åŠ ä¸»å¹²æ¨¡å‹è®¡ç®—è´Ÿæ‹…**çš„å‰æä¸‹ï¼Œå°†æ§åˆ¶æ›´æ–°é¢‘ç‡ä»åŸºçº¿~2.4 Hzæå‡è‡³~9 Hzï¼Œå®ç°äº†4å€æå‡ã€‚\n\n2.  **æ—¶é—´é”™ä½è®­ç»ƒç­–ç•¥**ï¼š\n    - **æŒ‘æˆ˜**ï¼šä¸Šè¿°æ¶æ„å¯¼è‡´ç­–ç•¥åœ¨æ¨ç†æ—¶ï¼Œä½¿ç”¨çš„è¯­ä¹‰æ„å›¾æ˜¯â€œè¿‡æ—¶â€çš„ï¼Œè€Œæœ¬ä½“æ„ŸçŸ¥æ˜¯å®æ—¶çš„ï¼Œå­˜åœ¨æ—¶é—´é”™ä½ã€‚\n    - **è§£å†³æ–¹æ¡ˆ**ï¼šåœ¨è®­ç»ƒæ—¶ä¸»åŠ¨æ³¨å…¥å¯å˜çš„å»¶è¿Ÿã€‚è®©ç­–ç•¥å­¦ä¹ ä½¿ç”¨**å½“å‰çš„æœ¬ä½“æ„ŸçŸ¥çŠ¶æ€**ï¼Œå»è¡¥å¿å’Œæ ¡æ­£**è¿‡æ—¶çš„è¯­ä¹‰æ„å›¾**ï¼Œä»è€Œå®ç°å¯¹VLMå»¶è¿Ÿçš„é¢„æµ‹æ€§è¡¥å¿ã€‚\n\n3.  **é¢å‘å•æ­¥ç§¯åˆ†çš„æµåŒ¹é…æ¨ç†ä¼˜åŒ–**ï¼š\n    - æ ‡å‡†æµåŒ¹é…è®­ç»ƒå‡åŒ€å…³æ³¨æ•´ä¸ªæ¦‚ç‡è·¯å¾„ã€‚ç”±äºTIDALçš„å¾®å¾ªç¯**åªä»å™ªå£°æº**è¿›è¡Œå•æ­¥ç§¯åˆ†ï¼Œè®ºæ–‡æå‡ºäº†**æ—¶é—´åç½®é‡‡æ ·**ï¼Œåœ¨è®­ç»ƒæ—¶è®©æŸå¤±å‡½æ•°é‡ç‚¹ä¼˜åŒ–`tâ‰ˆ0`é™„è¿‘çš„å‘é‡åœºå‡†ç¡®æ€§ã€‚\n    - åŒæ—¶é‡‡ç”¨**è§†ç•ŒåŠ æƒæŸå¤±**ï¼Œæ›´é‡è§†å³å°†æ‰§è¡Œçš„çŸ­æ—¶åŠ¨ä½œå—ï¼Œç¡®ä¿æ§åˆ¶çš„å³æ—¶ç¨³å®šæ€§ã€‚\n\n4.  **å·®åˆ†è¿åŠ¨é¢„æµ‹å™¨**ï¼š\n    - é™æ€è§†è§‰ç¼–ç å™¨å¯¹é€Ÿåº¦ä¸æ•æ„Ÿã€‚è®ºæ–‡å¼•å…¥ä¸€ä¸ªè½»é‡çº§CNNç½‘ç»œï¼Œä»è¿ç»­å›¾åƒå¸§å·®ä¸­é¢„æµ‹ç›®æ ‡è¿åŠ¨åµŒå…¥ï¼ˆä½ç½®ã€é€Ÿåº¦ï¼‰ã€‚\n    - é‡‡ç”¨**æ¥è§¦é—¨æ§æ³¨å…¥æœºåˆ¶**ï¼šä»…åœ¨æœªæ¥è§¦ç‰©ä½“æ—¶æ³¨å…¥è¿åŠ¨ä¿¡æ¯ï¼Œæ¥è§¦ååˆ™å½’é›¶ï¼Œé¿å…æ§åˆ¶ä¸ç¨³å®šï¼Œå¹³æ»‘åœ°åˆ‡æ¢è‡³æœ¬ä½“æ„ŸçŸ¥æ§åˆ¶ã€‚\n\n### **ä¸‰ã€ è§£å†³æ–¹æ¡ˆçš„è¿ä½œæœºåˆ¶**\nTIDALçš„è§£å†³æ–¹æ¡ˆæ˜¯ä¸€ä¸ªç³»ç»Ÿæ€§çš„å·¥ç¨‹ï¼Œå…¶è¿ä½œæµç¨‹å¦‚ä¸‹ï¼š\n\n```mermaid\ngraph TD\n    A[å¼€å§‹] --> B{å®å¾ªç¯è§¦å‘?};\n    B -- æ˜¯ --> C[è°ƒç”¨VLMä¸»å¹²<br>ç”Ÿæˆå¹¶ç¼“å­˜è¯­ä¹‰åµŒå…¥ â„°];\n    B -- å¦ --> D[è¯»å–ç¼“å­˜çš„è¯­ä¹‰åµŒå…¥ â„°];\n    C --> D;\n    D --> E[å¾®å¾ªç¯: æ•è·å®æ—¶çŠ¶æ€];\n    E --> F[å·®åˆ†è¿åŠ¨é¢„æµ‹å™¨<br>è®¡ç®—è¿åŠ¨åµŒå…¥ m_t];\n    F --> G[æ¥è§¦é—¨æ§èåˆ<br>ç”ŸæˆèåˆçŠ¶æ€ sÌƒ_t];\n    G --> H[å•æ­¥æµåŒ¹é…ç§¯åˆ†<br>æ¡ä»¶: sÌƒ_t + â„°];\n    H --> I[æ‰§è¡ŒåŠ¨ä½œå—çš„å‰Næ­¥];\n    I --> J{å®å‘¨æœŸç»“æŸ?};\n    J -- å¦ --> E;\n    J -- æ˜¯ --> B;\n```\n\n1.  **æ¨ç†æ—¶**ï¼šç³»ç»ŸæŒ‰å›ºå®šå‘¨æœŸï¼ˆå¦‚16æ­¥ï¼‰è¿è¡Œä¸€æ¬¡å®å¾ªç¯ï¼Œæ›´æ–°è¯­ä¹‰ç¼“å­˜ã€‚åœ¨æ­¤å‘¨æœŸå†…ï¼Œå¾®å¾ªç¯é«˜é¢‘è¿è¡Œï¼Œæ¯æ¬¡éƒ½ä¼šï¼š\n    - è·å–æœ€æ–°çš„æœ¬ä½“æ„ŸçŸ¥å’Œè§†è§‰ä¿¡æ¯ã€‚\n    - é€šè¿‡è¿åŠ¨é¢„æµ‹å™¨è®¡ç®—åŠ¨æ€ä¿¡æ¯ã€‚\n    - å°†åŠ¨æ€ä¿¡æ¯ä¸ç¼“å­˜è¯­ä¹‰èåˆã€‚\n    - æ‰§è¡Œä¸€æ¬¡æµåŒ¹é…ç§¯åˆ†ï¼Œç”Ÿæˆæ–°åŠ¨ä½œå¹¶æ‰§è¡Œã€‚\n2.  **è®­ç»ƒæ—¶**ï¼šä½¿ç”¨åŒ…å«æ—¶é—´å»¶è¿Ÿçš„ä¸“å®¶æ•°æ®ï¼Œè®­ç»ƒç­–ç•¥å­¦ä¼šç”¨â€œç°åœ¨â€çš„èº«ä½“æ„Ÿè§‰å»ç†è§£å¹¶æ‰§è¡Œâ€œè¿‡å»â€çš„è¯­ä¹‰æŒ‡ä»¤ï¼Œå¹¶ä¼˜åŒ–æµåŒ¹é…ç½‘ç»œåœ¨èµ·ç‚¹çš„å‡†ç¡®æ€§ã€‚\n\n### **å››ã€ å®é™…ä»·å€¼ä¸æ•ˆæœ**\n- **æ€§èƒ½æå‡**ï¼šåœ¨åŠ¨æ€æ‹¦æˆªä»»åŠ¡ä¸­ï¼Œæ€§èƒ½è¾¾åˆ°**åŸºçº¿æ–¹æ³•çš„2å€**ï¼ˆæˆåŠŸç‡0.61 vs. 0.31ï¼‰ã€‚åœ¨æ¨¡æ‹ŸçœŸå®ä¸–ç•Œâ€œéæš‚åœâ€æ¨ç†çš„ä¸¥è‹›åè®®ä¸‹ï¼ŒTIDALä¿æŒäº†è¿‘ä¸€åŠçš„æ€§èƒ½ï¼Œè€ŒåŸºçº¿æ–¹æ³•å‡ ä¹å¤±æ•ˆã€‚\n- **æ•ˆç‡æå‡**ï¼šåœ¨è¾¹ç¼˜ç¡¬ä»¶ä¸Šå®ç°çº¦**9 Hzçš„é«˜é¢‘æ§åˆ¶æ›´æ–°**ï¼Œä¸”æ˜¯**ä¸»å¹²ç­‰è®¡ç®—**çš„ï¼Œæœªå¢åŠ é¢å¤–è®¡ç®—æˆæœ¬ã€‚\n- **æ³›åŒ–æ€§**ï¼šåœ¨é™æ€ä»»åŠ¡ä¸Šæ€§èƒ½æœ‰è½»å¾®å›å½’ï¼Œä½†ä¿ç•™äº†ä¸»å¹²æ¨¡å‹çš„å¤§éƒ¨åˆ†è¯­ä¹‰èƒ½åŠ›ã€‚è¿™è¡¨æ˜ç”¨å¯æ§çš„é™æ€ç²¾åº¦æŸå¤±ï¼Œæ¢å–äº†å…³é”®çš„åŠ¨æ€ååº”èƒ½åŠ›ã€‚\n- **ç³»ç»Ÿæ­£äº¤æ€§**ï¼šTIDALæ˜¯ä¸€ä¸ªè°ƒåº¦æ¡†æ¶ï¼Œå¯å…¼å®¹ç°æœ‰çš„æ¨¡å‹å‹ç¼©ã€é‡åŒ–ç­‰åŠ é€ŸæŠ€æœ¯ï¼Œå½¢æˆå åŠ ä¼˜åŠ¿ã€‚\n- **å»¶ä¼¸å‘ç°**ï¼šå®éªŒè¡¨æ˜ï¼Œé€šè¿‡å®æ—¶çŠ¶æ€åé¦ˆï¼Œ**å•æ¬¡è¯­ä¹‰åµŒå…¥çš„æœ‰æ•ˆå¯¿å‘½å¯è¿œè¶…å…¶åŸæœ¬è®¾è®¡çš„åŠ¨ä½œå—é•¿åº¦**ï¼Œæå‡äº†è®¡ç®—èµ„æºçš„åˆ©ç”¨ç‡ã€‚\n\n**æ€»ç»“**ï¼šTIDALçš„æ ¸å¿ƒè´¡çŒ®åœ¨äºé€šè¿‡**ç®—æ³•å’Œæ¶æ„å±‚é¢çš„åˆ›æ–°è°ƒåº¦**ï¼Œè€Œéå•çº¯å‹ç¼©æ¨¡å‹ï¼Œå·§å¦™åœ°åŒ–è§£äº†å¤§æ¨¡å‹ä½é¢‘æ¨ç†ä¸æœºå™¨äººé«˜é¢‘æ§åˆ¶ä¹‹é—´çš„çŸ›ç›¾ï¼Œä¸ºåœ¨åŠ¨æ€ç°å®ä¸–ç•Œä¸­éƒ¨ç½²å¤§å‹VLAæ¨¡å‹æä¾›äº†ä¸€æ¡åˆ‡å®å¯è¡Œçš„è·¯å¾„ã€‚",
            "timestamp": "2026-01-27T16:01:56.370038",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "åŸºäºä»–çš„å‰ä½œï¼Œæ¢³ç†è¿™ä¸ªæ–¹å‘çš„æ•´ä¸ªå‘å±•è„‰ç»œï¼Œæ¯ä¸€æ­¥ç›¸æ¯”äºä¹‹å‰çš„å·¥ä½œéƒ½æ”¹è¿›äº†ä»€ä¹ˆï¼Œç€é‡äºå‡ ä¸ªä¸åŒçš„å‘å±•æ–¹å‘ã€‚",
            "answer": "## è®ºæ–‡å‘å±•è„‰ç»œæ¢³ç†ï¼šä»VLAæ¨¡å‹åˆ°å®æ—¶é«˜é¢‘æ§åˆ¶\n\næœ¬æ–‡æå‡ºçš„TIDALæ¡†æ¶ï¼Œæ˜¯é’ˆå¯¹å¤§è§„æ¨¡è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹åœ¨åŠ¨æ€ç¯å¢ƒä¸­**æ¨ç†å»¶è¿Ÿé«˜ã€æ§åˆ¶é¢‘ç‡ä½**è¿™ä¸€æ ¸å¿ƒç“¶é¢ˆçš„è§£å†³æ–¹æ¡ˆã€‚è¦ç†è§£å…¶åˆ›æ–°æ€§ï¼Œéœ€è¦æ¢³ç†è¯¥é¢†åŸŸä»åŸºç¡€æ¨¡å‹æ¶æ„åˆ°å®æ—¶æ€§ä¼˜åŒ–çš„æ•´ä¸ªå‘å±•è„‰ç»œã€‚å…¶æ¼”è¿›ä¸»è¦æ²¿ç€**ä¸‰ä¸ªä¸»è¦æ–¹å‘**å±•å¼€ï¼š**1) æ¨¡å‹æ¶æ„çš„æ¼”è¿›**ï¼Œ**2) å»¶è¿Ÿç¼“è§£ç­–ç•¥çš„ä¼˜åŒ–**ï¼Œä»¥åŠ**3) æ‰§è¡ŒèŒƒå¼çš„é©æ–°**ã€‚TIDALæ˜¯ç¬¬ä¸‰ç±»æ–¹å‘çš„é›†å¤§æˆè€…ï¼Œå¹¶å·§å¦™åœ°èåˆäº†å‰ä¸¤ç±»çš„æ€æƒ³ã€‚\n\n### å‘å±•è„‰ç»œä¸å…³é”®æ”¹è¿›\n\n#### æ–¹å‘ä¸€ï¼šæ¨¡å‹æ¶æ„çš„æ¼”è¿› (ä»ç¦»æ•£åˆ°è¿ç»­ï¼Œä»å•ä½“åˆ°åˆ†å±‚)\n\nè¿™ä¸€æ­¥çš„æ ¸å¿ƒæ˜¯**æå‡åŠ¨ä½œç”Ÿæˆçš„è¿ç»­æ€§å’Œè¯­ä¹‰æ¨ç†çš„è´¨é‡**ã€‚\n\n1.  **æ—©æœŸï¼šVLM + ç¦»æ•£åŠ¨ä½œä»¤ç‰Œ (å¦‚ RT-2, OpenVLA)**\n    *   **ç‰¹ç‚¹**ï¼šå°†å¤§è§„æ¨¡é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹ç›´æ¥ä½œä¸ºç­–ç•¥ï¼Œè¾“å‡ºç¦»æ•£åŒ–çš„åŠ¨ä½œä»¤ç‰Œã€‚\n    *   **æ”¹è¿›**ï¼šé¦–æ¬¡å°†äº’è”ç½‘è§„æ¨¡çš„è¯­ä¹‰çŸ¥è¯†å¼•å…¥æœºå™¨äººæ§åˆ¶ï¼Œå®ç°äº†æŒ‡ä»¤è·Ÿéšçš„æ³›åŒ–èƒ½åŠ›ã€‚\n    *   **å±€é™**ï¼šç¦»æ•£åŠ¨ä½œåœ¨ç²¾ç»†ã€è¿ç»­çš„æœºå™¨äººæ§åˆ¶ä¸­å­˜åœ¨ç“¶é¢ˆã€‚\n\n2.  **ä¸­æœŸï¼šæ‰©æ•£/æµåŒ¹é…ç­–ç•¥ (å¦‚ Octo, Ï€â‚€)**\n    *   **æ”¹è¿›**ï¼šç”¨**æ‰©æ•£è¿‡ç¨‹**æˆ–**æµåŒ¹é…**æ›¿ä»£ç¦»æ•£åŠ¨ä½œå¤´ï¼Œç›´æ¥ç”Ÿæˆè¿ç»­çš„åŠ¨ä½œè½¨è¿¹ã€‚è¿™å¤§å¹…æå‡äº†åŠ¨ä½œçš„å¹³æ»‘æ€§å’Œæ§åˆ¶ç²¾åº¦ï¼Œæ›´é€‚åˆçœŸå®çš„ç‰©ç†æ‰§è¡Œã€‚\n\n3.  **è¿‘æœŸï¼šåˆ†å±‚æ¶æ„æˆä¸ºæ ‡å‡† (å¦‚ GR00T, Ï€â‚€.5)**\n    *   **æ”¹è¿›**ï¼šæ˜ç¡®**è§£è€¦è¯­ä¹‰æ¨ç†å’ŒåŠ¨ä½œç”Ÿæˆ**ã€‚ä½¿ç”¨ä¸€ä¸ªâ€œé‡â€çš„VLMéª¨å¹²è¿›è¡Œé«˜å±‚è¯­ä¹‰ç†è§£å’Œè§„åˆ’ï¼Œè¾“å‡ºä¸€ä¸ªâ€œæ„å›¾â€åµŒå…¥ï¼›å†ä½¿ç”¨ä¸€ä¸ªâ€œè½»â€çš„æ‰©æ•£å˜æ¢å™¨æ ¹æ®è¯¥æ„å›¾ç”Ÿæˆå…·ä½“åŠ¨ä½œã€‚\n    *   **æ„ä¹‰**ï¼šå¥ å®šäº†ç°ä»£VLAçš„åŸºç¡€æ¶æ„ï¼Œä½†**æ‰§è¡ŒèŒƒå¼æœªå˜**ï¼Œä»é‡‡ç”¨â€œæ‰¹é‡è®¡ç®—-ç„¶åæ‰§è¡Œâ€çš„æ¨¡å¼ï¼ŒVLMçš„æ¨ç†å»¶è¿Ÿæˆä¸ºæ•´ä¸ªç³»ç»Ÿçš„é¢‘ç‡ç“¶é¢ˆã€‚\n\n#### æ–¹å‘äºŒï¼šå»¶è¿Ÿç¼“è§£ç­–ç•¥ (åœ¨æ—¢å®šæ¶æ„å†…â€œæŒ¤â€æ€§èƒ½)\n\nè¿™ä¸€æ­¥çš„æ ¸å¿ƒæ˜¯**é€šè¿‡å„ç§å‹ç¼©å’Œä¼˜åŒ–æŠ€æœ¯ï¼Œå‡å°‘å•æ¬¡æ¨ç†çš„è®¡ç®—å¼€é”€å’Œå»¶è¿Ÿ**ã€‚\n\n1.  **æ¨¡å‹ç®€åŒ–ä¸è’¸é¦ (å¦‚ TinyVLA, SmolVLA)**\n    *   **æ”¹è¿›**ï¼šè®­ç»ƒæ›´å°ã€æ›´é«˜æ•ˆçš„ç­–ç•¥æ¨¡å‹ï¼Œæˆ–ä½¿ç”¨çŠ¶æ€ç©ºé—´æ¨¡å‹ç­‰æ›¿ä»£Transformerï¼Œç›´æ¥æå‡ååé‡ã€‚\n    *   **å±€é™**ï¼š**ç‰ºç‰²äº†å¤§æ¨¡å‹ä¸°å¯Œçš„è¯­ä¹‰å…ˆéªŒå’Œæ¨ç†èƒ½åŠ›**ï¼Œç”¨æ€§èƒ½æ¢é€Ÿåº¦ã€‚\n\n2.  **é™æ€å‹ç¼©ä¸è‡ªé€‚åº”æ¨ç† (å¦‚ BitVLAé‡åŒ–, FlashVLAä»¤ç‰Œå‰ªæ, DeeR-VLAæ—©é€€)**\n    *   **æ”¹è¿›**ï¼šé€šè¿‡é‡åŒ–ã€å‰ªæã€åŠ¨æ€å±‚è·³è¿‡ç­‰æŠ€æœ¯ï¼Œå‡å°‘éª¨å¹²ç½‘ç»œçš„è®¡ç®—é‡ï¼Œå±äºç³»ç»Ÿçº§ä¼˜åŒ–ã€‚\n    *   **å±€é™**ï¼šè™½ç„¶å‡å°‘äº†æ¯æ­¥è®¡ç®—ï¼Œä½†**ä»å—é™äºâ€œè§‚å¯Ÿ-ç„¶å-è¡ŒåŠ¨â€çš„ä¸²è¡Œç“¶é¢ˆ**ã€‚æ¨¡å‹ä»éœ€ç­‰å¾…å®Œæ•´çš„æ¨ç†å®Œæˆåæ‰èƒ½æ‰§è¡Œã€‚\n\n3.  **å¼‚æ­¥æµæ°´çº¿ä¸æœªæ¥æ„ŸçŸ¥ (å¦‚ Real-Time Chunking, VLASH)**\n    *   **æ”¹è¿›**ï¼šå°è¯•æ‰“ç ´ä¸²è¡Œä¾èµ–ã€‚ä¾‹å¦‚ï¼Œåœ¨æ‰§è¡Œå½“å‰åŠ¨ä½œå—çš„åŒæ—¶ï¼Œæ¨ç†ä¸‹ä¸€ä¸ªåŠ¨ä½œå—ï¼›æˆ–è®­ç»ƒç­–ç•¥æ¥è¡¥å¿å»¶è¿Ÿï¼Œä½¿å…¶èƒ½åŸºäºé¢„æµ‹çš„æœªæ¥çŠ¶æ€è¿›è¡Œå†³ç­–ã€‚\n    *   **å±€é™**ï¼šéœ€è¦è¾ƒé«˜çš„VLMååé‡æ¥æœ€å°åŒ–é¢„æµ‹èŒƒå›´ï¼Œä¸”**æ¡ä»¶äºé™ˆæ—§çš„è§‚æµ‹æˆ–ä¸ç¡®å®šçš„æœªæ¥çŠ¶æ€é¢„æµ‹**ï¼Œå¢åŠ äº†å¤æ‚æ€§ã€‚\n\n#### æ–¹å‘ä¸‰ï¼šæ‰§è¡ŒèŒƒå¼çš„é©æ–° (é‡æ–°è®¾è®¡æ¨ç†-æ‰§è¡Œçš„å…³ç³»)\n\nè¿™ä¸€æ­¥çš„æ ¸å¿ƒæ˜¯**ä»æ ¹æœ¬ä¸Šæ”¹å˜æ¨¡å‹æ¨ç†ä¸æœºå™¨äººæ‰§è¡Œä¹‹é—´çš„æ—¶åºå…³ç³»ï¼Œä»¥å®ç°é«˜é¢‘é—­ç¯**ã€‚TIDALå±äºæ­¤æ–¹å‘ï¼Œå¹¶å¯¹æ¯”äº†è¯¥æ–¹å‘å†…çš„å…¶ä»–å·¥ä½œã€‚\n\n1.  **å®Œå…¨è§£è€¦çš„åŒç³»ç»Ÿæ¶æ„ (å¦‚ DuoCore-FS, Fast-in-Slow)**\n    *   **æ”¹è¿›**ï¼šå°†è¯­ä¹‰æ¨ç†å’Œè¿åŠ¨æ§åˆ¶å½»åº•åˆ†ç¦»ä¸ºä¸¤ä¸ª**å¹¶è¡Œ**çš„è¿›ç¨‹ã€‚æ…¢é€ŸVLMåœ¨åå°å¼‚æ­¥æ›´æ–°ä¸€ä¸ªæ½œåœ¨ç¼“å†²åŒºï¼Œå¿«é€Ÿç­–ç•¥ä»¥é«˜é¢‘æŸ¥è¯¢è¯¥ç¼“å†²åŒºã€‚\n    *   **å±€é™**ï¼š**ç¡¬ä»¶è´Ÿæ‹…é‡**ï¼Œéœ€è¦è¶³å¤Ÿçš„å†…å­˜å¸¦å®½å’Œç®—åŠ›åŒæ—¶è¿è¡Œä¸¤ä¸ªæ´»è·ƒæ¨¡å‹ï¼Œå¯¹è¾¹ç¼˜è®¾å¤‡ä¸å‹å¥½ã€‚\n\n2.  **TIDALï¼šæ—¶åºäº¤é”™æ‰©æ•£ä¸åŠ¨ä½œå¾ªç¯ (æœ¬æ–‡å·¥ä½œ)**\n    *   **æ ¸å¿ƒæ”¹è¿›**ï¼šæå‡ºäº† **â€œäº¤é”™â€è€Œéâ€œå¹¶è¡Œâ€** çš„ç­–ç•¥ï¼Œåœ¨**ä¸²è¡Œæ‰§è¡Œé¢„ç®—å†…æœ€å¤§åŒ–è®¡ç®—åˆ©ç”¨ç‡**ã€‚\n        *   **æ´å¯Ÿ**ï¼šè¯­ä¹‰æ„å›¾åœ¨çŸ­æ—¶é—´å†…å…·æœ‰æŒä¹…æ€§ï¼Œè€Œç‰©ç†çŠ¶æ€ç¬æ¯ä¸‡å˜ã€‚å› æ­¤ï¼Œæ˜‚è´µçš„VLMæ— éœ€æ¯ä¸€æ­¥éƒ½åŒæ­¥æŸ¥è¯¢ã€‚\n        *   **æœºåˆ¶**ï¼š\n            *   **å®è§‚å¾ªç¯ (ä½é¢‘)**ï¼šç¼“å­˜VLMç”Ÿæˆçš„è¯­ä¹‰åµŒå…¥ã€‚\n            *   **å¾®è§‚å¾ªç¯ (é«˜é¢‘)**ï¼š**å°†å•æ­¥æµåŒ¹é…ç§¯åˆ†ä¸åŠ¨ä½œæ‰§è¡Œäº¤é”™è¿›è¡Œ**ã€‚æ¯æ¬¡åªç”Ÿæˆå¹¶æ‰§è¡Œä¸€ä¸ªåŠ¨ä½œå­å—ï¼Œç„¶åç«‹å³æ ¹æ®æœ€æ–°è§‚æµ‹é‡æ–°ç§¯åˆ†ï¼Œå®ç°â€œæ»‘åŠ¨çª—å£â€å¼æ‰§è¡Œã€‚\n        *   **å…³é”®æŠ€æœ¯**ï¼š\n            *   **æ—¶é—´é”™ä½è®­ç»ƒ**ï¼šè®©ç­–ç•¥å­¦ä¼šä½¿ç”¨å®æ—¶æœ¬ä½“æ„Ÿè§‰æ¥è¡¥å¿è¿‡æ—¶çš„è¯­ä¹‰æ„å›¾ã€‚\n            *   **å·®åˆ†è¿åŠ¨é¢„æµ‹å™¨**ï¼šå¼¥è¡¥é™æ€è§†è§‰ç¼–ç å™¨å¯¹é€Ÿåº¦ä¸æ•æ„Ÿçš„ç¼ºé™·ã€‚\n            *   **æ—¶é—´åç½®é‡‡æ ·**ï¼šä¼˜åŒ–æµåŒ¹é…è®­ç»ƒï¼Œä½¿å…¶ä¸“æ³¨äºæ¨ç†æ—¶ä½¿ç”¨çš„å•æ­¥ç§¯åˆ†ã€‚\n    *   **ç›¸æ¯”å‰ä½œçš„æå‡**ï¼š\n        *   **vs. åˆ†å±‚æ¶æ„æ ‡å‡†èŒƒå¼**ï¼šå°†æ§åˆ¶é¢‘ç‡ä»~2.4 Hzæå‡è‡³~9 Hzï¼Œ**æ¶ˆé™¤äº†â€œæ‰§è¡Œç›²åŒºâ€**ï¼Œä½¿æœºå™¨äººèƒ½åœ¨åŠ¨æ€ç¯å¢ƒä¸­ï¼ˆå¦‚æ‹¦æˆªç§»åŠ¨ç‰©ä½“ï¼‰åšå‡ºååº”ã€‚\n        *   **vs. æ¨¡å‹ç®€åŒ–æ–¹å‘**ï¼š**ä¿æŒäº†å®Œæ•´å¤§æ¨¡å‹çš„è¯­ä¹‰æ™ºèƒ½**ï¼Œä»…é€šè¿‡ç®—æ³•è°ƒåº¦å®ç°å°æ¨¡å‹çš„é€Ÿåº¦ã€‚\n        *   **vs. å¼‚æ­¥æµæ°´çº¿æ–¹å‘**ï¼š**æ¡ä»¶äºå½“å‰èåˆçŠ¶æ€**ï¼Œè€Œéé¢„æµ‹çš„æœªæ¥çŠ¶æ€ï¼Œé¿å…äº†é¢„æµ‹çš„ä¸ç¡®å®šæ€§ã€‚\n        *   **vs. åŒç³»ç»Ÿæ¶æ„æ–¹å‘**ï¼šå®ç°äº†ç±»ä¼¼çš„è§£è€¦æ•ˆæœï¼Œä½†**æ— éœ€ç¡¬ä»¶å¹¶è¡Œ**ï¼Œç®—æ³•ä¸Šå°†å¾®è§‚å¾ªç¯å»¶è¿Ÿå‹ç¼©åˆ°å¯å¿½ç•¥æ°´å¹³ï¼Œæ›´é€‚åˆè¾¹ç¼˜éƒ¨ç½²ã€‚\n\n### æ€»ç»“ï¼šä¸‰ä¸ªæ–¹å‘çš„äº¤æ±‡ä¸TIDALçš„å®šä½\n\n| å‘å±•æ–¹å‘ | æ ¸å¿ƒç›®æ ‡ | ä»£è¡¨æ€§æ–¹æ³• | å…³é”®æ”¹è¿› | é—ç•™é—®é¢˜/å±€é™ |\n| :--- | :--- | :--- | :--- | :--- |\n| **æ¶æ„æ¼”è¿›** | æå‡åŠ¨ä½œè´¨é‡ä¸è¯­ä¹‰èƒ½åŠ› | ç¦»æ•£ä»¤ç‰Œ â†’ æ‰©æ•£æµ â†’ åˆ†å±‚æ¶æ„ | å®ç°è¿ç»­ã€ç²¾ç»†çš„è¯­ä¹‰æ§åˆ¶ | æœªè§£å†³æ¨ç†å»¶è¿Ÿå¯¼è‡´çš„é¢‘ç‡ç“¶é¢ˆ |\n| **å»¶è¿Ÿç¼“è§£** | å‡å°‘å•æ¬¡æ¨ç†å¼€é”€ | è’¸é¦ã€å‹ç¼©ã€æ—©é€€ã€å¼‚æ­¥æµæ°´çº¿ | åœ¨ç¡¬ä»¶å±‚é¢åŠ é€Ÿæ¨¡å‹ | ä»å—é™äºä¸²è¡ŒèŒƒå¼æˆ–ç‰ºç‰²è¯­ä¹‰èƒ½åŠ› |\n| **èŒƒå¼é©æ–°** | é‡æ„æ¨ç†-æ‰§è¡Œæ—¶åº | åŒç³»ç»Ÿå¹¶è¡Œã€**TIDALäº¤é”™æ‰§è¡Œ** | å®ç°é«˜é¢‘é—­ç¯æ§åˆ¶ï¼Œä¿æŒè¯­ä¹‰èƒ½åŠ› | åŒç³»ç»Ÿç¡¬ä»¶è¦æ±‚é«˜ï¼›TIDALåœ¨é™æ€ä»»åŠ¡ä¸Šæœ‰è½»å¾®æ€§èƒ½å›å½’ |\n\n**TIDALçš„ç‹¬ç‰¹ä»·å€¼åœ¨äº**ï¼šå®ƒç«™åœ¨äº†**åˆ†å±‚æ¶æ„**çš„è‚©è†€ä¸Šï¼Œå¸æ”¶äº†**å»¶è¿Ÿç¼“è§£**ä¸­å…³äºæ—¶é—´å†—ä½™ï¼ˆç¼“å­˜è¯­ä¹‰ï¼‰å’Œè¿åŠ¨æ„ŸçŸ¥çš„æ€æƒ³ï¼Œå¹¶é€šè¿‡**èŒƒå¼é©æ–°**æå‡ºäº†ä¸€ä¸ªè®¡ç®—é«˜æ•ˆçš„â€œäº¤é”™â€è°ƒåº¦æ¡†æ¶ã€‚å®ƒä¸æ˜¯ä¸€ä¸ªæ›¿ä»£VLAéª¨å¹²çš„æ¨¡å‹ï¼Œè€Œæ˜¯ä¸€ä¸ª**éª¨å¹²æ— å…³çš„ã€ç®—æ³•å±‚é¢çš„â€œåŠ é€Ÿå™¨â€æ¨¡å—**ï¼Œæ—¨åœ¨å°†ç°æœ‰å¼ºå¤§ä½†ç¼“æ…¢çš„VLAæ¨¡å‹ç›´æ¥å¸¦å…¥éœ€è¦é«˜é¢‘å“åº”çš„åŠ¨æ€ç°å®ä¸–ç•Œåœºæ™¯ä¸­ã€‚å…¶å®éªŒè¡¨æ˜ï¼Œè¿™ç§èŒƒå¼è½¬å˜å¸¦æ¥äº†åŠ¨æ€ä»»åŠ¡æ€§èƒ½çš„å€å¢å’Œå¯¹éæš‚åœï¼ˆæ›´è´´è¿‘ç°å®ï¼‰è¯„ä¼°åè®®çš„å¼ºå¤§é²æ£’æ€§ã€‚",
            "timestamp": "2026-01-27T16:02:56.412262",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "ä»–çš„å‰ä½œæœ‰å“ªäº›ï¼Ÿä½¿ç”¨è¡¨æ ¼ä»”ç»†è®²è®²ä»–çš„æ¯ç¯‡å‰ä½œï¼Œä»–å’Œå‰ä½œçš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Œä¸»è¦æ”¹å–„æ˜¯ä»€ä¹ˆï¼Ÿç€é‡äºå…·ä½“ç›¸æ¯”äºä¹‹å‰æ–‡ç« çš„æ”¹åŠ¨",
            "answer": "## TIDAL è®ºæ–‡çš„å‰ä½œåˆ†æä¸å¯¹æ¯”\n\næ ¹æ®è®ºæ–‡çš„â€œRelated Workâ€éƒ¨åˆ†ï¼ŒTIDAL çš„ç ”ç©¶å»ºç«‹åœ¨è¿‘å¹´æ¥ä¸€ç³»åˆ—æ—¨åœ¨è§£å†³ VLA æ¨¡å‹æ¨ç†å»¶è¿Ÿå’Œå®æ—¶æ§åˆ¶é—®é¢˜çš„ç ”ç©¶ä¹‹ä¸Šã€‚å…¶â€œå‰ä½œâ€å¹¶éæŒ‡åŒä¸€ä½œè€…å›¢é˜Ÿçš„è¿ç»­å·¥ä½œï¼Œè€Œæ˜¯æŒ‡è¯¥é¢†åŸŸå†…ä¸ºè§£å†³ç±»ä¼¼é—®é¢˜æ‰€æå‡ºçš„ä»£è¡¨æ€§æ–¹æ³•ã€‚TIDAL ä¸è¿™äº›å‰ä½œçš„æ ¸å¿ƒåŒºåˆ«åœ¨äºå…¶**é€šè¿‡æ—¶åºäº¤é”™çš„è®¡ç®—è°ƒåº¦å’Œå•æ­¥æµé›†æˆï¼Œåœ¨ä¿æŒå¤§æ¨¡å‹è¯­ä¹‰èƒ½åŠ›çš„åŒæ—¶ï¼Œå®ç°äº†é«˜é¢‘æ§åˆ¶ï¼Œä¸”ä¸ä¾èµ–ç¡¬ä»¶å¹¶è¡Œ**ã€‚\n\nä»¥ä¸‹è¡¨æ ¼è¯¦ç»†æ¢³ç†äº†ç›¸å…³çš„å‰ä½œï¼Œå¹¶é‡ç‚¹å¯¹æ¯”äº† TIDAL ä¸å®ƒä»¬çš„æ ¸å¿ƒåŒºåˆ«å’Œæ”¹è¿›ã€‚\n\n### å‰ä½œåˆ†ç±»ä¸å¯¹æ¯”åˆ†æ\n\n| å‰ä½œç±»åˆ« | ä»£è¡¨æ€§å·¥ä½œ | æ ¸å¿ƒæ–¹æ³• | ä¸»è¦å±€é™ / å¾…è§£å†³é—®é¢˜ | TIDAL ä¸ä¹‹çš„åŒºåˆ«ä¸ä¸»è¦æ”¹å–„ |\n| :--- | :--- | :--- | :--- | :--- |\n| **1. æ¨¡å‹ç®€åŒ–ä¸è’¸é¦** | **TinyVLA** [9], **SmolVLA** [18], **Consistency Policy** [20] | è®­ç»ƒæ›´å°çš„ç­–ç•¥æ¨¡å‹ï¼Œæˆ–é€šè¿‡ä¸€è‡´æ€§è’¸é¦å°†æ‰©æ•£å¤´å‹ç¼©ä¸ºå•æ­¥æ±‚è§£å™¨ã€‚ | **ç‰ºç‰²è¯­ä¹‰èƒ½åŠ›**ï¼šä¸ºæ¢å–é€Ÿåº¦ï¼Œä¸¢å¤±äº†å¤§åŸºç¡€æ¨¡å‹çš„ä¸°å¯Œè¯­ä¹‰å…ˆéªŒå’Œæ¨ç†èƒ½åŠ›ã€‚Consistency Policy ä»…åŠ é€ŸåŠ¨ä½œå¤´ï¼Œæœªè§£å†³ VLM ä¸»å¹²ç“¶é¢ˆã€‚ | **ä¿ç•™å®Œæ•´ä¸»å¹²**ï¼šTIDAL **ä¸å‹ç¼©æˆ–æ›¿æ¢**å¤§æ¨¡å‹ä¸»å¹²ï¼ˆå¦‚ GR00T-3Bï¼‰ï¼Œè€Œæ˜¯é€šè¿‡**ç¼“å­˜è¯­ä¹‰åµŒå…¥**å’Œ**äº¤é”™æ‰§è¡Œ**æ¥é‡ç”¨å…¶è¾“å‡ºï¼Œä»è€Œåœ¨è·å¾—å°æ¨¡å‹é€Ÿåº¦çš„åŒæ—¶ï¼Œ**ä¿æŒäº†å¤§æ¨¡å‹çš„è¯­ä¹‰æ™ºèƒ½**ã€‚æ”¹å–„åœ¨äº**ä¸ç‰ºç‰²è¯­ä¹‰æ³›åŒ–èƒ½åŠ›**çš„å‰æä¸‹æå‡é¢‘ç‡ã€‚ |\n| **2. é™æ€å‹ç¼©ä¸è‡ªé€‚åº”æ¨ç†** | **BitVLA** [7] (é‡åŒ–), **FlashVLA** [8] (tokenå‰ªæ), **DeeR-VLA** [23] (æ—©é€€) | é€šè¿‡é‡åŒ–ã€å‰ªæå‡å°‘è®¡ç®—/å†…å­˜ï¼Œæˆ–é€šè¿‡åŠ¨æ€æœºåˆ¶ï¼ˆå¦‚æ—©é€€ï¼‰åœ¨ç½®ä¿¡åº¦é«˜æ—¶æå‰åœæ­¢å‰å‘ä¼ æ’­ã€‚ | **ä»å—é¡ºåºç“¶é¢ˆé™åˆ¶**ï¼šè¿™äº›æ–¹æ³•ä¼˜åŒ–äº†**æ¯æ­¥çš„è®¡ç®—æ•ˆç‡**ï¼Œä½†æ¨ç†èŒƒå¼ä»æ˜¯â€œè§‚å¯Ÿ-è®¡ç®—-æ‰§è¡Œâ€çš„é¡ºåºæµç¨‹ï¼Œæ§åˆ¶é¢‘ç‡ä»å—é™äºæœ€æ…¢ç¯èŠ‚ï¼ˆé€šå¸¸æ˜¯VLMï¼‰ã€‚ | **æ­£äº¤æ€§ä¸æ—¶åºè°ƒåº¦**ï¼šTIDAL ä¸è¿™äº›ç³»ç»Ÿçº§ä¼˜åŒ–**æ­£äº¤**ï¼Œå¯å°†å…¶ä½œä¸ºåŠ é€Ÿåçš„ä¸»å¹²è¿›ä¸€æ­¥ä½¿ç”¨ã€‚TIDAL çš„æ ¸å¿ƒæ”¹å–„æ˜¯**å¼•å…¥äº†æ—¶åºè°ƒåº¦å™¨**ï¼Œå°†æ˜‚è´µçš„ VLM æŸ¥è¯¢ä¸é«˜é¢‘åŠ¨ä½œç”Ÿæˆ**åœ¨æ—¶é—´ä¸Šè§£è€¦**ï¼Œä»è€Œæ‰“ç ´äº†â€œè®¡ç®—æ—¶å¿…é¡»åœæ­¢æ‰§è¡Œâ€çš„é¡ºåºä¾èµ–ï¼Œ**ä»ç³»ç»Ÿå±‚é¢æå‡äº†é‡è§„åˆ’é¢‘ç‡**ã€‚ |\n| **3. å¼‚æ­¥æµæ°´çº¿ä¸æœªæ¥æ„ŸçŸ¥** | **Real-Time Chunking (RTC)** [5], **VLASH** [6] | **å¼‚æ­¥æ‰§è¡Œ**ï¼šåœ¨æ‰§è¡Œä¸Šä¸€ä¸ªåŠ¨ä½œå—æ—¶ï¼Œå¹¶è¡Œè®¡ç®—ä¸‹ä¸€ä¸ªå—ï¼ˆRTCï¼‰ã€‚æˆ–è®­ç»ƒç­–ç•¥**å¯¹æœªæ¥çŠ¶æ€è¿›è¡Œé¢„æµ‹å’Œè¡¥å¿**ä»¥å¤„ç†å»¶è¿Ÿï¼ˆVLASHï¼‰ã€‚ | **å¤æ‚åº¦ä¸ä¸ç¡®å®šæ€§**ï¼šæµæ°´çº¿æ–¹æ³•éœ€è¦è¶³å¤Ÿé«˜çš„ VLM ååé‡æ¥æœ€å°åŒ–é¢„æµ‹èŒƒå›´ã€‚æœªæ¥çŠ¶æ€é¢„æµ‹æœ¬èº«å…·æœ‰ä¸ç¡®å®šæ€§ï¼Œå¢åŠ äº†ç­–ç•¥å­¦ä¹ çš„å¤æ‚æ€§ã€‚ | **äº¤é”™è€Œéå¹¶è¡Œï¼Œå½“å‰çŠ¶æ€è€Œéæœªæ¥çŠ¶æ€**ï¼šTIDAL é‡‡ç”¨**äº¤é”™**ç­–ç•¥ï¼Œåœ¨å•ä¸ªè®¡ç®—æµä¸­ç©¿æ’æ‰§è¡Œä¸è½»é‡çº§è®¡ç®—ï¼Œ**æ— éœ€ç¡¬ä»¶å¹¶è¡Œæ”¯æŒ**ã€‚ç­–ç•¥ç›´æ¥åŸºäº**å½“å‰èåˆçŠ¶æ€**ï¼ˆå®æ—¶æœ¬ä½“æ„ŸçŸ¥+è¿åŠ¨é¢„æµ‹ï¼‰è¿›è¡Œæ¡ä»¶ç”Ÿæˆï¼Œ**é¿å…äº†é¢„æµ‹æœªæ¥ç³»ç»ŸçŠ¶æ€çš„å¤æ‚æ€§å’Œè¯¯å·®**ã€‚æ”¹å–„åœ¨äº**æ›´ç®€å•çš„æ‰§è¡Œæ¶æ„å’Œæ›´å¯é çš„å®æ—¶æ¡ä»¶**ã€‚ |\n| **4. è§£è€¦ä¸åŒç³»ç»Ÿæ¶æ„** | **DuoCore-FS** [30], **Fast-in-Slow** [10] | **å¹¶è¡Œæ¶æ„**ï¼šä¸€ä¸ªæ…¢é€Ÿ VLM åœ¨åå°æ›´æ–°æ½œåœ¨ç¼“å†²åŒºï¼Œä¸€ä¸ªå¿«é€Ÿç­–ç•¥é«˜é¢‘æŸ¥è¯¢è¯¥ç¼“å†²åŒºã€‚ | **ç¡¬ä»¶è´Ÿæ‹…é‡**ï¼šéœ€è¦è¶³å¤Ÿçš„å†…å­˜å¸¦å®½å’Œç®—åŠ›æ¥**åŒæ—¶ç»´æŒä¸¤ä¸ªæ´»è·ƒæ¨¡å‹**çš„è¿è¡Œï¼Œå¯¹è¾¹ç¼˜è®¾å¤‡ä¸å‹å¥½ã€‚ | **ä¸²è¡Œå¤ç”¨è€Œéç¡¬ä»¶å¹¶è¡Œ**ï¼šTIDAL é€šè¿‡**æ—¶åºå¤ç”¨**å°† VLM å’ŒåŠ¨ä½œå¤´è§†ä¸ºä¸²è¡Œä½†äº¤é”™æ‰§è¡Œçš„ç»„ä»¶ï¼Œ**æœ€å¤§åŒ–è¾¹ç¼˜è®¾å¤‡çš„è®¡ç®—åˆ©ç”¨ç‡**ã€‚å…¶**å•æ­¥æµé›†æˆ**æœºåˆ¶åœ¨ç®—æ³•ä¸Šå‹ç¼©äº†å¾®å¾ªç¯çš„å»¶è¿Ÿï¼Œæ— éœ€é¢å¤–ç¡¬ä»¶ã€‚æ”¹å–„åœ¨äº**ä»¥æ›´ä½çš„ç¡¬ä»¶æˆæœ¬å®ç°äº†ç±»ä¼¼çš„é«˜é¢‘å“åº”èƒ½åŠ›**ã€‚ |\n| **5. åŠ¨ä½œåˆ†å—ä¸é«˜çº§è°ƒåº¦** | **æ ‡å‡†å¼€ç¯åŸºçº¿** (OpenVLA [13], A0 [35]), **Bidirectional Decoding** [37] | **é¢„æµ‹åæ‰§è¡Œ**ï¼šåœ¨å‘¨æœŸå¼€å§‹æ—¶ç”Ÿæˆä¸€ä¸ªå›ºå®šé•¿åº¦çš„åŠ¨ä½œå—ï¼Œç„¶åå¼€ç¯æ‰§è¡Œã€‚é«˜çº§æ–¹æ³•å¦‚åŒå‘è§£ç å°è¯•åœ¨å—è¾¹ç•Œè¿›è¡Œå¹³æ»‘æ‹¼æ¥ã€‚ | **æ‰§è¡Œç›²åŒº**ï¼šåœ¨é•¿æ‰§è¡Œçª—å£å†…ï¼Œæœºå™¨äººå¯¹ç¯å¢ƒå˜åŒ–æ— å“åº”ã€‚å³ä½¿å¼‚æ­¥ç”Ÿæˆï¼ŒåŠ¨ä½œä»åŸºäº**è¿‡æ—¶è§‚æµ‹**ï¼ˆæ¨ç†å»¶è¿Ÿå¼€å§‹æ—¶çš„çŠ¶æ€ï¼‰è¿›è¡Œæ¡ä»¶åŒ–ã€‚ | **ä»é™æ€è®¡åˆ’åˆ°åŠ¨æ€å‘é‡åœºæŸ¥è¯¢**ï¼šTIDAL åˆ©ç”¨æµåŒ¹é…çš„å‘é‡åœºç‰¹æ€§ï¼Œ**å°†åŠ¨ä½œå—è§†ä¸ºæŸ”æ€§æµå½¢è€Œéåˆšæ€§åºåˆ—**ã€‚é€šè¿‡**äº¤é”™å•æ­¥é›†æˆ**ï¼Œåœ¨æ¯ä¸ªæ§åˆ¶æ­¥éƒ½å°†**æœ€æ–°çš„æœ¬ä½“æ„ŸçŸ¥çŠ¶æ€æ³¨å…¥æ±‚è§£å™¨**ï¼Œä»è€Œå®ç°å¯¹åŠ¨æ€ç¯å¢ƒçš„**é«˜é¢‘é—­ç¯ååº”**ã€‚æ”¹å–„åœ¨äº**ä»æ ¹æœ¬ä¸Šæ¶ˆé™¤äº†æ‰§è¡Œç›²åŒº**ï¼Œå®ç°äº†çœŸæ­£çš„å®æ—¶ååº”ã€‚ |\n\n### æ€»ç»“ï¼šTIDAL çš„æ ¸å¿ƒåˆ›æ–°ä¸æ”¹è¿›\n\nç»¼åˆæ¥çœ‹ï¼ŒTIDAL ç›¸å¯¹äºå‰ä½œçš„ä¸»è¦**å…·ä½“æ”¹åŠ¨å’Œæ”¹å–„**ä½“ç°åœ¨ä»¥ä¸‹ä¸‰ä¸ªå±‚é¢ï¼š\n\n1.  **æ¶æ„å±‚é¢ï¼šç‹¬åˆ›çš„åŒé¢‘äº¤é”™å¾ªç¯**\n    *   **æ”¹åŠ¨**ï¼šå°†æ ‡å‡†çš„åŒæ­¥â€œæ‰¹å¤„ç†-æ‰§è¡Œâ€å¾ªç¯ï¼Œæ‹†åˆ†ä¸º**å®è§‚æ„å›¾å¾ªç¯**ï¼ˆä½é¢‘ï¼Œ~2.5Hzï¼Œç¼“å­˜è¯­ä¹‰åµŒå…¥ï¼‰å’Œ**å¾®è§‚æ§åˆ¶å¾ªç¯**ï¼ˆé«˜é¢‘ï¼Œ~9Hzï¼Œå•æ­¥æµé›†æˆï¼‰ã€‚\n    *   **æ”¹å–„**ï¼š**é‡æ–°åˆ†é…äº†è®¡ç®—é¢„ç®—**ï¼Œä½¿æ˜‚è´µçš„è¯­ä¹‰æ¨ç†ä¸å†æˆä¸ºæ§åˆ¶é¢‘ç‡çš„ç“¶é¢ˆï¼Œåœ¨**åŒç­‰ä¸»å¹²è®¡ç®—é‡**ä¸‹å°†æ§åˆ¶æ›´æ–°é¢‘ç‡æå‡äº†çº¦4å€ã€‚\n\n2.  **ç®—æ³•å±‚é¢ï¼šå•æ­¥æµé›†æˆä¸æ—¶é—´åç½®è®­ç»ƒ**\n    *   **æ”¹åŠ¨**ï¼šå¾®è§‚å¾ªç¯ä¸­ï¼Œ**ä»…æ‰§è¡Œä¸€æ¬¡æ¬§æ‹‰ç§¯åˆ†æ­¥**ï¼ˆä»å™ªå£°æº `t=0` å‡ºå‘ï¼‰æ¥ç”ŸæˆåŠ¨ä½œï¼Œå¹¶åªæ‰§è¡Œè¯¥è½¨è¿¹çš„å‰å‡ æ­¥ã€‚åœ¨è®­ç»ƒæ—¶ï¼Œ**åç½®æµæ—¶é—´é‡‡æ ·**ï¼ˆä½¿ç”¨Betaåˆ†å¸ƒï¼‰ä½¿å…¶é›†ä¸­åœ¨ `tâ‰ˆ0` é™„è¿‘ã€‚\n    *   **æ”¹å–„**ï¼šå°†åŠ¨ä½œå—ç”Ÿæˆæ—¶é—´å‹ç¼©åˆ°å¯å¿½ç•¥çš„æ°´å¹³ï¼ˆ~19msï¼‰ï¼Œä½¿å¾—é«˜é¢‘äº¤é”™æˆä¸ºå¯èƒ½ã€‚è®­ç»ƒä¸æ¨ç†æ¨¡å¼å¯¹é½ï¼Œ**æœ€å¤§åŒ–æœ‰é™è®¡ç®—é¢„ç®—çš„æ•ˆç‡**ã€‚\n\n3.  **è®­ç»ƒä¸æ„ŸçŸ¥å±‚é¢ï¼šæ—¶æ€é”™ä½è®­ç»ƒä¸å·®åˆ†è¿åŠ¨æ³¨å…¥**\n    *   **æ”¹åŠ¨**ï¼šåœ¨è®­ç»ƒä¸­**æ³¨å…¥å¯å˜å»¶è¿Ÿ**ï¼Œè®©ç­–ç•¥å­¦ä¹ åŸºäº**è¿‡æ—¶çš„è¯­ä¹‰æ„å›¾**å’Œ**å®æ—¶çš„æœ¬ä½“æ„ŸçŸ¥**è¿›è¡Œé¢„æµ‹æ€§è¡¥å¿ã€‚é¢å¤–å¼•å…¥ä¸€ä¸ªè½»é‡çº§**å·®åˆ†è¿åŠ¨é¢„æµ‹å™¨**ï¼Œä¸ºç­–ç•¥æä¾›æ˜¾å¼çš„é€Ÿåº¦ä¿¡æ¯ã€‚\n    *   **æ”¹å–„**ï¼šä½¿ç­–ç•¥èƒ½å¤Ÿ**é²æ£’åœ°å¤„ç† VLM çš„å›ºæœ‰å»¶è¿Ÿå’Œè¯­ä¹‰çº¿ç´¢çš„é™ˆæ—§æ€§**ã€‚å¼¥è¡¥äº†é™æ€è§†è§‰ç¼–ç å™¨å¯¹é€Ÿåº¦ä¸æ•æ„Ÿçš„ç¼ºé™·ï¼Œä¸ºåŠ¨æ€æ‹¦æˆªæä¾›äº†å…³é”®ä¿¡å·ã€‚**è¿åŠ¨é¢„æµ‹å™¨ä¸é«˜é¢‘æ¶æ„ååŒ**ï¼ŒåŒæ—¶æä¾›äº†æ„ŸçŸ¥ä¿¡å·å’Œå“åº”æœºä¼šã€‚\n\n**æ€»è€Œè¨€ä¹‹ï¼ŒTIDAL çš„æ ¸å¿ƒçªç ´åœ¨äºï¼Œå®ƒæ²¡æœ‰é€šè¿‡ç®€åŒ–æ¨¡å‹æˆ–å¢åŠ ç¡¬ä»¶æ¥æ¢å–é€Ÿåº¦ï¼Œè€Œæ˜¯é€šè¿‡ä¸€ç§ç²¾å·§çš„ã€ç®—æ³•é©±åŠ¨çš„â€œæ—¶é—´æ¢ç©ºé—´â€ç­–ç•¥ï¼Œé‡æ–°ç»„ç»‡äº†å¤§è§„æ¨¡ VLA æ¨¡å‹çš„æ¨ç†å’Œæ‰§è¡Œæµç¨‹ï¼Œä»è€Œåœ¨åŠ¨æ€ç¯å¢ƒä¸­å®ç°äº†è¯­ä¹‰æ™ºèƒ½ä¸é«˜é¢‘æ§åˆ¶çš„å…³é”®ç»Ÿä¸€ã€‚**",
            "timestamp": "2026-01-27T16:03:58.209446",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "è®ºæ–‡æå‡ºäº†å“ªäº›å…³é”®æŠ€æœ¯æ–¹æ³•ï¼Œè¯·åˆ—è¡¨æ ¼å…·ä½“è¯¦ç»†è¯´æ˜æŠ€æœ¯ç»†èŠ‚ï¼Œéœ€è¦åŒ…å«å…·ä½“çš„æ•°å­¦åŸç†æ¨å¯¼ï¼Œä»¥åŠå…·ä½“å‚æ•°ã€‚",
            "answer": "å¥½çš„ï¼Œä½œä¸ºä¸€åä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡åˆ†æåŠ©æ‰‹ï¼Œæˆ‘å°†å¯¹è¿™ç¯‡é¢˜ä¸ºã€ŠTIDAL: Temporally Interleaved Diffusion and Action Loop for High-Frequency VLA Controlã€‹çš„è®ºæ–‡è¿›è¡Œæ·±å…¥åˆ†æï¼Œå¹¶è¯¦ç»†é˜è¿°å…¶æå‡ºçš„å…³é”®æŠ€æœ¯æ–¹æ³•ã€‚\n\n## è®ºæ–‡æ ¸å¿ƒæŠ€æœ¯åˆ›æ–°åˆ†æ\n\næœ¬æ–‡çš„æ ¸å¿ƒé—®é¢˜æ˜¯ï¼š**å¤§è§„æ¨¡è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹å› æ¨ç†å»¶è¿Ÿé«˜ï¼Œè¢«è¿«é‡‡ç”¨â€œæ‰¹é‡è®¡ç®—-å¼€ç¯æ‰§è¡Œâ€çš„ä½é¢‘èŒƒå¼ï¼Œå¯¼è‡´åœ¨åŠ¨æ€ç¯å¢ƒä¸­ï¼ˆå¦‚ç›®æ ‡ç§»åŠ¨æ—¶ï¼‰å› â€œæ‰§è¡Œç›²åŒºâ€è€Œå¤±è´¥ã€‚**\n\nTIDAL çš„è§£å†³æ–¹æ¡ˆæ˜¯ï¼š**é€šè¿‡ä¸€ä¸ªåŒé¢‘ç‡ã€å±‚æ¬¡åŒ–çš„æ¶æ„ï¼Œå°†è¯­ä¹‰æ¨ç†ä¸é«˜é¢‘é©±åŠ¨è§£è€¦ï¼Œåœ¨ä¸å¢åŠ éª¨å¹²ç½‘ç»œè®¡ç®—è´Ÿæ‹…çš„å‰æä¸‹ï¼Œå°†æ§åˆ¶é¢‘ç‡æå‡çº¦4å€ï¼ˆä»~2.4 Hzåˆ°~9 Hzï¼‰ã€‚**\n\nä»¥ä¸‹æ˜¯å…¶å…³é”®æŠ€æœ¯æ–¹æ³•çš„è¯¦ç»†è¯´æ˜ï¼š\n\n| æŠ€æœ¯æ–¹æ³• | æ ¸å¿ƒæ€æƒ³ | æŠ€æœ¯ç»†èŠ‚ä¸æ•°å­¦åŸç† | å…·ä½“å‚æ•°ä¸å®ç° |\n| :--- | :--- | :--- | :--- |\n| **1. å±‚æ¬¡åŒ–åŒé¢‘ç‡æ¶æ„** | å°†æ˜‚è´µçš„VLMæ¨ç†ï¼ˆè¯­ä¹‰æ„å›¾ç”Ÿæˆï¼‰ä¸è½»é‡çš„åŠ¨ä½œç”Ÿæˆï¼ˆæµåŒ¹é…ç§¯åˆ†ï¼‰è§£è€¦ï¼Œå¹¶é”™æ—¶è°ƒåº¦ã€‚ | **å®è§‚æ„å›¾å¾ªç¯ï¼ˆä½é¢‘ï¼‰**ï¼š<br>â€¢ æ¯éš” `H` æ­¥ï¼ˆä¸€ä¸ªå®å‘¨æœŸï¼‰æŸ¥è¯¢ä¸€æ¬¡VLMéª¨å¹²ç½‘ç»œ `Î¦_VLM`ï¼Œç”Ÿæˆå¹¶ç¼“å­˜è¯­ä¹‰åµŒå…¥ `â„°_k`ã€‚<br>â€¢ å…¬å¼ï¼š`â„°_k = Î¦_VLM(I_tk, l_instr)` <br><br>**å¾®è§‚æ§åˆ¶å¾ªç¯ï¼ˆé«˜é¢‘ï¼‰**ï¼š<br>â€¢ åœ¨æ¯ä¸ªå®å‘¨æœŸå†…ï¼Œè¿›è¡Œ `K` æ¬¡å¾®è§‚æ›´æ–°ã€‚æ¯æ¬¡æ›´æ–°æ—¶ï¼Œ**ä¸é‡æ–°æŸ¥è¯¢VLM**ï¼Œè€Œæ˜¯å°†**ç¼“å­˜çš„è¯­ä¹‰åµŒå…¥ `â„°`** ä¸**å®æ—¶èåˆçš„ç‰©ç†çŠ¶æ€ `sÌƒ_t`** ä¸€èµ·è¾“å…¥ç»™æµåŒ¹é…åŠ¨ä½œå¤´ `v_Î¸`ã€‚<br>â€¢ æ‰§è¡Œ**å•æ­¥æ¬§æ‹‰ç§¯åˆ†**ç”ŸæˆåŠ¨ä½œè½¨è¿¹ï¼š`Ã¢ = x_0 + v_Î¸(x_0, 0, sÌƒ_t, â„°)`ï¼Œå…¶ä¸­ `x_0 ~ N(0, I)`ã€‚<br>â€¢ åªæ‰§è¡Œç”Ÿæˆè½¨è¿¹çš„å‰ `N` æ­¥ï¼Œç„¶åç«‹å³è¿›è¡Œä¸‹ä¸€æ¬¡å¾®è§‚æ›´æ–°ï¼Œå½¢æˆâ€œæ»‘åŠ¨çª—å£â€å¼æ‰§è¡Œã€‚ | â€¢ **é¢„æµ‹è§†é‡ `H = 16`**ï¼šVLMæ¯æ¬¡ç”Ÿæˆè¦†ç›–16æ­¥çš„è¯­ä¹‰æ„å›¾ã€‚<br>â€¢ **æ‰§è¡Œå—å¤§å° `N = 4`**ï¼šæ¯æ¬¡å¾®è§‚æ›´æ–°åæ‰§è¡Œ4æ­¥åŠ¨ä½œã€‚<br>â€¢ **å»¶è¿Ÿé˜¶æ®µæ•° `K = 4`**ï¼šæ¯ä¸ªå®å‘¨æœŸè¿›è¡Œ4æ¬¡å¾®è§‚æ›´æ–° (`H = K * N`)ã€‚<br>â€¢ **æ›´æ–°é¢‘ç‡**ï¼šå¾®è§‚å¾ªç¯å‘¨æœŸ ~100 ms (æ¨ç†19ms + æ‰§è¡Œ80ms) â†’ **~9 Hz**ã€‚åŸºçº¿å‘¨æœŸ ~413 ms â†’ **~2.4 Hz**ã€‚ |\n| **2. æ—¶é—´é”™ä½è®­ç»ƒç­–ç•¥** | åœ¨è®­ç»ƒä¸­æ¨¡æ‹Ÿæ¨ç†å»¶è¿Ÿï¼Œè®©ç­–ç•¥å­¦ä¼šä½¿ç”¨**è¿‡æ—¶çš„è¯­ä¹‰æ„å›¾**å’Œ**å®æ—¶çš„æœ¬ä½“æ„ŸçŸ¥**æ¥é¢„æµ‹å¹¶è¡¥å¿å»¶è¿Ÿå¸¦æ¥çš„è¯¯å·®ã€‚ | **åŠ¨æ€å»¶è¿Ÿæ³¨å…¥**ï¼š<br>â€¢ ä»é•¿åº¦ä¸º `L = H + (K-1)*N = 28` çš„è½¨è¿¹æ®µä¸­é‡‡æ ·æ•°æ®ã€‚<br>â€¢ éšæœºé‡‡æ ·å»¶è¿Ÿé˜¶æ®µ `k ~ U{0, K-1}`ã€‚è®­ç»ƒæ ·æœ¬æ„æˆä¸ºï¼š<br>  - **å†»ç»“æ„å›¾**ï¼šæ¥è‡ªæ—¶é—´ `t=0` çš„å›¾åƒ `I_0` ç¼–ç çš„ `â„°_0`ã€‚<br>  - **å½“å‰çŠ¶æ€**ï¼šæ¥è‡ªæ—¶é—´ `t = k*N` çš„æœ¬ä½“æ„ŸçŸ¥çŠ¶æ€ `s_{k*N}`ã€‚<br>  - **åŠ¨ä½œç›®æ ‡**ï¼šä» `t = k*N` å¼€å§‹çš„ `H` æ­¥çœŸå®åŠ¨ä½œ `a_{k*N : k*N+H}`ã€‚<br><br>**æ°´å¹³åŠ æƒ & æ—¶é—´åç½®çš„æµåŒ¹é…æŸå¤±**ï¼š<br>â€¢ æŸå¤±å‡½æ•°åŸºäºæ¡ä»¶æµåŒ¹é…ï¼š<br>```math\nâ„’(Î¸) = ğ”¼_{k,t,x_0,x_1}[âˆ‘_{i=0}^{H-1} w_i Â· â€– v_Î¸(Ïˆ_t(x_0,x_1), t, s_{kÂ·N}, â„°_0)^{(i)} - (x_1^{(i)} - x_0^{(i)}) â€–^2]\n```<br>å…¶ä¸­ `Ïˆ_t(x_0, x_1) = (1-t)x_0 + t x_1` ä¸ºæœ€ä¼˜ä¼ è¾“è·¯å¾„ã€‚<br>â€¢ **æ°´å¹³æƒé‡ `w_i`**ï¼šå¯¹å³å°†æ‰§è¡Œçš„æ­¥æ•°èµ‹äºˆæ›´é«˜æƒé‡ã€‚`w_i = 2.0 (if i < N), else 1.0`ã€‚<br>â€¢ **æ—¶é—´åç½®é‡‡æ · `p(t)`**ï¼šç”±äºæ¨ç†æ—¶åªä» `t=0` åšå•æ­¥ç§¯åˆ†ï¼Œè®­ç»ƒæ—¶åº”è®©æ¨¡å‹åœ¨ `tâ‰ˆ0` é™„è¿‘æ›´å‡†ç¡®ã€‚é‡‡æ · `s ~ Beta(Î±, Î²)`, ä»¤ `t = 1-s`ã€‚è®ºæ–‡è®¾ç½® `Î±=5.0, Î²=1.0`ï¼Œä½¿ `t` çš„æ¦‚ç‡å¯†åº¦é›†ä¸­åœ¨0é™„è¿‘ã€‚ | â€¢ **è½¨è¿¹é•¿åº¦ `L = 28`**ã€‚<br>â€¢ **å»¶è¿Ÿé˜¶æ®µ `k âˆˆ {0, 1, 2, 3}`**ã€‚<br>â€¢ **æ°´å¹³æƒé‡ `w_i`**ï¼š`N=4` æ­¥å†…æƒé‡ä¸º2.0ï¼Œå…¶ä½™ä¸º1.0ã€‚<br>â€¢ **Betaåˆ†å¸ƒå‚æ•°**ï¼š`Î± = 5.0, Î² = 1.0`ã€‚ |\n| **3. å·®åˆ†è¿åŠ¨é¢„æµ‹å™¨** | è§£å†³é™æ€è§†è§‰ç¼–ç å™¨å¯¹é€Ÿåº¦ä¸æ•æ„Ÿçš„é—®é¢˜ï¼Œä¸ºç­–ç•¥æä¾›é«˜é¢‘çš„è¿åŠ¨å­¦ç‰¹å¾ï¼Œä½¿å…¶èƒ½è·Ÿè¸ªç§»åŠ¨ç›®æ ‡ã€‚ | **è¿åŠ¨ç‰¹å¾æå–**ï¼š<br>â€¢ è¾“å…¥ä¸ºå½“å‰å¸§ä¸å†å²å¸§ï¼ˆæ»å `k=4`ï¼‰çš„å½’ä¸€åŒ–åƒç´ å·®ï¼š`Î”I_t = ğ’¯(I_t) - ğ’¯(I_{t-k})`ã€‚<br>â€¢ ä½¿ç”¨ä¸€ä¸ªè½»é‡çš„7å±‚CNNå¤„ç† `Î”I_t`ï¼Œåæ¥MLPç“¶é¢ˆå±‚ï¼Œè¾“å‡ºä½ç»´è¿åŠ¨åµŒå…¥ `m_t âˆˆ â„^64`ã€‚<br><br>**è¾…åŠ©é¢„è®­ç»ƒ**ï¼š<br>ä½¿ç”¨è¾…åŠ©æŸå¤±å‡½æ•°é¢„è®­ç»ƒè¿åŠ¨é¢„æµ‹å™¨ `Ïˆ_motion`ï¼Œä½¿å…¶ç¼–ç ç‰©ç†åŠ¨åŠ›å­¦ï¼š<br>```math\nâ„’_aux = Î»_1â€–pÌ‚_t - p_tâ€–^2 + Î»_2â€–vÌ‚_t - v_tâ€–^2 + Î»_3â€–pÌ‚_{t+k} - p_{t+k}â€–^2\n```<br>é¢„æµ‹æœªæ¥ä½ç½® `p_{t+k}` ä½¿å…¶éšå«ç¼–ç åŠ¨é‡ï¼Œå®ç°é¢„æµ‹æ€§æ‹¦æˆªã€‚<br><br>**æ¥è§¦é—¨æ§èåˆ**ï¼š<br>æ ¹æ®å¤¹çˆªä¼ æ„Ÿå™¨çš„äºŒè¿›åˆ¶æ¥è§¦çŠ¶æ€ `c_t`ï¼Œå°†è¿åŠ¨åµŒå…¥ä¸æœ¬ä½“æ„ŸçŸ¥çŠ¶æ€èåˆï¼š<br>```math\nsÌƒ_t = Concat(s_prop, (1 - c_t) Â· m_t)\n```<br>åœ¨éæ¥è§¦é˜¶æ®µ(`c_t=0`)ï¼Œç­–ç•¥æ¥æ”¶å®Œæ•´çš„è¿åŠ¨å‘é‡ï¼›åœ¨æ¥è§¦/æ“ä½œé˜¶æ®µ(`c_t=1`)ï¼Œè¿åŠ¨å‘é‡è¢«ç½®é›¶ï¼Œç­–ç•¥å›é€€åˆ°æœ¬ä½“æ„ŸçŸ¥æ§åˆ¶ã€‚ | â€¢ **è¿åŠ¨åµŒå…¥ç»´åº¦**ï¼š`m_t âˆˆ â„^64`ã€‚<br>â€¢ **ç½‘ç»œç»“æ„**ï¼š7å±‚CNN + MLPç“¶é¢ˆã€‚<br>â€¢ **å¸§æ»å `k = 4`**ã€‚<br>â€¢ **è¾…åŠ©æŸå¤±æƒé‡**ï¼š`Î»_1, Î»_2, Î»_3`ï¼ˆè®ºæ–‡æœªç»™å‡ºå…·ä½“å€¼ï¼Œé€šå¸¸é€šè¿‡è°ƒå‚ç¡®å®šï¼‰ã€‚<br>â€¢ **èåˆæ–¹å¼**ï¼šæ‹¼æ¥ï¼Œå¹¶é€šè¿‡ `(1 - c_t)` è¿›è¡Œé—¨æ§ã€‚ |\n| **4. å•æ­¥æµç§¯åˆ†æ¨ç†ä¼˜åŒ–** | å°†æ ‡å‡†çš„å¤šæ¬¡è¿­ä»£æ‰©æ•£/æµåŒ¹é…é‡‡æ ·è¿‡ç¨‹ï¼Œå‹ç¼©ä¸º**å•æ­¥æ¬§æ‹‰ç§¯åˆ†**ï¼Œä½¿å¾®è§‚å¾ªç¯çš„æ¨ç†å»¶è¿Ÿæä½ã€‚ | **æ•°å­¦åŸç†**ï¼š<br>â€¢ æµåŒ¹é…å­¦ä¹ ä¸€ä¸ªå‘é‡åœº `v_Î¸(x, t, c)`ï¼Œå®ƒå®šä¹‰äº†ä»å™ªå£°åˆ†å¸ƒ `p_0(x_0)` åˆ°æ•°æ®åˆ†å¸ƒ `p_1(x_1)` çš„æ¦‚ç‡è·¯å¾„ `p_t(x)` çš„å¸¸å¾®åˆ†æ–¹ç¨‹ï¼š`dx/dt = v_Î¸(x, t, c)`ã€‚<br>â€¢ ä¼ ç»Ÿé‡‡æ ·éœ€ä» `t=0` åˆ° `t=1` æ•°å€¼ç§¯åˆ†å¤šæ¬¡ã€‚TIDAL åˆ©ç”¨**æ—¶é—´åç½®è®­ç»ƒ**ï¼Œä½¿å­¦å¾—çš„å‘é‡åœºåœ¨ `tâ‰ˆ0` æ—¶éå¸¸å‡†ç¡®ï¼Œå› æ­¤åªéœ€ä»åˆå§‹å™ªå£° `x_0` å‡ºå‘ï¼Œæ‰§è¡Œ**ä¸€æ¬¡æ¬§æ‹‰ç§¯åˆ†**ï¼š<br>```math\nx_1 â‰ˆ x_0 + v_Î¸(x_0, 0, sÌƒ_t, â„°)\n```<br>è¿™ä¸€æ­¥ç›´æ¥é¢„æµ‹äº†ä»å™ªå£°æŒ‡å‘ç›®æ ‡åŠ¨ä½œè½¨è¿¹çš„å‘é‡ï¼Œå…¶è¾“å‡º `x_1` å³è¢«è§†ä¸ºç”Ÿæˆçš„åŠ¨ä½œè½¨è¿¹ `Ã¢`ã€‚ | â€¢ **ç§¯åˆ†æ­¥æ•°**ï¼š1ï¼ˆå•æ­¥æ¬§æ‹‰ç§¯åˆ†ï¼‰ã€‚<br>â€¢ **æ¨ç†æ—¶é—´**ï¼š~19 msï¼ˆåœ¨NVIDIA Jetson AGX Orinä¸Šï¼‰ã€‚<br>â€¢ **ä¸åŸºçº¿å¯¹æ¯”**ï¼šåŸºçº¿ä½¿ç”¨å¤šæ­¥é‡‡æ ·ï¼ˆå¦‚4æ­¥ï¼‰ï¼Œè€—æ—¶é•¿ï¼›TIDALé€šè¿‡è®­ç»ƒä¼˜åŒ–ï¼Œç”¨ä¸€æ­¥è¾¾åˆ°è¶³å¤Ÿ",
            "timestamp": "2026-01-27T16:05:09.118770",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "ä»–ä½¿ç”¨äº†å“ªäº›è¯„ä»·æŒ‡æ ‡ä¸æ•°æ®é›†ï¼Œåˆ—è¡¨æ ¼å…·ä½“è®²è®²ä»–çš„è¯„ä»·æŒ‡æ ‡çš„ç»†èŠ‚ä¸æ•°æ®é›†çš„ç»†èŠ‚",
            "answer": "## è®ºæ–‡è¯„ä»·æŒ‡æ ‡ä¸æ•°æ®é›†åˆ†æ\n\n### ä¸€ã€ è¯„ä»·æŒ‡æ ‡\n\nè®ºæ–‡ä¸»è¦ä½¿ç”¨**ä»»åŠ¡æˆåŠŸç‡**ä½œä¸ºæ ¸å¿ƒè¯„ä»·æŒ‡æ ‡ï¼Œå¹¶åœ¨ä¸åŒå®éªŒè®¾ç½®ä¸‹è¿›è¡Œå¯¹æ¯”ã€‚å…·ä½“ç»†èŠ‚å¦‚ä¸‹ï¼š\n\n| è¯„ä»·æŒ‡æ ‡åç§° | è®¡ç®—æ–¹å¼ | å®éªŒåœºæ™¯ | ç»†èŠ‚ä¸ç›®çš„ |\n| :--- | :--- | :--- | :--- |\n| **é™æ€ä»»åŠ¡æˆåŠŸç‡** | æˆåŠŸå®Œæˆç»™å®šä»»åŠ¡çš„æµ‹è¯•å›åˆæ¯”ä¾‹ã€‚ | RoboCasaå®˜æ–¹é™æ€åŸºå‡†æµ‹è¯•ï¼ˆ8ä¸ªä»»åŠ¡ï¼‰ã€‚ | ç”¨äºè¯„ä¼°æ¨¡å‹åœ¨**é™æ€ç¯å¢ƒ**ä¸‹çš„é€šç”¨ä»»åŠ¡å®Œæˆèƒ½åŠ›ï¼ŒéªŒè¯TIDALæ¶æ„æ˜¯å¦å› ä¼˜åŒ–åŠ¨æ€æ€§èƒ½è€Œç‰ºç‰²äº†åŸºç¡€è¯­ä¹‰æ¨ç†å’Œè§„åˆ’èƒ½åŠ›ã€‚ |\n| **åŠ¨æ€æ‹¦æˆªä»»åŠ¡æˆåŠŸç‡** | æˆåŠŸæ‹¦æˆªç§»åŠ¨ç›®æ ‡å¹¶å®Œæˆåç»­æ“ä½œï¼ˆæ”¾å…¥æŠ½å±‰ã€å…³é—­ï¼‰çš„æµ‹è¯•å›åˆæ¯”ä¾‹ã€‚ | è‡ªå®šä¹‰çš„åŠ¨æ€æ‹¦æˆªåŸºå‡†æµ‹è¯•ï¼ˆåˆ†Easyå’ŒHardä¸¤ä¸ªéš¾åº¦ï¼‰ã€‚ | **æ ¸å¿ƒåˆ›æ–°éªŒè¯æŒ‡æ ‡**ã€‚ç”¨äºé‡åŒ–TIDALåœ¨**åŠ¨æ€ç¯å¢ƒ**ä¸­çš„æ€§èƒ½æå‡ï¼Œç›´æ¥è¯æ˜å…¶é«˜é¢‘æ›´æ–°å’ŒåŠ¨æ€æ„ŸçŸ¥çš„æœ‰æ•ˆæ€§ã€‚ |\n| **æ€§èƒ½ä¿æŒç‡** | åœ¨â€œéæš‚åœæ¨ç†â€åè®®ä¸‹çš„æˆåŠŸç‡ Ã· åœ¨â€œæš‚åœæ¨ç†â€åè®®ä¸‹çš„æˆåŠŸç‡ã€‚ | åŠ¨æ€æ‹¦æˆªä»»åŠ¡ï¼ˆEasyéš¾åº¦ï¼‰ã€‚ | ç”¨äºè¯„ä¼°æ–¹æ³•åœ¨**æ›´è´´è¿‘ç°å®**çš„ä»¿çœŸè®¾ç½®ä¸‹çš„é²æ£’æ€§ã€‚åœ¨éæš‚åœåè®®ä¸­ï¼Œç¯å¢ƒï¼ˆç›®æ ‡è¿åŠ¨ï¼‰åœ¨æ¨¡å‹æ¨ç†æ—¶ä»åœ¨æŒç»­ï¼Œæ¨¡æ‹Ÿäº†çœŸå®ä¸–ç•Œçš„è®¡ç®—å»¶è¿Ÿã€‚ |\n| **è¯­ä¹‰æ„å›¾å¯¿å‘½åˆ†æ** | åœ¨å›ºå®šé™æ€ä»»åŠ¡ä¸Šï¼Œé€æ­¥å»¶é•¿è¯­ä¹‰åµŒå…¥ç¼“å­˜æ—¶é—´ï¼ˆå‚æ•° `l`ï¼‰ï¼Œè§‚å¯ŸæˆåŠŸç‡å˜åŒ–ã€‚ | å•ä¸ªä»£è¡¨æ€§çš„é™æ€ä»»åŠ¡ã€‚ | åˆ†æ**ç¼“å­˜è¯­ä¹‰æ„å›¾çš„æœ‰æ•ˆæ—¶é•¿**ï¼Œæ¢ç©¶TIDALæ¶æ„å¦‚ä½•åˆ©ç”¨å®æ—¶æœ¬ä½“æ„ŸçŸ¥æ¥æ‰©å±•å•æ¬¡VLMæŸ¥è¯¢çš„æœ‰æ•ˆä½œç”¨èŒƒå›´ï¼Œè¶…è¶ŠåŸç”ŸåŠ¨ä½œå—ï¼ˆ16æ­¥ï¼‰çš„é™åˆ¶ã€‚ |\n\n**å…³é”®ç»†èŠ‚ï¼š**\n1.  **å¯¹æ¯”åŸºçº¿**ï¼šæ‰€æœ‰æŒ‡æ ‡å‡ä¸æ ‡å‡†çš„**å¼€ç¯åŸºçº¿**è¿›è¡Œå¯¹æ¯”ï¼Œè¯¥åŸºçº¿é‡‡ç”¨â€œæ‰¹å¤„ç†-æ‰§è¡Œâ€èŒƒå¼ï¼Œåœ¨è®¡ç®—å’ŒåŠ¨ä½œæ‰§è¡ŒæœŸé—´å¯¹ç¯å¢ƒå˜åŒ–æ— å“åº”ã€‚\n2.  **åè®®åŒºåˆ†**ï¼š\n    *   **æš‚åœæ¨ç†**ï¼šæ ‡å‡†çš„å­¦æœ¯è¯„ä¼°åè®®ï¼Œåœ¨æ¨¡å‹è¿›è¡Œæ¨ç†æ—¶æš‚åœç‰©ç†ä»¿çœŸã€‚è¿™æ¶ˆé™¤äº†è®¡ç®—å»¶è¿Ÿçš„å½±å“ï¼Œè¯„ä¼°çš„æ˜¯â€œç†æƒ³è®¡ç®—æ¡ä»¶â€ä¸‹çš„ç­–ç•¥è´¨é‡ã€‚\n    *   **éæš‚åœæ¨ç†**ï¼šæ›´ä¸¥æ ¼çš„è¯„ä¼°åè®®ï¼Œåœ¨æ¨¡å‹æ¨ç†æ—¶ä»¿çœŸç¯å¢ƒï¼ˆå¦‚ç›®æ ‡ç§»åŠ¨ï¼‰ç…§å¸¸è¿›è¡Œã€‚è¿™æ¨¡æ‹Ÿäº†**çœŸå®éƒ¨ç½²ä¸­çš„å»¶è¿Ÿ**ï¼Œæ˜¯è¯„ä¼°æ–¹æ³•å®é™…åº”ç”¨æ½œåŠ›çš„å…³é”®ã€‚\n3.  **æ§åˆ¶å˜é‡**ï¼šå®éªŒåœ¨**éª¨å¹²ç½‘ç»œç­‰è®¡ç®—é‡**çº¦æŸä¸‹è¿›è¡Œï¼Œç¡®ä¿æ€§èƒ½æå‡æºäºTIDALçš„**æ—¶åºè°ƒåº¦æ¶æ„**ï¼Œè€Œéå•çº¯å¢åŠ äº†è®¡ç®—èµ„æºã€‚\n\n### äºŒã€ æ•°æ®é›†\n\nè®ºæ–‡ä½¿ç”¨äº†ä¸¤ä¸ªåŸºå‡†ç¯å¢ƒå¥—ä»¶ï¼Œå¹¶ä¸ºæ­¤ä¸“é—¨æ”¶é›†äº†å¾®è°ƒæ•°æ®ã€‚\n\n| æ•°æ®é›†/ç¯å¢ƒåç§° | ç±»å‹ | ä»»åŠ¡æè¿° | ç»†èŠ‚ä¸ç”¨é€” |\n| :--- | :--- | :--- | :--- |\n| **RoboCasa (MuJoCo)** | ä»¿çœŸåŸºå‡†å¥—ä»¶ | åŒ…å«å¤šç§æ—¥å¸¸å®¶å±…æ“ä½œçš„é•¿è§†é‡ä»»åŠ¡ï¼Œå¦‚æ‰“å¼€æŸœé—¨ã€æ‘†æ”¾ç‰©å“ç­‰ã€‚**ç›®æ ‡ç‰©ä½“æ˜¯é™æ­¢çš„**ã€‚ | **æ¥æº**ï¼šå®˜æ–¹â€˜RoboCasa-GR1â€™åŸºå‡†ã€‚ <br> **ç”¨é€”**ï¼šä½œä¸º**é™æ€ä»»åŠ¡å¯¹ç…§ç»„**ï¼ŒåŒ…å«8ä¸ªä»»åŠ¡ï¼Œç”¨äºè¯„ä¼°å’Œç¡®ä¿TIDALåœ¨ç»§æ‰¿å¤§å‹VLAæ¨¡å‹è¯­ä¹‰æ³›åŒ–èƒ½åŠ›æ–¹é¢æ²¡æœ‰ä¸¥é‡é€€åŒ–ã€‚ |\n| **åŠ¨æ€æ‹¦æˆªåŸºå‡†** | è‡ªå®šä¹‰ä»¿çœŸåŸºå‡† | æœºå™¨äººéœ€è¦ï¼š1) æ‹¦æˆªä¸€ä¸ª**æŒç»­ç§»åŠ¨**çš„ç½å­ï¼›2) å°†å…¶æ”¾å…¥æŠ½å±‰ï¼›3) å…³é—­æŠ½å±‰ã€‚ç›®æ ‡è¢«èµ‹äºˆéšæœºåˆé€Ÿåº¦ï¼Œå¹¶åœ¨è¾¹ç•Œéšæœº90åº¦è½¬å‘ã€‚ | **åˆ†å±‚**ï¼šæ ¹æ®ç›®æ ‡åˆå§‹è¿åŠ¨æ–¹å‘ç›¸å¯¹äºæœºå™¨äººæ“ä½œæ‰‹çš„éš¾æ˜“ç¨‹åº¦ï¼Œåˆ†ä¸º **Easy** å’Œ **Hard** ä¸¤ä¸ªå±‚çº§ã€‚ <br> **ç”¨é€”**ï¼š**æ ¸å¿ƒè¯„ä¼°åœºæ™¯**ï¼Œä¸“é—¨è®¾è®¡ç”¨äºæš´éœ²æ ‡å‡†VLAæ¨¡å‹å› è®¡ç®—å»¶è¿Ÿå’Œå¼€ç¯æ‰§è¡Œå¯¼è‡´çš„â€œæ‰§è¡Œç›²åŒºâ€é—®é¢˜ï¼ŒéªŒè¯TIDALçš„é«˜é¢‘ååº”èƒ½åŠ›ã€‚ |\n| **åŠ¨æ€ä»»åŠ¡ä¸“å®¶æ¼”ç¤ºæ•°æ®é›†** | ä¸“é—¨æ”¶é›†çš„å¾®è°ƒæ•°æ® | åŒ…å«2000ä¸ªæˆåŠŸå®ŒæˆåŠ¨æ€æ‹¦æˆªä»»åŠ¡çš„è½¨è¿¹ã€‚ | **æ”¶é›†æ–¹æ³•**ï¼šé‡‡ç”¨ **â€œæš‚åœä»¿çœŸé¢„è¨€æœºâ€ç­–ç•¥**è‡ªåŠ¨åŒ–æ”¶é›†ã€‚å³åœ¨ä»¿çœŸçš„æ¯ä¸€æ­¥éƒ½æš‚åœï¼Œè¿è¡Œå®Œæ•´çš„VLAæ¨ç†ç”ŸæˆåŠ¨ä½œï¼Œä»è€Œå¾—åˆ°åœ¨å¿½ç•¥è®¡ç®—å»¶è¿Ÿç†æƒ³æ¡ä»¶ä¸‹çš„å®Œç¾é—­è½¨è½¨è¿¹ã€‚ <br> **ç”¨é€”**ï¼šç”¨äºå¯¹TIDALç­–ç•¥è¿›è¡Œ**ç›‘ç£å¾®è°ƒ**ï¼Œä¸ºå…¶æä¾›åœ¨åŠ¨æ€ç¯å¢ƒä¸­å¦‚ä½•æ­£ç¡®è·Ÿè¸ªå’Œæ‹¦æˆªç›®æ ‡çš„ä¸“å®¶ç¤ºèŒƒã€‚è¿™ç§æ–¹æ³•é¿å…äº†æ˜‚è´µçš„äººåŠ›é¥æ“ä½œã€‚ |\n\n**æ€»ç»“**ï¼š\nè®ºæ–‡çš„è¯„ä»·ä½“ç³»è®¾è®¡ç²¾è‰¯ï¼Œ**é™æ€ä¸åŠ¨æ€ä»»åŠ¡ç»“åˆ**ï¼Œ**ç†æƒ³ä¸éæš‚åœåè®®å¯¹ç…§**ï¼Œå…¨é¢è¯„ä¼°äº†TIDALåœ¨ä¿æŒé€šç”¨èƒ½åŠ›çš„åŒæ—¶ï¼Œè§£å†³åŠ¨æ€äº¤äº’è¿™ä¸€æ ¸å¿ƒç—›ç‚¹çš„æ•ˆæœã€‚ä¸“é—¨æ„å»ºçš„åŠ¨æ€æ‹¦æˆªåŸºå‡†å’Œæ”¶é›†çš„ä¸“å®¶æ•°æ®ï¼Œç›´æ¥é’ˆå¯¹ç°æœ‰VLAæ¨¡å‹çš„çŸ­æ¿ï¼Œæœ‰åŠ›åœ°æ”¯æ’‘äº†å…¶åˆ›æ–°ä»·å€¼çš„è®ºè¯ã€‚",
            "timestamp": "2026-01-27T16:05:49.429018",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "è®ºæ–‡åœ¨å“ªäº›æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Ÿä¸»è¦çš„è¯„ä¼°æŒ‡æ ‡å’Œæ€§èƒ½æå‡æ˜¯å¤šå°‘ï¼Ÿ",
            "answer": "## è®ºæ–‡å®éªŒæ•°æ®é›†ã€è¯„ä¼°æŒ‡æ ‡ä¸æ€§èƒ½æå‡åˆ†æ\n\n### ä¸€ã€ å®éªŒæ•°æ®é›†\nè®ºæ–‡åœ¨ä¸¤ä¸ªä¸»è¦åŸºå‡†æµ‹è¯•é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼š\n\n1.  **é™æ€ä»»åŠ¡åŸºå‡†ï¼ˆStatic Tasksï¼‰**ï¼š\n    *   **æ¥æº**ï¼šå®˜æ–¹ `RoboCasa-GR1` åŸºå‡†æµ‹è¯•é›†ã€‚\n    *   **ç‰¹ç‚¹**ï¼šåŒ…å« **8ä¸ªé•¿è§†é‡ä»»åŠ¡**ï¼Œç›®æ ‡ç‰©ä½“æ˜¯**é™æ­¢çš„**ã€‚ç”¨äºè¯„ä¼°æ¨¡å‹åœ¨**é€šç”¨é™æ€ä»»åŠ¡**ä¸Šçš„èƒ½åŠ›ï¼Œä½œä¸ºæ§åˆ¶ç»„ï¼ŒéªŒè¯TIDALæ¶æ„æ˜¯å¦ä¿ç•™äº†åŸºç¡€å¤§æ¨¡å‹çš„è¯­ä¹‰æ³›åŒ–èƒ½åŠ›ã€‚\n\n2.  **åŠ¨æ€æ‹¦æˆªåŸºå‡†ï¼ˆDynamic Interception Benchmarkï¼‰**ï¼š\n    *   **æ„å»ºæ–¹å¼**ï¼šä½œè€…åœ¨RoboCasaï¼ˆMuJoCoï¼‰ä»¿çœŸç¯å¢ƒä¸­è‡ªè¡Œæ„å»ºã€‚\n    *   **ä»»åŠ¡æè¿°**ï¼šæœºå™¨äººéœ€è¦**æ‹¦æˆªä¸€ä¸ªç§»åŠ¨çš„ç‰©ä½“**ï¼Œå°†å…¶æ”¾å…¥æŠ½å±‰ï¼Œç„¶åå…³é—­æŠ½å±‰ã€‚ç›®æ ‡ç‰©ä½“è¢«èµ‹äºˆéšæœºåˆé€Ÿåº¦ï¼ˆ0.04â€“0.06 m/sï¼‰ï¼Œå¹¶åœ¨è¾¹ç•Œå¤„éšæœº90åº¦è½¬å‘ï¼Œå½¢æˆéç¡®å®šæ€§è½¨è¿¹ã€‚\n    *   **éš¾åº¦åˆ†å±‚**ï¼š\n        *   **ç®€å•ï¼ˆEasyï¼‰**ï¼šç›®æ ‡å‘æœºå™¨äººè¿åŠ¨æ–¹å‘ï¼ˆå³æˆ–ä¸Šï¼‰ç§»åŠ¨ï¼Œæ˜“äºæ‹¦æˆªã€‚\n        *   **å›°éš¾ï¼ˆHardï¼‰**ï¼šç›®æ ‡è¿œç¦»æœºå™¨äººæˆ–è¿›å…¥é®æŒ¡åŒºåŸŸç§»åŠ¨ï¼Œéœ€è¦å¤æ‚çš„ç»•è¡Œæ“ä½œã€‚\n    *   **æ•°æ®æ”¶é›†**ï¼šä¸ºæ­¤ä»»åŠ¡æ”¶é›†äº†**2000æ¡**æˆåŠŸè½¨è¿¹çš„å¾®è°ƒæ•°æ®é›†ï¼Œä½¿ç”¨â€œæš‚åœä»¿çœŸé¢„è¨€æœºâ€ç­–ç•¥ç”Ÿæˆç†æƒ³çš„é—­ç¯ä¸“å®¶æ•°æ®ã€‚\n\n### äºŒã€ ä¸»è¦è¯„ä¼°æŒ‡æ ‡\næ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡æ˜¯**ä»»åŠ¡æˆåŠŸç‡ï¼ˆSuccess Rateï¼‰**ï¼Œå³åœ¨å¤šæ¬¡è¯•éªŒä¸­æˆåŠŸå®ŒæˆæŒ‡å®šä»»åŠ¡çš„æ¯”ç‡ã€‚\n\n### ä¸‰ã€ æ€§èƒ½æå‡ä¸å…³é”®ç»“æœ\n\n#### 1. åŠ¨æ€ä»»åŠ¡æ€§èƒ½ï¼ˆæ ¸å¿ƒè´¡çŒ®ï¼‰\nTIDALåœ¨åŠ¨æ€æ‹¦æˆªä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—æå‡ï¼Œ**æ€§èƒ½ç¿»å€**ã€‚\n\n| æ–¹æ³• | åŠ¨æ€ä»»åŠ¡ï¼ˆç®€å•ï¼‰æˆåŠŸç‡ | åŠ¨æ€ä»»åŠ¡ï¼ˆå›°éš¾ï¼‰æˆåŠŸç‡ | æ€§èƒ½æå‡ï¼ˆç®€å•ï¼‰ |\n| :--- | :--- | :--- | :--- |\n| **åŸºçº¿ï¼ˆOpen-Loopï¼‰** | 0.31 (31%) | 0.16 (16%) | - |\n| **TIDALï¼ˆæœ¬æ–‡ï¼‰** | **0.61 (61%)** | **0.36 (36%)** | **â‰ˆ 2å€** |\n\n*   **ç»“è®º**ï¼šè¿™éªŒè¯äº†TIDALçš„æ ¸å¿ƒä»·å€¼â€”â€”é€šè¿‡**é«˜é¢‘é—­ç¯æ§åˆ¶**ï¼ˆ~9 Hzï¼‰æœ‰æ•ˆåº”å¯¹åŠ¨æ€ç¯å¢ƒï¼Œå¼¥è¡¥äº†åŸºçº¿æ–¹æ³•å› é•¿å»¶è¿Ÿå’Œå¼€ç¯æ‰§è¡Œå¯¼è‡´çš„â€œæ‰§è¡Œç›²åŒºâ€ã€‚\n\n#### 2. é™æ€ä»»åŠ¡æ€§èƒ½ï¼ˆæƒè¡¡åˆ†æï¼‰\nåœ¨é™æ€ä»»åŠ¡ä¸Šï¼ŒTIDALçš„æ€§èƒ½ç•¥æœ‰å›å½’ï¼Œè¿™ä½“ç°äº†å…¶è®¾è®¡ä¸Šçš„**æƒè¡¡**ã€‚\n\n| æ–¹æ³• | é™æ€ä»»åŠ¡ï¼ˆå®˜æ–¹ï¼‰å¹³å‡æˆåŠŸç‡ |\n| :--- | :--- |\n| **åŸºçº¿ï¼ˆOpen-Loopï¼‰** | **0.5925 (59.25%)** |\n| **TIDALï¼ˆæœ¬æ–‡ï¼‰** | 0.5094 (50.94%) |\n\n*   **åŸå› åˆ†æ**ï¼š\n    1.  **æ¶æ„ä¼˜åŠ¿**ï¼šåŸºçº¿æ¨¡å‹ï¼ˆæ ‡å‡†æ‰¹å¤„ç†-æ‰§è¡ŒèŒƒå¼ï¼‰çš„è®­ç»ƒç›®æ ‡ä¸é™æ€ä»»åŠ¡è¯„ä¼°æ–¹å¼å®Œå…¨åŒ¹é…ã€‚\n    2.  **ä¼˜åŒ–å¤æ‚åº¦**ï¼šTIDALçš„åŒå±‚æ¶æ„å’Œæ—¶åŸŸé”™ä½è®­ç»ƒå¢åŠ äº†ä¼˜åŒ–éš¾åº¦ï¼Œå¯èƒ½éœ€è¦æ›´å¤šè®­ç»ƒæ­¥æ•°æ”¶æ•›ã€‚\n*   **å…³é”®è®ºç‚¹**ï¼šè®ºæ–‡æ˜ç¡®æŒ‡å‡ºï¼Œè¿™æ˜¯ç”¨**å¾®å°çš„é™æ€ç²¾åº¦æŸå¤±**ï¼Œæ¢å–äº†**å…³é”®çš„åŠ¨æ€ååº”èƒ½åŠ›**ï¼Œè€Œè¿™æ˜¯åŸºçº¿æ¨¡å‹å®Œå…¨ä¸å…·å¤‡çš„ã€‚\n\n#### 3. å…¶ä»–å…³é”®æ€§èƒ½æŒ‡æ ‡\n*   **æ§åˆ¶é¢‘ç‡æå‡**ï¼šTIDALå°†æœ‰æ•ˆæ§åˆ¶æ›´æ–°é¢‘ç‡ä»åŸºçº¿çš„ **~2.4 Hz** æå‡è‡³ **~9 Hz**ï¼Œå®ç°äº† **4å€** çš„é¢‘ç‡å¢åŠ ã€‚\n*   **éæš‚åœæ¨ç†é²æ£’æ€§**ï¼šåœ¨æ›´è´´è¿‘çœŸå®ä¸–ç•Œï¼ˆä»¿çœŸä¸æš‚åœç­‰å¾…æ¨ç†ï¼‰çš„è¯„ä¼°åè®®ä¸‹ï¼š\n    *   åŸºçº¿æˆåŠŸç‡ä»0.31**æš´è·Œè‡³0.09**ï¼ˆä¿ç•™ç‡~29%ï¼‰ï¼Œè¿‘ä¹å¤±æ•ˆã€‚\n    *   TIDALæˆåŠŸç‡ä»0.61é™è‡³0.30ï¼ˆä¿ç•™ç‡~49%ï¼‰ï¼Œ**ä»ä¿æŒå¯ç”¨æ€§**ï¼Œä¸”æ€§èƒ½æ˜¯åŸºçº¿çš„ **3å€ä»¥ä¸Š**ã€‚è¿™è¯æ˜äº†TIDALåœ¨**å®é™…éƒ¨ç½²**ä¸­çš„æ½œåœ¨ä¼˜åŠ¿ã€‚\n*   **è¯­ä¹‰æ„å›¾å¯¿å‘½å»¶é•¿**ï¼šå®éªŒè¡¨æ˜ï¼Œé€šè¿‡èåˆå®æ—¶æœ¬ä½“æ„ŸçŸ¥ï¼ŒTIDALèƒ½å°†å•æ¬¡VLMæŸ¥è¯¢ç”Ÿæˆçš„è¯­ä¹‰æ„å›¾çš„æœ‰æ•ˆå¯¿å‘½ï¼Œä»å›ºæœ‰çš„16æ­¥**å»¶é•¿è‡³çº¦44æ­¥**ï¼Œæ˜¾è‘—æå‡äº†è®¡ç®—æ•ˆç‡ã€‚\n\n### æ€»ç»“\nè®ºæ–‡é€šè¿‡**é™æ€**ä¸**åŠ¨æ€**ä¸¤ç±»åŸºå‡†çš„å¯¹æ¯”å®éªŒï¼Œå…¨é¢è¯„ä¼°äº†TIDALã€‚å…¶æ ¸å¿ƒä»·å€¼ä½“ç°åœ¨ï¼š\n*   **åŠ¨æ€åœºæ™¯**ï¼š**2å€æ€§èƒ½æå‡**ï¼Œè§£å†³äº†ç°æœ‰VLAæ¨¡å‹åœ¨åŠ¨æ€ä»»åŠ¡ä¸­å¤±æ•ˆçš„å…³é”®ç“¶é¢ˆã€‚\n*   **ç³»ç»Ÿå“åº”**ï¼š**4å€æ§åˆ¶é¢‘ç‡æå‡**ï¼Œå¹¶åœ¨æ­¤é¢‘ç‡ä¸‹ä¿æŒäº†æ¨¡å‹çš„è¯­ä¹‰æ¨ç†èƒ½åŠ›ã€‚\n*   **å®é™…ä»·å€¼**ï¼šåœ¨éæš‚åœæ¨ç†è¯„ä¼°ä¸­è¡¨ç°å‡º**å¼ºé²æ£’æ€§**ï¼Œä¸ºä»ä»¿çœŸåˆ°çœŸå®ä¸–ç•Œçš„è¿ç§»å¥ å®šäº†åšå®åŸºç¡€ã€‚æ€§èƒ½çš„å°å¹…æƒè¡¡ï¼ˆé™æ€ä»»åŠ¡ï¼‰è¢«è¯æ˜æ˜¯æ¢å–åŠ¨æ€ååº”èƒ½åŠ›çš„åˆç†ä»£ä»·ã€‚",
            "timestamp": "2026-01-27T16:06:29.694120",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "è®ºæ–‡çš„ä¸»è¦å±€é™æ€§æœ‰å“ªäº›ï¼Ÿæœªæ¥å¯èƒ½çš„æ”¹è¿›æ–¹å‘æ˜¯ä»€ä¹ˆï¼Ÿ",
            "answer": "## è®ºæ–‡ä¸»è¦å±€é™æ€§åˆ†æ\n\nåŸºäºå¯¹è®ºæ–‡å†…å®¹çš„åˆ†æï¼ŒTIDALæ¡†æ¶è™½ç„¶å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ä»å­˜åœ¨ä»¥ä¸‹ä¸»è¦å±€é™æ€§ï¼š\n\n- **é™æ€ä»»åŠ¡æ€§èƒ½è½»å¾®ä¸‹é™**ï¼šåœ¨æ ‡å‡†çš„é™æ€ä»»åŠ¡åŸºå‡†æµ‹è¯•ï¼ˆå¦‚RoboCasaï¼‰ä¸­ï¼ŒTIDALçš„æˆåŠŸç‡ï¼ˆ50.94%ï¼‰ä½äºä¼ ç»Ÿçš„å¼€ç¯åŸºçº¿æ–¹æ³•ï¼ˆ59.25%ï¼‰ã€‚è¿™è¡¨æ˜å…¶åˆ†å±‚æ¶æ„å’Œæ—¶åŸŸé”™ä½è®­ç»ƒç­–ç•¥å¢åŠ äº†ä¼˜åŒ–å¤æ‚æ€§ï¼Œå¯èƒ½ç‰ºç‰²äº†éƒ¨åˆ†åœ¨é™æ€ã€ç¡®å®šæ€§ç¯å¢ƒä¸­çš„è§„åˆ’ç²¾åº¦ã€‚\n- **å¯¹è¿åŠ¨é¢„æµ‹å™¨çš„ä¾èµ–**ï¼šåŠ¨æ€æ‹¦æˆªæ€§èƒ½çš„æå‡é«˜åº¦ä¾èµ–äº**å·®åˆ†è¿åŠ¨é¢„æµ‹å™¨**ã€‚æ¶ˆèå®éªŒè¡¨æ˜ï¼Œæ²¡æœ‰è¯¥æ¨¡å—çš„TIDALæ¶æ„æ€§èƒ½æå‡æœ‰é™ï¼ˆä»…ä»0.31æå‡è‡³0.33ï¼‰ã€‚è¿™æ„å‘³ç€ç³»ç»Ÿå¤„ç†åŠ¨æ€ç›®æ ‡çš„èƒ½åŠ›å¹¶éä»…æºäºé«˜é¢‘æ›´æ–°ï¼Œè¿˜éœ€é¢å¤–çš„ã€ä¸“é—¨è®­ç»ƒçš„æ„ŸçŸ¥æ¨¡å—æ¥æä¾›é€Ÿåº¦ä¿¡æ¯ã€‚\n- **è®­ç»ƒå¤æ‚æ€§ä¸æ”¶æ•›æ€§**ï¼šè®ºæ–‡æŒ‡å‡ºï¼ŒTIDALçš„å±‚æ¬¡åŒ–ç»“æ„â€œå¢åŠ äº†ä¼˜åŒ–è´Ÿæ‹…â€ï¼Œå¯èƒ½éœ€è¦æ›´å¤šçš„è®­ç»ƒæ­¥æ•°æ‰èƒ½æ”¶æ•›ã€‚**æ—¶åŸŸé”™ä½è®­ç»ƒ**ç­–ç•¥è™½ç„¶æœ‰æ•ˆï¼Œä½†å¼•å…¥äº†ç¦»æ•£çš„å»¶è¿Ÿé˜¶æ®µé‡‡æ ·ï¼Œå¯èƒ½é™åˆ¶äº†æ¨¡å‹å¯¹è¿ç»­å»¶è¿ŸèŒƒå›´çš„æ³›åŒ–èƒ½åŠ›ã€‚\n- **è¯­ä¹‰æ„å›¾çš„å¯¿å‘½å­˜åœ¨æé™**ï¼šè™½ç„¶TIDALèƒ½å»¶é•¿è¯­ä¹‰åµŒå…¥çš„æœ‰æ•ˆæœŸï¼ˆä»æ ‡å‡†çš„16æ­¥å»¶ä¼¸è‡³çº¦44æ­¥ï¼‰ï¼Œä½†å½“å»¶è¿Ÿå‚æ•° `l` è¶…è¿‡ä¸€å®šé˜ˆå€¼ï¼ˆå¦‚60æ­¥ï¼‰æ—¶ï¼Œæ€§èƒ½ä¼šå‡ºç°æ–­å´–å¼ä¸‹è·Œï¼ˆæˆåŠŸç‡ä»~0.6é™è‡³~0.38ï¼‰ã€‚è¿™è¡¨æ˜åœ¨é•¿æ—¶é—´ä»»åŠ¡ä¸­ï¼Œä»ä¸å¯é¿å…åœ°éœ€è¦é‡æ–°æŸ¥è¯¢æ˜‚è´µçš„VLMéª¨å¹²ç½‘ç»œã€‚\n- **å°šæœªåœ¨çœŸå®ç‰©ç†ç³»ç»Ÿä¸ŠéªŒè¯**ï¼šæ‰€æœ‰å®éªŒå‡åœ¨MuJoCoä»¿çœŸç¯å¢ƒä¸­è¿›è¡Œã€‚å°½ç®¡â€œéæš‚åœæ¨ç†â€åè®®æ¨¡æ‹Ÿäº†çœŸå®ä¸–ç•Œçš„è®¡ç®—å»¶è¿Ÿï¼Œä½†è®ºæ–‡ç»“è®ºéƒ¨åˆ†æ˜ç¡®æåˆ°ï¼Œè¯¥æ–¹æ³•â€œæ­£åœ¨éƒ¨ç½²åˆ°ç‰©ç†æœºå™¨äººç¡¬ä»¶ä¸Šâ€ï¼Œè¯´æ˜å…¶**åœ¨çœŸå®åŠ¨æ€ç¯å¢ƒä¸­çš„é²æ£’æ€§ä»æœ‰å¾…å®è¯æ£€éªŒ**ã€‚\n\n## æœªæ¥å¯èƒ½çš„æ”¹è¿›æ–¹å‘\n\né’ˆå¯¹ä¸Šè¿°å±€é™æ€§ï¼Œè®ºæ–‡å†…å®¹åŠæŠ€æœ¯é€»è¾‘æš—ç¤ºäº†ä»¥ä¸‹å‡ ä¸ªæœ‰æ½œåŠ›çš„æ”¹è¿›æ–¹å‘ï¼š\n\n- **å¢å¼ºé™æ€ä»»åŠ¡æ€§èƒ½**ï¼š\n    - æ¢ç´¢æ›´ç²¾ç»†çš„**æŸå¤±å‡½æ•°è®¾è®¡**ï¼Œåœ¨åŠ¨æ€ååº”æ€§ä¸é™æ€ç²¾åº¦é—´å¯»æ±‚æ›´ä¼˜å¹³è¡¡ã€‚ä¾‹å¦‚ï¼Œè‡ªé€‚åº”è°ƒæ•´åœ°å¹³çº¿åŠ æƒå› å­ `w`ã€‚\n    - ç ”ç©¶**è¯¾ç¨‹å­¦ä¹ **ç­–ç•¥ï¼Œè®©ç­–ç•¥å…ˆåœ¨é™æ€ä»»åŠ¡ä¸Šæ”¶æ•›ï¼Œå†é€æ­¥å¼•å…¥åŠ¨æ€å’Œå»¶è¿Ÿè®­ç»ƒã€‚\n\n- **é™ä½å¯¹ä¸“ç”¨è¿åŠ¨é¢„æµ‹å™¨çš„ä¾èµ–**ï¼š\n    - æ¢ç´¢å°†**é€Ÿåº¦æ„ŸçŸ¥èƒ½åŠ›ç›´æ¥é›†æˆåˆ°VLMéª¨å¹²ç½‘ç»œæˆ–ç­–ç•¥ç½‘ç»œ**ä¸­çš„æ–¹æ³•ï¼Œä¾‹å¦‚é€šè¿‡æ—¶åŸŸæ³¨æ„åŠ›æœºåˆ¶æˆ–å…‰æµç‰¹å¾ä½œä¸ºæ ‡å‡†è¾“å…¥ã€‚\n    - ç ”ç©¶æ›´è½»é‡ã€æ›´é€šç”¨çš„åŠ¨æ€ç‰¹å¾æå–å™¨ã€‚\n\n- **ä¼˜åŒ–è®­ç»ƒç­–ç•¥ä¸æ¶æ„**ï¼š\n    - å°†ç¦»æ•£å»¶è¿Ÿé‡‡æ ·æ‰©å±•ä¸º**è¿ç»­å»¶è¿Ÿå»ºæ¨¡**ï¼Œä½¿ç­–ç•¥èƒ½å¹³æ»‘å¤„ç†ä»»æ„æ—¶é•¿çš„è¯­ä¹‰æ»åã€‚\n    - æ¢ç´¢**åœ¨çº¿è‡ªé€‚åº”æœºåˆ¶**ï¼Œè®©ç­–ç•¥èƒ½æ ¹æ®å½“å‰ä»»åŠ¡éš¾åº¦ï¼ˆé™æ€vsåŠ¨æ€ï¼‰å’Œç¯å¢ƒä¸ç¡®å®šæ€§ï¼ŒåŠ¨æ€è°ƒæ•´å¾®æ§åˆ¶å¾ªç¯çš„æ›´æ–°é¢‘ç‡æˆ–æ„å›¾ç¼“å­˜çš„ç”Ÿå‘½å‘¨æœŸã€‚\n\n- **å»¶é•¿è¯­ä¹‰ç¼“å­˜ä¸ç³»ç»Ÿçº§ååŒ**ï¼š\n    - å°†TIDALä¸**ç³»ç»Ÿçº§ä¼˜åŒ–**ï¼ˆå¦‚æ¨¡å‹é‡åŒ–ã€ä»¤ç‰Œä¿®å‰ªï¼‰æ›´æ·±åº¦ç»“åˆã€‚è®ºæ–‡æŒ‡å‡ºTIDALä¸æ­¤ç±»ä¼˜åŒ–â€œæ­£äº¤â€ï¼Œæœªæ¥å¯æ¢ç´¢ååŒæ•ˆåº”ï¼Œåœ¨åŠ é€Ÿçš„éª¨å¹²ç½‘ç»œä¸Šå®ç°æ›´é«˜é¢‘ç‡çš„æ„å›¾æ›´æ–°ã€‚\n    - ç ”ç©¶**å±‚æ¬¡åŒ–æ„å›¾åˆ·æ–°**ç­–ç•¥ï¼Œä¾‹å¦‚ï¼Œåœ¨æ£€æµ‹åˆ°ç¯å¢ƒå‘ç”Ÿé‡å¤§å˜åŒ–æ—¶æå‰è§¦å‘å®å¾ªç¯ï¼Œè€Œéå›ºå®šå‘¨æœŸã€‚\n\n- **æ¨è¿›ä»¿çœŸåˆ°ç°å®çš„è¿ç§»**ï¼š\n    - åœ¨çœŸå®æœºå™¨äººå¹³å°ä¸ŠéªŒè¯TIDALï¼Œå¹¶é’ˆå¯¹**çœŸå®ä¸–ç•Œçš„æ„ŸçŸ¥å™ªå£°ã€æ‰§è¡Œè¯¯å·®å’Œé€šä¿¡å»¶è¿Ÿ**è¿›è¡Œç®—æ³•å¢å¼ºã€‚\n    - å¼€å‘**sim-to-real**æŠ€æœ¯ï¼Œç¡®ä¿åœ¨ä»¿çœŸä¸­è®­ç»ƒçš„æ—¶åŸŸè¡¥å¿èƒ½åŠ›èƒ½æœ‰æ•ˆè¿ç§»åˆ°ç‰©ç†ä¸–ç•Œã€‚\n\n**æ€»ç»“è€Œè¨€**ï¼ŒTIDALçš„æ ¸å¿ƒä»·å€¼åœ¨äºé€šè¿‡ç®—æ³•å’Œè°ƒåº¦åˆ›æ–°ï¼Œåœ¨**ä¸å¢åŠ éª¨å¹²ç½‘ç»œè®¡ç®—è´Ÿæ‹…**çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡äº†VLAæ¨¡å‹åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„ååº”èƒ½åŠ›ã€‚æœªæ¥çš„å·¥ä½œå°†å›´ç»•**å·©å›ºå…¶é™æ€æ€§èƒ½ã€æå‡æ¶æ„çš„ä¼˜é›…æ€§ä¸è‡ªé€‚åº”æ€§ã€ä»¥åŠå®Œæˆä»ä»¿çœŸåˆ°ç°å®çš„å…³é”®è·¨è¶Š**å±•å¼€ã€‚",
            "timestamp": "2026-01-27T16:07:02.897279",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        }
    ],
    "is_hidden": false,
    "is_starred": false,
    "flag": true,
    "published_date": "2026-01-21T12:43:11Z",
    "created_at": "2026-01-27T15:53:20.599627",
    "updated_at": "2026-01-27T15:53:20.599634",
    "recommend": 0
}