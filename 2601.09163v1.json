{
  "id": "2601.09163v1",
  "title": "CEI: A Unified Interface for Cross-Embodiment Visuomotor Policy Learning in 3D Space",
  "authors": [
    "Tong Wu",
    "Shoujie Li",
    "Junhao Gong",
    "Changqing Guo",
    "Xingting Li",
    "Shilong Mu",
    "Wenbo Ding"
  ],
  "abstract": "Robotic foundation models trained on large-scale manipulation datasets have shown promise in learning generalist policies, but they often overfit to specific viewpoints, robot arms, and especially parallel-jaw grippers due to dataset biases. To address this limitation, we propose Cross-Embodiment Interface (\\CEI), a framework for cross-embodiment learning that enables the transfer of demonstrations across different robot arm and end-effector morphologies. \\CEI introduces the concept of \\textit{functional similarity}, which is quantified using Directional Chamfer Distance. Then it aligns robot trajectories through gradient-based optimization, followed by synthesizing observations and actions for unseen robot arms and end-effectors. In experiments, \\CEI transfers data and policies from a Franka Panda robot to \\textbf{16} different embodiments across \\textbf{3} tasks in simulation, and supports bidirectional transfer between a UR5+AG95 gripper robot and a UR5+Xhand robot across \\textbf{6} real-world tasks, achieving an average transfer ratio of 82.4\\%. Finally, we demonstrate that \\CEI can also be extended with spatial generalization and multimodal motion generation capabilities using our proposed techniques. Project website: https://cross-embodiment-interface.github.io/",
  "url": "https://arxiv.org/abs/2601.09163v1",
  "html_url": "https://arxiv.org/html/2601.09163v1",
  "html_content": "CEI\n: A Unified Interface for Cross-Embodiment Visuomotor Policy Learning in 3D Space\nTong Wu\n1\n, Shoujie Li\n12\n, Junhao Gong\n1\n, Changqing Guo\n1\n, Xingting Li\n1\n,\nShilong Mu\n3\n, and Wenbo Ding\n1\nManuscript received: September 26, 2025; Revised: December 6, 2025; Accepted: January 11, 2026.This paper was recommended for publication by Editor Aleksandra Faust upon evaluation of the Associate Editor and Reviewers‚Äô comments.\nThis work was supported by National Key R&D Program of China grant (2024YFB3816000), Guangdong Innovative and Entrepreneurial Research Team Program (2021ZT09L197), Shenzhen Science and Technology Program (JCYJ20220530143013030), Tsinghua Shenzhen International Graduate School-Shenzhen Pengrui Young Faculty Program of Shenzhen Pengrui Foundation (No. SZPR2023005) and Meituan.\nTong Wu and Shoujie Li contributed equally to this\nwork.\n(Corresponding author: Wenbo Ding, ding.wenbo@sz.tsinghua.edu.cn)\n1\nTong Wu, Shoujie Li, Junhao Gong, Changqing Guo, Xingting Li, Wenbo Ding are with Shenzhen International Graduate School, Tsinghua University, Shenzhen 518055, China. (email: {wu-t23, lsj20, gongjh24, gcq24, lixt25}@mails.tsinghua.edu.cn, ding.wenbo@sz.tsinghua.edu.cn))\n2\nShoujie Li is also with the School of Mechanical and Aerospace Engineering, Nanyang Technological University, Singapore 639956, Singapore. (email: shoujie.li@ntu.edu.sg)\n3\nShilong Mu is with Xspark Ai, Shenzhen 518052, China. (email: mu.shilong@xspark-ai.com)Digital Object Identifier (DOI): see top of this page.\nAbstract\nRobotic foundation models trained on large-scale manipulation datasets have shown promise in learning generalist policies, but they often overfit to specific viewpoints, robot arms, and especially parallel-jaw grippers due to dataset biases. To address this limitation, we propose Cross-Embodiment Interface (\nCEI\n), a framework for cross-embodiment learning that enables the transfer of demonstrations across different robot arm and end-effector morphologies.\nCEI\nintroduces the concept of\nfunctional similarity\n, which is quantified using Directional Chamfer Distance. Then it aligns robot trajectories through gradient-based optimization, followed by synthesizing observations and actions for unseen robot arms and end-effectors. In experiments,\nCEI\ntransfers data and policies from a Franka Panda robot to\n16\ndifferent embodiments across\n3\ntasks in simulation, and supports bidirectional transfer between a UR5+AG95 gripper robot and a UR5+Xhand robot across\n6\nreal-world tasks, achieving an average transfer ratio of 82.4%. Finally, we demonstrate that\nCEI\ncan also be extended with spatial generalization and multimodal motion generation capabilities using our proposed techniques. Project website:\nhttps://cross-embodiment-interface.github.io/\n.\nI\nIntroduction\nEmerging robotic foundation models are built upon scaling laws\n[\n11\n]\nand fueled by the growing availability of large-scale real-world manipulation datasets\n[\n7\n,\n26\n]\n. However, these datasets often suffer from significant distributional imbalances, leading models to overfit to specific camera viewpoints and robot embodiments\n[\n4\n]\n. For instance, OXE\n[\n13\n]\naggregates data from 60 datasets spanning multiple robotic platforms, yet remains heavily skewed toward Franka and xArm robots, with nearly all end-effectors limited to parallel grippers. Such biases limit the models‚Äô ability to generalize\n[\n9\n]\n, especially when faced with embodiment variations.\nTo mitigate the embodiment biases, approaches such as Mirage\n[\n3\n]\nand RoVi-Aug\n[\n4\n]\nemploy techniques like cross-painting and generative models to synthesize visual observations, creating the illusion that the source robot is performing the task under test-time conditions. While these methods enable zero-shot deployment by bridging domain and embodiment gaps, their applicability is largely restricted to scenarios involving parallel-jaw grippers and Operational Space Control (OSC). These preconditions present significant challenges for transfer to more complex embodiments, such as multi-fingered dexterous hands. In fact, the limitation is further compounded by the scarcity of dexterous hand data\n[\n18\n]\n, which continues to hinder the development of generalizable policies across diverse robot embodiments.\nFigure 1:\nCross-embodiment interface.\nCEI\nenables cross-embodiment transfer between different robots by synthesizing demonstrations from a source embodiment to a target embodiment. We transfer data and policies from a Franka Panda robot to 16 target embodiments across 3 tasks in simulation, and demonstrate bidirectional transfer between a UR5+AG95 gripper and a UR5+Xhand setup across 6 real-world tasks. We also showcase\nCEI\n‚Äôs compatibility with spatial generalization and multimodal motion generation.\nIntriguingly, the underlying similarity in manipulation strategies between parallel-jaw grippers and dexterous hands suggests the feasibility of such cross-embodiment learning. For instance, when humans grasp a bottle, they often adopt a gripper-like pose that naturally promotes force closure. This motivates the question of whether such shared manipulation affordances can be systematically exploited to enable effective transfer across distinct end-effector morphologies.\nTo enable policy learning across heterogeneous robot embodiments, we propose Cross-Embodiment Interface (\nCEI\n), a unified framework for cross-embodiment data synthesis.\nCEI\nleverages a novel notion of\nfunctional similarity\n, which captures shared interaction behaviors across different end-effectors, to align robot motions from a source embodiment to a target embodiment. This is accomplished by quantifying this similarity using the Directional Chamfer Distance\n[\n16\n]\nbetween embodiments‚Äô functional representations, aligning trajectories via gradient-based optimization, and synthesizing corresponding observations and actions for the target robot. Through extensive experiments in both simulation and real world, we show that\nCEI\neffectively transfers demonstrations and policies from a source robot equipped with a parallel-jaw gripper to a target robot with a five-fingered dexterous hand and vice versa, with an overall transfer ratio of 82.4%. Furthermore, we demonstrate that\nCEI\nis compatible with spatial generalization and support multimodal data generation using our extended techniques.\nOur contributions are summarized as follows:\n‚Ä¢\nWe propose a novel concept of\nfunctional similarity\nbased on Directional Chamfer Distance, coupled with gradient-based trajectory alignment, to transfer task-relevant manipulation behaviors across embodiments.\n‚Ä¢\nWe propose a general pipeline that leverages embodiment information to augment both observations and actions, enabling the synthesis of point cloud‚Äìbased demonstrations across heterogeneous robots.\n‚Ä¢\nExperiments on 16 embodiments over 3 simulation tasks and bidirectional transfers over 6 real-world tasks demonstrate\nCEI\n‚Äôs effectiveness on cross-embodiment learning. Furthermore, we showcase that\nCEI\ncan be extended with spatial generalization and multimodal motion generation for diverse data synthesis.\nII\nRelated Work\nII-A\nData Generation for Robotic Manipulation\nWhile recent imitation learning methods have exhibited impressive performance\n[\n6\n,\n24\n]\n, the high cost of collecting expert demonstrations poses significant challenges to scalability and real-world deployment. To mitigate this, online data generation approaches adapt existing demonstrations to novel object configurations and produce plausible interaction trajectories via rollouts in high-fidelity physics simulators\n[\n12\n]\n. Although these methods preserve physical realism, they tend to be computationally intensive, and challenging to apply directly in real-world settings.\nIn contrast, offline data generation synthesizes new demonstrations from existing datasets through trajectory transformations\n[\n20\n]\nor generative model-based visual augmentations\n[\n5\n]\n.\nCEI\nfocuses on cross-embodiment transfer through offline data generation, but addresses the challenge of extreme differences between end-effectors, enabling the learning of dexterous hand policies from parallel gripper data.\nII-B\nCross-embodiment Learning\nPrior work has explored bridging the embodiment gap through various strategies, including space alignment\n[\n25\n,\n22\n,\n2\n]\n, cross-painting\n[\n3\n,\n4\n]\n, dynamics modeling\n[\n10\n]\n, and reward model learning\n[\n23\n]\n. Other approaches incorporate embodiment information directly into the policy and train across a set of embodiments with varying kinematics and dynamics, demonstrating generalization to unseen morphologies within the training distribution\n[\n8\n,\n15\n,\n19\n]\n.\nRecently, many efforts have focused on collecting cross-embodiment datasets\n[\n7\n,\n13\n,\n17\n]\n, which have been shown to generalize effectively across embodiments\n[\n21\n,\n14\n]\n. In contrast to these efforts, our work addresses extreme cross-embodiment data generation, specifically demonstration transfer between a parallel gripper and a dexterous hand, without requiring embodiment-specific training data.\nIII\nProblem Formulation\nA visuomotor policy\nœÄ\n:\nùí™\n‚Üí\nùíú\n\\pi:\\mathcal{O}\\rightarrow\\mathcal{A}\nmaps visual observations\no\n‚àà\nùí™\no\\in\\mathcal{O}\nto actions\na\n‚àà\nùíú\na\\in\\mathcal{A}\n. In imitation learning, such policies are typically trained from a dataset of demonstrations\nùíü\n\\mathcal{D}\ncollected on a particular embodiment\nE\nE\n.\nWe represent each demonstration\nD\nE\n,\ns\n0\n‚äÜ\nùíü\nD_{E,s_{0}}\\subseteq\\mathcal{D}\nas a trajectory of observation-action pairs, conditioned on an initial task state\ns\n0\ns_{0}\nand robot embodiment\nE\nE\n:\nD\nE\n,\ns\n0\n=\n(\n(\no\n0\n,\na\n0\n)\n,\n(\no\n1\n,\na\n1\n)\n,\n‚Ä¶\n,\n(\no\nL\n‚àí\n1\n,\na\nL\n‚àí\n1\n)\n‚à£\ns\n0\n,\nE\n)\n.\nD_{E,s_{0}}=\\left((o_{0},a_{0}),(o_{1},a_{1}),\\dots,(o_{L-1},a_{L-1})\\mid s_{0},E\\right).\nEach observation\no\nt\n=\n(\no\nt\npcd\n,\no\nt\narm\n,\no\nt\nee\n)\no_{t}=(o_{t}^{\\text{pcd}},o_{t}^{\\text{arm}},o_{t}^{\\text{ee}})\nconsists of a point cloud and the proprioceptive states of the robot arm and end-effector, while each action\na\nt\n=\n(\na\nt\narm\n,\na\nt\nee\n)\na_{t}=(a_{t}^{\\text{arm}},a_{t}^{\\text{ee}})\nspecifies joint position targets for robot arm and end-effector.\nOur objective is to generate a corresponding demonstration\nD\n^\nE\n‚Ä≤\n,\ns\n0\n\\hat{D}_{E^{\\prime},s_{0}}\nfor a new target embodiment\nE\n‚Ä≤\nE^{\\prime}\npotentially differing in morphology and kinematics, starting from the same initial task state\ns\n0\ns_{0}\n:\nD\n^\nE\n‚Ä≤\n,\ns\n0\n=\n(\n(\no\n^\n0\n,\na\n^\n0\n)\n,\n(\no\n^\n1\n,\na\n^\n1\n)\n,\n‚Ä¶\n,\n(\no\n^\nL\n‚àí\n1\n,\na\n^\nL\n‚àí\n1\n)\n‚à£\ns\n0\n,\nE\n‚Ä≤\n)\n.\n\\hat{D}_{E^{\\prime},s_{0}}=\\left((\\hat{o}_{0},\\hat{a}_{0}),(\\hat{o}_{1},\\hat{a}_{1}),\\dots,(\\hat{o}_{L-1},\\hat{a}_{L-1})\\mid s_{0},E^{\\prime}\\right).\nUnlike prior work that focuses solely on the initial state or short trajectory segments, we aim to produce full demonstration trajectories that are executable on the target embodiment.\nEach embodiment\nE\nE\nincludes structural specifications such as joint limits, robot meshes and kinematic chains. We assume access to standardized robot description files (e.g., URDF and XML), which provide this information and allow embodiment-specific adaptation of actions and observations.\nIV\nMethod\nTo generate demonstrations for a new embodiment,\nCEI\nfirst defines the functional representations of both the source and target embodiments and employs the Directional Chamfer Distance to quantify the\nfunctional similarity\nbetween the two embodiments (Section\nIV-A\n). Leveraging the source demonstrations, functional representations and the metric,\nCEI\naligns the robot trajectories from the source embodiment to the target embodiment (Section\nIV-B\n). Finally,\nCEI\nsynthesizes corresponding observations and actions based on the aligned trajectories, obtaining the demonstrations for the target embodiment (Section\nIV-C\n). An overview of the full pipeline is illustrated in Fig.\n2\n.\nFigure 2:\nOverview of the pipeline. Given a source dataset, a source embodiment, and a target embodiment, we first define functional representations as sets of points with associated directions on both embodiments. We then compute functional similarity using the negative Directional Chamfer Distance between these representations. Trajectory alignment is performed by sequentially optimizing the functional similarity for each trajectory slice. Finally, we synthesize target actions with next joint positions and generate target observations by augmenting source point clouds with points sampled from the target embodiment. The viridis colormap is used to illustrate the temporal progression of the trajectory of functional representations.\nIV-A\nFunctional Similarity between Embodiments\nWhile two embodiments may differ significantly in morphology and kinematics, they can nonetheless exhibit similar object interaction behaviors. For example, in a pick-up task, a dexterous hand may grasp an object from opposing sides using the thumb and other four fingers‚Äîa strategy that is functionally analogous to the symmetric grasp of a parallel gripper. In this section, we propose a method to formally quantify this\nfunctional similarity\nbetween embodiments.\nIV-A\n1\nFunctional Representation\nWe represent an embodiment‚Äôs interaction feature through a set of point-direction pairs\nX\n=\n{\n(\np\ni\n,\nn\ni\n)\n}\ni\n=\n0\n,\n1\n,\n‚Ä¶\n,\nN\nX=\\{(p_{i},n_{i})\\}_{i=0,1,...,N}\n, referred to as the functional representation. As shown in Fig.\n2\n, the points\n{\np\ni\n}\n\\{p_{i}\\}\nlie on the embodiment‚Äôs surface and reflect potential contact areas with objects. The associated directions\n{\nn\ni\n}\n\\{n_{i}\\}\nare automatically computed as the surface normal in the vicinity of\n{\np\ni\n}\n\\{p_{i}\\}\n. All point-direction pairs are transformed to the world frame via forward kinematics, ensuring alignment happens in a common frame across embodiments. While this concept is inspired by\naffordance\n[\n1\n]\nwhich captures potential interaction sites on the object, we instead focus on the embodiment, emphasizing how the end-effector interacts with the environment.\nIV-A\n2\nDirectional Chamfer Distance\nTo quantify the similarity between two functional representations, we adopt the\nDirectional Chamfer Distance\n(DCD), which jointly considers spatial proximity and directional alignment between point sets. Specifically, given functional representations\nX\n=\n{\n(\np\ni\n,\nn\ni\n)\n}\ni\n=\n1\nN\nX=\\{(p_{i},n_{i})\\}_{i=1}^{N}\nand\nX\n‚Ä≤\n=\n{\n(\np\nj\n‚Ä≤\n,\nn\nj\n‚Ä≤\n)\n}\nj\n=\n1\nN\n‚Ä≤\nX^{\\prime}=\\{(p^{\\prime}_{j},n^{\\prime}_{j})\\}_{j=1}^{N^{\\prime}}\nfor the source and target embodiments respectively, DCD is defined as:\nDCD\n‚Äã\n(\nX\n,\nX\n‚Ä≤\n)\n\\displaystyle\\mathrm{DCD}(X,X^{\\prime})\n=\n1\nN\n‚Äã\n‚àë\ni\n=\n1\nN\nmin\nj\n‚Å°\n(\n‚Äñ\np\ni\n‚àí\np\nj\n‚Ä≤\n‚Äñ\n2\n‚àí\nŒª\n‚ãÖ\n‚ü®\nn\ni\n,\nn\nj\n‚Ä≤\n‚ü©\n)\n\\displaystyle=\\frac{1}{N}\\sum_{i=1}^{N}\\min_{j}\\left(\\|p_{i}\\!-\\!p^{\\prime}_{j}\\|_{2}\\!-\\!\\lambda\\!\\cdot\\!\\langle n_{i},n^{\\prime}_{j}\\rangle\\right)\n(1)\n+\n1\nN\n‚Ä≤\n‚Äã\n‚àë\nj\n=\n1\nN\n‚Ä≤\nmin\ni\n‚Å°\n(\n‚Äñ\np\nj\n‚Ä≤\n‚àí\np\ni\n‚Äñ\n2\n‚àí\nŒª\n‚ãÖ\n‚ü®\nn\nj\n‚Ä≤\n,\nn\ni\n‚ü©\n)\n,\n\\displaystyle+\\frac{1}{N^{\\prime}}\\sum_{j=1}^{N^{\\prime}}\\min_{i}\\left(\\|p^{\\prime}_{j}\\!-\\!p_{i}\\|_{2}\\!-\\!\\lambda\\!\\cdot\\!\\langle n^{\\prime}_{j},n_{i}\\rangle\\right),\nwhere\nŒª\n\\lambda\nis a weighting factor balancing spatial and directional terms. This formulation ensures that each point-direction pair in one set is matched to its most similar counterpart in the other and calculates the distance of two sets. We define the negative DCD as the measure of\nfunctional similarity\n, which increases as the functional representations of two embodiments become more consistent.\nIV-B\nTrajectory Alignment\nTo bridge the embodiment gap, we leverage the defined\nfunctional similarity\nto align the joint (proprioceptive) trajectories between two robots. Given a source embodiment and an associated demonstration, we first compute the trajectory of its functional representation\n{\nX\nt\n}\nt\n=\n0\nL\n‚àí\n1\n\\{X_{t}\\}_{t=0}^{L-1}\nusing a differentiable forward kinematics module\nFK\n, where\nX\nt\n=\nFK\nE\n‚Äã\n(\no\nt\narm\n,\no\nt\nee\n)\nX_{t}=\\text{FK}_{E}(o_{t}^{\\text{arm}},o_{t}^{\\text{ee}})\n.\nFor each frame\nt\nt\n, we initialize the target embodiment‚Äôs joint configuration\nq\nt\n‚Ä≤\nq^{\\prime}_{t}\nas a set of learnable variables and calculate the corresponding functional representation\nX\nt\n‚Ä≤\n=\nFK\nE\n‚Ä≤\n‚Äã\n(\nq\nt\n‚Ä≤\n)\nX^{\\prime}_{t}=\\text{FK}_{E^{\\prime}}(q^{\\prime}_{t})\n.\nWe then optimize functional similarity between\nX\nt\nX_{t}\nand\nX\nt\n‚Ä≤\nX^{\\prime}_{t}\nusing gradient descent:\nmin\nq\nt\n‚Ä≤\n‚Å°\n‚Ñí\nalign\n‚Äã\n(\nq\nt\n‚Ä≤\n)\n=\nw\n1\n‚Äã\nDCD\n‚Äã\n(\nX\nt\n,\nX\nt\n‚Ä≤\n)\n+\nw\n2\n‚Äã\n‚Ñí\n‚Äã\n(\nq\nt\n‚Ä≤\n)\n,\n\\min_{q^{\\prime}_{t}}\\mathcal{L}_{\\text{align}}(q^{\\prime}_{t})=w_{1}\\mathrm{DCD}(X_{t},X^{\\prime}_{t})+w_{2}\\mathcal{L}(q^{\\prime}_{t}),\n(2)\nwhere\n‚Ñí\n‚Äã\n(\nq\nt\n‚Ä≤\n)\n\\mathcal{L}(q^{\\prime}_{t})\npenalizes the out-of-range joint configuration, and\nw\n1\nw_{1}\n,\nw\n2\nw_{2}\nare weighting factors.\nRather than optimizing each frame independently, we treat the process as a sequential optimization problem. Specifically, the joint configuration at frame\nt\n+\n1\nt+1\nis initialized using the optimized result from frame\nt\nt\n:\nq\nt\n+\n1\n‚Ä≤\n‚Å£\n(\n0\n)\n‚Üê\nq\n^\nt\n,\nq^{\\prime(0)}_{t+1}\\leftarrow\\hat{q}_{t},\nwhere\nq\nt\n+\n1\n‚Ä≤\n‚Å£\n(\n0\n)\nq^{\\prime(0)}_{t+1}\nrepresents the initial joint configuration at\nt\n+\n1\nt+1\nand\nq\n^\nt\n\\hat{q}_{t}\ndenotes the optimized joint configuration at\nt\nt\n. This strategy not only accelerates convergence due to the small variation between adjacent frames, but also ensures temporal consistency in the generated trajectory.\nIV-C\nObservation and Action Generation\nIV-C\n1\nAction generation\nWe define the action at each timestep as the target embodiment‚Äôs joint configuration at the next frame:\na\nt\n=\nq\n^\nt\n+\n1\n.\na_{t}=\\hat{q}_{t+1}.\nSince the embodiment may not achieve the target position in time, we adopt a closed-loop control strategy during execution, where the embodiment continuously applies\na\nt\na_{t}\nuntil its current joint configuration reaches the target position.\nIV-C\n2\nObservation generation\nThe proprioceptive observation of the target embodiment is directly derived from the aligned trajectory:\n(\no\n^\nt\narm\n,\no\n^\nt\nee\n)\n=\nq\n^\nt\n.\n(\\hat{o}_{t}^{\\text{arm}},\\hat{o}_{t}^{\\text{ee}})=\\hat{q}_{t}.\nTo synthesize the point cloud, we first remove points that lie outside the defined workspace, and mask any point that falls within a distance threshold\nœÑ\n\\tau\n(e.g., 5 mm) of the source robot. This proximity is calculated using the minimum Euclidean distance to a uniformly sampled point cloud derived from the robot‚Äôs mesh. Next, we synthesize the point cloud for the target embodiment by first accessing target robot description file and then sampling points across the robot‚Äôs mesh. Both the cropping and augmentation steps are conditioned on the current proprioceptive state\nq\n^\nt\n\\hat{q}_{t}\n. Finally we apply Farthest Point Sampling (FPS) to downsample the point cloud to a fixed number (1024).\nDuring inference, the same process is applied to ensure consistency between the synthesized observations and those encountered at test time.\nV\nExperimental Setup\nFigure 3:\nTasks and embodiments for simulation evaluation. We investigate 3 tasks and 16 embodiments, which are combinations of 4 robot arms (UR5e, IIWA, Kinova3 and Franka Panda) and 4 end-effectors (FourierRighthand, InspireRightHand, FourierLefthand and RobotiqThreeFinger gripper).\nV-A\nImplementation Details\nTo construct the robot description, we utilize the\nXML\nfiles of the robot arms and end-effectors. The points of functional representation are sampled from the finger pad meshes, and their associated directional vectors are generated using\nTorchSDF\n. For efficient trajectory alignment, we employ\npytorch_kinematics\nas a batch forward kinematics engine, enabling highly parallelized computations.\nOptimization is performed with a maximum of 300 steps at each timestep. Early stopping is triggered if the alignment loss\n‚Ñí\nalign\n\\mathcal{L}_{\\text{align}}\ndoes not improve for 10 consecutive steps. We empirically determine that setting the weighting factor\nŒª\n=\n0.5\n\\lambda=0.5\n, and weights\nw\n1\n=\n1\nw_{1}=1\n,\nw\n2\n=\n1\nw_{2}=1\nyields robust performance across all tasks.\nV-B\nPolicy Training\nWe utilize 3D Diffusion Policy\n[\n24\n]\nto evaluate the synthesized data. The input consists of the current joint positions of both the robot arm and end-effector, along with a preprocessed point cloud of size [1024, 3]. The policy outputs target joint positions. We set the observation horizon to\nT\no\n=\n2\nT_{o}=2\n, action prediction horizon to\nT\np\n=\n16\nT_{p}=16\n, and action execution horizon to\nT\na\n=\n8\nT_{a}=8\n, following the settings in\n[\n24\n]\n. The model is trained for 3000 epochs using the AdamW optimizer with a learning rate of\n1\n√ó\n10\n‚àí\n4\n1\\times 10^{-4}\nand a 500-step warmup for training stabilization. All experiments are conducted on a single RTX 4090 GPU.\nV-C\nEvaluation Setup\nV-C\n1\nSimulation\nWe evaluate cross-embodiment transfer and visuomotor policy learning in simulation using\n3\nmanipulation tasks and\n16\nrobot embodiments (combinations of\n4\narms and\n4\nend-effectors) from robosuite\n[\n27\n]\n(as shown in Fig.\n3\n). Demonstrations collected on a Franka Panda via teleoperation are transferred to target embodiments using\nCEI\n. We evaluate transferred trajectories via simulation replay and train DP3 policies on the synthesized data, measuring performance over 20 trials with three seeds.\nFigure 4:\nLeft: Setup and associated objects in real-world experiments. Right: Real-world tasks. We evaluate transfer from the AG95 gripper to the Xhand on PushCube, OpenDrawer, and PlaceBird, and from the Xhand to the AG95 gripper on PickCup, PackageBread, and InsertFlower.\nTABLE I:\nFull Evaluation across Tasks and Embodiment Combinations in Simulation.\nTasks\nOpenDrawer\nPickCube\nStackCube\nGrippers / Robot Arms\nUR5e\nIIWA\nKinova3\nPanda\nUR5e\nIIWA\nKinova3\nPanda\nUR5e\nIIWA\nKinova3\nPanda\nFourierRightHand\n100\n100\n100\n100\n100\n100\n100\n100\n81\n81\n72\n72\n69\n69\n79\n79\n53\n53\n38\n38\n37\n37\n34\n34\nInspireRightHand\n91\n91\n87\n87\n87\n87\n84\n84\n50\n50\n45\n45\n33\n33\n43\n43\n24\n24\n16\n16\n12\n12\n15\n15\nFourierLeftHand\n100\n100\n96\n96\n98\n98\n100\n100\n88\n88\n83\n83\n81\n81\n79\n79\n57\n57\n47\n47\n50\n50\n47\n47\nRobotiqThreeFinger\n78\n78\n91\n91\n93\n93\n93\n93\n19\n19\n31\n31\n41\n41\n52\n52\n0\n0\n5\n5\n9\n9\nV-C\n2\nReal world\nIn real world deployment, demonstrations are collected via keyboard teleoperation on a UR5 arm, with RGB-D data captured by a RealSense L515 to generate scene point clouds, as shown in Fig.\n4\n(left). DP3 policies are trained on\nCEI\n-generated data and evaluated over 10 trials per task. We evaluate transfer between the AG95 gripper and Xhand on\n6\nreal-world tasks (Fig.\n4\nright):\n‚Ä¢\nPushCube.\nA cube is placed on the table. The robot must approach and align its end-effector to securely enclose the cube, then push it 20 cm to the right.\n‚Ä¢\nOpenDrawer.\nA drawer is positioned on the left side of the table. The robot moves toward the handle, inserts its fingertip, and pulls it to the right by about 10 cm.\n‚Ä¢\nPlaceBird.\nA toy bird is positioned on the left side of the table, while a box is fixed on the right. The robot approaches, grasps the bird stably, moves it over the box, lowers it, and places the bird inside.\n‚Ä¢\nPickCup.\nA cup is placed near the center of the table. The robot approaches, grasps the cup, and lifts it about 5 cm from the surface.\n‚Ä¢\nPackageBread.\nA toaster with baked bread is placed on the right side of the table, with a bag fixed on the left. The robot approaches the toaster, picks up the bread, moves it above the bag, and deposits the bread inside.\n‚Ä¢\nInsertFlower.\nA bouquet of flowers is placed on the right side of the table, and a vase is fixed on the left. The robot approaches, grasps the bouquet, rotates and moves it above the vase, then inserts and releases it.\nFor the first three tasks, we collect 25 AG95 demonstrations and transfer to Xhand; for the latter three, we collect data with Xhand and transfer to AG95.\nVI\nResults\nVI-A\nSimulation Results\nVI-A\n1\nGripper-to-hands transfer\nTo evaluate whether CEI effectively bridges the extreme embodiment gap from parallel-jaw grippers to dexterous multi-fingered hands, we validate the synthesized data by replaying the robot trajectory online, initialized with the same state when collecting the data.\nTable\nI\npresents the comprehensive evaluation of 16 different embodiments. The results indicate that despite variations in kinematics and morphology,\nCEI\nis capable of bridging the cross-embodiment gap by leveraging\nfunctional similarity\n.\nWe further observe that transfer difficulty correlates with contact richness. While OpenDrawer involves simple interactions, PickCube requires stable grasp acquisition, and StackCube entails sequential contact maintenance. These contact-rich scenarios amplify the susceptibility of our geometry-based synthesis to physical disturbances (e.g., slippage), explaining the observed performance degradation.\nAnalyzing performance across end-effectors, we find that the FourierRightHand and FourierLeftHand consistently achieve the highest success rates across all three tasks. In contrast, the InspireRightHand experiences an average performance drop of approximately 40%.\nAlthough the RobotiqThreeFinger exhibits minimal loss in OpenDrawer, it struggles with StackCube as kinematic constraints force a transition from stable ‚Äòfinger-pad‚Äô grasping to a low-contact ‚Äòfingertip‚Äô strategy, thereby reducing manipulation reliability.\nVI-A\n2\nAblation study on cross-embodiment techniques\nTable\nII\npresents an ablation study to investigate the key components that enable\nCEI\nto achieve cross-embodiment transfer. We compare\nCEI\nagainst two baselines: (1) Binary Manual Specification (BMS) generates end-effector motions by linearly interpolating between manually specified open and close poses, while constraining the end-effector to match the gripper aperture of the source embodiment, and (2)\nCEI\nwithout Direction removes directional information and uses only positional features for functional representation. We use a subset of embodiments: Emb. 1 = UR5e + FourierRightHand, Emb. 2 = IIWA + InspireRightHand, Emb. 3 = Kinova3 + FourierLeftHand, and Emb. 4 = Panda + RobotiqThreeFinger.\nThe results show that\nCEI\nwithout Direction achieves an average success rate of only 32%, only half of\nCEI\n. Although it is still capable of completing the OpenDrawer task, it struggles with object grasping tasks, highlighting the critical role of directional information for grasp motions.\nWe also observed that BMS failed in PickCube and StackCube because linear interpolation between manually defined poses often yields failed grasps. Additionally, kinematic discrepancies (e.g., end-effector frame offsets) caused frequent failures in OpenDrawer, rendering BMS inferior to\nCEI\neven when the degree of opening were explicitly constrained to be the same.\nTABLE II:\nAblation Study on Cross-embodiment Techniques.\nTask\nMethod\nEmb. 1\nEmb. 2\nEmb. 3\nEmb. 4\nAvg.\nOpenDrawer\nBMS\n80\n80\n92\n92\n87\n87\n64\n64\n81\n81\nCEI\nw/o Dir.\n84\n84\nùüèùüéùüé\n\\boldsymbol{100}\n91\n91\nùüèùüéùüé\n\\boldsymbol{100}\n94\n94\nCEI\n(Ours)\nùüèùüéùüé\n\\boldsymbol{100}\n87\n87\nùüóùüñ\n\\boldsymbol{98}\n93\n93\nùüóùüì\n\\boldsymbol{95}\nPickCube\nBMS\n0\n0\n0\n0\n0\nCEI\nw/o Dir.\n7\n7\n2\n2\n0\n0\n2\n2\nCEI\n(Ours)\nùüñùüè\n\\boldsymbol{81}\nùüíùüì\n\\boldsymbol{45}\nùüñùüè\n\\boldsymbol{81}\nùüìùüê\n\\boldsymbol{52}\nùüîùüì\n\\boldsymbol{65}\nStackCube\nBMS\n0\n0\n0\n0\n0\nCEI\nw/o Dir.\n0\n0\n0\n0\n0\nCEI\n(Ours)\nùüìùüë\n\\boldsymbol{53}\nùüèùüî\n\\boldsymbol{16}\nùüìùüé\n\\boldsymbol{50}\nùüó\n\\boldsymbol{9}\nùüëùüê\n\\boldsymbol{32}\nVI-A\n3\nSensitivity of functional representation\nTo evaluate the impact of different functional representation selections on transfer performance, we compare three variants: (1) Standard, which spans the entire finger pad to provide full coverage and is used across main experiments; (2) Reduced, which is limited to a subset of points near the center of the finger pad; and (3) Randomly Dropped (Rand. Drop.), where a subset of points is randomly removed from the full representation. We transfer 20 demonstrations with above three selections in the PickCube task using FourierRightHand and evaluate the success rate. As shown in Table\nIII\n, although the three selections differ, their success rates remain comparable, suggesting that\nCEI\nis robust to such variations and exhibits low sensitivity to the choice of functional representation.\nTABLE III:\nSensitivity Analysis of Functional Representations.\nFunctional\nRepresentation\nStandard\nReduced\nRand. Drop.\nSuccess Rate\n17\n17\n/\n20\n20\n18\n18\n/\n20\n20\n16\n16\n/\n20\n20\nFigure 5:\nQualitative evaluation. Left: Transfer from AG95 to Xhand in PushCube, OpenDrawer, and PlaceBird. Right: Transfer from Xhand to AG95 in PickCup, PackageBread, and InsertFlower. Manipulations of source policies are shown on the top rows, transferred ones on the bottom rows.\nVI-A\n4\nPolicy evaluation\nTable\nIV\npresents the policy evaluation results using synthesized cross-embodiment data. We observe that\nCEI\nachieves an average success rate of 62%, suggesting that the synthesized data effectively captures critical behaviors such as reaching the target position, grasping, and releasing, even without additional refinement or selection. We further compare\nCEI\nagainst two baselines: (1) No Augmentation, where the policy is trained solely on observations from source demonstrations, and (2)\nCEI\nwithout Inference Augmentation, where the policy uses raw observations during inference without additional augmentation. Policies trained without any augmentation fail to complete the tasks, demonstrating the necessity of targeted data augmentation for cross-embodiment generalization. Additionally, removing Inference Augmentation results in a 22% drop in success rate.\nThis performance degradation arises due to the partial and noisy observations during inference.\nTABLE IV:\nPolicy Evaluation on Synthesized Data Generated by\nCEI\n.\nTask\nMethod\nEmb. 1\nEmb. 2\nEmb. 3\nEmb. 4\nAvg.\nOpenDrawer\nNo Aug.\n0\n0\n0\n0\n0\nCEI\nw/o Inf. Aug.\nùüèùüéùüé\n\\boldsymbol{100}\n79\n79\n32\n32\n64\n64\n69\n69\nCEI\n(Ours)\nùüèùüéùüé\n\\boldsymbol{100}\nùüóùüé\n\\boldsymbol{90}\nùüèùüéùüé\n\\boldsymbol{100}\nùüóùüé\n\\boldsymbol{90}\nùüóùüì\n\\boldsymbol{95}\nPickCube\nNo Aug.\n0\n0\n0\n0\n0\nCEI\nw/o Inf. Aug.\n42\n42\n26\n26\n38\n38\n10\n10\n29\n29\nCEI\n(Ours)\nùüïùüó\n\\boldsymbol{79}\nùüîùüñ\n\\boldsymbol{68}\nùüîùüñ\n\\boldsymbol{68}\nùüêùüë\n\\boldsymbol{23}\nùüîùüé\n\\boldsymbol{60}\nStackCube\nNo Aug.\n0\n0\n0\n0\n0\nCEI\nw/o Inf. Aug.\n36\n36\n10\n10\n44\n44\n0\n23\n23\nCEI\n(Ours)\nùüìùüì\n\\boldsymbol{55}\nùüèùüî\n\\boldsymbol{16}\nùüìùüê\n\\boldsymbol{52}\n0\nùüëùüè\n\\boldsymbol{31}\nSource (ref.)\n100 / 100 / 97\n99\nVI-B\nReal-world Results\nVI-B\n1\nBidirectional transfer\nTable\nV\ndemonstrates the bidirectional transfer capabilities of\nCEI\non real-world tasks. We compare policies trained on synthesized data and deployed on the target embodiment against those trained on source data and deployed on the source embodiment. Results show that for simple tasks such as PushCube,\nCEI\nenables transfer from a parallel-jaw gripper to a dexterous hand without performance loss. Failures in tasks like OpenDrawer and PlaceBird are primarily due to challenges in dexterous contacts, such as fingers slipping off drawer handles. In transfers from a dexterous hand to a parallel gripper,\nCEI\nachieves similar performance.\nHowever, InsertFlower remains exceptionally challenging since the thin geometry of the flower stem makes it prone to slippage, leading to low success rates for both source and target embodiments.\nOverall,\nCEI\nachieves an average success rate of 70% across six tasks, with a transfer ratio (success rate of\nCEI\ndivided by that of the source embodiment) of 82.4%. Qualitative evaluation across 6 tasks is shown in Fig.\n5\n.\nTABLE V:\nReal-world Evaluation.\nAG95\n‚Üí\n\\rightarrow\nXhand\nMethod\nPushCube\nOpenDrawer\nPlaceBird\nAverage\nCEI\n(Ours)\n10\n/\n10\n10/10\n8\n/\n10\n8/10\n7\n/\n10\n7/10\n8.3\n/\n10\n8.3/10\nSource\n10\n/\n10\n10/10\n10\n/\n10\n10/10\n10\n/\n10\n10/10\n10\n/\n10\n10/10\nXhand\n‚Üí\n\\rightarrow\nAG95\nMethod\nPickCup\nPackageBread\nInsertFlower\nAverage\nCEI\n(Ours)\n6\n/\n10\n6/10\n9\n/\n10\n9/10\n2\n/\n10\n2/10\n5.7\n/\n10\n5.7/10\nSource\n8\n/\n10\n8/10\n9\n/\n10\n9/10\n4\n/\n10\n4/10\n7\n/\n10\n7/10\nFigure 6:\nSpatial generalization. Left: Experimental setup and task configuration, where each anchor is spaced 20‚Äâcm apart. Around each anchor, we sample a\n10\n√ó\n10\n10\\times 10\ngrid within the range\n[\n‚àí\n8\n‚Äã\ncm\n,\n8\n‚Äã\ncm\n]\n[-8\\,\\text{cm},8\\,\\text{cm}]\nfor data generation. Middle: Our approach enables the Xhand to press the button across most of the table surface. Right: Evaluation results on the 10 anchors. Each anchor is evaluated over 5 trials, with the results distinguished by different colors.\nVI-B\n2\nTime cost of transfer\nTo study how efficient the data generation process is, we evaluate the efficiency of\nCEI\n‚Äôs data generation by measuring the time required to synthesize 100, 200, 300 and 400 demonstrations. Given the substantial cost of collecting large-scale real-world demonstrations, we construct larger datasets by replicating a set of 25 collected trajectories through duplication at ratios of 4\n√ó\n\\times\n, 8\n√ó\n\\times\n, 12\n√ó\n\\times\n, and 16\n√ó\n\\times\n, respectively. We compare\nCEI\nwith MimicGen\n[\n12\n]\nand DemoGen\n[\n20\n]\non datasets with an average episode length of 105 steps. For MimicGen, we estimate time by multiplying the replay duration of each source trajectory by the number of generated demonstrations, and adding 20 seconds per trajectory for manual object resets, following\n[\n20\n]\n. Table\nVI\npresents the time required to generate those numbers of demonstrations. Results show that\nCEI\nrequires significantly less time than MimicGen, which highly depends on online execution. DemoGen generates hundreds of demonstrations in one second, while\nCEI\nrequires several minutes since it utilizes gradient-based optimization.\nTABLE VI:\nTime Cost for Generating Real-world Demonstrations.\n100 Demos\n200 Demos\n300 Demos\n400 Demos\nMimicGen\n6.4\n6.4\nh\n12.8\n12.8\nh\n19.2\n19.2\nh\n25.6\n25.6\nh\nDemoGen\n0.29\n0.29\ns\n0.54\n0.54\ns\n0.84\n0.84\ns\n1.14\n1.14\ns\nCEI\n(Ours)\n2.5\n2.5\nmin\n2.9\n2.9\nmin\n3.3\n3.3\nmin\n3.6\n3.6\nmin\nVII\nBroader Applications\nVII-A\nSpatial Generalization\nVII-A\n1\nSpatial augmentation\nCEI\ninherently facilitates spatial generalization, enabling the generation of diverse demonstrations across the entire workspace from only a single collected trajectory. Given a spatial transform\nùíØ\ni\n\\mathcal{T}_{i}\nwhich encapsulates the possible translational or rotational offset of the objects, we first apply it to the functional representation trajectory:\nX\n~\nt\n=\nX\nt\n+\n‚Ñí\n‚Äã\n(\nt\n)\n‚Äã\n(\nùíØ\ni\n‚Äã\n(\nX\nt\n)\n‚àí\nX\nt\n)\n,\nt\n=\n0\n,\n1\n,\n‚Ä¶\n,\nL\n‚àí\n1\n,\n\\tilde{X}_{t}=X_{t}+\\mathcal{L}(t)(\\mathcal{T}_{i}(X_{t})-X_{t}),\\quad t=0,1,\\ldots,L-1,\n(3)\nwhere\n‚Ñí\n‚Äã\n(\nt\n)\n=\nmin\n‚Å°\n(\nt\n0.8\n‚Äã\nL\n,\n1\n)\n\\mathcal{L}(t)=\\min(\\frac{t}{0.8L},1)\nis the clipped linear growth, ensuring that the generated demonstrations share an initial state while diverging to different terminal states by interpolation. The target embodiment is subsequently aligned to the augmented trajectory\n{\nX\n~\nt\n}\nt\n=\n0\nL\n‚àí\n1\n\\{\\tilde{X}_{t}\\}_{t=0}^{L-1}\nthrough the standard\nCEI\noptimization procedure.\nThe augmented point cloud is then obtained by applying\nùíØ\ni\n\\mathcal{T}_{i}\nto the object point cloud and synthesizing the robot point cloud according to the augmented trajectory.\nVII-A\n2\nPress the button anywhere on the table\nWe assess the spatial generalization of\nCEI\nin the PressButton task. Starting from a single demonstration collected with AG95, we generate 1,000 demonstrations across 10 anchors, where each anchor samples a\n10\n√ó\n10\n10\\times 10\ngrid within the range\n[\n‚àí\n8\n‚Äã\ncm\n,\n8\n‚Äã\ncm\n]\n[-8\\,\\text{cm},8\\,\\text{cm}]\n(Fig.\n6\n, left). We then train DP3 and evaluate it on each anchor position for 5 trials. As illustrated in Fig.\n6\n(middle and right), our approach extends the policy to press the button over a wide area of the table, rather than being limited to the original position. Moreover, we observe that performance on the left side is better than on the right, likely because the camera is positioned to the right of center and oriented toward the left.\nVII-B\nMultimodal Motion Generation\nFigure 7:\nMultimodality of\nCEI\n.\nCEI\ngenerates two different manipulation motions in OpenDrawer task from the same demonstration.\nIn previous experiments, we observed that varying the initial joint configuration produces different aligned trajectories. For example, when transferring a grasp motion from a gripper to a dexterous hand, the resulting pose of the dexterous hand remains valid even if rotated by\n180\n‚àò\n180^{\\circ}\naround the heading direction. To exploit such multimodality, we introduce an initialization strategy designed for enhancing data diversity.\nVII-B\n1\nElite-based initialization strategy (EIS)\nInstead of relying on random joint configurations, we uniformly sample candidate configurations from the joint space and rank them according to their\nfunctional similarity\nwith the functional representation of the source embodiment‚Äôs initial configuration. The top 10% of these candidates are then selected, and their mean configuration is used as the initialization. Subsequently, we proceed with the original process of\nCEI\nto obtain the aligned trajectory and synthesize corresponding demonstrations.\nVII-B\n2\nBimodal motion in OpenDrawer\nWe evaluate the extension in OpenDrawer task. As shown in Fig.\n7\n,\nCEI\ngenerates 2 different patterns that successfully open the drawer. Since we only manipulate the initialization and\nCEI\nproceeds the trajectory sequentially, the aligned trajectories remain temporally consistent while allowing for diverse motion patterns. We further train DP3 on 25 demonstrations with either an arbitrary motion pattern or a 1:1 mixture of patterns. As reported in Table\nVII\n, the multimodality has no adverse impact on task success.\nTABLE VII:\nSuccess Rates of Different Training Recipes.\nPattern 1\nPattern 2\nMixture of Pattern 1&2\nSuccess Rate\n8\n/\n10\n8/10\n7\n/\n10\n7/10\n7\n/\n10\n7/10\nVIII\nConclusion and Discussion\nIn this letter, we introduce\nCEI\n, a cross-embodiment framework that leverages\nfunctional similarity\nand automated data synthesis to transfer policies across diverse robots in both simulation and the real world. Beyond standard manipulation,\nCEI\nsupports spatial generalization and multimodal motion generation, providing a versatile foundation for scalable robot learning. While our current scope is point cloud-based cross-embodiment learning, preliminary results suggest our work also holds potential for RGB-based observations, as shown on our project website\nhttps://cross-embodiment-interface.github.io/\n. Although\nCEI\ncan synthesize hundreds of demonstrations in parallel within minutes, applying it to large-scale datasets remains an open direction that could further advance generalist policy learning. In addition, the current reliance on visual-kinematic inputs limits the detection of unstable contacts, such as the slippage seen in the InsertFlower task. Integrating tactile sensing would allow the policy to adapt to these physical disturbances in real-time, representing a key area for future improvement.\nReferences\n[1]\nS. Bahl, R. Mendonca, L. Chen, U. Jain, and D. Pathak\n(2023)\nAffordances from human videos as a versatile representation for robotics\n.\nIn\nProc. IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\n,\nCited by:\n¬ß\nIV-A\n1\n.\n[2]\nE. Bauer, E. Nava, and R. K. Katzschmann\n(2025)\nLatent action diffusion for cross-embodiment manipulation\n.\nArXiv\n.\nCited by:\n¬ß\nII-B\n.\n[3]\nL. Y. Chen, K. Dharmarajan, K. Hari, C. Xu, Q. Vuong, and K. Goldberg\n(2024)\nMIRAGE: cross-embodiment zero-shot policy transfer with cross-painting\n.\nIn\nProc. Robotics: Science and Systems (RSS)\n,\nCited by:\n¬ßI\n,\n¬ß\nII-B\n.\n[4]\nL. Y. Chen, C. Xu, K. Dharmarajan, R. Cheng, K. Keutzer, M. Tomizuka, Q. Vuong, and K. Goldberg\n(2025)\nRoVi-Aug: robot and viewpoint augmentation for cross-embodiment robot learning\n.\nIn\nProc. Conference on Robot Learning (CoRL)\n,\nCited by:\n¬ßI\n,\n¬ßI\n,\n¬ß\nII-B\n.\n[5]\nQ. Chen, S. C. Kiami, A. Gupta, and V. Kumar\n(2023)\nGenAug: retargeting behaviors to unseen situations via generative augmentation\n.\nIn\nProc. Robotics: Science and Systems (RSS)\n,\nCited by:\n¬ß\nII-A\n.\n[6]\nC. Chi, S. Feng, Y. Du, Z. Xu, E. Cousineau, B. C. Burchfiel, and S. Song\n(2023)\nDiffusion Policy: visuomotor policy learning via action diffusion\n.\nIn\nProc. Robotics: Science and Systems (RSS)\n,\nCited by:\n¬ß\nII-A\n.\n[7]\nF. Ebert, Y. Yang, K. Schmeckpeper, B. Bucher, G. Georgakis, K. Daniilidis, C. Finn, and S. Levine\n(2022)\nBridge Data: boosting generalization of robotic skills with cross-domain datasets\n.\nIn\nProc. Robotics: Science and Systems (RSS)\n,\nCited by:\n¬ßI\n,\n¬ß\nII-B\n.\n[8]\nH. Furuta, Y. Iwasawa, Y. Matsuo, and S. S. Gu\n(2023)\nA system for morphology-task generalization via unified representation and behavior distillation\n.\nIn\nProc. International Conference on Learning Representations (ICLR)\n,\nCited by:\n¬ß\nII-B\n.\n[9]\nJ. Gao, A. Xie, T. Xiao, C. Finn, and D. Sadigh\n(2024)\nEfficient data collection for robotic manipulation via compositional generalization\n.\nIn\nProc. Robotics: Science and Systems (RSS)\n,\nCited by:\n¬ßI\n.\n[10]\nE. S. Hu, K. Huang, O. Rybkin, and D. Jayaraman\n(2022)\nKnow Thyself: transferable visual control policies through robot-awareness\n.\nIn\nProc. International Conference on Learning Representations (ICLR)\n,\nCited by:\n¬ß\nII-B\n.\n[11]\nF. Lin, Y. Hu, P. Sheng, C. Wen, J. You, and Y. Gao\n(2024)\nData scaling laws in imitation learning for robotic manipulation\n.\nIn\nProc. International Conference on Learning Representations (ICLR)\n,\nCited by:\n¬ßI\n.\n[12]\nA. Mandlekar, S. Nasiriany, B. Wen, I. Akinola, Y. Narang, L. Fan, Y. Zhu, and D. Fox\n(2023)\nMimicGen: a data generation system for scalable robot learning using human demonstrations\n.\nIn\nProc. Conference on Robot Learning (CoRL)\n,\nCited by:\n¬ß\nII-A\n,\n¬ß\nVI-B\n2\n.\n[13]\nA. O‚ÄôNeill, A. Rehman, A. Maddukuri, A. Gupta, A. Padalkar, A. Lee, A. Pooley, A. Gupta, A. Mandlekar, A. Jain,\net al.\n(2024)\nOpen X-embodiment: robotic learning datasets and RT-X models\n.\nIn\nProc. the IEEE International Conference on Robotics and Automation (ICRA)\n,\nCited by:\n¬ßI\n,\n¬ß\nII-B\n.\n[14]\nOcto Model Team, D. Ghosh, H. Walke, K. Pertsch, K. Black, O. Mees, S. Dasari, J. Hejna, C. Xu, J. Luo, T. Kreiman, Y. L. Tan, L. Y. Chen, P. Sanketi, Q. Vuong, T. Xiao, D. Sadigh, C. Finn, and S. Levine\n(2024)\nOcto: an open-source generalist robot policy\n.\nIn\nProc. Robotics: Science and Systems (RSS)\n,\nCited by:\n¬ß\nII-B\n.\n[15]\nL. Shao, F. Ferreira, M. Jorda, V. Nambiar, J. Luo, E. Solowjow, J. A. Ojea, O. Khatib, and J. Bohg\n(2020)\nUniGrasp: learning a unified model to grasp with multifingered robotic hands\n.\nIEEE Robotics and Automation Letters\n5\n(\n2\n),\npp.¬†2286‚Äì2293\n.\nCited by:\n¬ß\nII-B\n.\n[16]\nH. Shi, H. Xu, Z. Huang, Y. Li, and J. Wu\n(2024)\nRoboCraft: learning to see, simulate, and shape elasto-plastic objects in 3D with graph networks\n.\nThe International Journal of Robotics Research\n43\n(\n4\n),\npp.¬†533‚Äì549\n.\nCited by:\n¬ßI\n.\n[17]\nH. R. Walke, K. Black, T. Z. Zhao, Q. Vuong, C. Zheng, P. Hansen-Estruch, A. W. He, V. Myers, M. J. Kim, M. Du, A. Lee, K. Fang, C. Finn, and S. Levine\n(2023)\nBridgeData V2: a dataset for robot learning at scale\n.\nIn\nProc. Conference on Robot Learning (CoRL)\n,\nCited by:\n¬ß\nII-B\n.\n[18]\nC. Wang, H. Shi, W. Wang, R. Zhang, F. Li, and K. Liu\n(2024)\nDexCap: scalable and portable mocap data collection system for dexterous manipulation\n.\nIn\nProc. Robotics: Science and Systems (RSS)\n,\nCited by:\n¬ßI\n.\n[19]\nZ. Xu, B. Qi, S. Agrawal, and S. Song\n(2021)\nAdaGrasp: learning an adaptive gripper-aware grasping policy\n.\nIn\nProc. IEEE International Conference on Robotics and Automation (ICRA)\n,\nCited by:\n¬ß\nII-B\n.\n[20]\nZ. Xue, S. Deng, Z. Chen, Y. Wang, Z. Yuan, and H. Xu\n(2025)\nDemoGen: synthetic demonstration generation for data-efficient visuomotor policy learning\n.\nIn\nProc. Robotics: Science and Systems (RSS)\n,\nCited by:\n¬ß\nII-A\n,\n¬ß\nVI-B\n2\n.\n[21]\nJ. H. Yang, C. Glossop, A. Bhorkar, D. Shah, Q. Vuong, C. Finn, D. Sadigh, and S. Levine\n(2024)\nPushing the limits of cross-embodiment learning for manipulation and navigation\n.\nIn\nProc. Robotics: Science and Systems (RSS)\n,\nCited by:\n¬ß\nII-B\n.\n[22]\nH. Yuan, B. Zhou, Y. Fu, and Z. Lu\n(2025)\nCross-embodiment dexterous grasping with reinforcement learning\n.\nIn\nProc. International Conference on Learning Representations (ICLR)\n,\nCited by:\n¬ß\nII-B\n.\n[23]\nK. Zakka, A. Zeng, P. Florence, J. Tompson, J. Bohg, and D. Dwibedi\n(2022)\nXIRL: cross-embodiment inverse reinforcement learning\n.\nIn\nProc. Conference on Robot Learning (CoRL)\n,\nCited by:\n¬ß\nII-B\n.\n[24]\nY. Ze, G. Zhang, K. Zhang, C. Hu, M. Wang, and H. Xu\n(2024)\n3D Diffusion Policy: generalizable visuomotor policy learning via simple 3D representations\n.\nIn\nProc. Robotics: Science and Systems (RSS)\n,\nCited by:\n¬ß\nII-A\n,\n¬ß\nV-B\n.\n[25]\nQ. Zhang, T. Xiao, A. A. Efros, L. Pinto, and X. Wang\n(2021)\nLearning cross-domain correspondence for control with dynamics cycle-consistency\n.\nIn\nProc. International Conference on Learning Representations (ICLR)\n,\nCited by:\n¬ß\nII-B\n.\n[26]\nT. Z. Zhao, J. Tompson, D. Driess, P. Florence, S. K. S. Ghasemipour, C. Finn, and A. Wahid\n(2024)\nALOHA Unleashed: a simple recipe for robot dexterity\n.\nIn\nProc. Conference on Robot Learning (CoRL)\n,\nCited by:\n¬ßI\n.\n[27]\nY. Zhu, J. Wong, A. Mandlekar, R. Mart√≠n-Mart√≠n, A. Joshi, S. Nasiriany, and Y. Zhu\n(2020)\nRobosuite: a modular simulation framework and benchmark for robot learning\n.\narXiv preprint arXiv:2009.12293\n.\nCited by:\n¬ß\nV-C\n1\n.",
  "preview_text": "Robotic foundation models trained on large-scale manipulation datasets have shown promise in learning generalist policies, but they often overfit to specific viewpoints, robot arms, and especially parallel-jaw grippers due to dataset biases. To address this limitation, we propose Cross-Embodiment Interface (\\CEI), a framework for cross-embodiment learning that enables the transfer of demonstrations across different robot arm and end-effector morphologies. \\CEI introduces the concept of \\textit{functional similarity}, which is quantified using Directional Chamfer Distance. Then it aligns robot trajectories through gradient-based optimization, followed by synthesizing observations and actions for unseen robot arms and end-effectors. In experiments, \\CEI transfers data and policies from a Franka Panda robot to \\textbf{16} different embodiments across \\textbf{3} tasks in simulation, and supports bidirectional transfer between a UR5+AG95 gripper robot and a UR5+Xhand robot across \\textbf{6} real-world tasks, achieving an average transfer ratio of 82.4\\%. Finally, we demonstrate that \\CEI can also be extended with spatial generalization and multimodal motion generation capabilities using our proposed techniques. Project website: https://cross-embodiment-interface.github.io/\n\nCEI\n: A Unified Interface for Cross-Embodiment Visuomotor Policy Learning in 3D Space\nTong Wu\n1\n, Shoujie Li\n12\n, Junhao Gong\n1\n, Changqing Guo\n1\n, Xingting Li\n1\n,\nShilong Mu\n3\n, and Wenbo Ding\n1\nManuscript received: September 26, 2025; Revised: December 6, 2025; Accepted: January 11, 2026.This paper was recommended for publication by Editor Aleksandra Faust upon evaluation of the Associate Editor and Reviewers‚Äô comments.\nThis work was supported by National Key R&D Program of China grant (2024YFB3816000), Guangdong Innovative and Entrepreneurial Research Team Program (2021ZT09L197), Shenzhen Science and Technology Program (JCYJ20220530143013030), Tsinghua Shenzhen International Graduate School-Shenzhe",
  "is_relevant": true,
  "relevance_score": 6.0,
  "extracted_keywords": [
    "locomotion",
    "whole body control"
  ],
  "one_line_summary": "CEIÊòØ‰∏Ä‰∏™Ë∑®ÂÖ∑Ë∫´Â≠¶‰π†ÁöÑÁªü‰∏ÄÊé•Âè£Ê°ÜÊû∂ÔºåÈÄöËøáÂäüËÉΩÁõ∏‰ººÊÄßÈáèÂåñÂíåËΩ®ËøπÂØπÈΩêÔºåÂÆûÁé∞‰∏çÂêåÊú∫Âô®‰∫∫ÂΩ¢ÊÄÅÈó¥ÁöÑÁ≠ñÁï•ËøÅÁßªÔºåÂπ∂ÊîØÊåÅÁ©∫Èó¥Ê≥õÂåñÂíåÂ§öÊ®°ÊÄÅËøêÂä®ÁîüÊàê„ÄÇ",
  "detailed_summary": "## ËÆ∫ÊñáÊëòË¶ÅÔºöCEI: Áî®‰∫é‰∏âÁª¥Á©∫Èó¥Ë∑®ÂÖ∑Ë∫´ËßÜËßâËøêÂä®Á≠ñÁï•Â≠¶‰π†ÁöÑÁªü‰∏ÄÊé•Âè£\n\n**1. Á†îÁ©∂ËÉåÊôØÂíåÂä®Êú∫**\nÂΩìÂâçÂü∫‰∫éÂ§ßËßÑÊ®°Êìç‰ΩúÊï∞ÊçÆÈõÜËÆ≠ÁªÉÁöÑÊú∫Âô®‰∫∫Âü∫Á°ÄÊ®°ÂûãÔºåËôΩÂ±ïÁé∞Âá∫Â≠¶‰π†ÈÄöÁî®Á≠ñÁï•ÁöÑÊΩúÂäõÔºå‰ΩÜÂ∏∏Âõ†Êï∞ÊçÆÂàÜÂ∏ÉÂÅèÂ∑ÆËÄåËøáÊãüÂêà‰∫éÁâπÂÆöËßÜËßí„ÄÅÊú∫Ê¢∞ËáÇÂèäÔºàÂ∞§ÂÖ∂ÊòØÔºâÂπ≥Ë°åÂ§πÁà™„ÄÇËøô‰∏•ÈáçÈôêÂà∂‰∫ÜÊ®°ÂûãÂú®Èù¢ÂØπ‰∏çÂêåÂΩ¢ÊÄÅÊú∫Âô®‰∫∫ÔºàÂ¶Ç‰ªéÂ§πÁà™Âà∞ÁÅµÂ∑ßÊâãÔºâÊó∂ÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÁé∞ÊúâÊñπÊ≥ïÔºàÂ¶ÇËßÜËßâÂêàÊàêÔºâÂ§öÂ±ÄÈôê‰∫éÂπ≥Ë°åÂ§πÁà™ÔºåÈöæ‰ª•Â∫îÂØπÊûÅÁ´ØÂΩ¢ÊÄÅÂ∑ÆÂºÇ„ÄÇÂõ†Ê≠§Ôºå‰∫üÈúÄ‰∏ÄÁßçËÉΩÂ§üË∑®Ë∂ä‰∏çÂêåÊú∫Âô®‰∫∫ÂΩ¢ÊÄÅËøõË°åÊºîÁ§∫Êï∞ÊçÆ‰∏éÁ≠ñÁï•ËøÅÁßªÁöÑÁªü‰∏ÄÊ°ÜÊû∂„ÄÇ\n\n**2. Ê†∏ÂøÉÊñπÊ≥ïÂíåÊäÄÊúØÂàõÊñ∞**\nÊú¨ÊñáÊèêÂá∫**Ë∑®ÂÖ∑Ë∫´Êé•Âè£ÔºàCEIÔºâ**ÔºåÂÖ∂Ê†∏ÂøÉÂàõÊñ∞Âú®‰∫éÔºö\n- **ÂäüËÉΩÁõ∏‰ººÊÄß**ÔºöÊèêÂá∫Êñ∞Ê¶ÇÂøµÔºåÈÄöËøá**ÂÆöÂêëÂÄíËßíË∑ùÁ¶ªÔºàDCDÔºâ**ÈáèÂåñ‰∏çÂêåÊú´Á´ØÊâßË°åÂô®Âú®Áâ©‰Ωì‰∫§‰∫íË°å‰∏∫‰∏äÁöÑÁõ∏‰ººÊÄßÔºåÂêåÊó∂ËÄÉËôëÁ©∫Èó¥ÈÇªËøë‰∏éÊñπÂêëÂØπÈΩê„ÄÇ\n- **Ê¢ØÂ∫¶ËΩ®ËøπÂØπÈΩê**ÔºöÂü∫‰∫éÂäüËÉΩÁõ∏‰ººÊÄßÔºåÈÄöËøáÂèØÂæÆÂâçÂêëËøêÂä®Â≠¶ÂíåÊ¢ØÂ∫¶‰ºòÂåñÔºåÂ∞ÜÊ∫êÊú∫Âô®‰∫∫ÁöÑÂÖ≥ËäÇËΩ®ËøπÂ∫èÂàóÂºèÂú∞ÂØπÈΩêÂà∞ÁõÆÊ†áÊú∫Âô®‰∫∫ÔºåÁ°Æ‰øùÊó∂Â∫è‰∏ÄËá¥ÊÄß„ÄÇ\n- **Áªü‰∏ÄÊï∞ÊçÆÂêàÊàê**ÔºöÂà©Áî®ÂØπÈΩêÂêéÁöÑËΩ®ËøπÔºåÂêåÊ≠•ÂêàÊàêÁõÆÊ†áÊú∫Âô®‰∫∫ÁöÑÁÇπ‰∫ëËßÇÊµãÔºàÈÄöËøáÊé©ËîΩ‰∏éÂ¢ûÂº∫ÔºâÂíåÂÖ≥ËäÇÂä®‰ΩúÔºåÁîüÊàêÂÆåÊï¥ÁöÑË∑®ÂÖ∑Ë∫´ÊºîÁ§∫Êï∞ÊçÆ„ÄÇ\n- **Êâ©Â±ïÂ∫îÁî®**ÔºöÊ°ÜÊû∂ÂèØËøõ‰∏ÄÊ≠•ÊîØÊåÅ**Á©∫Èó¥Ê≥õÂåñ**Ôºà‰ªéÂçïÊù°ËΩ®ËøπÁîüÊàêÊï¥‰∏™Â∑•‰ΩúÁ©∫Èó¥ÁöÑÊºîÁ§∫Ôºâ‰∏é**Â§öÊ®°ÊÄÅËøêÂä®ÁîüÊàê**ÔºàÈÄöËøáÁ≤æËã±ÂàùÂßãÂåñÁ≠ñÁï•‰∫ßÁîüÂ§öÊ†∑ÂåñÂä®‰ΩúÊ®°ÂºèÔºâ„ÄÇ\n\n**3. ‰∏ªË¶ÅÂÆûÈ™åÁªìÊûú**\n- **‰ªøÁúüÂÆûÈ™å**ÔºöÂ∞ÜFranka PandaÁöÑÊºîÁ§∫ËøÅÁßªËá≥**16Áßç**‰∏çÂêåÊú∫Ê¢∞ËáÇ‰∏éÊú´Á´ØÊâßË°åÂô®ÁªÑÂêàÔºàÂåÖÊã¨ÁÅµÂ∑ßÊâãÔºâÔºåÂú®ÂºÄÊäΩÂ±â„ÄÅÊäìÁ´ãÊñπ‰Ωì„ÄÅÂ†ÜÂè†Á´ãÊñπ‰Ωì‰∏â‰∏™‰ªªÂä°‰∏äÈ™åËØÅ‰∫ÜÊúâÊïàÊÄß„ÄÇ‰ªªÂä°ÊàêÂäüÁéáÈöèÊé•Ëß¶Â§çÊùÇÂ∫¶Â¢ûÂä†ËÄå‰∏ãÈôçÔºå‰ΩÜÂÖ≥ÈîÆ‰ªªÂä°ÔºàÂ¶ÇÊäìÂèñÔºâÂπ≥ÂùáÊàêÂäüÁéá‰ªçËææ**65%**„ÄÇÊ∂àËûçÂÆûÈ™åËØÅÂÆû‰∫ÜÊñπÂêë‰ø°ÊÅØ‰∏éÂ∫èÂàó‰ºòÂåñÁöÑÈáçË¶ÅÊÄß„ÄÇ\n- **ÁúüÂÆû‰∏ñÁïåÂÆûÈ™å**ÔºöÂú®UR5Êú∫Ê¢∞ËáÇ‰∏äÔºåÂÆûÁé∞‰∫ÜAG95Âπ≥Ë°åÂ§πÁà™‰∏éXhand‰∫îÊåáÁÅµÂ∑ßÊâã‰πãÈó¥ÁöÑ**ÂèåÂêëÁ≠ñÁï•ËøÅÁßª**ÔºåÊ∂µÁõñÊé®Á´ãÊñπ‰Ωì„ÄÅÂºÄÊäΩÂ±â„ÄÅÊîæÁΩÆÈ∏üÁé©ÂÖ∑Á≠â6‰∏™‰ªªÂä°ÔºåÂπ≥ÂùáÊàêÂäüÁéáËææ**70%**ÔºåËøÅÁßªÊØîÔºàÁõÆÊ†áÊàêÂäüÁéá/Ê∫êÊàêÂäüÁéáÔºâ‰∏∫**82.4%**„ÄÇ\n- **ÊïàÁéá**ÔºöÁîüÊàêÊï∞ÁôæÊù°ÊºîÁ§∫‰ªÖÈúÄÊï∞ÂàÜÈíüÔºåËøúÂø´‰∫é‰æùËµñÂú®Á∫øÁâ©ÁêÜ‰ªøÁúüÁöÑÊñπÊ≥ï„ÄÇ\n- **Á≠ñÁï•Â≠¶‰π†**Ôºö‰ΩøÁî®ÂêàÊàêÊï∞ÊçÆËÆ≠ÁªÉÁöÑ3D Diffusion PolicyÂú®‰ªøÁúü‰ªªÂä°‰∏≠Âπ≥ÂùáÊàêÂäüÁéáËææ**62%**ÔºåÊòæËëó‰ºò‰∫éÊó†Êï∞ÊçÆÂ¢ûÂº∫ÁöÑÂü∫Á∫ø„ÄÇ\n\n**4. Á†îÁ©∂ÊÑè‰πâÂíå‰ª∑ÂÄº**\nCEI‰∏∫Ëß£ÂÜ≥Êú∫Âô®‰∫∫Â≠¶‰π†‰∏≠ÁöÑ**ÂÖ∑Ë∫´ÂÅèÂ∑Æ**ÈóÆÈ¢òÊèê‰æõ‰∫ÜÊñ∞È¢ñ‰∏îÊúâÊïàÁöÑÊñπÊ°à„ÄÇÂÖ∂‰ª∑ÂÄºÂú®‰∫éÔºö\n- **Êé®Âä®ÈÄöÁî®Êú∫Âô®‰∫∫Â≠¶‰π†**Ôºö‰ΩøÂæóÂà©Áî®‰∏∞ÂØåÁöÑÂ§πÁà™Êï∞ÊçÆÊù•ËÆ≠ÁªÉÁÅµÂ∑ßÊâãÁ≠ñÁï•Êàê‰∏∫ÂèØËÉΩÔºåÁºìËß£‰∫ÜÁÅµÂ∑ßÊâãÊï∞ÊçÆÁ®ÄÁº∫ÁöÑÁì∂È¢àÔºåÊúâÂä©‰∫éÊûÑÂª∫Êõ¥ÂÖ∑Ê≥õÂåñËÉΩÂäõÁöÑÊú∫Âô®‰∫∫Âü∫Á°ÄÊ®°Âûã„ÄÇ\n- **ÊèêÂçáÊï∞ÊçÆÂà©Áî®ÊïàÁéá**ÔºöÊèê‰æõ‰∫Ü‰∏ÄÁßçÈ´òÊïàÁöÑÁ¶ªÁ∫øÊï∞ÊçÆÁîüÊàê‰∏éÂ¢ûÂº∫ÁÆ°ÈÅìÔºåËÉΩÊòæËëóÈôç‰ΩéÈíàÂØπÊñ∞Êú∫Âô®‰∫∫Âπ≥Âè∞Êî∂ÈõÜÊºîÁ§∫Êï∞ÊçÆÁöÑÊàêÊú¨„ÄÇ\n- **ÊñπÊ≥ïÈÄöÁî®ÊÄß**ÔºöÊ°ÜÊû∂‰∏ç‰æùËµñ‰∫éÁâπÂÆö‰ªªÂä°ÊàñÊéßÂà∂Âô®ÔºåÂü∫‰∫éÁÇπ‰∫ëÂíåËøêÂä®Â≠¶ÔºåÊòì‰∫éÈõÜÊàêÂà∞Áé∞ÊúâËßÜËßâËøêÂä®Á≠ñÁï•Â≠¶‰π†ÊµÅÁ®ã‰∏≠ÔºåÂπ∂‰∏∫Á©∫Èó¥Ê≥õÂåñ„ÄÅÂ§öÊ®°ÊÄÅÁîüÊàêÁ≠âÊõ¥ÂπøÊ≥õÁöÑÂ∫îÁî®Â•†ÂÆö‰∫ÜÂü∫Á°Ä„ÄÇ",
  "qa_pairs": [
    {
      "question": "ËøôÁØáËÆ∫ÊñáÁöÑÊ†∏ÂøÉÂàõÊñ∞ÁÇπÊòØ‰ªÄ‰πàÔºå‰ªñÊÉ≥Ëß£ÂÜ≥‰ªÄ‰πàÈóÆÈ¢òÔºåÊÄé‰πàËß£ÂÜ≥ÁöÑÔºü",
      "answer": "## ËÆ∫ÊñáÊ†∏ÂøÉÂàÜÊûêÔºöCEI\n\n### **‰∏Ä„ÄÅ Á†îÁ©∂ËÉåÊôØ‰∏éÊ†∏ÂøÉÈóÆÈ¢ò**\nÂΩìÂâçÂü∫‰∫éÂ§ßËßÑÊ®°Êï∞ÊçÆËÆ≠ÁªÉÁöÑÊú∫Âô®‰∫∫Âü∫Á°ÄÊ®°ÂûãÂ≠òÂú®‰∏Ä‰∏™ÂÖ≥ÈîÆÁì∂È¢àÔºö**Êï∞ÊçÆÂÅèÂ∑ÆÂØºËá¥ÁöÑ‚ÄúÂÖ∑Ë∫´ËøáÊãüÂêà‚Äù**„ÄÇÂÖ∑‰ΩìË°®Áé∞‰∏∫Ôºö\n- **Êï∞ÊçÆÈõÜ‰∏çÂπ≥Ë°°**ÔºöÁé∞ÊúâÂ§ßËßÑÊ®°Êìç‰ΩúÊï∞ÊçÆÈõÜÔºàÂ¶ÇOXEÔºâ‰∏•ÈáçÂÅèÂêë‰∫éÁâπÂÆöÊú∫Âô®‰∫∫ÔºàÂ¶ÇFranka„ÄÅxArmÔºâÂíåÁâπÂÆöÊú´Á´ØÊâßË°åÂô®Ôºà**Âá†‰πéÂÖ®ÊòØÂπ≥Ë°åÂ§πÁà™**Ôºâ„ÄÇ\n- **Ê≥õÂåñËÉΩÂäõÂèóÈôê**ÔºöÊ®°ÂûãÈöæ‰ª•Áõ¥Êé•ËøÅÁßªÂà∞ÂΩ¢ÊÄÅÂíåËøêÂä®Â≠¶Â∑ÆÂºÇÂ∑®Â§ßÁöÑÊñ∞Êú∫Âô®‰∫∫‰∏äÔºåÂ∞§ÂÖ∂ÊòØ**‰ªéÂπ≥Ë°åÂ§πÁà™ËøÅÁßªÂà∞Â§öÊåáÁÅµÂ∑ßÊâã**ÔºåÂõ†‰∏∫ÁÅµÂ∑ßÊâãÊï∞ÊçÆÊûÅÂ∫¶Á®ÄÁº∫„ÄÇ\n\n**Ê†∏ÂøÉÈóÆÈ¢ò**ÔºöÂ¶Ç‰ΩïÂà©Áî®‰∏∞ÂØåÁöÑÂπ≥Ë°åÂ§πÁà™ÊºîÁ§∫Êï∞ÊçÆÔºå‰∏∫ÂΩ¢ÊÄÅËø•ÂºÇÁöÑÊú∫Âô®‰∫∫ÔºàÂ¶ÇÁÅµÂ∑ßÊâãÔºâ**Ëá™Âä®ÂêàÊàêÂèØÊâßË°åÁöÑËßÜËßâËøêÂä®Á≠ñÁï•Êï∞ÊçÆ**Ôºå‰ªéËÄåÂÆûÁé∞Ë∑®ÂÖ∑Ë∫´ÁöÑÁ≠ñÁï•Â≠¶‰π†Ôºü\n\n### **‰∫å„ÄÅ Ê†∏ÂøÉÂàõÊñ∞ÁÇπ**\nCEI ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Áªü‰∏ÄÁöÑË∑®ÂÖ∑Ë∫´Êï∞ÊçÆÂêàÊàêÊ°ÜÊû∂ÔºåÂÖ∂ÂàõÊñ∞ÊÄß‰∏ªË¶Å‰ΩìÁé∞Âú®‰ª•‰∏ã‰∏â‰∏™Â±ÇÈù¢Ôºö\n\n1.  **Ê¶ÇÂøµÂàõÊñ∞ÔºöÂäüËÉΩÁõ∏‰ººÊÄß**\n    - ÊèêÂá∫‰∫Ü **‚ÄúÂäüËÉΩÁõ∏‰ººÊÄß‚Äù** Ëøô‰∏ÄÊ†∏ÂøÉÊ¶ÇÂøµ„ÄÇÂÆÉË∂ÖË∂ä‰∫ÜÁÆÄÂçïÁöÑÂá†‰ΩïÂΩ¢ÊÄÅÂåπÈÖçÔºåÂÖ≥Ê≥®‰∏çÂêåÊú´Á´ØÊâßË°åÂô®Âú®**ÊâßË°å‰ªªÂä°Êó∂ÁöÑ‰∫§‰∫íË°å‰∏∫ÊòØÂê¶Áõ∏‰ºº**Ôºà‰æãÂ¶ÇÔºåÂπ≥Ë°åÂ§πÁà™ÁöÑÂØπÁß∞ÊäìÊè°‰∏éÁÅµÂ∑ßÊâãÊãáÊåáÂØπÂõõÊåáÁöÑÊäìÊè°Âú®ÂäüËÉΩ‰∏äÊòØÁõ∏‰ººÁöÑÔºâ„ÄÇ\n    - ‰ΩøÁî® **ÊñπÂêëÊÄßÂÄíËßíË∑ùÁ¶ª** Êù•ÈáèÂåñËøôÁßçÁõ∏‰ººÊÄßÔºåÂêåÊó∂ËÄÉËôëÁ©∫Èó¥‰ΩçÁΩÆÂíåË°®Èù¢Ê≥ïÂêëÊñπÂêëÁöÑÂØπÈΩê„ÄÇ\n\n2.  **ÊñπÊ≥ïÂàõÊñ∞ÔºöÂü∫‰∫éÊ¢ØÂ∫¶ÁöÑËΩ®ËøπÂØπÈΩê‰∏éÊï∞ÊçÆÂêàÊàê**\n    - **Ê¢ØÂ∫¶‰ºòÂåñÂØπÈΩê**ÔºöÂ∞ÜËΩ®ËøπÂØπÈΩêÂª∫Ê®°‰∏∫‰∏Ä‰∏™**Â∫èÂàó‰ºòÂåñÈóÆÈ¢ò**„ÄÇÂØπ‰∫éÊ∫êÊú∫Âô®‰∫∫ÁöÑÊØè‰∏ÄÂ∏ßÔºåÈÄöËøáÊ¢ØÂ∫¶‰∏ãÈôç‰ºòÂåñÁõÆÊ†áÊú∫Âô®‰∫∫ÁöÑÂÖ≥ËäÇÈÖçÁΩÆÔºå‰ª•ÊúÄÂ§ßÂåñ‰∏éÊ∫êÊú∫Âô®‰∫∫ÂΩìÂâçÂäüËÉΩË°®Á§∫ÁöÑÂäüËÉΩÁõ∏‰ººÊÄßÔºåÂπ∂Âà©Áî®Ââç‰∏ÄÂ∏ßÁªìÊûúÂàùÂßãÂåñÂΩìÂâçÂ∏ßÔºå‰øùËØÅÊó∂Â∫è‰∏ÄËá¥ÊÄß„ÄÇ\n    - **Á´ØÂà∞Á´ØÊï∞ÊçÆÁîüÊàê**Ôºö‰∏ç‰ªÖÂêàÊàêÂä®‰ΩúÔºàÁõÆÊ†áÂÖ≥ËäÇ‰ΩçÁΩÆÔºâÔºåËøò**ÂêåÊ≠•ÂêàÊàêÂØπÂ∫îÁöÑËßÜËßâËßÇÊµã**ÔºàÁÇπ‰∫ëÔºâ„ÄÇÈÄöËøáÊé©ËîΩÊ∫êÊú∫Âô®‰∫∫ÁÇπ‰∫ëÂπ∂ÈááÊ†∑Ê∑ªÂä†ÁõÆÊ†áÊú∫Âô®‰∫∫ÁÇπ‰∫ëÔºåÁîüÊàêÁ¨¶ÂêàÁõÆÊ†áÊú∫Âô®‰∫∫ËßÜËßíÁöÑËßÇÊµã„ÄÇ\n\n3.  **Ê°ÜÊû∂ÈÄöÁî®ÊÄßÊâ©Â±ï**\n    - Â±ïÁ§∫‰∫ÜCEIÊ°ÜÊû∂ÂèØËΩªÊùæÊâ©Â±ïËá≥**Á©∫Èó¥Ê≥õÂåñ**Ôºà‰ªéÂçïÊù°ËΩ®ËøπÁîüÊàêË¶ÜÁõñÊï¥‰∏™Â∑•‰ΩúÁ©∫Èó¥ÁöÑÊï∞ÊçÆÔºâÂíå**Â§öÊ®°ÊÄÅËøêÂä®ÁîüÊàê**ÔºàÈÄöËøáÁ≤æËã±ÂàùÂßãÂåñÁ≠ñÁï•Ôºå‰ªéÂêå‰∏ÄÊ∫êÊºîÁ§∫ÁîüÊàêÂ§öÁßçÊúâÊïàÁöÑÁõÆÊ†áËøêÂä®Ê®°ÂºèÔºâ„ÄÇ\n\n### **‰∏â„ÄÅ Ëß£ÂÜ≥ÊñπÊ°àÔºöCEI ÊäÄÊúØÊµÅÁ®ã**\nCEI ÁöÑËß£ÂÜ≥ÊñπÊ°àÊòØ‰∏Ä‰∏™Ê∏ÖÊô∞ÁöÑ‰∏âÊ≠•ÊµÅÊ∞¥Á∫øÔºö\n\n1.  **ÂäüËÉΩË°®Á§∫‰∏éÁõ∏‰ººÊÄßËÆ°ÁÆó**\n    - ‰∏∫ÊØè‰∏™Êú∫Âô®‰∫∫ÂÆö‰πâ**ÂäüËÉΩË°®Á§∫**Ôºö‰∏ÄÁªÑ‰Ωç‰∫éÊú´Á´ØÊâßË°åÂô®ÊΩúÂú®Êé•Ëß¶Âå∫ÂüüÔºàÂ¶ÇÊâãÊåáÂû´ÔºâÁöÑ`(ÁÇπÔºåÊ≥ïÂêë)`ÂØπ„ÄÇ\n    - ÈÄöËøá**ÊñπÂêëÊÄßÂÄíËßíË∑ùÁ¶ª**ËÆ°ÁÆóÊ∫êÊú∫Âô®‰∫∫‰∏éÁõÆÊ†áÊú∫Âô®‰∫∫ÂäüËÉΩË°®Á§∫‰πãÈó¥ÁöÑÁõ∏‰ººÂ∫¶Ôºå‰Ωú‰∏∫ÂØπÈΩêÁöÑ‰ºòÂåñÁõÆÊ†á„ÄÇ\n\n2.  **Â∫èÂàóËΩ®ËøπÂØπÈΩê**\n    - ËæìÂÖ•Ê∫êÊú∫Âô®‰∫∫ÊºîÁ§∫ËΩ®Ëøπ„ÄÇ\n    - ÂØπ‰∫éÊØè‰∏ÄÊó∂Èó¥Ê≠• `t`ÔºåÂ∞ÜÁõÆÊ†áÊú∫Âô®‰∫∫ÁöÑÂÖ≥ËäÇÈÖçÁΩÆ `q_t‚Äò` ËÆæ‰∏∫ÂèØÂ≠¶‰π†ÂèòÈáè„ÄÇ\n    - ÈÄöËøáÊúÄÂ∞èÂåñÊçüÂ§±ÂáΩÊï∞ËøõË°å‰ºòÂåñÔºö`‚Ñí_align = w1 * DCD(ÂäüËÉΩË°®Á§∫_Xt, ÂäüËÉΩË°®Á§∫_Xt‚Äô) + w2 * ÂÖ≥ËäÇÈôê‰ΩçÊÉ©ÁΩö`„ÄÇ\n    - ÈááÁî®**Â∫èÂàóÂàùÂßãÂåñ**Ôºö`q_{t+1}‚Äò ÁöÑÂàùÂßãÂÄº = ‰ºòÂåñÂêéÁöÑ q_t‚Äò`ÔºåÁ°Æ‰øùËΩ®ËøπÂπ≥Êªë„ÄÇ\n\n3.  **ËßÇÊµã‰∏éÂä®‰ΩúÂêàÊàê**\n    - **Âä®‰ΩúÂêàÊàê**ÔºöÁõÆÊ†áÊú∫Âô®‰∫∫Âú®Êó∂Âàª `t` ÁöÑÂä®‰ΩúÂç≥ÂØπÈΩêÂêéÁöÑ‰∏ã‰∏ÄÂ∏ßÂÖ≥ËäÇ‰ΩçÁΩÆ `a_t = q_{t+1}‚Äò`„ÄÇ\n    - **ËßÇÊµãÂêàÊàê**Ôºö\n        - **Êú¨‰ΩìÊÑüÁü•**ÔºöÁõ¥Êé•‰ΩøÁî®ÂØπÈΩêÂêéÁöÑÂÖ≥ËäÇ‰ΩçÁΩÆ `q_t‚Äò`„ÄÇ\n        - **ÁÇπ‰∫ë**Ôºö‰ªéÊ∫êÂú∫ÊôØÁÇπ‰∫ë‰∏≠**ÁßªÈô§**Èù†ËøëÊ∫êÊú∫Âô®‰∫∫ÁöÑÁÇπÔºåÁÑ∂Âêé**Ê∑ªÂä†**Ê†πÊçÆÁõÆÊ†áÊú∫Âô®‰∫∫ÂΩìÂâç‰ΩçÂßø‰ªéÂÖ∂ÁΩëÊ†ºÊ®°ÂûãÈááÊ†∑ÁöÑÁÇπÔºåÊúÄÂêéËøõË°å‰∏ãÈááÊ†∑„ÄÇ\n\n### **Âõõ„ÄÅ ÂÆûÈôÖ‰ª∑ÂÄº‰∏éÊÑè‰πâ**\n- **Ëß£ÂÜ≥Êï∞ÊçÆÁ®ÄÁº∫ÈöæÈ¢ò**Ôºö‰∏∫Êï∞ÊçÆÁ®ÄÂ∞ëÁöÑÊú∫Âô®‰∫∫ÂΩ¢ÊÄÅÔºàÂ¶ÇÁÅµÂ∑ßÊâãÔºâÊèê‰æõ‰∫Ü‰∏ÄÁßçÈ´òÊïàÁöÑÊï∞ÊçÆÁîüÊàêÊñπÊ≥ïÔºå**Âà©Áî®‰∏∞ÂØåÊòìÂæóÁöÑÂπ≥Ë°åÂ§πÁà™Êï∞ÊçÆÂç≥ÂèØËÆ≠ÁªÉÁÅµÂ∑ßÊâãÁ≠ñÁï•**„ÄÇ\n- **ÊèêÂçáÊ®°ÂûãÊ≥õÂåñËÉΩÂäõ**ÔºöÊòØÊûÑÂª∫ÁúüÊ≠£‚ÄúÈÄöÁî®‚ÄùÊú∫Âô®‰∫∫Âü∫Á°ÄÊ®°ÂûãÁöÑÂÖ≥ÈîÆ‰∏ÄÊ≠•Ôºå‰ΩøÊ®°ÂûãËÉΩÈÄÇÂ∫îÂ§öÊ†∑ÂåñÁöÑÁâ©ÁêÜÂÆû‰Ωì„ÄÇ\n- **È´òÊïàÂÆûÁî®**ÔºöÂ±û‰∫éÁ¶ªÁ∫øÊï∞ÊçÆÁîüÊàêÊñπÊ≥ïÔºåÂêàÊàêÊï∞ÁôæÊù°ÊºîÁ§∫‰ªÖÈúÄÊï∞ÂàÜÈíüÔºåËøúÂø´‰∫éÂü∫‰∫éÁâ©ÁêÜ‰ªøÁúüÁöÑÂú®Á∫øÁîüÊàêÊñπÊ≥ïÔºåÂÖ∑Â§áÂÆûÈôÖÈÉ®ÁΩ≤ÁöÑÂèØË°åÊÄß„ÄÇ\n- **ÂèåÂêëËøÅÁßª**ÔºöÂÆûÈ™åÈ™åËØÅ‰∫ÜÂú®Âπ≥Ë°åÂ§πÁà™ÔºàUR5+AG95Ôºâ‰∏éÁÅµÂ∑ßÊâãÔºàUR5+XhandÔºâ‰πãÈó¥ÁöÑ**ÂèåÂêëÁ≠ñÁï•ËøÅÁßª**ÔºåÂú®6‰∏™ÁúüÂÆû‰∏ñÁïå‰ªªÂä°‰∏äÂπ≥ÂùáËøÅÁßªÊàêÂäüÁéáÈ´òËææ**82.4%**„ÄÇ\n\n**ÊÄªÁªì**ÔºöCEI ÁöÑÊ†∏ÂøÉÂú®‰∫éÈÄöËøáÂΩ¢ÂºèÂåñÂÆö‰πâÂπ∂‰ºòÂåñ‚ÄúÂäüËÉΩÁõ∏‰ººÊÄß‚ÄùÔºåÂú®ÁÆóÊ≥ïÂ±ÇÈù¢ÊûÑÂª∫‰∫Ü‰∏Ä‰∏™ËøûÊé•‰∏çÂêåÊú∫Âô®‰∫∫ÂΩ¢ÊÄÅÁöÑ‚ÄúÊé•Âè£‚ÄùÔºåÂÆûÁé∞‰∫ÜË∑®ÂÖ∑Ë∫´Ë°å‰∏∫‰∏éÊï∞ÊçÆÁöÑ‰º†ÈÄíÔºå‰∏∫ËßÑÊ®°Âåñ„ÄÅÈÄöÁî®ÂåñÁöÑÊú∫Âô®‰∫∫Â≠¶‰π†Êèê‰æõ‰∫ÜÊñ∞ÁöÑÊï∞ÊçÆÂºïÊìé„ÄÇ",
      "timestamp": "2026-01-20T17:57:46.948034",
      "thinking": null,
      "is_reasoning": false,
      "parent_qa_id": null
    },
    {
      "question": "Âü∫‰∫é‰ªñÁöÑÂâç‰ΩúÔºåÊ¢≥ÁêÜËøô‰∏™ÊñπÂêëÁöÑÊï¥‰∏™ÂèëÂ±ïËÑâÁªúÔºåÊØè‰∏ÄÊ≠•Áõ∏ÊØî‰∫é‰πãÂâçÁöÑÂ∑•‰ΩúÈÉΩÊîπËøõ‰∫Ü‰ªÄ‰πàÔºåÁùÄÈáç‰∫éÂá†‰∏™‰∏çÂêåÁöÑÂèëÂ±ïÊñπÂêë„ÄÇ",
      "answer": "## ËÆ∫Êñá„ÄäCEI: A Unified Interface for Cross-Embodiment Visuomotor Policy Learning in 3D Space„ÄãÂèëÂ±ïËÑâÁªúÂàÜÊûê\n\nÂü∫‰∫éËÆ∫ÊñáÂÜÖÂÆπÂèäÂÖ∂ÂºïÁî®ÁöÑÁõ∏ÂÖ≥ÊñáÁåÆÔºåÂèØ‰ª•Ê¢≥ÁêÜÂá∫**Ë∑®ÂÖ∑Ë∫´ÔºàCross-EmbodimentÔºâËßÜËßâËøêÂä®Á≠ñÁï•Â≠¶‰π†**ÊñπÂêëÁöÑÂèëÂ±ïËÑâÁªú„ÄÇËØ•È¢ÜÂüü‰∏ªË¶ÅÂõ¥Áªï**Â¶Ç‰ΩïÂÖãÊúçÊú∫Âô®‰∫∫ÂΩ¢ÊÄÅÔºàËáÇ„ÄÅÊú´Á´ØÊâßË°åÂô®ÔºâÂ∑ÆÂºÇÂ∏¶Êù•ÁöÑÊï∞ÊçÆÂÅèÂ∑ÆÂíåÊ≥õÂåñÈöæÈ¢ò**Â±ïÂºÄÔºåÊºîËøõË∑ØÂæÑÊ∏ÖÊô∞Ôºå‰∏ªË¶ÅÊ≤øÁùÄ‰ª•‰∏ãÂá†‰∏™ÂÖ≥ÈîÆÊñπÂêëÂèëÂ±ïÔºö\n\n### ÂèëÂ±ïËÑâÁªúÊÄªËßà\nËØ•È¢ÜÂüü‰ªéÊó©ÊúüÂÖ≥Ê≥®**È¢ÜÂüüËá™ÈÄÇÂ∫îÔºàDomain AdaptationÔºâ**Âíå**ÁâπÂÆöÂΩ¢ÊÄÅÁ≠ñÁï•Â≠¶‰π†**ÔºåÈÄêÊ≠•ÊºîËøõÂà∞**Âà©Áî®Â§ßËßÑÊ®°Êï∞ÊçÆÊûÑÂª∫Âü∫Á°ÄÊ®°Âûã**ÔºåÂπ∂ÊúÄÁªàËÅöÁÑ¶‰∫éËß£ÂÜ≥**ÊûÅÁ´ØÂΩ¢ÊÄÅÂ∑ÆÂºÇÔºàÂ¶ÇÂπ≥Ë°åÂ§πÁà™‰∏éÁÅµÂ∑ßÊâãÔºâ‰∏ãÁöÑÊï∞ÊçÆÁîüÊàê‰∏éÁ≠ñÁï•ËøÅÁßª**Ëøô‰∏ÄÊ†∏ÂøÉÊåëÊàò„ÄÇCEI ÊòØËøô‰∏ÄËÑâÁªú‰∏≠ÈíàÂØπ‚ÄúÊûÅÁ´ØË∑®ÂÖ∑Ë∫´Êï∞ÊçÆÂêàÊàê‚ÄùÈóÆÈ¢òÁöÑÊúÄÊñ∞Ëß£ÂÜ≥ÊñπÊ°à„ÄÇ\n\n‰ª•‰∏ãÊòØÊåâ‰∏ªË¶ÅÂèëÂ±ïÊñπÂêëÊ¢≥ÁêÜÁöÑÊºîËøõÊ≠•È™§Ôºö\n\n---\n\n### ÂèëÂ±ïÊñπÂêë‰∏ÄÔºö‰ªéÈ¢ÜÂüüËá™ÈÄÇÂ∫îÂà∞ÂÖ∑Ë∫´Èó¥ÈöôÂº•ÂêàÔºàBridging the Embodiment GapÔºâ\n\nÊó©ÊúüÂ∑•‰Ωú‰∏ªË¶ÅËß£ÂÜ≥ËßÜËßâËßÇÂØüÂ±ÇÈù¢ÁöÑÈ¢ÜÂüüÂ∑ÆÂºÇÔºàÂ¶ÇËßÜËßí„ÄÅÂÖâÁÖßÔºâÔºåÂêéÊù•ÊâçÊÑèËØÜÂà∞Êú∫Âô®‰∫∫Êú¨‰ΩìÂΩ¢ÊÄÅÂ∑ÆÂºÇÊòØÊõ¥Ê†πÊú¨ÁöÑÈöúÁ¢ç„ÄÇ\n\n1.  **Êó©ÊúüÈ¢ÜÂüüËá™ÈÄÇÂ∫îÊñπÊ≥ï**\n    *   **‰ª£Ë°®Â∑•‰Ωú**ÔºöÂü∫‰∫éÂæ™ÁéØ‰∏ÄËá¥ÊÄßÔºàDynamics Cycle-ConsistencyÔºâÁ≠âÊñπÊ≥ïÔºåÂ≠¶‰π†‰∏çÂêåÈ¢ÜÂüüÔºàÂ¶Ç‰ªøÁúü‰∏éÁúüÂÆûÔºâ‰πãÈó¥ÁöÑÂØπÂ∫îÂÖ≥Á≥ª„Äê25„Äë„ÄÇ\n    *   **ÊîπËøõ‰∏éÂ±ÄÈôê**ÔºöËøô‰∫õÊñπÊ≥ï‰∏ªË¶ÅÂÖ≥Ê≥®**ËßÜËßâËßÇÂØüÁ©∫Èó¥**Êàñ**Âä®ÊÄÅÊ®°Âûã**ÁöÑÊò†Â∞Ñ„Äê10, 25„ÄëÔºåÂπ∂Êú™ÊòæÂºèÂ§ÑÁêÜÊú∫Âô®‰∫∫**ÂΩ¢ÊÄÅÂíåËøêÂä®Â≠¶**ÁöÑÊ†πÊú¨Â∑ÆÂºÇÔºåÂõ†Ê≠§Èöæ‰ª•Áõ¥Êé•Â∫îÁî®‰∫é‰ªéÂ§πÁà™Âà∞ÁÅµÂ∑ßÊâãÁ≠âÂΩ¢ÊÄÅËø•ÂºÇÁöÑËøÅÁßª„ÄÇ\n\n2.  **ÊòæÂºèÂº•ÂêàÂÖ∑Ë∫´Èó¥ÈöôÁöÑÂàùÊ≠•Â∞ùËØï**\n    *   **‰ª£Ë°®Â∑•‰Ωú**Ôºö**MIRAGE**„Äê3„ÄëÂíå **RoVi-Aug**„Äê4„Äë„ÄÇ\n    *   **Ê†∏ÂøÉÊîπËøõ**ÔºöËøô‰∫õÊñπÊ≥ïÂºïÂÖ•‰∫Ü‚ÄúË∑®ÁªòÂà∂Ôºàcross-paintingÔºâ‚ÄùÂíåÁîüÊàêÊ®°ÂûãÊäÄÊúØÔºå**Âú®ÂÉèÁ¥†Â±ÇÈù¢ÂêàÊàêÁõÆÊ†áÊú∫Âô®‰∫∫ÁöÑËßÜËßâËßÇÂØü**ÔºåÂà∂ÈÄ†Âá∫Ê∫êÊú∫Âô®‰∫∫Ê≠£Âú®ÁõÆÊ†áÂΩ¢ÊÄÅ‰∏ãÊâßË°å‰ªªÂä°ÁöÑ‚ÄúÂπªË±°‚Äù„ÄÇËøôÂÆûÁé∞‰∫Ü‰ªé**ËßÇÂØüÂ±ÇÈù¢**ÁöÑÈõ∂Ê†∑Êú¨ÈÉ®ÁΩ≤„ÄÇ\n    *   **ÂÖ≥ÈîÆÂ±ÄÈôêÔºàCEI ÁöÑÂá∫ÂèëÁÇπÔºâ**Ôºö\n        *   **ÂΩ¢ÊÄÅÂÅáËÆæÂº∫**Ôºö‰∏•Èáç‰æùËµñ**Âπ≥Ë°åÂ§πÁà™**Âíå**Êìç‰ΩúÁ©∫Èó¥ÊéßÂà∂ÔºàOSCÔºâ**ÔºåÈöæ‰ª•ËøÅÁßªÂà∞Â§öÊåáÁÅµÂ∑ßÊâãÁ≠âÂ§çÊùÇÂΩ¢ÊÄÅ„Äê4„Äë„ÄÇ\n        *   **‰ªÖÂ§ÑÁêÜËßÇÂØü**ÔºöÊú™ÂêåÊ≠•ÁîüÊàê‰∏éÂêàÊàêËßÇÂØüÁõ∏ÂåπÈÖçÁöÑ„ÄÅÂèØ‰æõÁõÆÊ†áÊú∫Âô®‰∫∫ÊâßË°åÁöÑ**ÂÖ≥ËäÇÂä®‰Ωú**„ÄÇÁ≠ñÁï•Âú®‚ÄúÁúãÂà∞‚ÄùÁõÆÊ†áÊú∫Âô®‰∫∫ÂêéÔºå‰ªçÂèØËÉΩËæìÂá∫‰∏çÈÄÇÂêàÂÖ∂ËøêÂä®Â≠¶ÁöÑÂä®‰Ωú„ÄÇ\n\n### ÂèëÂ±ïÊñπÂêë‰∫åÔºöÂü∫‰∫éÂ§ßËßÑÊ®°Ë∑®ÂÖ∑Ë∫´Êï∞ÊçÆÈõÜÁöÑÈÄöÁî®Á≠ñÁï•Â≠¶‰π†\n\nÂè¶‰∏ÄÊù°Ë∑ØÂæÑÊó®Âú®ÈÄöËøáÊî∂ÈõÜÊµ∑Èáè„ÄÅÂ§öÊ†∑ÂåñÁöÑÊú∫Âô®‰∫∫Êï∞ÊçÆÔºåÁõ¥Êé•ËÆ≠ÁªÉÂá∫ÂØπÂΩ¢ÊÄÅÂèòÂåñÂÖ∑ÊúâÈ≤ÅÊ£íÊÄßÁöÑ‚ÄúÈÄöÁî®‚ÄùÁ≠ñÁï•„ÄÇ\n\n1.  **Â§ßËßÑÊ®°Êï∞ÊçÆÈõÜÁöÑÊûÑÂª∫**\n    *   **‰ª£Ë°®Â∑•‰Ωú**Ôºö**Bridge Data**„Äê7„Äë„ÄÅ**BridgeData V2**„Äê17„Äë„ÄÅ**Open X-embodiment (OXE)**„Äê13„Äë„ÄÇ\n    *   **Ê†∏ÂøÉÊîπËøõ**ÔºöÊ±áÈõÜÊù•Ëá™Êï∞ÂçÅ‰∏™‰∏çÂêåÊú∫Âô®‰∫∫Âπ≥Âè∞ÁöÑÁúüÂÆû‰∏ñÁïåÊºîÁ§∫Êï∞ÊçÆÔºåËØÅÊòé‰∫Ü**Êï∞ÊçÆËßÑÊ®°‰∏éÂ§öÊ†∑ÊÄß**ÂØπÁ≠ñÁï•Ê≥õÂåñËÉΩÂäõÁöÑÈáçË¶ÅÊÄß„ÄÇOXE Á≠âÊï∞ÊçÆÈõÜ‰∏∫ËÆ≠ÁªÉ **RT-X** Á≠âÂ§ßÂûãÊú∫Âô®‰∫∫Âü∫Á°ÄÊ®°ÂûãÂ•†ÂÆö‰∫ÜÂü∫Á°Ä„Äê13, 14„Äë„ÄÇ\n    *   **ÂÖ≥ÈîÆÂ±ÄÈôêÔºàCEI ÁöÑÂä®Êú∫Ôºâ**Ôºö\n        *   **Êï∞ÊçÆÂàÜÂ∏ÉÂÅèÂ∑Æ**ÔºöÂç≥‰ΩøÊòØÂ§ßËßÑÊ®°Êï∞ÊçÆÈõÜÔºå‰πü‰∏•ÈáçÂÅèÂêë‰∫é Franka„ÄÅxArm Á≠âÊµÅË°åÊú∫Ê¢∞ËáÇÂíå**Âπ≥Ë°åÂ§πÁà™**„Äê13„Äë„ÄÇÁÅµÂ∑ßÊâãÊï∞ÊçÆÊûÅÂÖ∂Á®ÄÁº∫„Äê18„ÄëÔºåÂØºËá¥Ê®°Âûã‰ªç‰ºöËøáÊãüÂêàÂà∞‰∏ªÊµÅÂΩ¢ÊÄÅ„ÄÇ\n        *   **Êó†Ê≥ïÂ§ÑÁêÜÊûÅÁ´ØÊú™ËßÅÂΩ¢ÊÄÅ**ÔºöÊ®°ÂûãÊ≥õÂåñËÉΩÂäõÂèóÈôê‰∫éËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠ÂΩ¢ÊÄÅÁöÑÂàÜÂ∏É„ÄÇÂØπ‰∫éËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠ÂÆåÂÖ®Êú™Âá∫Áé∞ËøáÁöÑ„ÄÅÂΩ¢ÊÄÅÂ∑ÆÂºÇÊûÅÂ§ßÁöÑÊú∫Âô®‰∫∫ÔºàÂ¶Ç‰ªé‰ªÖÊúâÂ§πÁà™ÁöÑÊï∞ÊçÆÈõÜÊ≥õÂåñÂà∞ÁÅµÂ∑ßÊâãÔºâÔºåÊÄßËÉΩ‰ºöÊÄ•Ââß‰∏ãÈôç„ÄÇ\n\n### ÂèëÂ±ïÊñπÂêë‰∏âÔºöË∑®ÂÖ∑Ë∫´Á≠ñÁï•‰∏éË°®Á§∫ÁöÑÁªü‰∏ÄÂ≠¶‰π†\n\nËøôÈÉ®ÂàÜÂ∑•‰ΩúÂ∞ùËØïÂú®Á≠ñÁï•ÁΩëÁªúÊû∂ÊûÑÊàñÂ≠¶‰π†ËøáÁ®ã‰∏≠ÂµåÂÖ•ÂΩ¢ÊÄÅ‰ø°ÊÅØÔºå‰ª•ÊîØÊåÅÂØπ‰∏ÄÁªÑÂ∑≤Áü•ÂΩ¢ÊÄÅÁöÑÊ≥õÂåñ„ÄÇ\n\n1.  **Áªü‰∏ÄÁ≠ñÁï•Êû∂ÊûÑ**\n    *   **‰ª£Ë°®Â∑•‰Ωú**Ôºö**UniGrasp**„Äê15„Äë„ÄÅ**AdaGrasp**„Äê19„Äë„ÄÅ‰ª•Âèä‰∏Ä‰∫õÂ∞ÜÂΩ¢ÊÄÅÁºñÁ†Å‰∏éÁ≠ñÁï•ÂÖ±ÂêåËÆ≠ÁªÉÁöÑÊñπÊ≥ï„Äê8„Äë„ÄÇ\n    *   **Ê†∏ÂøÉÊîπËøõ**ÔºöËÆæËÆ°ËÉΩÂ§üÊé•Êî∂**ÂΩ¢ÊÄÅÊèèËø∞ÔºàÂ¶ÇURDFÔºâ** ‰Ωú‰∏∫ËæìÂÖ•ÁöÑÁ≠ñÁï•ÁΩëÁªúÔºåÂú®**‰∏ÄÁªÑÁªôÂÆöÁöÑ„ÄÅÂ§öÊ†∑ÁöÑÂΩ¢ÊÄÅ‰∏ä**ËøõË°åËÆ≠ÁªÉÔºåÊó®Âú®Ê≥õÂåñÂà∞ËØ•ÈõÜÂêàÂÜÖÁöÑÊú™ËßÅÂΩ¢ÊÄÅ„ÄÇ\n    *   **ÂÖ≥ÈîÆÂ±ÄÈôê**Ôºö\n        *   **ÈúÄË¶ÅÁõÆÊ†áÂΩ¢ÊÄÅÊï∞ÊçÆ**ÔºöÈÄöÂ∏∏ÈúÄË¶ÅÂú®ÂåÖÂê´ÁõÆÊ†áÂΩ¢ÊÄÅÔºàÊàñÁõ∏‰ººÂΩ¢ÊÄÅÔºâÁöÑ**Ê∑∑ÂêàÊï∞ÊçÆÈõÜ**‰∏äËøõË°åËÆ≠ÁªÉÔºåÊó†Ê≥ïÂÆûÁé∞‰ªéÂçï‰∏ÄÊ∫êÂΩ¢ÊÄÅÂà∞ÂÆåÂÖ®Êú™Áü•ÁõÆÊ†áÂΩ¢ÊÄÅÁöÑÈõ∂Ê†∑Êú¨ËøÅÁßª„ÄÇ\n        *   **Ê≥õÂåñËåÉÂõ¥ÊúâÈôê**ÔºöÊÄßËÉΩÈ´òÂ∫¶‰æùËµñ‰∫éËÆ≠ÁªÉÊâÄËßÅÂΩ¢ÊÄÅÁöÑË¶ÜÁõñËåÉÂõ¥ÔºåÂØπ‰∫éÂÉè‰ªéÂ§πÁà™Âà∞ÁÅµÂ∑ßÊâãËøôÊ†∑ÁöÑ‚ÄúÂàÜÂ∏ÉÂ§ñ‚ÄùÊ≥õÂåñÊåëÊàòÂ∑®Â§ß„ÄÇ\n\n### ÂèëÂ±ïÊñπÂêëÂõõÔºöÁ¶ªÁ∫øÁöÑË∑®ÂÖ∑Ë∫´Êï∞ÊçÆÁîüÊàê‰∏éÂêàÊàêÔºàCEI ÊâÄÂ±ûÊñπÂêëÔºâ\n\nËøôÊòØ CEI Áõ¥Êé•Êé®ËøõÁöÑÊñπÂêëÔºåÊó®Âú®‰∏ç‰æùËµñÁõÆÊ†áÂΩ¢ÊÄÅ‰ªª‰ΩïÁúüÂÆûÊï∞ÊçÆÁöÑÊÉÖÂÜµ‰∏ãÔºå**ÁÆóÊ≥ïÊÄßÂú∞ÂêàÊàê**ÂèØÁî®‰∫éËÆ≠ÁªÉÁõÆÊ†áÁ≠ñÁï•ÁöÑÊºîÁ§∫Êï∞ÊçÆ„ÄÇ\n\n1.  **ÈÄöÁî®Êï∞ÊçÆÁîüÊàêÊäÄÊúØ**\n    *   **‰ª£Ë°®Â∑•‰Ωú**Ôºö**MimicGen**„Äê12„ÄëÔºàÂú®Á∫øÔºâÂíå **DemoGen**„Äê20„ÄëÔºàÁ¶ªÁ∫øÔºâ„ÄÇ\n    *   **Ê†∏ÂøÉÊîπËøõ**Ôºö\n        *   **MimicGen**ÔºöÂú®È´ò‰øùÁúüÁâ©ÁêÜÊ®°ÊãüÂô®‰∏≠ÈáçÊîæÊ∫êËΩ®ËøπÔºåÈÄöËøáÁâ©ÁêÜ‰ªøÁúüÁîüÊàêÊñ∞ÈÖçÁΩÆ‰∏ãÁöÑÊï∞ÊçÆÔºå‰øùËØÅÁâ©ÁêÜÁúüÂÆûÊÄßÔºå‰ΩÜ**ËÆ°ÁÆóÊàêÊú¨È´ò**‰∏îÈöæ‰ª•Áî®‰∫éÁúüÂÆû‰∏ñÁïå„ÄÇ\n        *   **DemoGen**ÔºöÈÄöËøáËΩ®ËøπÂèòÊç¢Á¶ªÁ∫øÁîüÊàêÊï∞ÊçÆÔºå**ÈÄüÂ∫¶Âø´**Ôºå‰ΩÜ‰∏ªË¶ÅÂ§ÑÁêÜ**Áâ©‰ΩìÈÖçÁΩÆÂèòÂåñ**ÔºåÊú™Ëß£ÂÜ≥**Êú∫Âô®‰∫∫ÂΩ¢ÊÄÅÂèòÂåñ**ÁöÑÊ†πÊú¨ÈóÆÈ¢ò„ÄÇ\n    *   **ÂÖ≥ÈîÆÂ±ÄÈôê**ÔºöÂÆÉ‰ª¨ÈÉΩ**Êú™‰∏ìÈó®ËÆæËÆ°Áî®‰∫éÂ§ÑÁêÜÊú´Á´ØÊâßË°åÂô®ÂΩ¢ÊÄÅÁöÑÊûÅÁ´ØÂ∑ÆÂºÇ**„ÄÇ\n\n2.  **CEI ÁöÑÈù©ÂëΩÊÄßÊîπËøõ**\n    *   **Ê†∏ÂøÉÂàõÊñ∞**ÔºöÊèêÂá∫‰∫ÜÈ¶ñ‰∏™‰∏ìÈó®Ëß£ÂÜ≥**‰ªéÂπ≥Ë°åÂ§πÁà™Âà∞Â§öÊåáÁÅµÂ∑ßÊâãÔºàÂèäÂèçÂêëÔºâ** ËøôÁ±ªÊûÅÁ´ØË∑®ÂÖ∑Ë∫´Êï∞ÊçÆÁîüÊàêÈóÆÈ¢òÁöÑÊ°ÜÊû∂„ÄÇ\n    *   **ÂÖ∑‰ΩìÊîπËøõÁÇπ**Ôºö\n        *   **ÊèêÂá∫‚ÄúÂäüËÉΩÁõ∏‰ººÊÄß‚ÄùÊ¶ÇÂøµ**ÔºöË∂ÖË∂äÂá†‰ΩïÂ§ñÂΩ¢Ôºå‰ªé**Áâ©‰Ωì‰∫§‰∫íË°å‰∏∫**ÁöÑÂ±ÇÈù¢ÂÆö‰πâÂΩ¢ÊÄÅÈó¥ÁöÑÁõ∏‰ººÊÄß„ÄÇËøôÊòØÂÆûÁé∞ÊûÅÁ´ØËøÅÁßªÁöÑÁêÜËÆ∫Âü∫Á°Ä„ÄÇ\n        *   **ÂºïÂÖ•ÊñπÂêëÊÄßÂÄíËßíË∑ùÁ¶ª**Ôºö‰ΩøÁî® **DCD**„Äê16„ÄëÈáèÂåñÂäüËÉΩÁõ∏‰ººÊÄßÔºåÂêåÊó∂ËÄÉËôë**Á©∫Èó¥Ë∑ùÁ¶ªÂíåË°®Èù¢Ê≥ïÂêëÂØπÈΩê**ÔºåËøôÂØπÊäìÂèñÁ≠âÊé•Ëß¶‰∏∞ÂØåÁöÑ‰ªªÂä°Ëá≥ÂÖ≥ÈáçË¶ÅÔºà ablation ÂÆûÈ™åËØÅÊòéÊñπÂêë‰ø°ÊÅØÊòØÂÖ≥ÈîÆÔºâ„ÄÇ\n        *   **Á´ØÂà∞Á´ØÁöÑËΩ®Ëøπ„ÄÅËßÇÂØü„ÄÅÂä®‰ΩúÂêàÊàê**Ôºö\n            *   **Âü∫‰∫éÊ¢ØÂ∫¶ÁöÑËΩ®ËøπÂØπÈΩê**ÔºöÈÄöËøá‰ºòÂåñ DCDÔºåÂ∞ÜÊ∫êËΩ®ËøπÂú®**ÂäüËÉΩÂ±ÇÈù¢**ÂØπÈΩêÂà∞ÁõÆÊ†áÂΩ¢ÊÄÅÔºåÁîüÊàêÁõÆÊ†áÂÖ≥ËäÇËΩ®Ëøπ„ÄÇ\n            *   **ÂêåÊ≠•ÂêàÊàêÁÇπ‰∫ëËßÇÂØüÂíåÂÖ≥ËäÇÂä®‰Ωú**Ôºö‰∏ç‰ªÖÁîüÊàêÁúãËµ∑Êù•ÂÉèÁõÆÊ†áÊú∫Âô®‰∫∫ÁöÑËßÇÂØüÔºåËøòÁîüÊàê‰∏é‰πã‰∏•Ê†ºÂåπÈÖç„ÄÅÂèØÊâßË°åÁöÑÂä®‰ΩúÂ∫èÂàóÔºåÂΩ¢ÊàêÂÆåÊï¥ÁöÑÊºîÁ§∫Êï∞ÊçÆÂØπ `(o, a)`„ÄÇ\n        *   **ÂÆûÁé∞ÁúüÊ≠£ÁöÑÈõ∂Ê†∑Êú¨ÂèåÂêëËøÅÁßª**Ôºö‰ªÖÈúÄÊ∫êÊú∫Âô®‰∫∫Êï∞ÊçÆÂíåÁõÆÊ†áÊú∫Âô®‰∫∫ÁöÑÊèèËø∞Êñá‰ª∂ÔºàURDFÔºâÔºåÂç≥ÂèØÁîüÊàêÁõÆÊ†áÊï∞ÊçÆÔºåÂπ∂Âú®‰ªøÁúüÂíåÁúüÂÆû‰∏ñÁïå‰∏≠È™åËØÅ‰∫Ü**Â§πÁà™‚ÜîÁÅµÂ∑ßÊâã**ÁöÑÂèåÂêëÁ≠ñÁï•ËøÅÁßªÔºåÂπ≥ÂùáËøÅÁßªÁéáËææ **82.4%**„ÄÇ\n        *   **ÊãìÂ±ïÊÄß**ÔºöÊ°ÜÊû∂Â§©ÁÑ∂ÊîØÊåÅ**Á©∫Èó¥Ê≥õÂåñ**Ôºà‰ªéÂçïÊù°ËΩ®ËøπÁîüÊàêË¶ÜÁõñÂ∑•‰ΩúÁ©∫Èó¥ÁöÑÂ§öÊ†∑Êï∞ÊçÆÔºâÂíå**Â§öÊ®°ÊÄÅËøêÂä®ÁîüÊàê**ÔºàÈÄöËøáÂàùÂßãÂåñÁ≠ñÁï•‰∫ßÁîü‰∏çÂêåÁöÑÊúâÊïàÂä®‰ΩúÊ®°ÂºèÔºâ„ÄÇ\n\n### ÊÄªÁªìÔºöÂèëÂ±ïËÑâÁªú‰∏é CEI ÁöÑÂÆö‰Ωç\n\n| ÂèëÂ±ïÈò∂ÊÆµ | Ê†∏ÂøÉÊÄùÊÉ≥ | ‰ª£Ë°®ÊÄßÂ∑•‰Ωú/ÊñπÊ≥ï | Áõ∏ÂØπ‰∫éÂâç‰ΩúÁöÑÊîπËøõ | ÈÅóÁïôÈóÆÈ¢ò/Â±ÄÈôê |\n| :--- | :--- | :--- | :--- | :--- |\n| **1. È¢ÜÂüüËá™ÈÄÇÂ∫î** | ÂØπÈΩê‰∏çÂêåÈ¢ÜÂüüÁöÑËßÜËßâ/Âä®ÊÄÅÁâπÂæÅ„ÄÇ | Âæ™ÁéØ‰∏ÄËá¥ÊÄß„Äê25„Äë„ÄÅRobot-Awareness„Äê10„Äë | ÂºÄÂßãÂ§ÑÁêÜ‰ªøÁúüÂà∞ÁúüÂÆûÁöÑÂ∑ÆÂºÇ„ÄÇ | Êú™Â§ÑÁêÜÊú∫Âô®‰∫∫Êú¨‰ΩìÂΩ¢ÊÄÅÂ∑ÆÂºÇ„ÄÇ |\n| **2. ËßÜËßâÂ±ÇÈù¢Âº•Âêà** | Âú®ÂõæÂÉèÂ±ÇÈù¢‚ÄúÁªòÂà∂‚ÄùÁõÆÊ†áÊú∫Âô®‰∫∫„ÄÇ | MIRAGE„Äê3„Äë, RoVi-Aug„Äê4„Äë | ÂÆûÁé∞‰∫ÜËßÇÂØüÂ±ÇÈù¢ÁöÑÈõ∂Ê†∑Êú¨Ë∑®ÂÖ∑Ë∫´„ÄÇ | ÂÅáËÆæÂπ≥Ë°åÂ§πÁà™ÔºõÊú™ÁîüÊàêÂåπÈÖçÁöÑÂä®‰ΩúÔºõÈöæ‰ª•Â§ÑÁêÜÁÅµÂ∑ßÊâã„ÄÇ |\n| **3. Â§ßÊï∞ÊçÆÈ©±Âä®** | Êî∂ÈõÜÂ§öÊ†∑Êï∞ÊçÆËÆ≠ÁªÉÈÄöÁî®Á≠ñÁï•„ÄÇ | OXE„Äê13„Äë, RT-X/Octo„Äê14„Äë | ËØÅÊòé‰∫ÜÂ§ßËßÑÊ®°Êï∞ÊçÆÁöÑÂ®ÅÂäõÔºåÊûÑÂª∫‰∫ÜÂü∫Á°ÄÊ®°Âûã„ÄÇ | Êï∞ÊçÆÂ≠òÂú®ÂΩ¢ÊÄÅÂÅèÂ∑ÆÔºõÂØπÊûÅÁ´ØÊú™ËßÅÂΩ¢ÊÄÅÊ≥õÂåñÂ∑Æ„ÄÇ |\n| **4. Áªü‰∏ÄÁ≠ñÁï•Â≠¶‰π†** | Â∞ÜÂΩ¢ÊÄÅÁºñÁ†Å‰Ωú‰∏∫Á≠ñÁï•ËæìÂÖ•„ÄÇ | UniGrasp„Äê15„Äë, AdaGrasp„Äê19„Äë | ÂèØÊ≥õÂåñÂà∞ËÆ≠ÁªÉÂàÜÂ∏ÉÂÜÖÁöÑÊú™ËßÅÂΩ¢ÊÄÅ„ÄÇ | ÈúÄË¶ÅÁõÆÊ†áÂΩ¢ÊÄÅÁõ∏ÂÖ≥Êï∞ÊçÆÔºõÊó†Ê≥ïÂ§ÑÁêÜÂàÜÂ∏ÉÂ§ñÊûÅÁ´ØÂΩ¢ÊÄÅ„ÄÇ |\n| **5. Á¶ªÁ∫øÊï∞ÊçÆÁîüÊàê** | ÁÆóÊ≥ïÊÄßÂêàÊàêÊñ∞Êï∞ÊçÆ„ÄÇ | MimicGen„Äê12„Äë, DemoGen„Äê20„Äë | È´òÊïàÊâ©ÂÖÖÊï∞ÊçÆÔºåËß£ÂÜ≥Áâ©‰ΩìÈÖçÁΩÆÊ≥õÂåñ„ÄÇ | Êú™Ëß£ÂÜ≥Êú∫Âô®‰∫∫ÂΩ¢ÊÄÅÂèòÂåñÁöÑÊ†πÊú¨ÈóÆÈ¢ò„ÄÇ |\n| **6. ÊûÅÁ´ØË∑®ÂÖ∑Ë∫´ÂêàÊàê (CEI)** | **Âü∫‰∫éÂäüËÉΩÁõ∏‰ººÊÄßÁöÑËΩ®Ëøπ‰∏éÊï∞ÊçÆÂêàÊàê**„ÄÇ | **CEI**",
      "timestamp": "2026-01-20T17:58:54.007760",
      "thinking": null,
      "is_reasoning": false,
      "parent_qa_id": null
    },
    {
      "question": "‰ªñÁöÑÂâç‰ΩúÊúâÂì™‰∫õÔºü‰ΩøÁî®Ë°®Ê†º‰ªîÁªÜËÆ≤ËÆ≤‰ªñÁöÑÊØèÁØáÂâç‰ΩúÔºå‰ªñÂíåÂâç‰ΩúÁöÑÂå∫Âà´ÊòØ‰ªÄ‰πàÔºå‰∏ªË¶ÅÊîπÂñÑÊòØ‰ªÄ‰πàÔºüÁùÄÈáç‰∫éÂÖ∑‰ΩìÁõ∏ÊØî‰∫é‰πãÂâçÊñáÁ´†ÁöÑÊîπÂä®",
      "answer": "## CEIËÆ∫ÊñáÁöÑÂâç‰ΩúÂàÜÊûê‰∏éÂØπÊØî\n\nÊ†πÊçÆËÆ∫ÊñáÂÜÖÂÆπÔºåCEIÁöÑÁ†îÁ©∂Âª∫Á´ãÂú®Â§ö‰∏™Áõ∏ÂÖ≥Â∑•‰ΩúÁöÑÂü∫Á°Ä‰∏äÔºå‰ΩÜÂÖ∂Ê†∏ÂøÉÂàõÊñ∞ÁÇπÂú®‰∫éËß£ÂÜ≥**ÊûÅÁ´ØÂΩ¢ÊÄÅÂ∑ÆÂºÇÔºàÂ¶ÇÂπ≥Ë°åÂ§πÁà™‰∏éÁÅµÂ∑ßÊâãÔºâ‰πãÈó¥ÁöÑË∑®ÂÖ∑Ë∫´Êï∞ÊçÆÁîüÊàê**„ÄÇËÆ∫Êñá‰∏≠ÊòéÁ°ÆÊèêÂèäÂπ∂ÂØπÊØî‰∫ÜÊï∞ÁØáÂÖ≥ÈîÆÁöÑÂâç‰Ωú„ÄÇ‰ª•‰∏ãÊòØËøô‰∫õÂâç‰ΩúÁöÑËØ¶ÁªÜÂàÜÊûêÔºåÂπ∂‰ª•Ë°®Ê†ºÂΩ¢ÂºèÊÄªÁªìCEI‰∏éÂÆÉ‰ª¨ÁöÑÊ†∏ÂøÉÂå∫Âà´ÂíåÊîπËøõ„ÄÇ\n\n### ÂÖ≥ÈîÆÂâç‰ΩúÂàÜÊûê\n\n| Ââç‰ΩúÂêçÁß∞ (ÂºïÁî®ÁºñÂè∑) | Ê†∏ÂøÉÊñπÊ≥ï / ÂÖ≥Ê≥®ÁÇπ | ‰∏éCEIÁöÑ‰∏ªË¶ÅÂå∫Âà´ | CEIÁöÑ‰∏ªË¶ÅÊîπËøõ / ÂàõÊñ∞ |\n| :--- | :--- | :--- | :--- |\n| **Mirage [3]** | **Ë∑®ÁªòÂà∂**ÔºöÈÄöËøáÂõæÂÉèÁºñËæëÊäÄÊúØÔºàÂ¶ÇÂ∞ÜÊ∫êÊú∫Âô®‰∫∫ÁöÑÂõæÂÉè‚ÄúÁªòÂà∂‚ÄùÊàêÁõÆÊ†áÊú∫Âô®‰∫∫ÁöÑÂ§ñËßÇÔºâÊù•ÂêàÊàêËßÜËßâËßÇÊµãÔºå‰ª•ÂÆûÁé∞Èõ∂Ê†∑Êú¨Á≠ñÁï•ËøÅÁßª„ÄÇ | 1. **ÂÖ≥Ê≥®Â±ÇÈù¢**Ôºö‰∏ªË¶ÅËß£ÂÜ≥**ËßÜËßâÂ§ñËßÇ**ÁöÑÂ∑ÆÂºÇÔºåÂ±û‰∫éÂõæÂÉèÂüüËΩ¨Êç¢„ÄÇ<br>2. **ÂΩ¢ÊÄÅÈôêÂà∂**ÔºöÊñπÊ≥ï**‰∏•Èáç‰æùËµñÂπ≥Ë°åÂ§πÁà™**ÂíåÊìç‰ΩúÁ©∫Èó¥ÊéßÂà∂ÔºàOSCÔºâÔºåÈöæ‰ª•ËøÅÁßªÂà∞ÁÅµÂ∑ßÊâãÁ≠âÂ§çÊùÇÂΩ¢ÊÄÅ„ÄÇ<br>3. **Êï∞ÊçÆÁîüÊàê**Ôºö‰æßÈáç‰∫éËßÇÊµãÔºàÂõæÂÉèÔºâÁöÑÂêàÊàêÔºåÂØπÂä®‰ΩúÁöÑÈÄÇÈÖçËÉΩÂäõÊúâÈôê„ÄÇ | 1. **ÂÖ≥Ê≥®ÂäüËÉΩËÄåÈùûÂ§ñËßÇ**ÔºöÊèêÂá∫**ÂäüËÉΩÁõ∏‰ººÊÄß**Ê¶ÇÂøµÔºå‰ªéÊú∫Âô®‰∫∫**‰∏éÁâ©‰Ωì‰∫§‰∫íÁöÑË°å‰∏∫Êú¨Ë¥®**Âá∫ÂèëËøõË°åÂØπÈΩêÔºå‰∏ç‰æùËµñËßÜËßâÂ§ñËßÇÂåπÈÖç„ÄÇ<br>2. **Ëß£ÂÜ≥ÊûÅÁ´ØÂΩ¢ÊÄÅÂ∑ÆÂºÇ**Ôºö‰∏ìÈó®ËÆæËÆ°Áî®‰∫éÂú®**Âπ≥Ë°åÂ§πÁà™‰∏éÂ§öÊåáÁÅµÂ∑ßÊâã**‰πãÈó¥ËøõË°åÂèåÂêëÊï∞ÊçÆ‰∏éÁ≠ñÁï•ËøÅÁßª„ÄÇ<br>3. **ÂÖ®ËΩ®ËøπÁîüÊàê**ÔºöÂêåÊ≠•ÂêàÊàê**ËßÇÊµãÔºàÁÇπ‰∫ëÔºâÂíåÂä®‰ΩúÔºàÂÖ≥ËäÇËΩ®ËøπÔºâ**ÔºåÁîüÊàêÂÆåÊï¥„ÄÅÂèØÊâßË°åÁöÑÁõÆÊ†áÊú∫Âô®‰∫∫ÊºîÁ§∫ËΩ®Ëøπ„ÄÇ |\n| **RoVi-Aug [4]** | **Êú∫Âô®‰∫∫‰∏éËßÜÁÇπÂ¢ûÂº∫**ÔºöÁªìÂêàÁîüÊàêÊ®°ÂûãÂíåË∑®ÁªòÂà∂ÊäÄÊúØÔºåÂêåÊó∂Â¢ûÂº∫Êú∫Âô®‰∫∫Â§ñËßÇÂíåÁõ∏Êú∫ËßÜÁÇπÔºå‰ª•Áº©Â∞èÈ¢ÜÂüüÂíåÂÖ∑Ë∫´Â∑ÆË∑ù„ÄÇ | 1. **ÈóÆÈ¢òËåÉÂõ¥**ÔºöÂêåÊó∂Â§ÑÁêÜ**ÂÖ∑Ë∫´Â∑ÆÂºÇ**Âíå**ËßÜÁÇπÂ∑ÆÂºÇ**„ÄÇ<br>2. **ÊñπÊ≥ïÂü∫Á°Ä**ÔºöÂêåÊ†∑Âü∫‰∫éÁîüÊàêÂºèËßÜËßâÂ¢ûÂº∫ÔºåÂÖ∂**ÊúâÊïàÊÄßÂâçÊèêÊòØÊ∫ê‰∏éÁõÆÊ†áÂΩ¢ÊÄÅÂú®ËßÜËßâÂíåËøêÂä®Â≠¶‰∏ä‰∏çËÉΩÁõ∏Â∑ÆÂ§™Â§ß**ÔºàÊñá‰∏≠ÊåáÂá∫ÂÖ∂ÈÄÇÁî®ÊÄß‰ªçÂ±ÄÈôê‰∫éÂπ≥Ë°åÂ§πÁà™ÂíåOSCÔºâ„ÄÇ<br>3. **Êï∞ÊçÆÂü∫Á°Ä**ÔºöÈúÄË¶Å‰∏ÄÂÆöÈáèÁöÑË∑®ÂÖ∑Ë∫´Êï∞ÊçÆÊù•ËÆ≠ÁªÉÁîüÊàêÊ®°Âûã„ÄÇ | 1. **‰∏ìÊîªÂΩ¢ÊÄÅÈ∏øÊ≤ü**ÔºöCEI**‰∏ìÊ≥®‰∫éËß£ÂÜ≥Áî±Â∑®Â§ßÂΩ¢ÊÄÅÂ∑ÆÂºÇÔºàÁâπÂà´ÊòØÊú´Á´ØÊâßË°åÂô®ÔºâÂ∏¶Êù•ÁöÑÊ†πÊú¨ÊÄßÊåëÊàò**ÔºåËÄå‰∏ç‰∏ªË¶ÅÂ§ÑÁêÜËßÜÁÇπÂèòÂåñ„ÄÇ<br>2. **Âü∫‰∫éÂá†‰Ωï‰∏é‰ºòÂåñÁöÑÊó†Êï∞ÊçÆÁîüÊàê**Ôºö**Êó†ÈúÄ‰∏∫ÁõÆÊ†áÂΩ¢ÊÄÅÊî∂ÈõÜ‰ªª‰ΩïÊºîÁ§∫Êï∞ÊçÆ**„ÄÇ‰ªÖÂà©Áî®Êú∫Âô®‰∫∫ÁöÑURDF/XMLÊèèËø∞Êñá‰ª∂ÔºåÈÄöËøáÂü∫‰∫éÊ¢ØÂ∫¶ÁöÑËΩ®Ëøπ‰ºòÂåñÂÆûÁé∞ËøÅÁßªÔºåËß£ÂÜ≥‰∫ÜÁÅµÂ∑ßÊâãÊï∞ÊçÆÁ®ÄÁº∫ÁöÑÁì∂È¢à„ÄÇ<br>3. **ÂºïÂÖ•ÈáèÂåñÊåáÊ†á**ÔºöÂàõÊñ∞ÊÄßÂú∞‰ΩøÁî®**ÂÆöÂêëÂÄíËßíË∑ùÁ¶ª**Êù•ÂΩ¢ÂºèÂåñÂíåÈáèÂåñ‚ÄúÂäüËÉΩÁõ∏‰ººÊÄß‚ÄùÔºå‰∏∫Ë∑®ÂÖ∑Ë∫´ÂØπÈΩêÊèê‰æõ‰∫ÜÂèØ‰ºòÂåñÁöÑÊòéÁ°ÆÁõÆÊ†á„ÄÇ |\n| **MimicGen [12]** | **Âú®Á∫øÊï∞ÊçÆÁîüÊàê**ÔºöÂú®È´ò‰øùÁúüÁâ©ÁêÜÊ®°ÊãüÂô®‰∏≠ÔºåÈÄöËøáË∞ÉÊï¥Áâ©‰ΩìÈÖçÁΩÆÂπ∂ÊâßË°åÁ≠ñÁï• rollout Êù•ÁîüÊàêÊñ∞ÁöÑ„ÄÅÁâ©ÁêÜ‰∏äÁúüÂÆûÁöÑÊºîÁ§∫„ÄÇ | 1. **ÁîüÊàêËåÉÂºè**Ôºö**Âú®Á∫øÁîüÊàê**Ôºå‰æùËµñÊ®°ÊãüÂô®‰∏≠ÁöÑÁâ©ÁêÜÊâßË°å„ÄÇ<br>2. **ËÆ°ÁÆóÊàêÊú¨**ÔºöÊØèÊ¨°ÁîüÊàêÈÉΩÈúÄË¶ÅËøõË°åÁâ©ÁêÜ‰ªøÁúüÔºå**ËÆ°ÁÆóÂØÜÈõÜ„ÄÅËÄóÊó∂**„ÄÇ<br>3. **ÈÄÇÁî®ÊÄß**Ôºö‰∏ªË¶ÅÈÄÇÁî®‰∫é‰ªøÁúüÁéØÂ¢ÉÔºåÁõ¥Êé•Â∫îÁî®‰∫éÁúüÂÆû‰∏ñÁïåÊàêÊú¨È´òÔºàÈúÄÊâãÂä®ÈáçÁΩÆÁâ©‰ΩìÁ≠âÔºâ„ÄÇ | 1. **Á¶ªÁ∫øÁîüÊàêËåÉÂºè**ÔºöCEIÊòØ**ÂÆåÂÖ®Á¶ªÁ∫øÁöÑÊï∞ÊçÆÂêàÊàêÊñπÊ≥ï**„ÄÇÁªôÂÆöÊ∫êÊºîÁ§∫ÔºåÁõ¥Êé•ÈÄöËøáËÆ°ÁÆóÂíå‰ºòÂåñÁîüÊàêÁõÆÊ†áÊºîÁ§∫Ôºå**‰∏ç‰æùËµñÁâ©ÁêÜ‰ªøÁúü**„ÄÇ<br>2. **ÊïàÁéáÂ§ßÂπÖÊèêÂçá**ÔºöÂ¶ÇË°®VIÊâÄÁ§∫ÔºåÁîüÊàêÊï∞ÁôæÊù°ÊºîÁ§∫‰ªÖÈúÄ**Êï∞ÂàÜÈíü**ÔºåËÄåMimicGenÈúÄË¶Å**Êï∞Â∞èÊó∂**ÔºåÊïàÁéáÈ´òÂá∫Êï∞‰∏™Êï∞ÈáèÁ∫ß„ÄÇ<br>3. **ÊëÜËÑ±Áâ©ÁêÜÁ∫¶Êùü**Ôºö‰∏ç‰æùËµñ‰∫éÊ®°ÊãüÂô®ÊòØÂê¶ÊîØÊåÅÁõÆÊ†áÊú∫Âô®‰∫∫ÊàñÁ≤æÁ°ÆÁöÑÁâ©ÁêÜÂèÇÊï∞ÔºåÂè™Ë¶ÅÊúâÊú∫Âô®ÁöÑËøêÂä®Â≠¶ÊèèËø∞Âç≥ÂèØÂ∑•‰ΩúÔºå**Êõ¥ÈÄöÁî®„ÄÅÊõ¥ËΩªÈáè**„ÄÇ |\n| **DemoGen [20]** | **Á¶ªÁ∫øËΩ®ËøπÂèòÊç¢**ÔºöÈÄöËøáÂØπÁé∞ÊúâÊºîÁ§∫ËΩ®ËøπËøõË°åÂá†‰ΩïÂèòÊç¢ÔºàÂ¶ÇÂπ≥Áßª„ÄÅÊóãËΩ¨ÔºâÊù•ÁîüÊàêÊñ∞Êï∞ÊçÆÔºå‰∏ªË¶ÅÁî®‰∫é**Á©∫Èó¥Ê≥õÂåñ**„ÄÇ | 1. **Ê†∏ÂøÉËÉΩÂäõ**Ôºö‰∏ìÊ≥®‰∫é**Âêå‰∏ÄÊú∫Âô®‰∫∫**Âú®**‰∏çÂêåÁ©∫Èó¥‰ΩçÁΩÆ**ÊâßË°åÁõ∏Âêå‰ªªÂä°ÁöÑÊï∞ÊçÆÁîüÊàê„ÄÇ<br>2. **ÂΩ¢ÊÄÅÂ§ÑÁêÜ**Ôºö**‰∏çÂÖ∑Â§áË∑®‰∏çÂêåÊú∫Âô®‰∫∫ÂΩ¢ÊÄÅËøõË°åÊï∞ÊçÆËøÅÁßªÁöÑËÉΩÂäõ**„ÄÇ | 1. **Êâ©Â±ïÁîüÊàêÁª¥Â∫¶**ÔºöCEIÁöÑÊ†∏ÂøÉÊòØ**Ë∑®ÂΩ¢ÊÄÅÁîüÊàê**ÔºåËÄåDemoGenÊòØ**Á©∫Èó¥ÁîüÊàê**„ÄÇCEI**Â∞ÜÁ©∫Èó¥Ê≥õÂåñ‰Ωú‰∏∫ÂÖ∂‰∏Ä‰∏™Êâ©Â±ïÂ∫îÁî®**ÔºàËßÅVII-AËäÇÔºâÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Ê°ÜÊû∂ÁöÑÁÅµÊ¥ªÊÄß„ÄÇ<br>2. **ÊñπÊ≥ïÊú¨Ë¥®‰∏çÂêå**ÔºöDemoGenÊòØÁÆÄÂçïÁöÑÂá†‰ΩïÂèòÊç¢ÔºõCEIÊ∂âÂèäÂ§çÊùÇÁöÑÂü∫‰∫éÂäüËÉΩÁõ∏‰ººÊÄßÁöÑËΩ®Ëøπ‰ºòÂåñÂíåËßÇÊµãÂêàÊàê„ÄÇCEIÂú®ÈúÄË¶ÅÊó∂‰πüÂèØ‰ª•ÈõÜÊàêÁ±ª‰ººDemoGenÁöÑÁ©∫Èó¥ÂèòÊç¢Êù•Â¢ûÂº∫Êï∞ÊçÆÂ§öÊ†∑ÊÄß„ÄÇ |\n\n### ÊÄªÁªìÔºöCEIÁöÑÊ†∏ÂøÉÁ™ÅÁ†¥\n\nÁªºÂêàÊù•ÁúãÔºåCEIÁõ∏ÂØπ‰∫éÂÖ∂Ââç‰ΩúÁöÑÊ†∏ÂøÉÂå∫Âà´ÂíåÊîπÂñÑÈõÜ‰∏≠‰∫é‰ª•‰∏ãÂá†ÁÇπÔºö\n\n1.  **ÈóÆÈ¢òÂÆö‰πâ‰∏äÁöÑÊ∑±Âåñ**Ôºö‰ªéÂâç‰Ωú‰∏ªË¶ÅËß£ÂÜ≥**ËßÜËßâÂüüÈÄÇÂ∫î**Êàñ**ÊúâÈôêÂΩ¢ÊÄÅÂèòÂåñ**ÔºåËΩ¨ÂêëÊîªÂÖã**Âπ≥Ë°åÂ§πÁà™‰∏éÁÅµÂ∑ßÊâã‰πãÈó¥ÊûÅÁ´ØÂΩ¢ÊÄÅÂ∑ÆÂºÇ**Ëøô‰∏ÄÊõ¥ÂÖ∑ÊåëÊàòÊÄßÁöÑÈóÆÈ¢ò„ÄÇ\n2.  **ÊñπÊ≥ïËÆ∫‰∏äÁöÑÂàõÊñ∞**Ôºö\n    *   **ÊèêÂá∫‚ÄúÂäüËÉΩÁõ∏‰ººÊÄß‚Äù**ÔºöË∂ÖË∂ä‰∫ÜË°®Èù¢ÂØπÈΩêÔºàÂ§ñËßÇ„ÄÅÂÖ≥ËäÇÁ©∫Èó¥ÔºâÔºåÊäì‰Ωè‰∫Ü‚Äú‰∫§‰∫íË°å‰∏∫‚ÄùËøô‰∏ÄÊú¨Ë¥®Ôºå‰∏∫Ë∑®ÂÖ∑Ë∫´Â≠¶‰π†Êèê‰æõ‰∫ÜÊñ∞ÁöÑÁêÜËÆ∫ËßÜËßí„ÄÇ\n    *   **ÊûÑÂª∫Âü∫‰∫é‰ºòÂåñÁöÑÁ¶ªÁ∫øÁîüÊàêÁÆ°ÈÅì**ÔºöÁªìÂêàDCDÂ∫¶Èáè„ÄÅÂèØÂæÆÂàÜËøêÂä®Â≠¶ÂíåÂ∫èÂàó‰ºòÂåñÔºåÂÆûÁé∞‰∫Ü**Êó†ÈúÄÁõÆÊ†áÊï∞ÊçÆ„ÄÅÊó†ÈúÄ‰ªøÁúü**ÁöÑÈ´òÊïà„ÄÅÈ´òË¥®ÈáèËΩ®Ëøπ‰∏éËßÇÊµãÂêàÊàê„ÄÇ\n3.  **ËÉΩÂäõ‰∏äÁöÑÊãìÂ±ï**Ôºö\n    *   **ÂèåÂêëËøÅÁßª**ÔºöÂÆûÁé∞‰∫ÜÂ§πÁà™‚ÜíÁÅµÂ∑ßÊâãÂíåÁÅµÂ∑ßÊâã‚ÜíÂ§πÁà™ÁöÑÂèåÂêëÊúâÊïàËøÅÁßª„ÄÇ\n    *   **Âü∫Á°ÄÊ°ÜÊû∂ÁöÑÂÖºÂÆπÊÄß**ÔºöÂ±ïÁ§∫‰∫ÜÂÖ∂Ê†∏ÂøÉÊñπÊ≥ïÂèØËΩªÊùæ‰∏é**Á©∫Èó¥Ê≥õÂåñ**Âíå**Â§öÊ®°ÊÄÅËøêÂä®ÁîüÊàê**Á≠âÊäÄÊúØÁªìÂêàÔºåÂΩ¢Êàê‰∏Ä‰∏™Êõ¥Âº∫Â§ßÁöÑÊï∞ÊçÆÂêàÊàêÂ∑•ÂÖ∑ÁÆ±„ÄÇ\n\n**ÁÆÄË®Ä‰πãÔºåCEIÁöÑÊ†∏ÂøÉÊîπËøõÂú®‰∫éÔºöÂÆÉ‰∏çÂÜçËØïÂõæËÆ©Êú∫Âô®‰∫∫‚ÄúÁúãËµ∑Êù•‚Äù‰∏ÄÊ†∑ÔºàÂ¶ÇMirageÔºâÔºåÊàñÂè™Âú®Áõ∏‰ººÂΩ¢ÊÄÅÈó¥ËøÅÁßªÔºàÂ¶ÇRoVi-AugÔºâÔºåËÄåÊòØÈÄöËøáËÆ©Êú∫Âô®‰∫∫Âú®‰ªªÂä°‰∏≠‚ÄúË°å‰∏∫ÂäüËÉΩ‚ÄùÁ≠âÊïàÔºå‰ªéËÄåÂú®ÁÆóÊ≥ïÂ±ÇÈù¢ÊâìÈÄö‰∫ÜÊà™ÁÑ∂‰∏çÂêåÁöÑÊú∫Âô®‰∫∫ÂΩ¢ÊÄÅ‰πãÈó¥ÁöÑÊï∞ÊçÆ‰∏éÁ≠ñÁï•ËøÅÁßªÈÄöÈÅì„ÄÇ**",
      "timestamp": "2026-01-20T17:59:40.849081",
      "thinking": null,
      "is_reasoning": false,
      "parent_qa_id": null
    },
    {
      "question": "ËÆ∫ÊñáÊèêÂá∫‰∫ÜÂì™‰∫õÂÖ≥ÈîÆÊäÄÊúØÊñπÊ≥ïÔºåËØ∑ÂàóË°®Ê†ºÂÖ∑‰ΩìËØ¶ÁªÜËØ¥ÊòéÊäÄÊúØÁªÜËäÇÔºåÈúÄË¶ÅÂåÖÂê´ÂÖ∑‰ΩìÁöÑÊï∞Â≠¶ÂéüÁêÜÊé®ÂØºÔºå‰ª•ÂèäÂÖ∑‰ΩìÂèÇÊï∞„ÄÇ",
      "answer": "Â•ΩÁöÑÔºå‰Ωú‰∏∫‰∏ÄÂêç‰∏ì‰∏öÁöÑÂ≠¶ÊúØËÆ∫ÊñáÂàÜÊûêÂä©ÊâãÔºåÊàëÂ∞ÜÂØπËøôÁØáÈ¢ò‰∏∫„ÄäCEI: A Unified Interface for Cross-Embodiment Visuomotor Policy Learning in 3D Space„ÄãÁöÑËÆ∫ÊñáËøõË°åÊ∑±ÂÖ•ÂàÜÊûêÔºåÂπ∂ËØ¶ÁªÜÈòêËø∞ÂÖ∂ÊèêÂá∫ÁöÑÂÖ≥ÈîÆÊäÄÊúØÊñπÊ≥ï„ÄÇ\n\n## ËÆ∫ÊñáÊ†∏ÂøÉÊäÄÊúØÂàõÊñ∞‰∏é‰ª∑ÂÄºÂàÜÊûê\n\nÊú¨ÊñáÁöÑÊ†∏ÂøÉË¥°ÁåÆÂú®‰∫éÊèêÂá∫‰∫Ü‰∏Ä‰∏™Âêç‰∏∫ **CEI** ÁöÑÁªü‰∏ÄÊ°ÜÊû∂ÔºåÊó®Âú®Ëß£ÂÜ≥Êú∫Âô®‰∫∫Âü∫Á°ÄÊ®°ÂûãÂõ†Êï∞ÊçÆÂÅèËßÅËÄåÈöæ‰ª•Âú®‰∏çÂêåÂΩ¢ÊÄÅÁöÑÊú∫Âô®‰∫∫ÔºàÁâπÂà´ÊòØ‰ªéÂπ≥Ë°åÂ§πÁà™Âà∞ÁÅµÂ∑ßÊâãÔºâ‰πãÈó¥ËøõË°åÁ≠ñÁï•ËøÅÁßªÁöÑÈöæÈ¢ò„ÄÇÂÖ∂Ê†∏ÂøÉÊÄùÊÉ≥ÊòØÂà©Áî®**ÂäüËÉΩÁõ∏‰ººÊÄß**Êù•ÂØπÈΩê‰∏çÂêåÊú∫Âô®‰∫∫ÁöÑËøêÂä®ËΩ®ËøπÔºåÂπ∂ÂêàÊàêÁõÆÊ†áÊú∫Âô®‰∫∫ÁöÑËßÇÊµãÂíåÂä®‰ΩúÊï∞ÊçÆ„ÄÇ\n\n### ÂÖ≥ÈîÆÊäÄÊúØÊñπÊ≥ïËØ¶Ëø∞\n\n‰ª•‰∏ãË°®Ê†ºËØ¶ÁªÜËØ¥Êòé‰∫ÜCEIÊ°ÜÊû∂‰∏≠ÁöÑÂÖ≥ÈîÆÊäÄÊúØÁªÑ‰ª∂„ÄÅÂÖ∂Êï∞Â≠¶ÂéüÁêÜ„ÄÅÂÆûÁé∞ÁªÜËäÇÂèäÂèÇÊï∞„ÄÇ\n\n| ÊäÄÊúØÊ®°Âùó | Ê†∏ÂøÉÊ¶ÇÂøµ‰∏éÁõÆÊ†á | Êï∞Â≠¶ÂéüÁêÜ‰∏éÊé®ÂØºÁªÜËäÇ | ÂÖ∑‰ΩìÂèÇÊï∞‰∏éÂÆûÁé∞ÁªÜËäÇ |\n| :--- | :--- | :--- | :--- |\n| **1. ÂäüËÉΩË°®Á§∫** | Â∞ÜÊú∫Âô®‰∫∫ÁöÑ‰∫§‰∫íËÉΩÂäõÊäΩË±°‰∏∫‰∏ÄÁªÑ**ÁÇπ-ÊñπÂêëÂØπ** `X = {(p_i, n_i)}`ÔºåÁî®‰∫éÈáèÂåñ‰∏çÂêåÂΩ¢ÊÄÅÊú∫Âô®‰∫∫‰πãÈó¥ÁöÑ**ÂäüËÉΩÁõ∏‰ººÊÄß**„ÄÇ | - **ÁÇπ `p_i`**ÔºöÈááÊ†∑Ëá™Êú∫Âô®‰∫∫Êú´Á´ØÊâßË°åÂô®ÔºàÂ¶ÇÊâãÊåáÊåáËÖπÔºâË°®Èù¢ÁöÑÁÇπÔºå‰ª£Ë°®ÊΩúÂú®ÁöÑÁâ©‰ΩìÊé•Ëß¶Âå∫Âüü„ÄÇ<br>- **ÊñπÂêë `n_i`**ÔºöÁÇπ `p_i` Â§ÑÁöÑË°®Èù¢Ê≥ïÂêëÈáèÔºå‰ª£Ë°®Êé•Ëß¶Êó∂ÁöÑÂèØËÉΩÊñΩÂäõÊñπÂêë„ÄÇ<br>- ÈÄöËøáÊ≠£ÂêëËøêÂä®Â≠¶Â∞ÜÊâÄÊúâÁÇπ-ÊñπÂêëÂØπËΩ¨Êç¢Âà∞‰∏ñÁïåÂùêÊ†áÁ≥ªÔºåÁ°Æ‰øùÂú®‰∏çÂêåÊú∫Âô®‰∫∫‰πãÈó¥ËøõË°åÂØπÈΩêÊó∂Êúâ‰∏Ä‰∏™ÂÖ±ÂêåÁöÑÂèÇËÄÉÁ≥ª„ÄÇ | - **ÈááÊ†∑Êù•Ê∫ê**Ôºö‰ªéÊâãÊåáÊåáÂû´ÁΩëÊ†ºË°®Èù¢ÈááÊ†∑„ÄÇ<br>- **Ê≥ïÂêëÈáèËÆ°ÁÆó**Ôºö‰ΩøÁî® `TorchSDF` Â∫ìËá™Âä®ËÆ°ÁÆóÈááÊ†∑ÁÇπÈôÑËøëÁöÑË°®Èù¢Ê≥ïÁ∫ø„ÄÇ<br>- **ÁõÆÁöÑ**ÔºöÂ∞ÜÂ§çÊùÇÁöÑÂá†‰ΩïÂΩ¢ÊÄÅËΩ¨Âåñ‰∏∫ÂèØÁî®‰∫éÈáèÂåñÊØîËæÉÁöÑÈõÜÂêà„ÄÇ |\n| **2. ÂäüËÉΩÁõ∏‰ººÊÄßÂ∫¶ÈáèÔºàÊñπÂêëÂÄíËßíË∑ùÁ¶ªÔºâ** | ÈáèÂåñ‰∏§‰∏™ÂäüËÉΩË°®Á§∫ÈõÜÂêà `X` Âíå `X'` ‰πãÈó¥ÁöÑÁõ∏‰ººÂ∫¶ÔºåÂêåÊó∂ËÄÉËôë**Á©∫Èó¥Ë∑ùÁ¶ª**Âíå**ÊñπÂêëÂØπÈΩê**„ÄÇ | ÈááÁî®**ÊñπÂêëÂÄíËßíË∑ùÁ¶ª**Ôºö<br>```math<br>DCD(X, X') = (1/N) Œ£_{i=1}^{N} min_j (‚Äñp_i - p'_j‚Äñ‚ÇÇ - Œª¬∑‚ü®n_i, n'_j‚ü©) <br>                + (1/N') Œ£_{j=1}^{N'} min_i (‚Äñp'_j - p_i‚Äñ‚ÇÇ - Œª¬∑‚ü®n'_j, n_i‚ü©)<br>```<br>**Êé®ÂØº‰∏éËß£Èáä**Ôºö<br>1. **Á¨¨‰∏ÄÈ°π**ÔºöÂØπ‰∫éÊ∫êÈõÜÂêà `X` ‰∏≠ÁöÑÊØè‰∏™ÁÇπ `(p_i, n_i)`ÔºåÂú®ÁõÆÊ†áÈõÜÂêà `X'` ‰∏≠ÂØªÊâæÊúÄÂåπÈÖçÁöÑÁÇπ `(p'_j, n'_j)`„ÄÇÂåπÈÖç‰ª£‰ª∑Áî±‰∏§ÈÉ®ÂàÜÁªÑÊàêÔºö<br>   - `‚Äñp_i - p'_j‚Äñ‚ÇÇ`ÔºöÁ©∫Èó¥Ê¨ßÊ∞èË∑ùÁ¶ªÔºåË∂äÂ∞èË∂äÂ•Ω„ÄÇ<br>   - `-Œª¬∑‚ü®n_i, n'_j‚ü©`ÔºöÊ≥ïÂêëÈáèÁÇπÁßØÁöÑË¥üÂÄº„ÄÇÁî±‰∫éÁÇπÁßØ `‚ü®¬∑,¬∑‚ü©` Ë∂äÂ§ßË°®Á§∫ÊñπÂêëË∂ä‰∏ÄËá¥ÔºåÂä†‰∏äË¥üÂè∑ÂêéÔºåÊï¥‰Ωì‰ª£‰ª∑Ë∂äÂ∞èË°®Á§∫ÊñπÂêëË∂äÂåπÈÖç„ÄÇ<br>2. **Á¨¨‰∫åÈ°π**ÔºöÂØπÁß∞Âú∞Ôºå‰ªéÁõÆÊ†áÈõÜÂêàÂêëÊ∫êÈõÜÂêàËøõË°åÂåπÈÖçÔºåÁ°Æ‰øùÂ∫¶ÈáèÁöÑÂØπÁß∞ÊÄß„ÄÇ<br>3. **ÊúÄÁªàÁõ∏‰ººÂ∫¶**ÔºöËÆ∫ÊñáÂ∞Ü **`-DCD(X, X')`** ÂÆö‰πâ‰∏∫ÂäüËÉΩÁõ∏‰ººÂ∫¶ÔºåÂç≥ `DCD` ÂÄºË∂äÂ∞èÔºàË¥üÂÄºË∂äÂ§ßÔºâÔºåÁõ∏‰ººÂ∫¶Ë∂äÈ´ò„ÄÇ | - **Âπ≥Ë°°ÂèÇÊï∞ `Œª`**ÔºöÁî®‰∫éÊùÉË°°Á©∫Èó¥Ë∑ùÁ¶ªÂíåÊñπÂêë‰∏ÄËá¥ÊÄßÁöÑÈáçË¶ÅÊÄß„ÄÇËÆ∫ÊñáÈÄöËøáÂÆûÈ™åÁ°ÆÂÆö `Œª = 0.5`„ÄÇ<br>- **Ë∑ùÁ¶ªÂ∫¶Èáè**Ôºö‰ΩøÁî® L2 ËåÉÊï∞ËÆ°ÁÆóÁ©∫Èó¥Ë∑ùÁ¶ª„ÄÇ<br>- **ÊñπÂêëÂ∫¶Èáè**Ôºö‰ΩøÁî®ÂêëÈáèÁÇπÁßØËÆ°ÁÆóÊñπÂêë‰∏ÄËá¥ÊÄß„ÄÇ |\n| **3. Âü∫‰∫éÊ¢ØÂ∫¶ÁöÑËΩ®ËøπÂØπÈΩê** | Â∞ÜÊ∫êÊú∫Âô®‰∫∫ÁöÑÊºîÁ§∫ËΩ®ËøπÔºàÂäüËÉΩË°®Á§∫Â∫èÂàó `{X_t}`ÔºâÈÄöËøá‰ºòÂåñÔºåÂØπÈΩêÂà∞ÁõÆÊ†áÊú∫Âô®‰∫∫ÁöÑÂÖ≥ËäÇÁ©∫Èó¥ÔºåÁîüÊàêÁõÆÊ†áËΩ®Ëøπ `{q'_t}`„ÄÇ | **‰ºòÂåñÈóÆÈ¢òÂÆö‰πâ**Ôºö<br>ÂØπ‰∫éÊØè‰∏ÄÊó∂Èó¥Ê≠• `t`ÔºåÂàùÂßãÂåñÁõÆÊ†áÊú∫Âô®‰∫∫ÂÖ≥ËäÇÈÖçÁΩÆ `q'_t` ‰∏∫ÂèØÂ≠¶‰π†ÂèòÈáèÔºåÈÄöËøáÊ≠£ÂêëËøêÂä®Â≠¶ `FK_{E'}(q'_t)` ÂæóÂà∞ÂÖ∂ÂäüËÉΩË°®Á§∫ `X'_t`„ÄÇÊúÄÂ∞èÂåñÂØπÈΩêÊçüÂ§±Ôºö<br>```math<br>min_{q'_t} ‚Ñí_align(q'_t) = w‚ÇÅ¬∑DCD(X_t, X'_t) + w‚ÇÇ¬∑‚Ñí_reg(q'_t)<br>```<br>**ÊçüÂ§±È°πÂàÜËß£**Ôºö<br>- **`DCD(X_t, X'_t)`**ÔºöÈ©±Âä®ÁõÆÊ†áÊú∫Âô®‰∫∫ÁöÑÂäüËÉΩË°®Á§∫‰∏éÊ∫êÊú∫Âô®‰∫∫Âú®ÂΩìÂâçÂ∏ßÁöÑÂäüËÉΩË°®Á§∫Áõ∏‰ºº„ÄÇ<br>- **`‚Ñí_reg(q'_t)`**ÔºöÊ≠£ÂàôÂåñÈ°πÔºåÊÉ©ÁΩöË∂ÖÂá∫ÂÖ≥ËäÇÈôê‰ΩçÁöÑÈÖçÁΩÆÔºåÁ°Æ‰øùÁîüÊàêÁöÑËΩ®ËøπÂú®Áâ©ÁêÜ‰∏äÂèØË°å„ÄÇ<br><br>**Â∫èÂàó‰ºòÂåñÁ≠ñÁï•**Ôºö<br>‰∏∫ÈÅøÂÖçÈÄêÂ∏ßÁã¨Á´ã‰ºòÂåñÂØºËá¥ËΩ®Ëøπ‰∏çËøûÁª≠ÔºåÈááÁî®Â∫èÂàóÂàùÂßãÂåñÔºö<br>`q'_{t+1}^{(0)} ‚Üê qÃÇ_t`<br>Âç≥Á¨¨ `t+1` Â∏ßÁöÑ‰ºòÂåñÂàùÂßãÂÄºÔºå‰ΩøÁî®Á¨¨ `t` Â∏ß‰ºòÂåñÂêéÁöÑÁªìÊûú `qÃÇ_t`„ÄÇËøô‰øùËØÅ‰∫ÜËΩ®ËøπÁöÑÊó∂Á©∫Âπ≥ÊªëÊÄßÔºåÂπ∂Âä†ÈÄüÊî∂Êïõ„ÄÇ | - **‰ºòÂåñÂô®**Ôºö‰ΩøÁî®Ê¢ØÂ∫¶‰∏ãÈôçÊ≥ï„ÄÇ<br>- **ÊçüÂ§±ÊùÉÈáç**Ôºö`w‚ÇÅ = 1`, `w‚ÇÇ = 1`„ÄÇ<br>- **Ê≠£ÂàôÈ°π**Ôºö`‚Ñí_reg` ÂÖ∑‰ΩìÂΩ¢ÂºèÊú™Âú®Ê≠£ÊñáËØ¶Ëø∞ÔºåÈÄöÂ∏∏‰∏∫ÂØπË∂ÖÂá∫Èôê‰ΩçÁöÑÂÖ≥ËäÇÊñΩÂä†ÁöÑ‰∫åÊ¨°ÊÉ©ÁΩö„ÄÇ<br>- **‰ºòÂåñÊ≠•Êï∞**ÔºöÊØèÂ∏ßÊúÄÂ§ß‰ºòÂåñ300Ê≠•ÔºåËã•ÊçüÂ§±ËøûÁª≠10Ê≠•Êó†ÊîπÂñÑÂàôÊèêÂâçÂÅúÊ≠¢„ÄÇ<br>- **Ê≠£ÂêëËøêÂä®Â≠¶ÂºïÊìé**Ôºö‰ΩøÁî® `pytorch_kinematics` ÂÆûÁé∞ÊâπÈáèÂèØÂæÆËÆ°ÁÆó„ÄÇ |\n| **4. ËßÇÊµã‰∏éÂä®‰ΩúÂêàÊàê** | Ê†πÊçÆÂØπÈΩêÂêéÁöÑÁõÆÊ†áÊú∫Âô®‰∫∫ÂÖ≥ËäÇËΩ®Ëøπ `{qÃÇ_t}`ÔºåÁîüÊàêÂèØÁî®‰∫éËÆ≠ÁªÉÁõÆÊ†áÊú∫Âô®‰∫∫Á≠ñÁï•ÁöÑÂÆåÊï¥ÊºîÁ§∫Êï∞ÊçÆ `DÃÇ_{E', s‚ÇÄ}`„ÄÇ | **Âä®‰ΩúÁîüÊàê**Ôºö<br>`a_t = qÃÇ_{t+1}`<br>Â∞ÜÂä®‰ΩúÂÆö‰πâ‰∏∫‰∏ã‰∏ÄÂ∏ßÁöÑÁõÆÊ†áÂÖ≥ËäÇ‰ΩçÁΩÆ„ÄÇÊâßË°åÊó∂ÈááÁî®Èó≠ÁéØÊéßÂà∂ÔºåÊåÅÁª≠ÊñΩÂä†ËØ•Âä®‰ΩúÁõ¥Ëá≥Êú∫Âô®‰∫∫Âà∞ËææÁõÆÊ†á‰ΩçÁΩÆ„ÄÇ<br><br>**ËßÇÊµãÁîüÊàê**Ôºö<br>1. **Êú¨‰ΩìÊÑüÁü•ËßÇÊµã**ÔºöÁõ¥Êé•ÂèñËá™ÂØπÈΩêÂêéÁöÑËΩ®ËøπÔºå`(oÃÇ_t^{arm}, oÃÇ_t^{ee}) = qÃÇ_t`„ÄÇ<br>2. **ÁÇπ‰∫ëËßÇÊµãÂêàÊàê**Ôºö<br>   - **Ë£ÅÂâ™**ÔºöÁßªÈô§Â∑•‰ΩúÁ©∫Èó¥Â§ñÁöÑÁÇπÔºåÂπ∂**Êé©Á†Å**ÊéâË∑ùÁ¶ªÊ∫êÊú∫Âô®‰∫∫ÁΩëÊ†ºË°®Èù¢Â∞è‰∫éÈòàÂÄº `œÑ` ÁöÑÁÇπÔºàÈò≤Ê≠¢Ê∫êÊú∫Âô®‰∫∫ÈÅÆÊå°ÁõÆÊ†áËßÜËßíÔºâ„ÄÇ<br>   - **Â¢ûÂº∫**ÔºöÊ†πÊçÆÂΩìÂâçÂÖ≥ËäÇÁä∂ÊÄÅ `qÃÇ_t`Ôºå‰ªéÁõÆÊ†áÊú∫Âô®‰∫∫ÁΩëÊ†ºË°®Èù¢ÈááÊ†∑ÁÇπÔºåÊ∑ªÂä†Âà∞ÁÇπ‰∫ë‰∏≠„ÄÇ<br>   - **ÈôçÈááÊ†∑**Ôºö‰ΩøÁî®ÊúÄËøúÁÇπÈááÊ†∑Â∞ÜÁÇπ‰∫ëÂõ∫ÂÆöÂà∞1024‰∏™ÁÇπ„ÄÇ | - **Ë∑ùÁ¶ªÈòàÂÄº `œÑ`**Ôºö‰æãÂ¶Ç 5 mmÔºåÁî®‰∫éÁ°ÆÂÆöÈúÄË¶ÅÊé©Á†ÅÁöÑÊ∫êÊú∫Âô®‰∫∫ÈôÑËøëÁÇπ‰∫ëÂå∫Âüü„ÄÇ<br>- **ÁÇπ‰∫ëÂ§ßÂ∞è**ÔºöÂõ∫ÂÆö‰∏∫ `[1024, 3]`„ÄÇ<br>- **Êé®ÁêÜÊó∂‰∏ÄËá¥ÊÄß**ÔºöÊµãËØïÊó∂ÂØπÁúüÂÆûËßÇÊµãÂ∫îÁî®Áõ∏ÂêåÁöÑÊé©Á†ÅÂíåÂ¢ûÂº∫ÊµÅÁ®ãÔºåÁ°Æ‰øùËÆ≠ÁªÉ‰∏éÊµãËØïÁöÑËßÇÊµãÂàÜÂ∏É‰∏ÄËá¥„ÄÇ |\n| **5. Êâ©Â±ïÂ∫îÁî®ÔºöÁ©∫Èó¥Ê≥õÂåñ** | ‰ªéÂçïÊù°ÊºîÁ§∫ËΩ®ËøπÔºåÈÄöËøáÁ©∫Èó¥ÂèòÊç¢ÁîüÊàêË¶ÜÁõñÊï¥‰∏™Â∑•‰ΩúÁ©∫Èó¥ÁöÑÂ§öÊ†∑ÂåñÊºîÁ§∫Êï∞ÊçÆ„ÄÇ | ÁªôÂÆö‰∏Ä‰∏™Á©∫Èó¥ÂèòÊç¢ `ùíØ_i`ÔºàÂ¶ÇÂπ≥ÁßªÔºâÔºåÈ¶ñÂÖàÂØπÊ∫êÂäüËÉΩË°®Á§∫ËΩ®ËøπËøõË°å**Ê∏êËøõÂºèÊèíÂÄº**Ôºö<br>```math<br>XÃÉ_t = X_t + ‚Ñí(t)¬∑(ùíØ_i(X_t) - X_t), t=0,1,...,L-1<br>```<br>ÂÖ∂‰∏≠ `‚Ñí(t) = min(t/(0.8L), 1)` ÊòØ‰∏Ä‰∏™Ë£ÅÂâ™Á∫øÊÄßÂ¢ûÈïøÂáΩÊï∞„ÄÇ<br>**ÂéüÁêÜ**Ôºö<br>- Âú®ËΩ®ËøπÂàùÊúü (`t` ËæÉÂ∞è)Ôºå`‚Ñí(t)‚âà0`Ôºå`XÃÉ_t ‚âà X_t`Ôºå‰øùËØÅÊâÄÊúâÁîüÊàêËΩ®ËøπÁöÑ**ÂàùÂßãÁä∂ÊÄÅÁõ∏Âêå**„ÄÇ<br>- Âú®ËΩ®ËøπÂêéÊúü (`t` Êé•Ëøë `L`)Ôºå`‚Ñí(t)=1`Ôºå`XÃÉ_t = ùíØ_i(X_t)`Ôºå‰ΩøÂæóËΩ®Ëøπ**ÊúÄÁªàÁä∂ÊÄÅ**Ê†πÊçÆÂèòÊç¢ `ùíØ_i` ÂèëÁîüÂèòÂåñ„ÄÇ<br>- ÈöèÂêéÔºå‰ΩøÁî®Ê†áÂáÜÁöÑCEIËΩ®ËøπÂØπÈΩêÊµÅÁ®ãÔºåÂ∞ÜÁõÆÊ†áÊú∫Âô®‰∫∫‰∏éËøô‰∏™‚ÄúÁ©∫Èó¥Â¢ûÂº∫Âêé‚ÄùÁöÑËΩ®Ëøπ `{XÃÉ_t}` ÂØπÈΩêÔºåÂπ∂ÂêàÊàêÁõ∏Â∫îÁöÑÁÇπ‰∫ëÔºàÂØπÁâ©‰ΩìÁÇπ‰∫ëÂ∫îÁî® `ùíØ_i`Ôºâ„ÄÇ | - **ÊèíÂÄºÂáΩÊï∞**Ôºö‰ΩøÁî®Âú®80%ËΩ®ËøπÈïøÂ∫¶Â§ÑÈ•±ÂíåÁöÑÁ∫øÊÄßÂáΩÊï∞ÔºåÁ°Æ‰øù‰ªªÂä°ÂêéÂçäÊÆµÂÆåÂÖ®ÊâßË°åÂèòÊç¢ÂêéÁöÑÂä®‰Ωú„ÄÇ |\n| **6. Êâ©Â±ïÂ∫îÁî®ÔºöÂ§öÊ®°ÊÄÅËøêÂä®ÁîüÊàê** | Âà©Áî®ÂäüËÉΩÁõ∏‰ººÊÄßÂ∫¶ÈáèÁöÑÂ§öËß£ÁâπÊÄßÔºå‰ªéÂçïÊù°Ê∫êÊºîÁ§∫ÁîüÊàêÂ§öÁßçÂèØË°åÁöÑÁõÆÊ†áÊú∫Âô®‰∫∫ËøêÂä®Ê®°Âºè„ÄÇ | **Á≤æËã±ÂàùÂßãÂåñÁ≠ñÁï•**Ôºö<br>1. ‰ªéÁõÆÊ†áÊú∫Âô®‰∫∫ÁöÑÂÖ≥ËäÇÁ©∫Èó¥‰∏≠ÂùáÂåÄÈááÊ†∑Â§ßÈáèÂàùÂßãÈÖçÁΩÆÂÄôÈÄâ„ÄÇ<br>2. ËÆ°ÁÆóÊØè‰∏™ÂÄôÈÄâÈÖçÁΩÆÁöÑÂäüËÉΩË°®Á§∫‰∏éÊ∫êÊú∫Âô®‰∫∫ÂàùÂßãÂäüËÉΩË°®Á§∫ÁöÑ `-",
      "timestamp": "2026-01-20T18:00:45.959228",
      "thinking": null,
      "is_reasoning": false,
      "parent_qa_id": null
    },
    {
      "question": "‰ªñ‰ΩøÁî®‰∫ÜÂì™‰∫õËØÑ‰ª∑ÊåáÊ†á‰∏éÊï∞ÊçÆÈõÜÔºåÂàóË°®Ê†ºÂÖ∑‰ΩìËÆ≤ËÆ≤‰ªñÁöÑËØÑ‰ª∑ÊåáÊ†áÁöÑÁªÜËäÇ‰∏éÊï∞ÊçÆÈõÜÁöÑÁªÜËäÇ",
      "answer": "## ËÆ∫ÊñáËØÑ‰ª∑ÊåáÊ†á‰∏éÊï∞ÊçÆÈõÜÂàÜÊûê\n\n### ‰∏Ä„ÄÅ ‰∏ªË¶ÅËØÑ‰ª∑ÊåáÊ†á\n\nËÆ∫ÊñáÈááÁî®ÁöÑÊ†∏ÂøÉËØÑ‰ª∑ÊåáÊ†áÊòØ**‰ªªÂä°ÊàêÂäüÁéá**ÔºåÂπ∂Âú®‰∏çÂêåÂÆûÈ™åËÆæÁΩÆ‰∏ãËøõË°å‰∫ÜÁªÜÂåñÂíåÂØπÊØî„ÄÇÂÖ∑‰ΩìÊåáÊ†áÁªÜËäÇÂ¶Ç‰∏ãË°®ÊâÄÁ§∫Ôºö\n\n| ËØÑ‰ª∑ÊåáÊ†á | ËÆ°ÁÆóÊñπÂºè‰∏éÁªÜËäÇ | ÂÆûÈ™åÂú∫ÊôØ | ‰ΩúÁî®‰∏éËØ¥Êòé |\n| :--- | :--- | :--- | :--- |\n| **‰ªªÂä°ÊàêÂäüÁéá** | ÊàêÂäüÂÆåÊàê‰ªªÂä°ÁöÑËØïÈ™åÊ¨°Êï∞ / ÊÄªËØïÈ™åÊ¨°Êï∞„ÄÇ | ‰ªøÁúü‰∏éÁúüÂÆû‰∏ñÁïåÂÆûÈ™åÁöÑÊ†∏ÂøÉÊåáÊ†á„ÄÇ | Áõ¥Êé•Ë°°Èáè**Ë∑®ÂÖ∑Ë∫´Êï∞ÊçÆÂêàÊàê**Âíå**Á≠ñÁï•Â≠¶‰π†**ÁöÑÊúâÊïàÊÄß„ÄÇÂú®‰ªøÁúü‰∏≠ÈÄöËøáÊ®°ÊãüÂô®ÂõûÊîæÈ™åËØÅËΩ®ËøπÂèØË°åÊÄßÔºåÂú®ÁúüÂÆû‰∏ñÁïå‰∏≠ÈÄöËøáÁ≠ñÁï•ÈÉ®ÁΩ≤ËØÑ‰º∞ÊúÄÁªàÊÄßËÉΩ„ÄÇ |\n| **Ë∑®ÂÖ∑Ë∫´ËΩ¨ÁßªÁéá** | (ÁõÆÊ†áÂÖ∑Ë∫´Á≠ñÁï•ÊàêÂäüÁéá) / (Ê∫êÂÖ∑Ë∫´Á≠ñÁï•ÊàêÂäüÁéá) √ó 100%„ÄÇ | ÁúüÂÆû‰∏ñÁïåÂèåÂêëËΩ¨ÁßªÂÆûÈ™åÔºàË°® VÔºâ„ÄÇ | ÈáèÂåñ**CEIÊ°ÜÊû∂ÁöÑËΩ¨ÁßªÊïàÁéá**ÔºåË°°ÈáèÂú®ÂÖãÊúçÂÖ∑Ë∫´Â∑ÆÂºÇÂêéÔºåÁõÆÊ†áÊú∫Âô®‰∫∫ËÉΩ‰øùÁïôÊ∫êÊú∫Âô®‰∫∫ÊÄßËÉΩÁöÑÁôæÂàÜÊØî„ÄÇËÆ∫Êñá‰∏≠Âπ≥ÂùáËææÂà∞ **82.4%**„ÄÇ |\n| **Êó∂Èó¥ÊàêÊú¨** | ÁîüÊàêÊåáÂÆöÊï∞ÈáèÊºîÁ§∫ÊâÄÈúÄÁöÑÊÄªÊó∂Èó¥ÔºàÁßí/ÂàÜÈíü/Â∞èÊó∂Ôºâ„ÄÇ | ÁúüÂÆû‰∏ñÁïåÊï∞ÊçÆÁîüÊàêÊïàÁéáÂØπÊØîÔºàË°® VIÔºâ„ÄÇ | ËØÑ‰º∞**CEIÁöÑÁ¶ªÁ∫øÊï∞ÊçÆÁîüÊàêÊïàÁéá**Ôºå‰∏éÂú®Á∫øÊñπÊ≥ïÔºàMimicGenÔºâÂíåÂø´ÈÄüËΩ®ËøπÂèòÊç¢ÊñπÊ≥ïÔºàDemoGenÔºâËøõË°åÂØπÊØî„ÄÇ |\n| **ÂØπÈΩêÊçüÂ§±** | ÂÖ¨Âºè(2): `‚Ñí_align = w1 * DCD(X_t, X'_t) + w2 * ‚Ñí(q'_t)`„ÄÇ | ËΩ®ËøπÂØπÈΩê‰ºòÂåñËøáÁ®ã„ÄÇ | **ÂÜÖÈÉ®‰ºòÂåñÊåáÊ†á**ÔºåÁî®‰∫éÊ¢ØÂ∫¶‰∏ãÈôçÔºåÁ°Æ‰øùÁõÆÊ†áÊú∫Âô®‰∫∫ÁöÑÂäüËÉΩË°®Á§∫‰∏éÊ∫êÊú∫Âô®‰∫∫ÂØπÈΩêÔºåÂêåÊó∂Êª°Ë∂≥ÂÖ≥ËäÇÈôêÂà∂„ÄÇDCDÔºàÂÆöÂêëÂÄíËßíË∑ùÁ¶ªÔºâÊòØÊ†∏ÂøÉÁõ∏‰ººÂ∫¶Â∫¶Èáè„ÄÇ |\n\n**ÂÖ≥ÈîÆÊåáÊ†áÊ∑±Â∫¶Ëß£ÊûêÔºö**\n- **ÂÆöÂêëÂÄíËßíË∑ùÁ¶ª**Ôºö ËøôÊòØ**CEI**ÁöÑÊäÄÊúØÊ†∏ÂøÉÔºåÁî®‰∫éÈáèÂåñ‚ÄúÂäüËÉΩÁõ∏‰ººÊÄß‚Äù„ÄÇÂÆÉ‰∏ç‰ªÖËÆ°ÁÆóÁÇπ‰∫ëÁöÑÁ©∫Èó¥Ë∑ùÁ¶ªÔºà`||p_i - p'_j||_2`ÔºâÔºåËøòÂä†ÂÖ•‰∫ÜÊñπÂêëÂØπÈΩêÈ°πÔºà`-Œª¬∑<n_i, n'_j>`Ôºâ„ÄÇËøô‰ΩøÂæóÂåπÈÖçËøáÁ®ãÊõ¥ÂÖ≥Ê≥®**Êé•Ëß¶ÁÇπÁöÑÊ≥ïÁ∫øÊñπÂêë**ÔºåÂØπ‰∫éÊäìÂèñÁ≠âÈúÄË¶ÅÁâπÂÆöÊé•Ëß¶ÂäõÂêëÁöÑ‰ªªÂä°Ëá≥ÂÖ≥ÈáçË¶ÅÔºàËßÅÊ∂àËûçÂÆûÈ™åË°®IIÔºâ„ÄÇ\n- **ÊàêÂäüÁéáÁöÑÂàÜÂ±ÇËØÑ‰º∞**Ôºö ÂÆûÈ™åËÆæËÆ°Â∑ßÂ¶ôÂú∞Âå∫ÂàÜ‰∫Ü **‚ÄúËΩ®ËøπÂèØË°åÊÄß‚Äù**Ôºà‰ªøÁúü‰∏≠Áõ¥Êé•ÂõûÊîæÂêàÊàêËΩ®ËøπÔºâÂíå **‚ÄúÁ≠ñÁï•ÊÄßËÉΩ‚Äù**ÔºàÁî®ÂêàÊàêÊï∞ÊçÆËÆ≠ÁªÉÁ≠ñÁï•Âπ∂ËØÑ‰º∞Ôºâ„ÄÇËøôÂàÜÂà´È™åËØÅ‰∫Ü**Êï∞ÊçÆÂêàÊàêË¥®Èáè**Âíå**Á≠ñÁï•Â≠¶‰π†ÊïàÊûú**„ÄÇ\n\n### ‰∫å„ÄÅ ‰ΩøÁî®ÁöÑÊï∞ÊçÆÈõÜ\n\nËÆ∫ÊñáÂ∑•‰Ωú‰∏ªË¶ÅÂü∫‰∫é**Ëá™Ë°åÊî∂ÈõÜÁöÑÊºîÁ§∫Êï∞ÊçÆ**ÔºåÂπ∂Âà©Áî®**CEI**ÂØπÂÖ∂ËøõË°åË∑®ÂÖ∑Ë∫´ÂêàÊàêÔºåËÄåÈùûÁõ¥Êé•‰ΩøÁî®Áé∞ÊúâÂ§ßÂûãÊï∞ÊçÆÈõÜ„ÄÇÊï∞ÊçÆÁªÜËäÇÂ¶Ç‰∏ãÔºö\n\n| Êï∞ÊçÆÈõÜÁ±ªÂûã | Ê∫êÊú∫Âô®‰∫∫ | ‰ªªÂä°‰∏éÊï∞Èáè | Êï∞ÊçÆÂÜÖÂÆπ‰∏éÊ†ºÂºè | Áî®ÈÄî |\n| :--- | :--- | :--- | :--- | :--- |\n| **‰ªøÁúüÊ∫êÊï∞ÊçÆ** | Franka Panda (Â∏¶Âπ≥Ë°åÂ§πÁà™) | 3‰∏™‰ªªÂä°ÔºöOpenDrawer, PickCube, StackCube„ÄÇÈÄöËøáÈÅ•Êìç‰ΩúÊî∂ÈõÜÊºîÁ§∫„ÄÇ | - **ËßÇÊµã**Ôºö ÁÇπ‰∫ë (`o_t^pcd`)„ÄÅÊú∫Ê¢∞ËáÇÂÖ≥ËäÇÁä∂ÊÄÅ (`o_t^arm`)„ÄÅÊú´Á´ØÊâßË°åÂô®Áä∂ÊÄÅ (`o_t^ee`)„ÄÇ<br>- **Âä®‰Ωú**Ôºö Êú∫Ê¢∞ËáÇÂíåÊú´Á´ØÊâßË°åÂô®ÁöÑÁõÆÊ†áÂÖ≥ËäÇ‰ΩçÁΩÆ (`a_t^arm`, `a_t^ee`)„ÄÇ | ‰Ωú‰∏∫**Ê∫êÊºîÁ§∫**ÔºåÁî®‰∫éÂêë**16Áßç**ÁõÆÊ†áÂÖ∑Ë∫´Ôºà4ÁßçÊú∫Ê¢∞ËáÇ √ó 4ÁßçÊú´Á´ØÊâßË°åÂô®ÔºâËøõË°åËΩ¨ÁßªÂíåÁ≠ñÁï•ËÆ≠ÁªÉ„ÄÇ |\n| **ÁúüÂÆû‰∏ñÁïåÊ∫êÊï∞ÊçÆ** | 1. UR5 + AG95 Âπ≥Ë°åÂ§πÁà™<br>2. UR5 + Xhand ‰∫îÊåáÁÅµÂ∑ßÊâã | 6‰∏™‰ªªÂä°ÔºåÂèåÂêëËΩ¨ÁßªÔºö<br>- AG95‚ÜíXhand: PushCube, OpenDrawer, PlaceBird (ÂêÑ25Êù°ÊºîÁ§∫)<br>- Xhand‚ÜíAG95: PickCup, PackageBread, InsertFlower (ÂêÑ25Êù°ÊºîÁ§∫) | - **ËßÇÊµã**Ôºö Áî±RealSense L515 RGB-DÁõ∏Êú∫ÁîüÊàêÁöÑÂú∫ÊôØÁÇπ‰∫ëÔºå‰ª•ÂèäÊú∫Âô®‰∫∫Êú¨‰ΩìÊÑüÁä∂ÊÄÅ„ÄÇ<br>- **Âä®‰Ωú**Ôºö ÂÖ≥ËäÇ‰ΩçÁΩÆÁõÆÊ†á„ÄÇÈÄöËøáÈîÆÁõòÈÅ•Êìç‰ΩúÊî∂ÈõÜ„ÄÇ | Áî®‰∫éÈ™åËØÅ**CEIÂú®ÁúüÂÆûÂ§çÊùÇÂú∫ÊôØ‰∏ãÁöÑÂèåÂêëË∑®ÂÖ∑Ë∫´ËΩ¨ÁßªËÉΩÂäõ**Ôºå‰ªéÁÆÄÂçïÂ§πÁà™Âà∞ÁÅµÂ∑ßÊâãÔºåÂèç‰πã‰∫¶ÁÑ∂„ÄÇ |\n| **ÂêàÊàêÊï∞ÊçÆÔºàÁî±CEIÁîüÊàêÔºâ** | Â§öÁßçÁõÆÊ†áÊú∫Âô®‰∫∫Ôºà‰ªøÁúü16ÁßçÔºåÁúüÂÆû‰∏ñÁïå2ÁßçÔºâ | ‰∏éÊ∫ê‰ªªÂä°ÂØπÂ∫îÔºåÈÄöËøá**CEI**Ê°ÜÊû∂Ëá™Âä®ÂêàÊàê„ÄÇ | Ê†ºÂºè‰∏éÊ∫êÊï∞ÊçÆ‰∏ÄËá¥ÔºåÂåÖÂê´‰∏∫ÁõÆÊ†áÊú∫Âô®‰∫∫ÂêàÊàêÁöÑÁÇπ‰∫ëËßÇÊµã„ÄÅÂÖ≥ËäÇÁä∂ÊÄÅËßÇÊµãÂíåÂÖ≥ËäÇÂä®‰Ωú„ÄÇ | 1. **Áõ¥Êé•ËØÑ‰º∞**ÔºöÂú®‰ªøÁúü‰∏≠ÂõûÊîæÔºåÈ™åËØÅÂêàÊàêËΩ®ËøπÁöÑÂèØË°åÊÄßÔºàË°®IÔºâ„ÄÇ<br>2. **Á≠ñÁï•ËÆ≠ÁªÉ**Ôºö‰Ωú‰∏∫ËÆ≠ÁªÉÈõÜÔºåÁî®‰∫éËÆ≠ÁªÉ3D Diffusion PolicyÔºåËØÑ‰º∞ÊúÄÁªàÁ≠ñÁï•ÊÄßËÉΩÔºàË°®IV, VÔºâ„ÄÇ |\n| **Á©∫Èó¥Ê≥õÂåñÂêàÊàêÊï∞ÊçÆ** | AG95 ‚Üí Xhand | PressButton‰ªªÂä°„ÄÇ‰ªé**1Êù°**Ê∫êÊºîÁ§∫ÔºåÈÄöËøáÁ©∫Èó¥ÂèòÊç¢ÁîüÊàê**1000Êù°**ÊºîÁ§∫ÔºåÂàÜÂ∏ÉÂú®10‰∏™ÈîöÁÇπÂë®Âõ¥ÁöÑ10x10ÁΩëÊ†º‰∏ä„ÄÇ | Â∫îÁî®Á©∫Èó¥ÂèòÊç¢ `ùíØ_i` ÂØπÂäüËÉΩË°®Á§∫ËΩ®ËøπÂíåÁâ©‰ΩìÁÇπ‰∫ëËøõË°åÊèíÂÄºÔºåÂÜçÂà©Áî®CEIÁîüÊàêÂØπÂ∫îÁõÆÊ†áÊú∫Âô®‰∫∫ÁöÑÂÖ®Â•óÊï∞ÊçÆ„ÄÇ | Áî®‰∫éÈ™åËØÅ**CEIÊîØÊåÅ‰ªéÂçïÊù°ÊºîÁ§∫ËøõË°åÂ§ßËßÑÊ®°Á©∫Èó¥Êï∞ÊçÆÂ¢ûÂº∫**ÁöÑËÉΩÂäõÔºåÊòæËëóÊèêÂçáÁ≠ñÁï•ÁöÑÂ∑•‰ΩúÁ©∫Èó¥Ê≥õÂåñÊÄßËÉΩÔºàÂõæ6Ôºâ„ÄÇ |\n\n**Êï∞ÊçÆÈõÜÂÖ≥ÈîÆÁÇπÂàÜÊûêÔºö**\n- **Ëß£ÂÜ≥Êï∞ÊçÆÂÅèÂ∑ÆÈóÆÈ¢ò**Ôºö ÂΩìÂâçÂ§ßÂûãÊú∫Âô®‰∫∫Êï∞ÊçÆÈõÜÔºàÂ¶ÇOXEÔºâÂ≠òÂú®‰∏•ÈáçÂÅèÂ∑ÆÔºåËøáÂ∫¶ÈõÜ‰∏≠‰∫éFranka/xArmÂíåÂπ≥Ë°åÂ§πÁà™„ÄÇ**CEI**ÁöÑÂàõÊñ∞Âú®‰∫éÔºå**Êó†ÈúÄ‰∏∫ÁõÆÊ†áÂÖ∑Ë∫´ÔºàÂ∞§ÂÖ∂ÊòØÁ®ÄÁº∫ÁöÑÁÅµÂ∑ßÊâãÔºâÊî∂ÈõÜ‰ªª‰ΩïÁúüÂÆûÊï∞ÊçÆ**ÔºåÂç≥ÂèØ‰ªé‰∏∞ÂØåÁöÑÂ§πÁà™Êï∞ÊçÆ‰∏≠ÂêàÊàêÂá∫ÂèØÁî®ÊºîÁ§∫„ÄÇ\n- **‰ªøÁúüÂà∞ÁúüÂÆûÁöÑ‰∏ÄËá¥ÊÄß**Ôºö Âú®‰ªøÁúüÂíåÁúüÂÆû‰∏ñÁïåÂÆûÈ™å‰∏≠ÔºåÊï∞ÊçÆÊ®°ÊÄÅ‰øùÊåÅÁªü‰∏ÄÔºà‰ª•**ÁÇπ‰∫ë**‰∏∫Ê†∏ÂøÉËßÜËßâËßÇÊµãÔºâÔºåÁ°Æ‰øù‰∫ÜÊñπÊ≥ïÈ™åËØÅÁöÑËøûË¥ØÊÄßÂíåÁªìËÆ∫ÁöÑÂèØÈù†ÊÄß„ÄÇ\n- **‰ªªÂä°ËÆæËÆ°ÂÖ∑ÊúâÊ¢ØÂ∫¶ÈöæÂ∫¶**Ôºö ‰ªéÁÆÄÂçïÁöÑÊé®Âä®ÔºàPushCubeÔºâÂà∞ÈúÄË¶ÅÁ®≥ÂÆöÊäìÂèñÂíåÊîæÁΩÆÁöÑÂ§çÊùÇ‰ªªÂä°ÔºàPlaceBird, InsertFlowerÔºâÔºå‰ªªÂä°ÈöæÂ∫¶ÈÄíÂ¢ûÔºåÂÖ®Èù¢Ê£ÄÈ™å‰∫ÜÊñπÊ≥ïÂú®**‰∏çÂêåÊé•Ëß¶‰∏∞ÂØåÂ∫¶**Âú∫ÊôØ‰∏ãÁöÑÊúâÊïàÊÄßÔºàÂ¶ÇË°®IÁªìÊûúÂàÜÊûêÊâÄÁ§∫Ôºâ„ÄÇ",
      "timestamp": "2026-01-20T18:01:31.016634",
      "thinking": null,
      "is_reasoning": false,
      "parent_qa_id": null
    },
    {
      "question": "ËÆ∫ÊñáÂú®Âì™‰∫õÊï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜÂÆûÈ™åÔºü‰∏ªË¶ÅÁöÑËØÑ‰º∞ÊåáÊ†áÂíåÊÄßËÉΩÊèêÂçáÊòØÂ§öÂ∞ëÔºü",
      "answer": "## ËÆ∫ÊñáÂÆûÈ™åÊï∞ÊçÆÈõÜ‰∏éËØÑ‰º∞ÊåáÊ†áÂàÜÊûê\n\n### ‰∏Ä„ÄÅÂÆûÈ™åÊï∞ÊçÆÈõÜ\nËÆ∫ÊñáÂú®**‰ªøÁúü**Âíå**ÁúüÂÆû‰∏ñÁïå**‰∏§ÁßçÁéØÂ¢É‰∏ãËøõË°å‰∫ÜÂÆûÈ™åÔºåÂÖ∑‰ΩìÊï∞ÊçÆÈõÜÊûÑÂª∫Â¶Ç‰∏ãÔºö\n\n#### 1. **‰ªøÁúüÂÆûÈ™åÊï∞ÊçÆÈõÜ**\n- **‰ªªÂä°**Ôºö3‰∏™Âü∫Á°ÄÊìç‰Ωú‰ªªÂä°  \n  - `OpenDrawer`ÔºàÊâìÂºÄÊäΩÂ±âÔºâ  \n  - `PickCube`ÔºàÊäìÂèñÁ´ãÊñπ‰ΩìÔºâ  \n  - `StackCube`ÔºàÂ†ÜÂè†Á´ãÊñπ‰ΩìÔºâ  \n- **Êú∫Âô®‰∫∫ÂΩ¢ÊÄÅ**Ôºö16Áßç‰∏çÂêåÁöÑÊú∫Âô®‰∫∫ÁªÑÂêà  \n  - **Êú∫Ê¢∞ËáÇ**ÔºöUR5e„ÄÅIIWA„ÄÅKinova3„ÄÅFranka PandaÔºàÂÖ±4ÁßçÔºâ  \n  - **Êú´Á´ØÊâßË°åÂô®**ÔºöFourierRightHand„ÄÅInspireRightHand„ÄÅFourierLeftHand„ÄÅRobotiqThreeFingerÔºàÂÖ±4ÁßçÔºâ  \n- **Êï∞ÊçÆÊù•Ê∫ê**Ôºö‰ΩøÁî®Franka PandaÊú∫Âô®‰∫∫ÈÄöËøáÈÅ•Êìç‰ΩúÊî∂ÈõÜÊºîÁ§∫Êï∞ÊçÆÔºåÂπ∂ÈÄöËøáCEIÊ°ÜÊû∂ËøÅÁßªÂà∞ÂÖ∂‰ªñ15ÁßçÊú∫Âô®‰∫∫ÂΩ¢ÊÄÅ„ÄÇ\n\n#### 2. **ÁúüÂÆû‰∏ñÁïåÂÆûÈ™åÊï∞ÊçÆÈõÜ**\n- **‰ªªÂä°**Ôºö6‰∏™Êìç‰Ωú‰ªªÂä°ÔºàÂàÜ‰∏∫‰∏§ÁªÑÔºâ  \n  - **AG95Âπ≥Ë°åÂ§πÁà™ ‚Üí XhandÁÅµÂ∑ßÊâã**Ôºö  \n    - `PushCube`ÔºàÊé®Âä®Á´ãÊñπ‰ΩìÔºâ  \n    - `OpenDrawer`ÔºàÊâìÂºÄÊäΩÂ±âÔºâ  \n    - `PlaceBird`ÔºàÊîæÁΩÆÁé©ÂÖ∑È∏üÔºâ  \n  - **XhandÁÅµÂ∑ßÊâã ‚Üí AG95Âπ≥Ë°åÂ§πÁà™**Ôºö  \n    - `PickCup`ÔºàÊäìÂèñÊùØÂ≠êÔºâ  \n    - `PackageBread`ÔºàÂåÖË£ÖÈù¢ÂåÖÔºâ  \n    - `InsertFlower`ÔºàÊèíÂÖ•Ëä±ÊùüÔºâ  \n- **Êú∫Âô®‰∫∫Âπ≥Âè∞**ÔºöUR5Êú∫Ê¢∞ËáÇ + AG95Â§πÁà™ / XhandÁÅµÂ∑ßÊâã  \n- **Êï∞ÊçÆÊî∂ÈõÜ**ÔºöÈÄöËøáÈîÆÁõòÈÅ•Êìç‰ΩúÊî∂ÈõÜ25Êù°ÊºîÁ§∫ËΩ®ËøπÔºå‰ΩøÁî®RGB-DÁõ∏Êú∫ÔºàRealSense L515ÔºâÁîüÊàêÂú∫ÊôØÁÇπ‰∫ë„ÄÇ\n\n---\n\n### ‰∫å„ÄÅ‰∏ªË¶ÅËØÑ‰º∞ÊåáÊ†á\n1. **ÊàêÂäüÁéáÔºàSuccess RateÔºâ**  \n   - Âú®‰ªøÁúüÂíåÁúüÂÆû‰∏ñÁïå‰∏≠ÔºåÈÄöËøá**Âú®Á∫øÂõûÊîæÂêàÊàêËΩ®Ëøπ**Êàñ**ÈÉ®ÁΩ≤ËÆ≠ÁªÉÂ•ΩÁöÑÁ≠ñÁï•**Êù•ËØÑ‰º∞‰ªªÂä°ÂÆåÊàêÊÉÖÂÜµ„ÄÇ\n   - ‰ªøÁúüÔºöÊØè‰∏™‰ªªÂä°-Êú∫Âô®‰∫∫ÁªÑÂêàËøõË°å20Ê¨°ËØïÈ™åÔºåËÆ°ÁÆóÂπ≥ÂùáÊàêÂäüÁéá„ÄÇ\n   - ÁúüÂÆû‰∏ñÁïåÔºöÊØè‰∏™‰ªªÂä°ËøõË°å10Ê¨°ËØïÈ™åÔºåËÆ°ÁÆóÊàêÂäüÁéá„ÄÇ\n\n2. **ËøÅÁßªÊØîÁéáÔºàTransfer RatioÔºâ**  \n   - ÂÆö‰πâÔºö`ËøÅÁßªÂêéÊàêÂäüÁéá / Ê∫êÊú∫Âô®‰∫∫ÊàêÂäüÁéá`„ÄÇ\n   - Áî®‰∫éÈáèÂåñË∑®ÂΩ¢ÊÄÅËøÅÁßªÁöÑÊÄßËÉΩ‰øùÊåÅÁ®ãÂ∫¶„ÄÇ\n\n3. **Êó∂Èó¥ÊàêÊú¨ÔºàTime CostÔºâ**  \n   - ÊµãÈáèÁîüÊàê100‚Äì400Êù°ÊºîÁ§∫ÊâÄÈúÄÁöÑÊó∂Èó¥Ôºå‰∏éÂü∫Á∫øÊñπÊ≥ïÔºàMimicGen„ÄÅDemoGenÔºâÂØπÊØî„ÄÇ\n\n---\n\n### ‰∏â„ÄÅÊÄßËÉΩÊèêÂçá‰∏éÂÖ≥ÈîÆÁªìÊûú\n\n#### 1. **‰ªøÁúüÂÆûÈ™åÁªìÊûú**\n- **Êï¥‰ΩìÊàêÂäüÁéá**ÔºöCEIÂú®16ÁßçÊú∫Âô®‰∫∫ÂΩ¢ÊÄÅ‰∏äÂπ≥ÂùáÊàêÂäüÁéáËææÂà∞**62%**ÔºàÁ≠ñÁï•ËØÑ‰º∞ÁªìÊûúÔºâ„ÄÇ\n- **Ë∑®ÂΩ¢ÊÄÅËøÅÁßªÊúâÊïàÊÄß**Ôºö  \n  - ‰ªéÂπ≥Ë°åÂ§πÁà™Âà∞ÁÅµÂ∑ßÊâãÁöÑËøÅÁßª‰∏≠Ôºå`OpenDrawer`‰ªªÂä°ÊàêÂäüÁéáÊúÄÈ´òÔºàÂπ≥Âùá95%ÔºâÔºå`StackCube`ËæÉ‰ΩéÔºàÂπ≥Âùá32%ÔºâÔºåËØ¥Êòé‰ªªÂä°Êé•Ëß¶Â§çÊùÇÂ∫¶ÂΩ±ÂìçËøÅÁßªÈöæÂ∫¶„ÄÇ\n  - **Ê∂àËûçÂÆûÈ™å**ÔºöCEIÂÆåÊï¥ÊñπÊ≥ïÁõ∏ÊØî**Êó†ÊñπÂêë‰ø°ÊÅØ**ÁöÑÁâàÊú¨ÔºåÊàêÂäüÁéáÊèêÂçáÁ∫¶‰∏ÄÂÄçÔºà65% vs. 32%ÔºâÔºõÁõ∏ÊØî**ÊâãÂä®Á∫øÊÄßÊèíÂÄºÔºàBMSÔºâ**ÔºåÂú®ÊäìÂèñ‰ªªÂä°‰∏ä‰ªé0%ÊèêÂçáËá≥65%„ÄÇ\n\n#### 2. **ÁúüÂÆû‰∏ñÁïåÂÆûÈ™åÁªìÊûú**\n- **ÂèåÂêëËøÅÁßªÊàêÂäüÁéá**Ôºö  \n  - AG95 ‚Üí XhandÔºöÂπ≥ÂùáÊàêÂäüÁéá **83%**Ôºà25/30Ôºâ  \n  - Xhand ‚Üí AG95ÔºöÂπ≥ÂùáÊàêÂäüÁéá **57%**Ôºà17/30Ôºâ  \n  - **Êï¥‰ΩìÂπ≥ÂùáÊàêÂäüÁéá**Ôºö**70%**Ôºà42/60Ôºâ\n- **ËøÅÁßªÊØîÁéá**Ôºö**82.4%**ÔºàÂç≥ËøÅÁßªÂêéÊÄßËÉΩËææÂà∞Ê∫êÊú∫Âô®‰∫∫ÊÄßËÉΩÁöÑ82.4%Ôºâ„ÄÇ\n- **ÊåëÊàò‰ªªÂä°**Ôºö`InsertFlower`Âõ†Áâ©‰ΩìÁªÜÂ∞èÊòìÊªëËêΩÔºåÊàêÂäüÁéáÊúÄ‰ΩéÔºàAG95: 40%, Xhand: 20%Ôºâ„ÄÇ\n\n#### 3. **ÊïàÁéáÂØπÊØî**\n- **Êï∞ÊçÆÁîüÊàêÊó∂Èó¥**Ôºö  \n  - CEIÁîüÊàê100Êù°ÊºîÁ§∫‰ªÖÈúÄ **2.5ÂàÜÈíü**ÔºåËøúÂø´‰∫éÂú®Á∫øÊñπÊ≥ïMimicGenÔºà6.4Â∞èÊó∂ÔºâÔºå‰ΩÜÊÖ¢‰∫éÁ∫ØËΩ®ËøπÂèòÊç¢ÊñπÊ≥ïDemoGenÔºà0.29ÁßíÔºâ„ÄÇ\n\n#### 4. **Êâ©Â±ïÂäüËÉΩÈ™åËØÅ**\n- **Á©∫Èó¥Ê≥õÂåñ**ÔºöÂú®`PressButton`‰ªªÂä°‰∏≠ÔºåÈÄöËøáÂçïÊù°ÊºîÁ§∫ÁîüÊàê1000Êù°Á©∫Èó¥ÂàÜÂ∏ÉÊï∞ÊçÆÔºåÁ≠ñÁï•ÂèØË¶ÜÁõñÊ°åÈù¢Â§ßÈÉ®ÂàÜÂå∫ÂüüÔºà80cm√ó80cmÔºâ„ÄÇ\n- **Â§öÊ®°ÊÄÅËøêÂä®ÁîüÊàê**ÔºöÂú®`OpenDrawer`‰ªªÂä°‰∏≠ÁîüÊàê‰∏§Áßç‰∏çÂêåÁöÑÂºÄÊäΩÂ±âÂä®‰ΩúÊ®°ÂºèÔºåÊàêÂäüÁéáÂùá‰øùÊåÅÂú®70%‰ª•‰∏ä„ÄÇ\n\n---\n\n### Âõõ„ÄÅÊ†∏ÂøÉÁªìËÆ∫\n- **ÊäÄÊúØÂàõÊñ∞‰ª∑ÂÄº**ÔºöCEIÈÄöËøá**ÂäüËÉΩÁõ∏‰ººÊÄßÂ∫¶Èáè**‰∏é**Ê¢ØÂ∫¶‰ºòÂåñÂØπÈΩê**ÔºåÈ¶ñÊ¨°ÂÆûÁé∞‰∫Ü‰ªéÂπ≥Ë°åÂ§πÁà™Âà∞Â§öÊåáÁÅµÂ∑ßÊâãÁöÑ**ÊûÅÁ´ØË∑®ÂΩ¢ÊÄÅÊºîÁ§∫ËøÅÁßª**ÔºåÂú®‰ªøÁúüÂíåÁúüÂÆû‰∏ñÁïå‰∏≠Âπ≥ÂùáËøÅÁßªÊØîÁéáË∂ÖËøá82%„ÄÇ\n- **ÂÆûÈôÖÂ∫îÁî®ÊÑè‰πâ**ÔºöÂ§ßÂπÖÈôç‰Ωé‰∫Ü‰∏∫Êñ∞ÂûãÊú∫Âô®‰∫∫Êî∂ÈõÜÊºîÁ§∫Êï∞ÊçÆÁöÑÊàêÊú¨ÔºåÂπ∂‰∏∫**Êú∫Âô®‰∫∫Âü∫Á°ÄÊ®°Âûã**Êèê‰æõ‰∫ÜË∑®ÂΩ¢ÊÄÅÊ≥õÂåñÁöÑÊï∞ÊçÆÂêàÊàêÂ∑•ÂÖ∑„ÄÇ",
      "timestamp": "2026-01-20T18:02:06.382242",
      "thinking": null,
      "is_reasoning": false,
      "parent_qa_id": null
    },
    {
      "question": "ËÆ∫ÊñáÁöÑ‰∏ªË¶ÅÂ±ÄÈôêÊÄßÊúâÂì™‰∫õÔºüÊú™Êù•ÂèØËÉΩÁöÑÊîπËøõÊñπÂêëÊòØ‰ªÄ‰πàÔºü",
      "answer": "## ËÆ∫Êñá‰∏ªË¶ÅÂ±ÄÈôêÊÄßÂàÜÊûê\n\nÂü∫‰∫éÂØπËÆ∫ÊñáÂÜÖÂÆπÁöÑÂàÜÊûêÔºå**CEI** Ê°ÜÊû∂ËôΩÁÑ∂ÂèñÂæó‰∫ÜÊòæËëóÁöÑË∑®ÂÖ∑Ë∫´Â≠¶‰π†ÊïàÊûúÔºå‰ΩÜ‰ªçÂ≠òÂú®‰ª•‰∏ãÂá†‰∏™ÂÖ≥ÈîÆÂ±ÄÈôêÊÄßÔºö\n\n### 1. **ÂØπÁâ©ÁêÜÊé•Ëß¶‰∏éÂä®ÊÄÅ‰∫§‰∫íÁöÑÂª∫Ê®°‰∏çË∂≥**\n- **ÈóÆÈ¢ò**ÔºöÊñπÊ≥ïÂü∫‰∫é**Âá†‰ΩïÂäüËÉΩÁõ∏‰ººÊÄß**ËøõË°åËΩ®ËøπÂØπÈΩêÔºå‰ΩÜÊú™ÊòæÂºèÂª∫Ê®°**Êé•Ëß¶ÂäõÂ≠¶**ÔºàÂ¶ÇÊë©Êì¶Âäõ„ÄÅÊªëÂä®„ÄÅÂäõÈó≠ÂêàÔºâ„ÄÇËøôÂú®Êé•Ëß¶‰∏∞ÂØåÁöÑ‰ªªÂä°ÔºàÂ¶Ç `StackCube`„ÄÅ`InsertFlower`Ôºâ‰∏≠Ë°®Áé∞ÊòéÊòæÔºåÊàêÂäüÁéá‰∏ãÈôç„ÄÇ\n- **Ë°®Áé∞**ÔºöÂú®ÈúÄË¶ÅÁ®≥ÂÆöÊäìÊè°ÊàñÁ≤æÁªÜÊìç‰ΩúÁöÑ‰ªªÂä°‰∏≠ÔºåÂêàÊàêÁöÑËΩ®ËøπÂèØËÉΩÂú®Áâ©ÁêÜ‰ªøÁúüÊàñÁé∞ÂÆû‰∏≠Âõ†ÊªëÂä®„ÄÅÁ¢∞ÊíûËÄåÂ§±Ë¥•„ÄÇ\n- **‰æãËØÅ**Ôºö`InsertFlower` ‰ªªÂä°‰∏≠ÔºåËä±ËåéÁªÜÊªëÔºå‰ªÖÈù†Âá†‰ΩïÂØπÈΩêÊó†Ê≥ï‰øùËØÅÁ®≥ÂÆöÊäìÊè°ÔºåÂØºËá¥ÊàêÂäüÁéá‰Ωé„ÄÇ\n\n### 2. **‰æùËµñËßÜËßâ-ËøêÂä®Â≠¶ËæìÂÖ•ÔºåÁº∫‰πèÂ§öÊ®°ÊÄÅÊÑüÁü•**\n- **ÈóÆÈ¢ò**ÔºöÂΩìÂâçÊ°ÜÊû∂‰ªÖ‰ΩøÁî®**ÁÇπ‰∫ë**Âíå**ÂÖ≥ËäÇÁä∂ÊÄÅ**‰Ωú‰∏∫ËæìÂÖ•ÔºåÁº∫‰πè**Ëß¶Ëßâ‰º†ÊÑü**Êàñ**ÂäõÂèçÈ¶à**‰ø°ÊÅØ„ÄÇ\n- **ÂΩ±Âìç**ÔºöÊó†Ê≥ïÂÆûÊó∂Ê£ÄÊµãÂíåÈÄÇÂ∫î‰∏çÁ®≥ÂÆöÁöÑÊé•Ëß¶Áä∂ÊÄÅÔºàÂ¶ÇÊªëÂä®ÔºâÔºåÈôêÂà∂‰∫ÜÂú®Âä®ÊÄÅ„ÄÅÈùûÁªìÊûÑÂåñÁéØÂ¢É‰∏≠ÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ\n\n### 3. **ËÆ°ÁÆóÊïàÁéá‰∏éÂèØÊâ©Â±ïÊÄßÊåëÊàò**\n- **ÈóÆÈ¢ò**ÔºöËôΩÁÑ∂ÊØîÂú®Á∫øÁîüÊàêÊñπÊ≥ïÔºàÂ¶Ç `MimicGen`ÔºâÂø´Ôºå‰ΩÜ**Âü∫‰∫éÊ¢ØÂ∫¶ÁöÑËΩ®ËøπÂØπÈΩê**‰ªçÈúÄÊï∞ÂàÜÈíüÁîüÊàêÊï∞ÁôæÊù°Á§∫ÊïôÔºåÈöæ‰ª•Áõ¥Êé•Â∫îÁî®‰∫é**Ë∂ÖÂ§ßËßÑÊ®°Êï∞ÊçÆÈõÜ**ÔºàÂ¶ÇÁôæ‰∏áÁ∫ßÔºâ„ÄÇ\n- **ÁªÜËäÇ**ÔºöÊØèÂ∏ßÈúÄ‰ºòÂåñÊúÄÂ§ö300Ê≠•ÔºåÂ∞ΩÁÆ°Â∑≤ÊâπÈáèÂπ∂Ë°åÔºå‰ΩÜËÆ°ÁÆóÂºÄÈîÄ‰ªçÂèØËÉΩÊàê‰∏∫Áì∂È¢à„ÄÇ\n\n### 4. **‰ªªÂä°‰∏éÂΩ¢ÊÄÅÊ≥õÂåñÁöÑËæπÁïå**\n- **ÈóÆÈ¢ò**ÔºöÂÆûÈ™åÈ™åËØÅÈõÜ‰∏≠‰∫é**ÊäìÂèñÁ±ª‰ªªÂä°**Âíå**ÁâπÂÆöÂΩ¢ÊÄÅËΩ¨Êç¢**ÔºàÂπ≥Ë°åÂ§πÁà™ ‚Üî ÁÅµÂ∑ßÊâãÔºâ„ÄÇÂØπ‰∫éÊõ¥ÊûÅÁ´ØÁöÑÂΩ¢ÊÄÅÂ∑ÆÂºÇÔºàÂ¶ÇÂ§öËáÇÊú∫Âô®‰∫∫„ÄÅÈùû‰ªø‰∫∫ÂΩ¢ÊÄÅÔºâÊàñÈùûÊäìÂèñ‰ªªÂä°ÔºàÂ¶ÇÊé®„ÄÅÊãßÔºâÁöÑÊ≥õÂåñËÉΩÂäõÊú™ÂÖÖÂàÜÈ™åËØÅ„ÄÇ\n- **ÊΩúÂú®È£éÈô©**ÔºöÂäüËÉΩÁõ∏‰ººÊÄßÂÅáËÆæÂèØËÉΩÂú®Êüê‰∫õ‰ªªÂä°-ÂΩ¢ÊÄÅÁªÑÂêà‰∏≠Â§±Êïà„ÄÇ\n\n### 5. **ÂàùÂßãÁä∂ÊÄÅ‰æùËµñ‰∏éËΩ®ËøπÂ§öÊ†∑ÊÄßÈôêÂà∂**\n- **ÈóÆÈ¢ò**ÔºöËΩ®ËøπÂØπÈΩê‰∏•Èáç‰æùËµñ**Ê∫êÁ§∫ÊïôÁöÑÂàùÂßãÁä∂ÊÄÅ**„ÄÇËôΩÁÑ∂ËÆ∫ÊñáÊèêÂá∫‰∫Ü**Á≤æËã±ÂàùÂßãÂåñÁ≠ñÁï•**Êù•Â¢ûÂä†Â§öÊ†∑ÊÄßÔºå‰ΩÜÁîüÊàêÁöÑËøêÂä®Ê®°Âºè‰ªçÂèóÈôê‰∫éÊ∫êËΩ®ËøπÁöÑÂÆèËßÇÁªìÊûÑ„ÄÇ\n- **Ë°®Áé∞**ÔºöÂ§öÊ®°ÊÄÅÁîüÊàêËÉΩÂäõÊúâÈôêÔºåÂèØËÉΩÊó†Ê≥ïË¶ÜÁõñÊâÄÊúâÂèØË°åÁöÑÁõÆÊ†áÊú∫Âô®‰∫∫ËøêÂä®Á≠ñÁï•„ÄÇ\n\n---\n\n## Êú™Êù•ÂèØËÉΩÁöÑÊîπËøõÊñπÂêë\n\n### 1. **ÈõÜÊàêÁâ©ÁêÜÊÑüÁü•‰∏éËß¶ËßâÂèçÈ¶à**\n- **ÊñπÂêë**ÔºöÂú®ÂäüËÉΩÁõ∏‰ººÊÄß‰ºòÂåñ‰∏≠ÂºïÂÖ•**Êé•Ëß¶ÂäõÊ®°Âûã**Êàñ**Ëß¶Ëßâ‰ø°Âè∑È¢ÑÊµã**„ÄÇ\n- **ÊñπÊ≥ï**Ôºö\n  - ‰ΩøÁî®**Áâ©ÁêÜ‰ªøÁúüÂô®**Êèê‰æõÊé•Ëß¶ÂäõÁõëÁù£ÔºåÊàñÂú®ÊçüÂ§±ÂáΩÊï∞‰∏≠Âä†ÂÖ•ÂäõÈó≠ÂêàÁ∫¶Êùü„ÄÇ\n  - ËûçÂêà**Ëß¶Ëßâ‰º†ÊÑüÂô®Êï∞ÊçÆ**ÔºàÂ¶Ç GelSight„ÄÅDigitÔºâÔºåÂÆûÁé∞‚ÄúËßÜËßâ-Ëß¶Ëßâ‚ÄùË∑®Ê®°ÊÄÅÂØπÈΩê„ÄÇ\n- **È¢ÑÊúü‰ª∑ÂÄº**ÔºöÊèêÂçáÂú®ÊªëÂä®„ÄÅÊüîÊÄßÁâ©‰ΩìÊìç‰ΩúÁ≠â‰ªªÂä°‰∏≠ÁöÑÊàêÂäüÁéáÂíåÈ≤ÅÊ£íÊÄß„ÄÇ\n\n### 2. **ÂºÄÂèëÊõ¥È´òÊïàÁöÑÂèØÊâ©Â±ïÁÆóÊ≥ï**\n- **ÊñπÂêë**ÔºöÂä†ÈÄüËΩ®ËøπÂØπÈΩêËøáÁ®ãÔºå‰ΩøÂÖ∂ÈÄÇÁî®‰∫éÂ§ßËßÑÊ®°Êï∞ÊçÆÂêàÊàê„ÄÇ\n- **ÊñπÊ≥ï**Ôºö\n  - ÈááÁî®**Á•ûÁªèÁΩëÁªúËøë‰ºº**ÂØπÈΩêËøáÁ®ãÔºåËÆ≠ÁªÉ‰∏Ä‰∏™‚ÄúÂØπÈΩêÁΩëÁªú‚ÄùÁõ¥Êé•È¢ÑÊµãÁõÆÊ†áÂÖ≥ËäÇËΩ®Ëøπ„ÄÇ\n  - Âà©Áî®**ÂÖÉÂ≠¶‰π†**Êàñ**Âø´ÈÄüËá™ÈÄÇÂ∫î**ÊäÄÊúØÔºåÂáèÂ∞ëÂØπÊñ∞ÂΩ¢ÊÄÅÁöÑ‰ºòÂåñÊ≠•Êï∞„ÄÇ\n- **È¢ÑÊúü‰ª∑ÂÄº**ÔºöÂÆûÁé∞ÂàÜÈíüÁ∫ßÁîüÊàêÊï∞ÂçÉÊù°Á§∫ÊïôÔºåÂä©ÂäõÂü∫Á°ÄÊ®°ÂûãËÆ≠ÁªÉ„ÄÇ\n\n### 3. **Êâ©Â±ï‰ªªÂä°‰∏éÂΩ¢ÊÄÅÊ≥õÂåñËåÉÂõ¥**\n- **ÊñπÂêë**ÔºöÈ™åËØÅÂπ∂ÊèêÂçáÊ°ÜÊû∂Âú®Êõ¥ÂπøÊ≥õ‰ªªÂä°ÂíåÊú∫Âô®‰∫∫ÂΩ¢ÊÄÅ‰∏äÁöÑÊúâÊïàÊÄß„ÄÇ\n- **ÊñπÊ≥ï**Ôºö\n  - Âú®Êõ¥Â§öÊ†∑ÂåñÁöÑ**‰ªªÂä°ÈõÜ**ÔºàÂ¶ÇË£ÖÈÖç„ÄÅÂ∑•ÂÖ∑‰ΩøÁî®ÔºâÂíå**Êú∫Âô®‰∫∫ÂΩ¢ÊÄÅÈõÜ**ÔºàÂ¶ÇÁßªÂä®Êú∫Ê¢∞ËáÇ„ÄÅÂõõË∂≥Êú∫Âô®‰∫∫Ôºâ‰∏äËøõË°åÊµãËØï„ÄÇ\n  - Êé¢Á¥¢**ÂàÜÂ±ÇÂäüËÉΩË°®Á§∫**Ôºå‰ª•ÊçïÊçâ‰∏çÂêåÁ≤íÂ∫¶ÔºàÂ¶ÇÊï¥‰ΩìÂßøÊÄÅ„ÄÅÊåáÂ∞ñÁªÜËäÇÔºâÁöÑÁõ∏‰ººÊÄß„ÄÇ\n- **È¢ÑÊúü‰ª∑ÂÄº**ÔºöÁúüÊ≠£ÂÆûÁé∞‚Äú‰ªª‰Ωï‰ªªÂä°Ôºå‰ªª‰ΩïÊú∫Âô®‰∫∫‚ÄùÁöÑÈÄöÁî®Á≠ñÁï•ËøÅÁßª„ÄÇ\n\n### 4. **Êé¢Á¥¢RGBËßÇÊµãÁöÑÂÖºÂÆπÊÄß**\n- **ÊñπÂêë**ÔºöÂ∞ÜÂΩìÂâçÁÇπ‰∫ëÊ°ÜÊû∂Êâ©Â±ïËá≥‰∏ªÊµÅÁöÑ**RGBËßÇÊµã**„ÄÇ\n- **ÊñπÊ≥ï**Ôºö\n  - Âà©Áî®**Á•ûÁªèÊ∏≤Êüì**ÊäÄÊúØÔºàÂ¶Ç NeRF„ÄÅDiffusionÔºâÂêàÊàêÁõÆÊ†áÊú∫Âô®‰∫∫ÁöÑRGBÂõæÂÉè„ÄÇ\n  - ÁªìÂêà**Ë∑®ÁªòÁîª**ÊäÄÊúØÔºåÂú®ÂÉèÁ¥†Á∫ßÂØπÈΩê‰∏çÂêåÂΩ¢ÊÄÅÁöÑÂ§ñËßÇ„ÄÇ\n- **È¢ÑÊúü‰ª∑ÂÄº**Ôºö‰∏éÁé∞ÊúâÂü∫‰∫éRGBÁöÑÂ§ßËßÑÊ®°Êï∞ÊçÆÈõÜÂíåÊ®°ÂûãÔºàÂ¶Ç RT-XÔºâÊõ¥Â•ΩÂÖºÂÆπ„ÄÇ\n\n### 5. **ÁªìÂêàÂº∫ÂåñÂ≠¶‰π†‰∏éÁ¶ªÁ∫øÊï∞ÊçÆÁîüÊàê**\n- **ÊñπÂêë**ÔºöÂ∞Ü `CEI` ÂêàÊàêÁöÑÊï∞ÊçÆ‰Ωú‰∏∫**È´òË¥®ÈáèÂàùÂßãÊï∞ÊçÆÈõÜ**ÔºåÁªìÂêà**Á¶ªÁ∫øÂº∫ÂåñÂ≠¶‰π†**Êàñ**Á§∫ËåÉÂ¢ûÂº∫RL**ËøõË°åÁ≠ñÁï•ÂæÆË∞É„ÄÇ\n- **ÊñπÊ≥ï**Ôºö\n  - ‰ΩøÁî® `CEI` Êï∞ÊçÆÈ¢ÑËÆ≠ÁªÉÁ≠ñÁï•ÔºåÂÜçÂú®ÁõÆÊ†áÁéØÂ¢É‰∏≠ËøõË°åÂ∞ëÈáè**Âú®Á∫ø‰∫§‰∫íÂæÆË∞É**„ÄÇ\n  - ÊûÑÂª∫**Âä®ÂäõÂ≠¶Ê®°Âûã**ÔºåÂØπÂêàÊàêËΩ®ËøπËøõË°åÁâ©ÁêÜÂêàÁêÜÊÄß‰øÆÊ≠£„ÄÇ\n- **È¢ÑÊúü‰ª∑ÂÄº**ÔºöÂº•Ë°•Á∫ØÂá†‰ΩïÂêàÊàêÁöÑ‰∏çË∂≥ÔºåÊèêÂçáÊúÄÁªàÁ≠ñÁï•Âú®ÁúüÂÆûÁâ©ÁêÜ‰∏ñÁïå‰∏≠ÁöÑÊÄßËÉΩ„ÄÇ\n\n### 6. **ÊûÑÂª∫ÂºÄÊ∫êÂü∫ÂáÜ‰∏éÂ∑•ÂÖ∑Èìæ**\n- **ÊñπÂêë**ÔºöÂ∞Ü `CEI` Ê°ÜÊû∂Ê®°ÂùóÂåñ„ÄÅÂºÄÊ∫êÂåñÔºåÂπ∂Âª∫Á´ãÊ†áÂáÜËØÑ‰º∞Âü∫ÂáÜ„ÄÇ\n- **ÊñπÊ≥ï**Ôºö\n  - ÂèëÂ∏É**Ë∑®ÂÖ∑Ë∫´Êï∞ÊçÆÂêàÊàêÁÆ°ÈÅì**ÁöÑ‰ª£Á†ÅÂ∫ì„ÄÇ\n  - ÂÆö‰πâ‰∏ÄÂ•óÊ†áÂáÜÁöÑ**Ë∑®ÂÖ∑Ë∫´ËΩ¨Áßª‰ªªÂä°ÈõÜ„ÄÅÂΩ¢ÊÄÅÈõÜÂíåËØÑ‰º∞ÂçèËÆÆ**„ÄÇ\n- **È¢ÑÊúü‰ª∑ÂÄº**ÔºöÈôç‰ΩéÁ§æÂå∫Á†îÁ©∂Èó®ÊßõÔºåÂä†ÈÄüË∑®ÂÖ∑Ë∫´Â≠¶‰π†È¢ÜÂüüÂèëÂ±ï„ÄÇ\n\n---\n\n## ÊÄªÁªì\n`CEI` ÁöÑÊ†∏ÂøÉË¥°ÁåÆÂú®‰∫éÊèêÂá∫‰∫Ü**ÂäüËÉΩÁõ∏‰ººÊÄß**Ëøô‰∏ÄÊ¶ÇÂøµÔºåÂπ∂ÈÄöËøá**Âü∫‰∫éÊ¢ØÂ∫¶ÁöÑËΩ®ËøπÂØπÈΩê**ÂÆûÁé∞‰∫Ü‰ªéÂπ≥Ë°åÂ§πÁà™Âà∞ÁÅµÂ∑ßÊâãÁ≠âÊûÅÁ´ØÂΩ¢ÊÄÅÈó¥ÁöÑÁ≠ñÁï•ËøÅÁßª„ÄÇÂÖ∂ÂΩìÂâçÂ±ÄÈôêÊÄß‰∏ªË¶ÅÊ∫ê‰∫é**Á∫ØÂá†‰ΩïËßÜËßí**Âíå**ÈùôÊÄÅ‰ºòÂåñËåÉÂºè**„ÄÇÊú™Êù•ÁöÑÊîπËøõÂ∞ÜÂõ¥Áªï**ÂºïÂÖ•Áâ©ÁêÜÊÑüÁü•**„ÄÅ**ÊèêÂçáËÆ°ÁÆóÊïàÁéá**„ÄÅ**Êâ©Â±ïÊ≥õÂåñËæπÁïå**‰ª•Âèä**ËûçÂêàÂ§öÊ®°ÊÄÅÂ≠¶‰π†**Â±ïÂºÄÔºåÊúÄÁªàÁõÆÊ†áÊòØÊûÑÂª∫‰∏Ä‰∏™È´òÊïà„ÄÅÈ≤ÅÊ£í„ÄÅÈÄöÁî®ÁöÑÊú∫Âô®‰∫∫Á≠ñÁï•ËøÅÁßª‰∏éÊï∞ÊçÆÂêàÊàêÂπ≥Âè∞„ÄÇ",
      "timestamp": "2026-01-20T18:02:49.826315",
      "thinking": null,
      "is_reasoning": false,
      "parent_qa_id": null
    }
  ],
  "is_hidden": false,
  "is_starred": false,
  "flag": "",
  "published_date": "2026-01-14T05:07:11Z",
  "created_at": "2026-01-20T17:49:48.108427",
  "updated_at": "2026-01-20T17:49:48.108434"
}