{
    "id": "2601.22686v1",
    "title": "FlyAware: Inertia-Aware Aerial Manipulation via Vision-Based Estimation and Post-Grasp Adaptation",
    "authors": [
        "Biyu Ye",
        "Na Fan",
        "Zhengping Fan",
        "Weiliang Deng",
        "Hongming Chen",
        "Qifeng Chen",
        "Ximin Lyu"
    ],
    "abstract": "ä¸ä¼ ç»Ÿå¤šæ—‹ç¿¼æ— äººæœºç›¸æ¯”ï¼Œç©ºä¸­æœºæ¢°è‡‚å‡­å€Ÿå…¶å“è¶Šçš„çµå·§æ€§ï¼Œåœ¨è‡ªåŠ¨åŒ–è¿è¾“å’Œåº”æ€¥æœåŠ¡é¢†åŸŸæ­£å—åˆ°è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ã€‚ç„¶è€Œï¼Œå…¶æ—¶å˜æƒ¯æ€§å‚æ•°çš„å¤æ‚æ€§å¯¹å…¶å®é™…éƒ¨ç½²æ„æˆäº†æŒ‘æˆ˜ï¼Œè¿™äº›å‚æ•°å¯¹è´Ÿè½½å˜åŒ–å’Œæœºæ¢°è‡‚æ„å‹é«˜åº¦æ•æ„Ÿã€‚å—äººç±»ä¸æœªçŸ¥ç‰©ä½“äº¤äº’ç­–ç•¥çš„å¯å‘ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„æœºè½½é²æ£’ç©ºä¸­æ“æ§æ¡†æ¶ã€‚è¯¥ç³»ç»Ÿå°†åŸºäºè§†è§‰çš„é¢„æŠ“å–æƒ¯æ€§ä¼°è®¡æ¨¡å—ä¸æŠ“å–åè‡ªé€‚åº”æœºåˆ¶ç›¸ç»“åˆï¼Œå®ç°äº†æƒ¯æ€§åŠ¨åŠ›å­¦çš„å®æ—¶ä¼°è®¡ä¸è‡ªé€‚åº”è°ƒæ•´ã€‚åœ¨æ§åˆ¶æ–¹é¢ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§åŸºäºå¢ç›Šè°ƒåº¦çš„æƒ¯æ€§æ„ŸçŸ¥è‡ªé€‚åº”æ§åˆ¶ç­–ç•¥ï¼Œå¹¶é€šè¿‡é¢‘åŸŸç³»ç»Ÿè¾¨è¯†è¯„ä¼°äº†å…¶é²æ£’æ€§ã€‚æœ¬ç ”ç©¶ä¸ºç©ºä¸­æœºæ¢°è‡‚çš„æŠ“å–åæ§åˆ¶æä¾›äº†æ–°æ€è·¯ï¼ŒçœŸå®ç¯å¢ƒä¸‹çš„å®éªŒéªŒè¯äº†æ‰€ææ¡†æ¶çš„æœ‰æ•ˆæ€§ä¸å¯è¡Œæ€§ã€‚",
    "url": "https://arxiv.org/abs/2601.22686v1",
    "html_url": "https://arxiv.org/html/2601.22686v1",
    "html_content": "FlyAware: Inertia-Aware Aerial Manipulation via Vision-Based Estimation and Post-Grasp Adaptation\nBiyu Ye\n1\n, Na Fan\n2\n, Zhengping Fan\n1\n, Weiliang Deng\n1\n, Hongming Chen\n1\n, Qifeng Chen\n2\n, and Ximin Lyu\n1,3\nManuscript received: June 27, 2025; Revised December 15, 2025; Accepted January 21, 2026. This paper was recommended for publication by Editor Soon-Jo Chung upon evaluation of the Associate Editor and Reviewersâ€™comments. This work is supported by the National Key Research and Development Program of China (Grant No. 2023YFB4706600), the National Natural Science Foundation of China (Grant No.62303495), the Research Grants Council of HKSAR (Grant No. AoE/E-601/24-N), and the Young Talent Support Project of Guangzhou Association for Science and Technology (Grant No. QT-2025-004).\n(Biyu Ye and Na Fan are co-first authors.) (Corresponding author: Ximin Lyu.)\n(Project page:\nhttps://flyaware.github.io/\n)\n1\nBiyu Ye, Zhengping Fan, Weiliang Deng, Hongming Chen and Ximin Lyu are with the School of Intelligent Systems Engineering, Sun Yat-sen University, Guangzhou 510275, China (e-mail: yeby9@mail2.sysu.edu.cn; fanzhp@mail.sysu.edu.cn; dengwliang@mail2.sysu.edu.cn; chenhm223@mail2.sysu.edu.cn; lvxm6@mail.sysu.edu.cn).\n2\nNa Fan and Qifeng Chen are with Visual Intelligence Lab, Cheng Kar-Shun Robotics Institute, The Hong Kong University of Science and Technology, Hong Kong, SAR, China (e-mail: nfanaa@cse.ust.hk; cqf@cse.ust.hk).\n3\nXimin Lyu is also with Differential Robotics Technology Company, Ltd., Hangzhou 311121, China.Digital Object Identifier: see top of this page.\nAbstract\nAerial manipulators (AMs) are gaining increasing attention in automated transportation and emergency services due to their superior dexterity compared to conventional multirotor drones. However, their practical deployment is challenged by the complexity of time-varying inertial parameters, which are highly sensitive to payload variations and manipulator configurations. Inspired by human strategies for interacting with unknown objects, this letter presents a novel onboard framework for robust aerial manipulation. The proposed system integrates a vision-based pre-grasp inertia estimation module with a post-grasp adaptation mechanism, enabling real-time estimation and adaptation of inertial dynamics. For control, we develop an inertia-aware adaptive control strategy based on gain scheduling, and assess its robustness via frequency-domain system identification. Our study provides new insights into post-grasp control for AMs, and real-world experiments validate the effectiveness and feasibility of the proposed framework.\nI\nINTRODUCTION\nAerial manipulators integrate the agility of drones with the dexterity of robotic arms, enabling complex tasks like grasping (Fig.\n1\n) and retrieving objects in hard-to-reach environmentsâ€”such as cliffs, rooftops, or under bridges\n[\n27\n,\n21\n]\n. Despite their potential, achieving precise and robust control remains a significant challenge. In particular, real-time estimation of geometric and inertial parametersâ€”including mass, center of mass (CoM), and moment of inertia (MoI)â€”is crucial for stable flight: mass governs translational behavior, CoM affects stability, and MoI dictates attitude dynamics\n[\n33\n]\n. These parameters, however, can vary significantly due to payload changes or manipulator reconfiguration, leading to estimation delays, prior knowledge gaps, and insufficient controller responsiveness during aerial interactions. Consequently, fast and accurate estimation becomes essential for maintaining reliable performance in dynamic, uncertain environments.\nTo cope with the unknown payload,\nmodel-based approaches use force/torque or IMU sensors.\nFor example, Mellinger\net al\n.\n[\n20\n]\nand Lee\net al\n.\n[\n17\n,\n15\n]\nestimate unknown payloads by identifying changes in dynamics post-grasping, but require over 20 s to converge.\nKalman filter-based methods\n[\n33\n,\n29\n]\nfuse IMU and motor data but suffer from slow convergence (tens of seconds) and limited accuracy\n[\n2\n,\n3\n]\n, while also neglecting manipulator-payload coupling\n[\n27\n]\n.\nRecent work\n[\n24\n]\nincludes manipulator variation in estimation but remains in simulation.\nRecently, learning-based methods\n[\n10\n]\nemerged to leverage neural networks to infer parameters without modeling.\nHowever, all above methods estimate the inertial parameters of the unknown object post-grasping, leading to estimation delays.\nMoreover, they lack knowledge of the object and its properties.\nIn contrast, we focus on estimating the individual inertial parameters of the payload, since the inertial properties of the aerial platform are already known, which slightly differs from\n[\n33\n,\n29\n,\n15\n]\nthat estimate combined system or payload parameters.\nAnother challenge is the design of an effective control strategy for AMs operating with a morphing manipulator and various payloads.\nAdaptive control techniques like sliding mode\n[\n14\n]\nor model reference adaptive controllers\n[\n1\n]\nare used to handle parameter uncertainty.\nYet, these systems without accelerometer measurements may respond more slowly to changes.\nTo achieve high real-time responsiveness, Gain Scheduled (GS) control has shown promise on AMs\n[\n23\n,\n6\n]\n, with some combining PID and Lyapunov adaptive control\n[\n23\n]\nto address changes in the CoM and external disturbances.\nHowever, existing designs that rely only on control error make it sensitive to noise or disturbances\n[\n15\n]\n.\nMost current GS-based controllers\n[\n23\n,\n6\n]\nignore payload variations, focusing solely on manipulator morphing.\nFigure 1:\nReal-world experiment: The aerial manipulator pre-senses and grasps objects arbitrarily placed on a table by a human operator.\nFigure 2:\nSystem overview.\nOur system processes two inputs: an RGB-D image stream of the scene and text specifying the target object.\nStage 1: Pre-Sensing:\nBefore grasping, the unknown target objectâ€™s inertial parameters (mass\nm\n~\no\n{\\tilde{m}}_{o}\nand MoI\nğ‰\n~\no\n\\tilde{\\mathbf{J}}_{o}\n) are pre-estimated by large vision and language models,\nand the object frame origin\nğ’ª\nO\n\\mathcal{O}_{O}\nis also obtained.\nStage 2: Adaptation:\nUpon grasping, the\nPerception Adaptation\nmodule updates the objectâ€™s mass and MoI to\nm\n^\no\n{\\hat{m}}_{o}\nand\nğ‰\n^\no\n\\hat{\\mathbf{J}}_{o}\nusing onboard force sensor feedback, then computes the systemâ€™s total MoI\nğ‰\n^\nt\n\\hat{\\mathbf{J}}_{t}\n.\nThe\nControl Adaptation\nmoduleâ€™s inertia-aware gain scheduling (IAGS) controller then calculates the inertia-aware gain, generating desired thrust magnitude\nT\ndes\nT^{\\mathrm{des}}\nand torque\nğ‰\ndes\n\\bm{\\tau}^{\\mathrm{des}}\n.\nInterestingly, humans approach grasping in a two-stage manner. First, they visually estimate object propertiesâ€”such as size, shape, or textureâ€”and integrate prior experience to infer mass and inertia before physical interaction\n[\n25\n]\n. Second, after contact, tactile feedback allows rapid refinement and force adjustment to ensure stability\n[\n13\n,\n7\n]\n. This preemptive-inference and feedback-refinement loop enables fast and robust graspingâ€”unlike most existing AM systems, which rely on post-grasp estimation and reactive control.\nMotivated by the human two-stage grasping strategy, we propose a perception-control framework for aerial manipulation (Fig.\n2\n) that mirrors this process:\nStage 1: Pre-Sensing\n: Before grasping, the system visually perceives the target object using RGB-D images and natural language input. It estimates the objectâ€™s pose, size, and shape, then infers physical priors such as density and volume to approximate its mass and moment of inertia. This stage mimics the way humans form expectations about an objectâ€™s weight and stability through sight and experience. In robotic systems, this requires visual-semantic understanding and 3D reasoning under uncertainty.\nCompared to traditional methods it avoids the need for time-consuming maneuvers like hovering or active excitation\n[\n33\n,\n15\n]\n, and removes dependencies on known object models or manual data annotation\n[\n16\n,\n31\n,\n28\n]\n.\nStage 2: Adaptation\n: Once the object is grasped, the system refines its estimates of mass and MoI using onboard sensor feedback. These updated inertial parameters are then used to adjust the control system in real time. This stage ensures robust, responsive flight performance under changing load conditions and manipulator configurations.\nSpecifically, we design an adaptive control strategy that dynamically adjusts control gains based on estimated inertia, without requiring predefined gain maps or operating points. This allows the system to maintain precise and agile control despite payload variations and structural reconfigurations.\nOur key contributions are as follows:\n1.\nA Novel Inertia Estimation Framework:\nWe design a two-stage framework that combines vision-based pre-grasp estimation with post-grasp adaptation to enable real-time inertial parameter updates for aerial manipulators.\n2.\nAn Inertia-Compensated Adaptive Strategy:\nWe develop a gain-scheduled adaptive controller that compensates for inertia variations, and validate its robustness through frequency-domain system identification.\n3.\nSuccessful Implementation and Verification:\nWe demonstrate the versatility and effectiveness of our framework through extensive validation, including diverse tasks, ablation studies, and real-world aerial manipulation experiments.\nTo the best of our knowledge, this is the first introduction of vision-based inertia estimation techniques to aerial manipulators.\nII\nSYSTEM MODELING\nII-A\nAM System Configuration\nOur AM system consists of a quadrotor as a flying base and a delta manipulator.\nFor modeling, we set up five coordinate systems: the world frame\nâ„±\nW\n\\mathcal{F}_{W}\n, the body frame\nâ„±\nB\n\\mathcal{F}_{B}\n, the manipulator frame\nâ„±\nM\n\\mathcal{F}_{M}\n, the end-effector frame\nâ„±\nE\n\\mathcal{F}_{E}\n, and the camera frame\nâ„±\nC\n\\mathcal{F}_{C}\n, each with a set of orthogonal bases.\nThe origins\nğ’ª\nB\n\\mathcal{O}_{B}\n,\nğ’ª\nC\n\\mathcal{O}_{C}\n,\nğ’ª\nM\n\\mathcal{O}_{M}\n, and\nğ’ª\nE\n\\mathcal{O}_{E}\nare the CoM of the AM, camera optical center, midpoint of three manipulator servos, and geometric center of the end-effector plane, respectively.\nII-B\nAM System Dynamics\nThe linear and angular dynamics of the AM system can be summarized by the following equations:\nğ‰\nâ€‹\n(\nğœ½\n)\n\\displaystyle\\bm{\\tau}(\\bm{\\theta})\n=\nâˆ‘\ni\n=\n1\n4\n(\nâ–³\nâ€‹\nğ’„\ni\nâ€‹\n(\nğœ½\n)\nÃ—\nğ‘»\ni\n+\nğ‰\ni\n)\n,\n\\displaystyle=\\textstyle\\sum_{i=1}^{4}\\left(\\triangle\\bm{c}_{i}(\\bm{\\theta})\\times\\bm{T}_{i}+\\bm{\\tau}_{i}\\right),\n(1a)\nm\nt\nâ€‹\nğ¯\nË™\nB\nW\n\\displaystyle m_{t}{}^{W}\\mathbf{\\dot{v}}_{B}\n=\nâˆ’\nm\nt\nâ€‹\ng\nâ€‹\nğ’†\n3\n+\nğ‘\nB\nW\nâ€‹\nâˆ‘\ni\n=\n1\n4\nğ‘»\ni\n,\n\\displaystyle=-m_{t}g\\bm{e}_{3}+{}^{W}\\mathbf{R}_{B}\\textstyle\\sum_{i=1}^{4}\\bm{T}_{i},\n(1b)\nğ‰\nt\n(\nğœ½\n)\nB\nğ\nË™\nB\n\\displaystyle\\mathbf{J}_{t}{}^{B}(\\bm{\\theta})\\bm{\\dot{\\omega}}_{B}\n=\nğ‰\n(\nğœ½\n)\nâˆ’\nğ\nB\nB\nÃ—\nğ‰\nt\n(\nğœ½\n)\nB\nğ\nB\n,\n\\displaystyle=\\bm{\\tau}(\\bm{\\theta})-{}^{B}\\bm{\\omega}_{B}\\times\\mathbf{J}_{t}{}^{B}(\\bm{\\theta})\\bm{\\omega}_{B},\n(1c)\nğ‘\nË™\nB\nW\n\\displaystyle{}^{W}\\mathbf{\\dot{R}}_{B}\n=\nğ‘\nB\nW\nâ€‹\nğ\n^\nB\nB\n.\n\\displaystyle={}^{W}\\mathbf{R}_{B}{}^{B}\\bm{\\hat{\\omega}}_{B}.\n(1d)\nwhere\nğœ½\n=\n[\nÎ¸\n1\n,\nÎ¸\n2\n,\nÎ¸\n3\n]\nâŠº\nâˆˆ\nâ„\n3\n\\bm{\\theta}=[\\theta_{1},\\theta_{2},\\theta_{3}]^{\\intercal}\\in\\mathbb{R}^{3}\nis the manipulatorâ€™s joint angles, controlled by three servos.\nâ–³\nâ€‹\nğ’„\ni\nâ€‹\n(\nğœ½\n)\nâˆˆ\nâ„\n3\n\\triangle\\bm{c}_{i}(\\bm{\\theta})\\in\\mathbb{R}^{3}\nrepresents the distance from each propeller center to the AM CoM.\nğ‘»\ni\nâˆˆ\nâ„\n3\n\\bm{T}_{i}\\in\\mathbb{R}^{3}\nand\nğ‰\ni\nâˆˆ\nâ„\n3\n\\bm{\\tau}_{i}\\in\\mathbb{R}^{3}\nare the force and torque generated by each propeller.\nm\nt\nm_{t}\nis the total mass of the AM.\nğ¯\nB\nW\nâˆˆ\nâ„\n3\n{}^{W}\\mathbf{v}_{B}\\in\\mathbb{R}^{3}\nis the linear velocity of\nâ„±\nB\n\\mathcal{F}_{B}\nwith respect to\nâ„±\nW\n\\mathcal{F}_{W}\n.\ng\ng\nis the gravitational acceleration, and\nğ’†\n3\n=\n[\n0\n,\n0\n,\n1\n]\nâŠº\n\\bm{e}_{3}=[0,0,1]^{\\intercal}\nin\nâ„±\nW\n\\mathcal{F}_{W}\n.\nğ‘\nB\nW\nâˆˆ\nâ„\n3\nÃ—\n3\n{}^{W}\\mathbf{R}_{B}\\in\\mathbb{R}^{3\\times 3}\nis the rotation of\nâ„±\nB\n\\mathcal{F}_{B}\nrelative to\nâ„±\nW\n\\mathcal{F}_{W}\n.\nğ\nB\nB\nâˆˆ\nâ„\n3\n{}^{B}\\bm{\\omega}_{B}\\in\\mathbb{R}^{3}\nis the angular velocity in\nâ„±\nB\n\\mathcal{F}_{B}\n.\nğ‰\nt\nâˆˆ\nâ„\n3\nÃ—\n3\n\\mathbf{J}_{t}\\in\\mathbb{R}^{3\\times 3}\nis the total inertia of the AM in\nâ„±\nB\n\\mathcal{F}_{B}\nwhich is both a function of the angle\nğœ½\n\\bm{\\theta}\nand time.\n(\nâ‹…\n)\n^\n\\hat{(\\cdot)}\ndenotes the skew-symmetric operator.\nII-C\nDelta Manipulator Kinematics\nThe 3-DOF parallel delta manipulator with 3-RSS (Revolute-Spherical-Spherical) configuration similar to\n[\n8\n]\nis favored for its compact design and low MoI, ideal for rapid and accurate position control\n[\n21\n]\n.\nCodourey\n[\n5\n]\ndescribes the forward kinematics of the manipulator, where the mapping\nh\nE\n:\nâ„\n3\nâ†’\nâ„\n3\nh_{E}:\\mathbb{R}^{3}\\to\\mathbb{R}^{3}\ntransforms the manipulatorâ€™s joint angles\nğœ½\n\\bm{\\theta}\ninto the translation vector\nğ’‘\nE\nM\n{}^{M}\\bm{p}_{E}\nfrom the manipulator frame origin\nğ’ª\nM\n\\mathcal{O}_{M}\nto the end-effector frame origin\nğ’ª\nE\n\\mathcal{O}_{E}\n.\nGuglielmetti et al.\n[\n11\n]\nderive the differential kinematics, computing the end-effector velocity Jacobian\nğ“™\n\\bm{\\mathcal{J}}\nto relate the joint velocities\nğœ½\nË™\n\\dot{\\bm{\\theta}}\nto the end-effector velocity\nğ¯\nE\nM\n{}^{M}\\mathbf{v}_{E}\n.\nThese relationships can be expressed as:\nğ’‘\nE\nM\n\\displaystyle{}^{M}\\bm{p}_{E}\n=\nh\nE\nâ€‹\n(\nğœ½\n)\n,\n\\displaystyle=h_{E}(\\bm{\\theta}),\n(2a)\nğ¯\nE\nM\n\\displaystyle{}^{M}\\mathbf{v}_{E}\n=\nğ“™\nâ€‹\nğœ½\nË™\n.\n\\displaystyle=\\bm{\\mathcal{J}}\\dot{\\bm{\\theta}}.\n(2b)\nGiven the desired end-effectorâ€™s position\nğ’‘\nE\nM\n{}^{M}\\bm{p}_{E}\nand velocity\nğ¯\nE\nM\n{}^{M}\\mathbf{v}_{E}\n, the required joint states\nğœ½\n\\bm{\\theta}\nand\nğœ½\nË™\n\\dot{\\bm{\\theta}}\ncan be computed via inverse kinematics from Eqs.Â (\n2a\n) and (\n2b\n).\nIII\nINERTIA PARAMETERS ESTIMATOR\nIn contrast to existing methods\n[\n20\n,\n17\n,\n15\n,\n33\n,\n29\n,\n24\n,\n10\n]\nthat involve time-consuming post-grasp estimation of the target objectâ€™s inertial parameters, we propose a more efficient human-inspired strategy.\nWe pre-sense and pre-estimate the objectâ€™s inertial parameters, followed by an onboard adaptation of these estimate.\nSubsequently, we compute the overall systemâ€™s inertial parameters, encompassing both the AM and the target object as the payload.\nIII-A\nPre-Grasp Target Object Pre-Sensing\nThe target object for grasping is specified by the user through text input when the AM initiates the mission.\nDuring Pre-Sensing, our method detects the target object in RGB-D images, estimates its pose and size, and simultaneously determines its shape scale factors and density using pre-trained vision and language models\n[\n26\n,\n18\n,\n22\n]\n.\nThe objectâ€™s inertial parameters are then computed from these model.\nIII-A\n1\nObject Detection\nTo detect unseen target objects without per-instance\ntraining, we resort to GroundedÂ SAM\n[\n26\n]\n.\nGiven the text prompt, the model generates a binary mask.\nBecause the detector is fully foundation-model based, no\ndataset or fine-tuning is required for new objects.\nIII-A\n2\nObject Pose and Volume Estimation\nBack-projection and point-set formation\nThe binary mask is applied to the depth map to lift a target-only point cloud. Because an unoriented bounding box can severely over-estimate volume when the object is rotated, we cast the task as a 9D pose problem and recover an oriented, tight box.\n9D Object Pose Estimation\nFor object pose and size estimation, we adopt IST-Net\n[\n18\n]\n, a state-of-the-art category-level method for 6D pose (rotation and translation) and 3D size estimation, resulting in a 9D representation.\nIn our AM setting, IST-Net provides reliable estimates at stand-off distances of\n3\nâ€“\n3\\text{\\,}\\mathrm{â€“}\n5\nm\n5\\text{\\,}\\mathrm{m}\n, and thus serves as the core perception module in our framework.\nMultiple tests on 8 objects averaging an average size estimation accuracy of\n90.6\n%\n90.6\\%\n.\nSome pose estimation results are shown in Fig.\n3\n.\nIII-A\n3\nGPT-Based Scale Factor and Density Estimation\nAlthough pose estimation yields tight 3D bounding boxes, real-world objects often deviate from box-like geometries (e.g., spheres, cones), leading to inaccurate volume and inertia estimates.\nTo address this, we leverage GPTâ€™s multimodal reasoning capabilities to refine volume and MoI estimates using object-specific prior knowledge (Fig.\n4\n). For real-time deployment, the GPT API is accessed onboard via an internet connection, enabling fast and accurate inference.\nGPT takes as input a segmented image, approximate object dimensions from point cloud data, and a textual description of the object (e.g., â€œa red cylindrical iron can filled with coffee beansâ€).\nWe use a standardized prompt template (Fig.\n4\n) to ensure reproducibility. GPT predicts:\n1. a volume scaling factor\nÎ²\n\\beta\n,\n2. a diagonal MoI scaling matrix\nğœ¶\nâˆˆ\nâ„\n3\nÃ—\n3\n\\bm{\\alpha}\\in\\mathbb{R}^{3\\times 3}\n, and\n3. the objectâ€™s average density\nÏ\n~\n\\tilde{\\rho}\n.\nThese are used to compute the refined object volume\nV\n^\no\n\\hat{V}_{o}\n, mass\nm\n~\no\n\\tilde{m}_{o}\n, and MoI\nğ‰\n~\no\n\\tilde{\\mathbf{J}}_{o}\n:\nm\n~\no\n\\displaystyle\\tilde{m}_{o}\n=\nÏ\n~\nâ€‹\nV\n^\no\n=\nÏ\n~\nâ€‹\nÎ²\nâ€‹\nV\n~\no\n,\n\\displaystyle=\\tilde{\\rho}\\hat{V}_{o}=\\tilde{\\rho}\\beta\\tilde{V}_{o},\n(3a)\nğ‰\n~\no\n\\displaystyle\\tilde{\\mathbf{J}}_{o}\n=\nğœ¶\n12\nâ€‹\nm\n~\no\nâ‹…\ndiag\nâ€‹\n(\nw\n2\n+\nh\n2\n,\nâ„“\n2\n+\nh\n2\n,\nâ„“\n2\n+\nw\n2\n)\n.\n\\displaystyle=\\frac{\\bm{\\alpha}}{12}\\tilde{m}_{o}\\cdot\\text{diag}(w^{2}+h^{2},\\ell^{2}+h^{2},\\ell^{2}+w^{2}).\n(3b)\nThis enables zero-shot generalization to unseen object types, making it suitable for open-set aerial manipulation.\nIII-B\nPost-Grasp Target Object Inertia Adaptation\nTo further refine the vision-based estimates of mass\nm\n~\no\n\\tilde{m}_{o}\nand MoI\nğ‰\n~\no\n\\tilde{\\mathbf{J}}_{o}\n, we employ a disturbance observer (DOB)\n[\n34\n]\nto adaptively update the mass and scale the MoI accordingly.\nFigure 3:\nPose estimation results in the camera coordinate frame.\nFigure 4:\nSystem prompt for object scale factor and density estimation.\nIII-B\n1\nObject Mass Adaptation\nUpon grasping the target object, it can be considered as subjected to a constant external force that steadily lifts it while maintaining a level attitude.\nThe grasping event is detected from the DOB-estimated external force, where the threshold is set above the hover noise level yet below the steady force of the lightest payload, and the condition must persist for at least\n0.5\n0.5\ns before switching.\nOnce triggered, this allows us to update the objectâ€™s mass estimation using onboard sensor measurements.\nInspired by the DOB framework in\n[\n34\n]\n, we adopt the following approach, which we refer to as DOBm for clarity, distinguishing it from the conventional use of DOB for direct disturbance compensation:\nm\n^\nË™\no\nâ€‹\ng\nâ€‹\nğ’†\n3\n=\nc\nm\na\nâ€‹\n(\nm\na\nâ€‹\nğš\nB\nW\nâˆ’\nm\na\nâ€‹\ng\nâ€‹\nğ’†\n3\n+\nğ‘\nB\nW\nâ€‹\nğ‘»\nâˆ’\nm\n^\no\nâ€‹\ng\nâ€‹\nğ’†\n3\n)\n.\n\\dot{\\hat{m}}_{o}g\\bm{e}_{3}=\\frac{c}{m_{a}}(m_{a}{}^{W}\\mathbf{a}_{B}-m_{a}g\\bm{e}_{3}+{}^{W}\\mathbf{R}_{B}\\bm{T}-\\hat{m}_{o}g\\bm{e}_{3}).\n(4)\nHere\nm\n^\no\n\\hat{m}_{o}\nis the estimated mass of the target object;\nm\na\nm_{a}\nis the AMâ€™s mass in its unloaded state;\nc\nc\nis a constant convergence parameter.\nğš\nB\nW\n{}^{W}\\mathbf{a}_{B}\nis the linear acceleration of the flying base in\nâ„±\nW\n\\mathcal{F}_{W}\n, derived from the IMU of the flight controller in real time;\nğ‘»\n\\bm{T}\nis the total thrust, computed as\nğ‘»\n=\nâˆ‘\ni\n=\n1\n4\nğ‘»\ni\n\\bm{T}=\\sum_{i=1}^{4}\\bm{T}_{i}\n, where\nğ‘»\ni\n\\bm{T}_{i}\nis the thrust from the\ni\ni\n-th propeller.\nFor each propeller, the thrust magnitude\nT\ni\n=\nâ€–\nğ‘»\ni\nâ€–\nT_{i}=||\\bm{T}_{i}||\nis proportional to the square of its motorâ€™s rotation rate\nÏ–\ni\n\\varpi_{i}\n(in RPM) as\nT\ni\n=\nc\nT\nâ€‹\nÏ–\ni\n2\nT_{i}=c_{T}\\varpi_{i}^{2}\n[\n9\n]\n, and the thrust coefficient\nc\nT\nc_{T}\nis empirically determined through in-situ calibration under actual flight conditions.\nUnlike conventional static bench testsâ€”which often fail to capture the complex aerodynamic interactions present during real flightsâ€”our calibration is conducted directly onboard during flight, ensuring higher relevance to operational dynamics.\nIII-B\n2\nObject MoI Adaptation\nIn our framework, the object mass is first estimated from Eq.Â (3) as\nm\n~\no\n\\tilde{m}_{o}\n, and then refined online by the DOB in Eq.Â (4) to obtain\nm\n^\no\n\\hat{m}_{o}\n. This correction compensates for inertia deviations caused by inaccurate mass estimation. Using the updated mass\nm\n^\no\n\\hat{m}_{o}\n, the objectâ€™s estimated MoI\nğ‰\n^\no\n\\hat{\\mathbf{J}}_{o}\nafter adaptation is scaled proportionally from the initial estimate\nğ‰\n~\no\n\\tilde{\\mathbf{J}}_{o}\nas:\nğ‰\n^\no\n=\nğ‰\n~\no\nâ€‹\n(\nm\n^\no\n/\nm\n~\no\n)\n.\n\\hat{\\mathbf{J}}_{o}=\\tilde{\\mathbf{J}}_{o}(\\hat{m}_{o}/\\tilde{m}_{o}).\n(5)\nIII-C\nPost-Grasp System Overall Inertia Computation\nAfter grasping, the system comprises three components: the quadrotor flying base, the manipulator, and the target object payload.\nSince the delta manipulatorâ€™s lightweight and compact design results in low inertia\n[\n21\n]\n, and its movable components account for less than\n3\n%\n3\\%\nof the overall mass in our system, we neglect the influence of manipulator joint variations on the systemâ€™s CoM and MoI calculations.\nIII-C\n1\nSystem Overall Mass\nThe mass of the AM, including the flying base and the manipulator in an unloaded state, is measured as\nm\na\nm_{a}\n, and the target objectâ€™s mass estimation is updated as\nm\n^\no\n\\hat{m}_{o}\n.\nTherefore the systemâ€™s total estimated mass\nm\n^\nt\n=\nm\na\n+\nm\n^\no\n\\hat{m}_{t}=m_{a}+\\hat{m}_{o}\n.\nIII-C\n2\nSystem Overall CoM\nThe systemâ€™s CoM is computed as the mass-weighted average of all components (the AM body and object) relative to\nğ’ª\nM\n\\mathcal{O}_{M}\n.\nThe real-time CoM\nğ’„\nt\n\\bm{c}_{t}\nvaries with manipulator joint angles\nğœ½\n\\bm{\\theta}\nas:\nğ’„\nt\nâ€‹\n(\nğœ½\n)\n=\n(\nm\na\nâ€‹\nğ’‘\nB\nM\n+\nm\n^\no\nâ€‹\nğ’‘\nO\nM\nâ€‹\n(\nğœ½\n)\n)\n/\nm\n^\nt\n.\n\\bm{c}_{t}(\\bm{\\theta})=(m_{a}{}^{M}\\bm{p}_{B}+\\hat{m}_{o}{}^{M}\\bm{p}_{O}(\\bm{\\theta}))/\\hat{m}_{t}.\n(6)\nHere\nğ’‘\nB\nM\n{}^{M}\\bm{p}_{B}\nis the vector from\nğ’ª\nM\n\\mathcal{O}_{M}\nto the unloaded AMâ€™s CoM\nğ’ª\nB\n\\mathcal{O}_{B}\n(measured via bifilar pendulum method\n[\n12\n]\n).\nğ’‘\nO\nM\nâ€‹\n(\nğœ½\n)\n=\nğ’‘\nE\nM\nâ€‹\n(\nğœ½\n)\n+\nğ’‘\nO\nE\n{}^{M}\\bm{p}_{O}(\\bm{\\theta})={}^{M}\\bm{p}_{E}(\\bm{\\theta})+{}^{E}\\bm{p}_{O}\nis the vector from\nğ’ª\nM\n\\mathcal{O}_{M}\nto the object frame origin\nğ’ª\nO\n\\mathcal{O}_{O}\n, assuming\nğ’ª\nO\n\\mathcal{O}_{O}\ncoincides with the objectâ€™s CoM.\nğ’‘\nE\nM\nâ€‹\n(\nğœ½\n)\n{}^{M}\\bm{p}_{E}(\\bm{\\theta})\nand\nğ’‘\nO\nE\n{}^{E}\\bm{p}_{O}\nare the vectors from\nğ’ª\nM\n\\mathcal{O}_{M}\nto\nğ’ª\nE\n\\mathcal{O}_{E}\n, and from\nğ’ª\nE\n\\mathcal{O}_{E}\nto\nğ’ª\nO\n\\mathcal{O}_{O}\n, respectively.\nIII-C\n3\nSystem Overall MoI\nThe systemâ€™s total estimated MoI\nğ‰\n^\nt\n\\hat{\\mathbf{J}}_{t}\nis derived via the parallel axis theorem:\nğ‰\n^\nt\n=\nğ‰\na\n+\nğ‰\n^\no\n\\displaystyle\\hat{\\mathbf{J}}_{t}=\\mathbf{J}_{a}+\\hat{\\mathbf{J}}_{o}\n+\nm\na\nâ€‹\n[\n(\nğ’…\na\nâ‹…\nğ’…\na\n)\nâ€‹\nğˆ\n3\nâˆ’\nğ’…\na\nâŠ—\nğ’…\na\n]\n\\displaystyle+m_{a}\\big[(\\bm{d}_{a}\\cdot\\bm{d}_{a})\\mathbf{I}_{3}-\\bm{d}_{a}\\otimes\\bm{d}_{a}\\big]\n(7)\n+\nm\n^\no\nâ€‹\n[\n(\nğ’…\no\nâ‹…\nğ’…\no\n)\nâ€‹\nğˆ\n3\nâˆ’\nğ’…\no\nâŠ—\nğ’…\no\n]\n.\n\\displaystyle+\\hat{m}_{o}\\big[(\\bm{d}_{o}\\cdot\\bm{d}_{o})\\mathbf{I}_{3}-\\bm{d}_{o}\\otimes\\bm{d}_{o}\\big].\nHere\nğ‰\na\n\\mathbf{J}_{a}\nis the AMâ€™s inertia in its unloaded state (measured via bifilar pendulum\n[\n12\n]\n).\nğ‰\n^\no\n\\hat{\\mathbf{J}}_{o}\nis the objectâ€™s inertia from Eq.Â (\n5\n).\nğ’…\na\n\\bm{d}_{a}\nand\nğ’…\no\n\\bm{d}_{o}\nare the vectors from the unloaded AMâ€™s CoM\nğ’ª\nB\n\\mathcal{O}_{B}\n, and the objectâ€™s CoM\nğ’ª\nO\n\\mathcal{O}_{O}\n, to the systemâ€™s total CoM\nğ’„\nt\nâ€‹\n(\nğœ½\n)\n\\bm{c}_{t}(\\bm{\\theta})\n, respectively.\nğˆ\n3\n\\mathbf{I}_{3}\nis the\n3\nÃ—\n3\n3\\times 3\nidentity matrix.\nâŠ—\n\\otimes\ndenotes the outer product.\nIV\nCONTROLLER DESIGN\nWe adopt a decoupled control approach\n[\n27\n,\n21\n]\nto separately control the quadrotor flying base and the delta manipulator as two subsystems.\nThis design choice is motivated by the delta manipulatorâ€™s lightweight and low-inertia structure, which introduces minimal dynamic coupling during typical aerial operations.\nWhile we neglect the manipulatorâ€™s mass and inertia in the control formulation, the payload is explicitly considered during both the inertia estimation and adaptive gain scheduling stages (Eq.Â (\n7\n)).\nAs a result, dominant coupling effects arising from the grasped object are accounted for, while residual coupling from the arm remains negligible under our experimental conditions, consistent with prior work\n[\n21\n]\n.\nFigure 5:\nInertia-compensated adaptive strategy.\n(A) Quadrotor Control Structure\n:\nComprises a position controller, an attitude controller, and a mixer.\n(B) Angular Rate Control Loop\n:\nThe PID control gains\nğŠ\nk\nrate\n\\mathbf{K}_{k}^{\\text{rate}}\nare dynamically adjusted through Inertia-Aware Gain Scheduling (IAGS) based on the manipulator joint angles\nğœ½\n\\bm{\\theta}\n.\nIV-A\nControl of the Delta Manipulator\nThe delta manipulatorâ€™s controller tracks predefined end-effector trajectories (desired position\nğ’‘\nE\ndes\nM\n{}^{M}\\bm{p}_{E}^{\\text{des}}\nand velocity\nğ¯\nE\ndes\nM\n{}^{M}\\mathbf{v}_{E}^{\\text{des}}\n) by commanding desired joint angles\nğœ½\ndes\n\\bm{\\theta}^{\\text{des}}\nand angular velocities\nğœ½\nË™\ndes\n\\bm{\\dot{\\theta}}^{\\text{des}}\nto the servos:\nğœ½\ndes\n\\displaystyle\\bm{\\theta}^{\\text{des}}\n=\nh\nE\nâˆ’\n1\nâ€‹\n(\nğ’‘\nE\ndes\nM\n)\n,\n\\displaystyle=h_{E}^{-1}({}^{M}\\bm{p}_{E}^{\\text{des}}),\n(8a)\nğœ½\nË™\ndes\n\\displaystyle\\bm{\\dot{\\theta}}^{\\text{des}}\n=\nğ’¥\nâˆ’\nğŸ\nâ€‹\nğ¯\nE\ndes\nM\n+\nğŠ\nÎ¸\nâ€‹\n(\nğœ½\ndes\nâˆ’\nğœ½\n)\n.\n\\displaystyle=\\mathbf{\\mathcal{J}^{-1}}{}^{M}\\mathbf{v}_{E}^{\\text{des}}+\\mathbf{K}_{\\theta}(\\bm{\\theta}^{\\text{des}}-\\bm{\\theta}).\n(8b)\nHere\nğœ½\ndes\n\\bm{\\theta}^{\\text{des}}\nis computed via inverse kinematics of Eq.Â (\n2a\n).\nğœ½\nË™\ndes\n\\bm{\\dot{\\theta}}^{\\text{des}}\ncombines feedforward velocity derived from inverse kinematics of Eq.Â (\n2b\n) with proportional (P) control feedback.\nğŠ\nÎ¸\n\\mathbf{K}_{\\theta}\nis a positive definite gain matrix for the proportional control.\nğœ½\n\\bm{\\theta}\nis the real-time joint angles sampled at 100 Hz.\nIV-B\nControl of the Quadrotor Flying Base\nIV-B\n1\nDifferential-Flatness-Based Cascade Feedback Control\nFig.\n5\n(A) illustrates our overall control strategy, which adopts a widely used cascade feedback architecture consisting of a position controller, an attitude controller, and a mixer. The position controller takes the desired position\nğ©\nd\nâ€‹\ne\nâ€‹\ns\n\\mathbf{p}^{des}\nas input and generates the desired thrust\nT\nd\nâ€‹\ne\nâ€‹\ns\nT^{des}\nand desired attitude\nğª\nd\nâ€‹\ne\nâ€‹\ns\n\\mathbf{q}^{des}\nbased on the differential flatness properties of quadrotors\n[\n4\n]\n. The attitude controller then outputs the desired torque\nğ‰\nd\nâ€‹\ne\nâ€‹\ns\n\\bm{\\tau}^{des}\n.\nThe attitude error is defined in a geometric manner on\nS\nâ€‹\nO\nâ€‹\n(\n3\n)\nSO(3)\n, following standard formulations in\n[\n19\n]\n.\nIV-B\n2\nAngular Rate Loop with Inertia-Aware Gain Scheduling (IAGS)\n-\nIAGS Controller Design\n.\nThe controller in the angular rate loop (Fig.\n5\n(B)) takes the angular rate error\nğ\ndes\nâˆ’\nğ\n\\bm{\\omega}^{\\text{des}}-\\bm{\\omega}\nas input and outputs the desired torque\nğ‰\ndes\n\\bm{\\tau}^{\\text{des}}\n.\nIt employs a standard PID controller as its backbone, with the proportional, integral, and derivative gains\nğŠ\np\nrate\n,\nğŠ\ni\nrate\n,\nğŠ\nd\nrate\nâˆˆ\nâ„\n3\nÃ—\n3\n\\mathbf{K}_{p}^{\\text{rate}},\\mathbf{K}_{i}^{\\text{rate}},\\mathbf{K}_{d}^{\\text{rate}}\\in\\mathbb{R}^{3\\times 3}\ndetermined through parameter tuning.\nTo counteract MoI variations induced by the manipulatorâ€™s motion, we introduce an additional inertia-aware adaptive term\nğŠ\nk\nrate\n\\mathbf{K}_{k}^{\\text{rate}}\n.\nFor clarity, the derivative term is expressed as the ideal operator\ns\ns\nin the frequency-domain analysis, while in practice it is implemented via a discrete-time causal approximation.\nThus, the controller transfer function in the Laplace domain is expressed as:\nG\nc\nâ€‹\n(\ns\n)\n=\n(\nğŠ\np\nrate\n+\nğŠ\ni\nrate\nâ€‹\n1\ns\n+\nğŠ\nd\nrate\nâ€‹\ns\n)\nâ€‹\nğŠ\nk\nrate\n.\n\\displaystyle G_{c}(s)=\\left(\\mathbf{K}_{p}^{\\text{rate}}+\\mathbf{K}_{i}^{\\text{rate}}\\frac{1}{s}+\\mathbf{K}_{d}^{\\text{rate}}s\\right)\\mathbf{K}_{k}^{\\text{rate}}.\n(9)\nTo facilitate implementation, the corresponding time-domain control law is given by:\nğ‰\nT\nd\nâ€‹\ne\nâ€‹\ns\n=\n(\nğŠ\np\nrate\nâ€‹\nğ\ne\n+\nğŠ\ni\nrate\nâ€‹\nâˆ«\nğ\ne\nâ€‹\nğ‘‘\nt\n+\nğŠ\nd\nrate\nâ€‹\nd\nâ€‹\nğ\ne\nd\nâ€‹\nt\n)\nâ€‹\nğŠ\nk\nrate\n,\n\\displaystyle\\bm{\\tau}_{T}^{des}=\\;\\Big(\\mathbf{K}_{p}^{\\text{rate}}\\,\\bm{\\omega}^{e}\\;+\\;\\mathbf{K}_{i}^{\\text{rate}}\\!\\int\\bm{\\omega}^{e}\\,dt\\;+\\;\\mathbf{K}_{d}^{\\text{rate}}\\frac{d\\bm{\\omega}^{e}}{dt}\\Big)\\,\\mathbf{K}_{k}^{\\text{rate}},\n(10)\nwhere\nğ‰\nT\nd\nâ€‹\ne\nâ€‹\ns\n\\bm{\\tau}_{T}^{des}\ndenotes the control torque output in the time domain, given the angular rate error\nğ\ne\n\\bm{\\omega}^{e}\n.\n-\nPower System\n.\nThe controller output\nğ‰\ndes\n\\bm{\\tau}^{\\text{des}}\nis fed into the Mixer to generate the rotational speed.\nThe rotational speed signal is then fed to the ESC, which controls the motor and propeller to produce the actual torque\nğ‰\n\\bm{\\tau}\n.\nThe transfer function from\nğ‰\ndes\n\\bm{\\tau}^{\\text{des}}\nto\nğ‰\n\\bm{\\tau}\ncan be written as:\nG\nm\nâ€‹\n(\ns\n)\n=\nK\nm\nÏ„\nm\nâ€‹\ns\n+\n1\n,\nG_{m}(s)=\\frac{K_{m}}{\\tau_{m}s+1},\n(11)\nwhere\nK\nm\nâˆˆ\nâ„\nK_{m}\\in\\mathbb{R}\nis the steady-state gain and\nÏ„\nm\n\\tau_{m}\nis the average time constant.\n-\nRotational Dynamics\n.\nThe control torque\nğ‰\n\\bm{\\tau}\nacts on the rotational dynamics, generating the corresponding angular velocity\nğ\n\\bm{\\omega}\n.\nThis approximation is justified by a small-perturbation linearization about hover\n(\nğ\nâ‹†\n=\nğŸ\n)\n(\\bm{\\omega}^{\\star}=\\mathbf{0})\n, where the quadratic gyroscopic term is negligible and\nğ‰\nt\n\\mathbf{J}_{t}\ncan be treated as locally diagonal. This matches our operating condition, as all grasping experiments are conducted from hover.\nUnder these assumptions, the transfer function is:\nG\nd\nâ€‹\n(\ns\n)\n=\nğ‰\nt\nâˆ’\n1\nâ€‹\n1\ns\n,\nG_{d}(s)=\\mathbf{J}_{t}^{-1}\\frac{1}{s},\n(12)\nwhere\nğ‰\nt\n\\mathbf{J}_{t}\nis the actual total MoI of the AM system.\n-\nAngular Rate Loop Transfer Function\n.\nThe overall open-loop transfer function of the angular rate loop,\nG\nopen\nrate\nâ€‹\n(\ns\n)\nG_{\\text{open}}^{\\text{rate}}(s)\n, is:\nG\nopen\nrate\nâ€‹\n(\ns\n)\n\\displaystyle G_{\\text{open}}^{\\text{rate}}(s)\n=\nG\nc\nâ€‹\n(\ns\n)\nâ€‹\nG\nm\nâ€‹\n(\ns\n)\nâ€‹\nG\nd\nâ€‹\n(\ns\n)\n\\displaystyle=G_{c}(s)G_{m}(s)G_{d}(s)\n(13)\n=\nK\nm\nâ€‹\n(\nğŠ\np\nrate\nâ€‹\ns\n+\nğŠ\ni\nrate\n+\nğŠ\nd\nrate\nâ€‹\ns\n2\n)\nâ€‹\nğŠ\nk\nrate\nâ€‹\nğ‰\nt\nâˆ’\n1\ns\n2\nâ€‹\n(\nÏ„\nm\nâ€‹\ns\n+\n1\n)\n.\n\\displaystyle=\\frac{K_{m}\\left(\\mathbf{K}_{p}^{\\text{rate}}s+\\mathbf{K}_{i}^{\\text{rate}}+\\mathbf{K}_{d}^{\\text{rate}}s^{2}\\right)\\mathbf{K}_{k}^{\\text{rate}}\\mathbf{J}_{t}^{-1}}{s^{2}(\\tau_{m}s+1)}.\n-\nDetermine Inertia-Aware Adaptive Gain\nğŠ\nk\nrate\n\\mathbf{K}_{k}^{\\text{rate}}\n.\nWe therefore design the inertia-aware adaptive gain\nğŠ\nk\nrate\n\\mathbf{K}_{k}^{\\text{rate}}\nas:\nğŠ\nk\nrate\n=\nğ‰\na\nâˆ’\n1\nâ€‹\nğ‰\n^\nt\n.\n\\mathbf{K}_{k}^{\\text{rate}}=\\mathbf{J}_{a}^{-1}\\hat{\\mathbf{J}}_{t}.\n(14)\nFigure 6:\nThe maximum values of the gain\nğŠ\nk\nrate\n\\mathbf{K}_{k}^{\\text{rate}}\nalong the three directions (x, y, and z).\nThe determination of\nğŠ\nk\nrate\nâˆˆ\nâ„\n3\nÃ—\n3\n\\mathbf{K}_{k}^{\\text{rate}}\\in\\mathbb{R}^{3\\times 3}\nis crucial for achieving stable control.\nThis gain is designed to dynamically adjust with changes in the systemâ€™s MoI\nğ‰\nt\n\\mathbf{J}_{t}\n, ensuring consistent control performance across various load conditions.\nThe reasons and advantages for this design are as follows:\n- The controller gain\nğŠ\nk\nrate\n\\mathbf{K}_{k}^{\\text{rate}}\ndynamically adjusts with changes in the systemâ€™s MoI\nğ‰\nt\n\\mathbf{J}_{t}\n.\nWhen\nğ‰\nt\n\\mathbf{J}_{t}\nincreases (e.g., due to manipulator motion or added payload),\nğŠ\nk\nrate\n\\mathbf{K}_{k}^{\\text{rate}}\nincreases to compensate for the higher inertia.\nWhen\nğ‰\nt\n\\mathbf{J}_{t}\ndecreases,\nğŠ\nk\nrate\n\\mathbf{K}_{k}^{\\text{rate}}\ndecreases to avoid over-response.\n- As detailed in Section\nIII-C\n, the total MoI\nğ‰\nt\n\\mathbf{J}_{t}\nof the AM depends on\nğ‰\na\n\\mathbf{J}_{a}\n,\nğ‰\no\n\\mathbf{J}_{o}\n, and\nğœ½\n\\bm{\\theta}\n.\nWhen the system is in its unloaded state,\nğ‰\nt\n=\nğ‰\na\n\\mathbf{J}_{t}=\\mathbf{J}_{a}\n, and thus\nğŠ\nk\nrate\nâ‰ˆ\nğˆ\n3\n\\mathbf{K}_{k}^{\\text{rate}}\\approx\\mathbf{I}_{3}\n(the identity matrix).\nThis ensures that the additional term\nğŠ\nk\nrate\n\\mathbf{K}_{k}^{\\text{rate}}\ndoes not affect the control of the AM in the unloaded state.\n- Substituting Eq.Â (\n14\n) into Eq.Â (\n13\n), and noting that\nğ‰\n^\nt\nâ€‹\nğ‰\nt\nâˆ’\n1\nâ‰ˆ\nğˆ\n3\n\\hat{\\mathbf{J}}_{t}\\mathbf{J}_{t}^{-1}\\approx\\mathbf{I}_{3}\n, the open-loop transfer function\nG\nopen\nrate\nâ€‹\n(\ns\n)\nG_{\\text{open}}^{\\text{rate}}(s)\nbecomes independent of\nğ‰\nt\n\\mathbf{J}_{t}\n.\nAs a result, the systemâ€™s dynamic characteristics are primarily determined by the nominal MoI\nğ‰\na\n\\mathbf{J}_{a}\n, rather than the current MoI\nğ‰\nt\n\\mathbf{J}_{t}\n.\nThis ensures consistent control performance across various load conditions, allowing the system to remain stable even during manipulator motion or changes in payload.\n- This design is simple yet effective, reducing the complexity of parameter tuning.\nComputationally,\nğ‰\na\n\\mathbf{J}_{a}\nis preconfigured, and\nğ‰\n^\nt\n\\hat{\\mathbf{J}}_{t}\ncan be quickly updated after grasping the object using Eq.Â (\n7\n), enabling real-time adaptation to changes in MoI.\nFigure 7:\nOpen-loop bode plot with uncertainty.\nIV-B\n3\nFrequency-Domain Stability Assessment\nTo evaluate closed-loop stability under payload-induced disturbances, we perform a\nÎ¼\n\\mu\n-analysis that jointly accounts for uncertainties in the post-grasp inertia and in the scheduled rate gain. The uncertainty bounds are physically grounded in the systemâ€™s payload envelope: we assume the heaviest admissible object, limited to 400 g within a\n20\nÃ—\n20\nÃ—\n20\nâ€‹\ncm\n3\n20{\\times}20{\\times}20~\\text{cm}^{3}\nbounding volume. By sweeping the Delta arm across its workspace and recomputing the whole-system inertia about the updated center of mass, this payload produces worst-case inertia scaling factors of\n3.52\nÃ—\n3.52\\times\n,\n3.79\nÃ—\n3.79\\times\n, and\n1.61\nÃ—\n1.61\\times\nalong the\nx\nx\n-,\ny\ny\n-, and\nz\nz\n-axes, respectively (Fig.\n6\n). In the robustness study, we therefore co-vary the inertia and the scheduled rate gain over the\nsame per-axis bounds\nâ€”anchored at unity and capped at\n3.52\nÃ—\n3.52\\times\n(x),\n3.79\nÃ—\n3.79\\times\n(y), and\n1.61\nÃ—\n1.61\\times\n(z).\nThe resulting\nÎ¼\n\\mu\nremains strictly below unity across\n[\n1\n,\n600\n]\n[1,600]\nrad/s, confirming robust stability; the\nÎ¼\n\\mu\n-critical case still exhibits a\n52.4\nâˆ˜\n52.4^{\\circ}\nphase margin at\n41.5\n41.5\nrad/s (Fig.\n7\n), providing headroom beyond\n45\nâˆ˜\n45^{\\circ}\n.\nFinally, we corroborated the analysis in both simulation and flight. Under the worst-case inertia, we swept the scheduled rate gains up to their per-axis boundsâ€”\n3.52\nÃ—\n3.52\\times\n(x),\n3.79\nÃ—\n3.79\\times\n(y), and\n1.61\nÃ—\n1.61\\times\n(z)â€”and observed no oscillation or divergence. These results support the fidelity of the identified plant and the validity of our stability assessment.\nTABLE I:\nExperimental Setup Parameters\nReal-World Experimental Parameters\nMass\nm\nm\n1.379\n1.379\nkg\nPos. gain\nğŠ\nÎ¸\n\\mathbf{K}_{\\theta}\n(\n20\n,\n20\n,\n20\n)\nâ€ \n(20,20,20)^{\\dagger}\nInertia\nğ‰\na\nâ€‹\n(\nk\nâ€‹\ng\nâ‹…\nm\n2\n)\n\\mathbf{J}_{a}({kg\\cdot m^{2}})\n(\n9.2\n,\n10.5\n,\n14.7\n)\nâ€ \nâ‹…\n10\nâˆ’\n3\n(9.2,10.5,14.7)^{\\dagger}\\cdot 10^{-3}\nPos. gain\nğŠ\npos\n\\mathbf{K}^{\\text{pos}}\n(\n4\n,\n4\n,\n3\n)\nâ€ \n(4,4,3)^{\\dagger}\nThrust coeff.\nc\nT\nc_{T}\n18.1712\n18.1712\nVel. gain\nğŠ\nvel\n\\mathbf{K}^{\\text{vel}}\n(\n3.5\n,\n3.4\n,\n3\n)\nâ€ \n(3.5,3.4,3)^{\\dagger}\nInner-loop\nPX4 v1.14 default, 400 Hz\nDOB gain\nc\nc\n10\n10\nDOB force LPF\n50â€‰Hz cutoff\nDOB rate\n100â€‰Hz\nâ„’\n1\n\\mathcal{L}_{1}\nmoment LPF\n5, 10 rad/s cutoff\nâ„’\n1\n\\mathcal{L}_{1}\nrate\n400â€‰Hz\nâ„’\n1\n\\mathcal{L}_{1}\nHurwitz gain\nğ€\nğ¬\n\\mathbf{A_{s}}\n(\nâˆ’\n10\n,\nâˆ’\n10\n,\nâˆ’\n10\n)\nâ€ \n(-10,-10,-10)^{\\dagger}\ngrav. accel.\ng\ng\n9.81\nâ€‹\nm\n/\ns\n2\n9.81\\,\\mathrm{m/s^{2}}\nâ€ \nMatrices in the table are diagonal. LPF denotes a low-pass filter.\nV\nEXPERIMENTS AND RESULTS\nWe evaluate our methods on a custom AM platform weighing 1.379 kg and measuring 240\nÃ—\n\\times\n240\nÃ—\n\\times\n220 mm\n3\n. The platform is equipped with a NxtPX4v2 flight controller, an Intel RealSense D435i depth camera, and an NVIDIA Jetson Orin NX 16 GB for onboard computation.\nThe delta arm is actuated by three DYNAMIXEL XL430-W250-T servo motors and equipped with an end-effector consisting of three suction cups driven by a vacuum pump.\nFig.\n2\nprovides an overview of the platform.\nOur system is developed in C++11 on Ubuntu 20.04 ROS Noetic with parameters listed in Tab.\nI\n, where\nâ„’\n1\n\\mathcal{L}_{1}\nQuad\n[\n32\n]\nis applied only to rotational dynamics.\nAccurate positioning is provided by the NOKOV motion capture system, while perception, planning, and control modules are executed on the onboard computer.\nIn our experiments eight different test objects with varying inertial parameters are used:\n1. A solid plastic box,\n2. A yellow tissue box,\n3. A mouse box,\n4. A solid cardboard box,\n5. A canned coffee bean container,\n6. A white iron can with candy,\n7. A dry powder extinguisher box, and\n8. A coke can.\nTABLE II:\nInertia Estimation Errors at Two Stages\nm\nt\nm_{t}\nc\nt\nx\nc^{x}_{t}\nc\nt\ny\nc^{y}_{t}\nc\nt\nz\nc^{z}_{t}\nJ\nt\nx\nâ€‹\nx\n{J}^{xx}_{t}\nJ\nt\ny\nâ€‹\ny\n{J}^{yy}_{t}\nJ\nt\nz\nâ€‹\nz\n{J}^{zz}_{t}\n(kg)\n(m)\n(m)\n(m)\n(\ng\nâ‹…\nm\n2\n)\n(g\\cdot m^{2})\n(\ng\nâ‹…\nm\n2\n)\n(g\\cdot m^{2})\n(\ng\nâ‹…\nm\n2\n)\n(g\\cdot m^{2})\nğ’†\nPre-Sensing\n\\bm{e}_{\\textbf{Pre-Sensing}}\n0.0380\n0.0009\n0.0002\n0.0051\n1.745\n1.789\n0.055\nğœ¹\nPre-Sensing\n\\bm{\\delta}_{\\textbf{Pre-Sensing}}\n-2.38%\n-15.33%\n-15.33%\n-21.93%\n-8.49%\n-8.08%\n-0.36%\nğ’†\nFinal\n\\bm{e}_{\\textbf{Final}}\n0.0058\n0.03e-12\n0.05e-12\n0.0003\n0.051\n0.051\n0.001\nğœ¹\nFinal\n\\bm{\\delta}_{\\textbf{Final}}\n-0.36%\n-2.27%\n-2.27%\n1.98%\n-0.45%\n-0.39%\n-5.19e-3%\ne\ne\nand\nÎ´\n\\delta\ndenote the absolute and relative errors respectively.\nV-A\nInertial Parameter Estimation\nTo demonstrate the accuracy and efficiency of our method, we evaluated it on a diverse set of everyday objects of varying shapes, sizes, and masses.\nFor clarity, we detail here a representative run with a 219 g coffee-can target while the AM flies in, grasps the object, and estimates the following inertial parameters online: the total mass\nm\nt\nm_{t}\n, center of mass\nğ’„\nt\n\\bm{c}_{t}\n, and principal moments of inertia\nğ‰\nt\n\\mathbf{J}_{t}\n.\nSimilar to\n[\n33\n]\n, an estimate is declared converged once it enters and subsequently remains within the following bounds: mass error\n<\n<\n4%, MoI error\n<\n<\n20%, and CoM error\n<\n<\n2mm.\nFig.\n8\nshows real-time estimation results for each parameter.\nAt\n0\nâ€‹\ns\n0~$\\mathrm{s}$\n, the AM begins flying toward the target object while performing object Pre-Sensing.\nBy\n2\nâ€‹\ns\n2~$\\mathrm{s}$\n, an initial estimate of the objectâ€™s mass and MoI is obtained, though these values are not yet applied to the systemâ€™s overall parameters as the object remains ungrasped.\nAt\n7\nâ€‹\ns\n7~$\\mathrm{s}$\n, the AM successfully grasps the object, triggering an update of the systemâ€™s inertial parameters to account for the objectâ€™s influence.\nThe absolute and relative errors of the estimation results at this Pre-Sensing stage are shown in the first two rows of Tab.\nII\n.\nThe relative errors for the total mass, CoM, and MoI are\nâˆ’\n2.38\n%\n-2.38\\%\n,\nâˆ’\n21.93\n%\n-21.93\\%\nto\nâˆ’\n15.33\n%\n-15.33\\%\n, and\nâˆ’\n8.49\n%\n-8.49\\%\nto\nâˆ’\n0.36\n%\n-0.36\\%\n, respectively.\nThrough adaptation based on onboard sensor feedback, the inertial parameters are further refined.\nThe absolute and relative errors are listed in the last two rows of Tab.\nII\n.\nAfter adaptation, the relative estimation errors for the total mass, CoM, and MoI improve to\n0.36\n%\n0.36\\%\n,\nâ‰¤\n2.27\n%\n\\leq 2.27\\%\n, and\nâ‰¤\n0.45\n%\n\\leq 0.45\\%\n, respectively.\nCompared to\n[\n33\n]\n(errors\n<\n4\n%\n<4\\%\n,\n5\n%\n5\\%\n,\n20\n%\n20\\%\nfor mass, CoM, MoI estimation, respectively) and\n[\n29\n]\n(mass error up to\n2.2\n%\n2.2\\%\n, no CoM/MoI estimation results reported), our Pre-Sensing results are competitive, while the post-adaptation results achieve significantly higher accuracy.\nFurthermore, unlike\n[\n15\n]\nand\n[\n33\n]\n, which require\n27\nâ€‹\ns\n27~$\\mathrm{s}$\nof hovering or\n19\nâ€‹\ns\n19~$\\mathrm{s}$\nof excitation trajectory after grasping, our approach completes the inertia estimation in approximately\n2\nâ€‹\ns\n2~$\\mathrm{s}$\n, achieving an approximately 10-fold improvement in efficiency.\nV-B\nHover Stabilization\nTo evaluate the proposed method, we conduct a hoverâ€“stabilization benchmark.\nThe experiment was conducted with a 400 g iron disc and eight different object mentioned above as the payload.\nThree trajectory segments were executed, each consisting of five back-and-forth motions at 10 cm/s along the body y-axis, under the PX4 v1.14.0\n[\n30\n]\n(0â€“20 s), the\nâ„’\n1\n\\mathcal{L}_{1}\nQuad\n[\n32\n]\n(20-40 s), and the proposed method (after 40 s), as shown in Fig.\n9\n.\nThe top shows the manipulator end-effector\ny\ny\n-axis tracking, the middle shows the AM rollâ€“attitude response, and the bottom shows the AM\ny\ny\n-position response.\nSpecifically, the PX4 baseline uses the multicopter cascaded attitudeâ€“rate PID controller (modules\nmc_att_control\nand\nmc_rate_control\n) from PX4 v1.14.0\n[\n30\n]\n.\nWe quantify performance using RMSE and maximum absolute error for position; averaged over all eight objects, our method consistently reduces all metrics relative to the baseline.\nAs summarized in Tab.\nIII\n, both\nâ„’\n1\n\\mathcal{L}_{1}\nQuad and our method reduce\ny\ny\n-axis position error under hover disturbance compared to PX4; our controller achieves the largest gains, lowering RMSE by\n28.2\n%\n28.2\\%\nand peak error by\n30.9\n%\n30.9\\%\nrelative to PX4.\nFor attitude tracking, our controller likewise improves performance, cutting attitude RMSE by\n29.4\n%\n29.4\\%\nand peak attitude error by\n28.5\n%\n28.5\\%\ncompared with PX4.\nFigure 8:\nReal-time inertia estimation during object grasping.\nTABLE III:\nHoverâ€“stabilization benchmark\nMethod\nPosition\nAttitude (roll)\nRMSE [m]\nMax [m]\nRMSE [rad]\nMax [rad]\nPX4 v1.14\n[\n30\n]\n0.143\nâˆ—\n0.307\nâˆ—\n0.099\nâˆ—\n0.200\nâˆ—\nâ„’\n1\n\\mathcal{L}_{1}\nQuad\n[\n32\n]\n0.120 (\nâ†“\n\\downarrow\n16.3%)\n0.259 (\nâ†“\n\\downarrow\n15.4%)\n0.080 (\nâ†“\n\\downarrow\n19.3%)\n0.184 (\nâ†“\n\\downarrow\n8.0%)\nOurs\n0.103 (\nâ†“\n\\downarrow\n28.2%)\n0.212 (\nâ†“\n\\downarrow\n30.9%)\n0.070 (\nâ†“\n\\downarrow\n29.4%)\n0.143 (\nâ†“\n\\downarrow\n28.5%)\nâˆ—\nReference values.\nâ†“\n\\downarrow\ndenotes reduction relative to PX4.\nV-C\nObject Manipulation and Transportation\nWe evaluate our framework in real-world manipulation and transportation scenarios through two representative tasks.\nTask 1 â€” Object Pick-and-Place\n:\nFor each of eight test objects, we perform 20 trials using both PX4 and our method. In each trial, the object is randomly placed 3 m away, after which the system detects, grasps, and transports it along a whole-body trajectory\n[\n8\n]\nto a table 5 m away at up to 4 m/s (Fig.\n10\n(A)). Our method consistently yields lower tracking errors across all objects, with larger gains for heavier payloads. The maximum RMSE improvement reaches 0.054 m, and averaged over all objects, the position-tracking RMSE mean and standard deviation are reduced by\n17.47\n%\n17.47\\%\nand\n59.91\n%\n59.91\\%\n, respectively (Fig.\n10\n(D)).\nTask 2 â€” Object Transportation Under Disturbances\n:\nThe aerial manipulator transports the object through a 40 cm racing gate while subjected to a lateral 5 m/s wind disturbance (Fig.\n10\n(A)). Gate passage requires arm retraction, introducing abrupt inertia changes, and the wind acts 2 m before the gate. Under these challenging conditions, our method reduces position and velocity RMSE by\n9.45\n%\n9.45\\%\nand\n9.7\n%\n9.7\\%\n, and reduces attitude and angular-rate RMSE by\n17.25\n%\n17.25\\%\nand\n20.35\n%\n20.35\\%\n, demonstrating improved robustness during disturbed transportation.\nFigure 9:\nEnd-effector trajectory tracking along the y-axis.\nV-D\nAblation Study\nThis section evaluates the effect of the Pre-Sensing module via ablation experiments in aerial manipulation tasks on two objects (Fig.\n10\n(B)).\nTwo experimental groups are considered: Group1 uses the standard PX4 controller without DOB compensation as the baseline\n[\n30\n]\n, while GroupÂ 2 further enables DOB-based control\n[\n34\n]\n.\nEach group includes four configurations:\nPre + DOBm\n,\nPre only\n,\nDOBm only\n, and\nBaseline\n, where\nPre\ndenotes the proposed Pre-Sensing module.\nFor each configuration, 16 trials are conducted with the object randomly placed approximately 3m away (Fig.\n10\n(C)).\nBy comparing\nPre only\nwith the baseline and\nPre + DOBm\nwith\nDOBm only\n, the ablation design isolates the effects of pre-sensing and DOB.\nOverall, the results (Tab.\nIV\n) show that Pre-Sensing consistently improves tracking performance and further enhances performance when combined with DOB-based control, demonstrating its independent and complementary role in the proposed framework.\nTABLE IV:\nAblation results on tracking performance\nMethod\nPosition\nAttitude\nRMSE [m]\nMax [m]\nRMSE [rad]\nMax [rad]\nGroup 1: PX4 without DOB Control as Baseline\nPre + DOBm\n0.064 (\nâ†“\n\\downarrow\n26.4%)\n0.141\n0.062 (\nâ†“\n\\downarrow\n36.1%)\n0.298\nPre only\n0.071 (\nâ†“\n\\downarrow\n18.4%)\n0.150\n0.058 (\nâ†“\n\\downarrow\n40.2%)\n0.293\nDOBm only / Baseline\nâˆ—\n[\n30\n]\n0.087\n0.291\n0.097\n0.307\nGroup 2: PX4 with DOB Control as Baseline\nPre + DOBm\n0.052 (\nâ†“\n\\downarrow\n26.8%)\n0.137\n0.042 (\nâ†“\n\\downarrow\n37.3%)\n0.193\nPre only\n0.059 (\nâ†“\n\\downarrow\n16.9%)\n0.151\n0.046 (\nâ†“\n\\downarrow\n31.3%)\n0.170\nDOBm only / Baseline\nâˆ—\n[\n34\n]\n0.071\n0.147\n0.067\n0.220\nâˆ—\nReference values.\nâ†“\n\\downarrow\ndenotes reduction within each group.\nDOBm only / Baseline\nâˆ—\nindicates identical results for the DOBm-only case and the baseline.\nFigure 10:\n(A) Task 1: Object Pick-and-Place (left); Task 2: Object Transportation under Disturbance (right). (B) The AM grasps different object that is randomly placed on the table in the ablation study. (C) Different reference trajectory (left) and 16 flight trials (right) in the ablation study. (D) Position tracking error in Object Pick-and-Place task. (E) DOB estimation of linear external forces during grasping process. (F) Position and attitude errors in the ablation study.\nVI\nCONCLUSION AND FUTURE WORK\nThis paper presents a unified aerial manipulation system that pre-senses object inertial properties and adaptively adjusts control in real time. The system integrates a vision-language-based human-inspired inertia estimator and an inertia-aware adaptive strategy, achieving\n<\n3\n%\n<3\\%\ninertia estimation error within 2Â s in average and improving position and attitude tracking accuracy by 43% and 30% (RMSE), respectively.\nThis work paves the way for future advances. Future work will pursue three directions: (i) leveraging the modular design of our perception and control components to deploy the framework on aerial vehicles with varying structures, enabling cross-platform generalization; (ii) refine object prompts online and embed anticipatory forceâ€“inertia predictions into the planner so that trajectories pre-compensate for expected disturbances; and (iii) scale the system to multi-object, outdoor settings to test real-time robustness.\nReferences\n[1]\nG. Baraban, M. Sheckells, S. Kim, and M. Kobilarov\n(2020)\nAdaptive parameter estimation for aerial manipulation\n.\nIn\nAmerican Control Conference\n,\npp.Â 614â€“619\n.\nCited by:\nÂ§I\n.\n[2]\nC. BÃ¶hm, G. Li, G. Loianno, and S. Weiss\n(2020)\nObservability-aware trajectories for geometric and inertial self-calibration\n.\nPower On and Go Robots\n.\nCited by:\nÂ§I\n.\n[3]\nC. BÃ¶hm, M. Scheiber, and S. Weiss\n(2021)\nFilter-based online system-parameter estimation for multicopter uavs\n.\nIn\nRobotics: Science and Systems\n,\nCited by:\nÂ§I\n.\n[4]\nH. Chen, B. Ye, X. Liang, W. Deng, and X. Lyu\n(2025)\nNDOB-based control of a uav with delta-arm considering manipulator dynamics\n.\nIn\nProc. IEEE Int. Conf. Robot. and Autom.\n,\npp.Â 7505â€“7511\n.\nCited by:\nÂ§\nIV-B\n1\n.\n[5]\nA. Codourey\n(1996)\nDynamic modelling and mass matrix evaluation of the DELTA parallel robot for axes decoupling control\n.\nIn\nProc. IEEE/RSJ Int. Conf. on Intell. Robots and Syst.\n,\nCited by:\nÂ§\nII-C\n.\n[6]\nC. Coulombe, D. SaussiÃ©, and S. Achiche\n(2022)\nModeling and gain-scheduled control of an aerial manipulator\n.\nInternational Journal of Dynamics and Control\n10\n(\n1\n),\npp.Â 217â€“229\n.\nCited by:\nÂ§I\n.\n[7]\nB. P. Delhaye, F. Schiltz, F. Crevecoeur, J. Thonnard, and P. LefÃ¨vre\n(2024)\nFast grip force adaptation to friction relies on localized fingerpad strains\n.\nScience advances\n10\n(\n3\n),\npp.Â eadh9344\n.\nCited by:\nÂ§I\n.\n[8]\nW. Deng, H. Chen, B. Ye, H. Chen, Z. Li, and X. Lyu\n(2025)\nWhole-body integrated motion planning for aerial manipulators\n.\nIEEE Trans. Robotics\n41\n,\npp.Â 6661â€“6679\n.\nCited by:\nÂ§\nII-C\n,\nÂ§\nV-C\n.\n[9]\nR. W. Deters, G. K. Ananda, and M. S. Selig\n(2014)\nReynolds number effects on the performance of small-scale propellers\n.\nIn\nAIAA Applied Aerodynamics Conference\n,\npp.Â 2151\n.\nCited by:\nÂ§\nIII-B\n1\n.\n[10]\nS. Gao, H. Hong, S. Sun, L. Luo, and S. Hu\n(2024)\nUncertainty modeling enabled meta adaptive control for aerial manipulators\n.\nJournal of Guidance, Control, and Dynamics\n47\n,\npp.Â 2148â€“2163\n.\nCited by:\nÂ§I\n,\nÂ§III\n.\n[11]\nP. Guglielmetti and R. Longchamp\n(1994)\nA closed form inverse dynamics model of the delta parallel robot\n.\nIFAC Proceedings Volumes\n27\n(\n14\n),\npp.Â 51â€“56\n.\nCited by:\nÂ§\nII-C\n.\n[12]\nM. R. Jardin and E. R. Mueller\n(2009)\nOptimized measurements of unmanned-air-vehicle mass moment of inertia with a bifilar pendulum\n.\nJournal of Aircraft\n46\n(\n3\n),\npp.Â 763â€“775\n.\nCited by:\nÂ§\nIII-C\n2\n,\nÂ§\nIII-C\n3\n.\n[13]\nR.S. Johansson and G. Westling\n(1988)\nCoordinated isometric muscle commands adequately and erroneously programmed for the weight during lifting task with precision grip\n.\nExperimental brain research\n71\n,\npp.Â 59â€“71\n.\nCited by:\nÂ§I\n.\n[14]\nS. Kim, S. Choi, and H. J. Kim\n(2013)\nAerial manipulation using a quadrotor with a two DOF robotic arm\n.\nIn\nProc. IEEE/RSJ Int. Conf. on Intell. Robots and Syst.\n,\nCited by:\nÂ§I\n.\n[15]\nH. Lee and H. J. Kim\n(2017)\nEstimation, control, and planning for autonomous aerial transportation\n.\nIEEE Trans. Ind. Electron.\n64\n(\n4\n),\npp.Â 3369â€“3379\n.\nCited by:\nÂ§I\n,\nÂ§I\n,\nÂ§III\n,\nÂ§\nV-A\n.\n[16]\nH. Lee, H. Kim, W. Kim, and H. J. Kim\n(2018)\nAn integrated framework for cooperative aerial manipulators in unknown environments\n.\nIEEE Robotics Autom. Lett.\n3\n(\n3\n),\npp.Â 2307â€“2314\n.\nCited by:\nÂ§I\n.\n[17]\nH. Lee, S. Kim, and H. J. Kim\n(2015)\nControl of an aerial manipulator using on-line parameter estimator for an unknown payload\n.\nIn\nProc. IEEE Int. Conf. Autom. Sci. Eng.\n,\npp.Â 316â€“321\n.\nCited by:\nÂ§I\n,\nÂ§III\n.\n[18]\nJ. Liu, Y. Chen, X. Ye, and X. Qi\n(2023)\nIST-net: prior-free category-level pose estimation with implicit space transformation\n.\nIn\nProc. IEEE/CVF Int. Conf. Comput. Vis.\n,\npp.Â 13978â€“13988\n.\nCited by:\nÂ§\nIII-A\n2\n,\nÂ§\nIII-A\n.\n[19]\nX. Lyu, H. Gu, Y. Wang, Z. Li, S. Shen, and F. Zhang\n(2017)\nDesign and implementation of a quadrotor tail-sitter vtol uav\n.\nIn\nProc. IEEE Int. Conf. Robot. and Autom.\n,\npp.Â 3924â€“3930\n.\nCited by:\nÂ§\nIV-B\n1\n.\n[20]\nD. Mellinger, Q. Lindsey, M. Shomin, and V. Kumar\n(2011)\nDesign, modeling, estimation and control for aerial grasping and manipulation\n.\nIn\nProc. IEEE/RSJ Int. Conf. on Intell. Robots and Syst.\n,\npp.Â 2668â€“2673\n.\nCited by:\nÂ§I\n,\nÂ§III\n.\n[21]\nA. Ollero, M. Tognon, A. SuÃ¡rez, D. Lee, and A. Franchi\n(2022)\nPast, present, and future of aerial robotic manipulators\n.\nIEEE Trans. Robotics\n38\n(\n1\n),\npp.Â 626â€“645\n.\nCited by:\nÂ§I\n,\nÂ§\nII-C\n,\nÂ§\nIII-C\n,\nÂ§IV\n.\n[22]\nOpenAI\n(2023)\nGPT-4 technical report\n.\narXiv:2303.08774\n.\nCited by:\nÂ§\nIII-A\n.\n[23]\nM. Orsag, C. M. Korpela, S. Bogdan, and P. Y. Oh\n(2014)\nHybrid adaptive control for aerial manipulation\n.\nJ. Int. Robotic Syst.\n73\n(\n1-4\n),\npp.Â 693â€“707\n.\nCited by:\nÂ§I\n.\n[24]\nC. Park, A. Ramirez-Serrano, and M. Bisheban\n(2023)\nEstimation of time-varying inertia of aerial manipulators performing manipulation of unknown objects\n.\nIn\nProc. Int. Conf. Control Syst. Robot.\n,\npp.Â 1â€“6\n.\nCited by:\nÂ§I\n,\nÂ§III\n.\n[25]\nV. V. Polanen and M. Davare\n(2015)\nSensorimotor memory biases weight perception during object lifting\n.\nFrontiers in human neuroscience\n9\n,\npp.Â 700\n.\nCited by:\nÂ§I\n.\n[26]\nT. Ren, S. Liu, A. Zeng, J. Lin, K. Li, H. Cao, J. Chen, X. Huang, Y. Chen, F. Yan, Z. Zeng, H. Zhang, F. Li, J. Yang, H. Li, Q. Jiang, and L. Zhang\n(2024)\nGrounded SAM: assembling open-world models for diverse visual tasks\n.\narXiv:2401.14159\n.\nCited by:\nÂ§\nIII-A\n1\n,\nÂ§\nIII-A\n.\n[27]\nF. Ruggiero, V. Lippiello, and A. Ollero\n(2018)\nAerial manipulation: A literature review\n.\nIEEE Robotics Autom. Lett.\n3\n(\n3\n),\npp.Â 1957â€“1964\n.\nCited by:\nÂ§I\n,\nÂ§I\n,\nÂ§IV\n.\n[28]\nT. Standley, O. Sener, D. Chen, and S. Savarese\n(2017)\nImage2mass: estimating the mass of an object from its image\n.\nIn\nProc. Conf. Robot Learn.\n,\npp.Â 324â€“333\n.\nCited by:\nÂ§I\n.\n[29]\nJ. Svacha, J. Paulos, G. Loianno, and V. Kumar\n(2020)\nIMU-based inertia estimation for a quadrotor using newton-euler dynamics\n.\nIEEE Robotics Autom. Lett.\n5\n(\n3\n),\npp.Â 3861â€“3867\n.\nCited by:\nÂ§I\n,\nÂ§III\n,\nÂ§\nV-A\n.\n[30]\nP. D. Team\n(2024)\nPX4 autopilot (v1.14.0)\n.\nNote:\nhttps://github.com/PX4/PX4-Autopilot/tree/v1.14.0[Online].\nCited by:\nÂ§\nV-B\n,\nÂ§\nV-D\n,\nTABLE III\n,\nTABLE IV\n.\n[31]\nJ. Wu, I. Yildirim, J. J. Lim, B. Freeman, and J. Tenenbaum\n(2015)\nGalileo: perceiving physical object properties by integrating a physics engine with deep learning\n.\nAdv. Neural Inf. Process. Syst.\n28\n.\nCited by:\nÂ§I\n.\n[32]\nZ. Wu, S. Cheng, P. Zhao, A. Gahlawat, K. A. Ackerman, A. Lakshmanan, C. Yang, J. Yu, and N. Hovakimyan\n(2025)\nâ„’\n1\n\\mathcal{L}_{1}\nquad: L1 adaptive augmentation of geometric control for agile quadrotors with performance guarantees\n.\nIEEE Trans. Control. Syst. Technol.\n33\n(\n2\n),\npp.Â 597â€“612\n.\nCited by:\nÂ§\nV-B\n,\nTABLE III\n,\nÂ§V\n.\n[33]\nV. WÃ¼est, V. Kumar, and G. Loianno\n(2019)\nOnline estimation of geometric and inertia parameters for multirotor aerial vehicles\n.\nIn\nProc. IEEE Int. Conf. Robot. and Autom.\n,\npp.Â 1884â€“1890\n.\nCited by:\nÂ§I\n,\nÂ§I\n,\nÂ§I\n,\nÂ§III\n,\nÂ§\nV-A\n,\nÂ§\nV-A\n.\n[34]\nH. Yu, X. Liang, and X. Lyu\n(2024)\nDOB-based wind estimation of A UAV using its onboard sensor\n.\nIn\nProc. IEEE/RSJ Int. Conf. on Intell. Robots and Syst.\n,\npp.Â 8126â€“8133\n.\nCited by:\nÂ§\nIII-B\n1\n,\nÂ§\nIII-B\n,\nÂ§\nV-D\n,\nTABLE IV\n.",
    "preview_text": "Aerial manipulators (AMs) are gaining increasing attention in automated transportation and emergency services due to their superior dexterity compared to conventional multirotor drones. However, their practical deployment is challenged by the complexity of time-varying inertial parameters, which are highly sensitive to payload variations and manipulator configurations. Inspired by human strategies for interacting with unknown objects, this letter presents a novel onboard framework for robust aerial manipulation. The proposed system integrates a vision-based pre-grasp inertia estimation module with a post-grasp adaptation mechanism, enabling real-time estimation and adaptation of inertial dynamics. For control, we develop an inertia-aware adaptive control strategy based on gain scheduling, and assess its robustness via frequency-domain system identification. Our study provides new insights into post-grasp control for AMs, and real-world experiments validate the effectiveness and feasibility of the proposed framework.\n\nFlyAware: Inertia-Aware Aerial Manipulation via Vision-Based Estimation and Post-Grasp Adaptation\nBiyu Ye\n1\n, Na Fan\n2\n, Zhengping Fan\n1\n, Weiliang Deng\n1\n, Hongming Chen\n1\n, Qifeng Chen\n2\n, and Ximin Lyu\n1,3\nManuscript received: June 27, 2025; Revised December 15, 2025; Accepted January 21, 2026. This paper was recommended for publication by Editor Soon-Jo Chung upon evaluation of the Associate Editor and Reviewersâ€™comments. This work is supported by the National Key Research and Development Program of China (Grant No. 2023YFB4706600), the National Natural Science Foundation of China (Grant No.62303495), the Research Grants Council of HKSAR (Grant No. AoE/E-601/24-N), and the Young Talent Support Project of Guangzhou Association for Science and Technology (Grant No. QT-2025-004).\n(Biyu Ye and Na Fan are co-first authors.) (Corresponding author: Ximin Lyu.)\n(Project page:\nhttps://flyaware.github.io/\n)\n1\nBiyu Ye, Zhengping Fan, Weiliang Deng, Hongming Ch",
    "is_relevant": true,
    "relevance_score": 3.0,
    "extracted_keywords": [
        "locomotion",
        "whole body control",
        "fine tune"
    ],
    "one_line_summary": "è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºè§†è§‰çš„æƒ¯æ€§æ„ŸçŸ¥ç©ºä¸­æ“çºµæ¡†æ¶ï¼Œé€šè¿‡é¢„æŠ“å–æƒ¯æ€§ä¼°è®¡å’ŒåæŠ“å–è‡ªé€‚åº”æ§åˆ¶æ¥å¢å¼ºæœºå™¨äººç³»ç»Ÿçš„é²æ£’æ€§ã€‚",
    "detailed_summary": "",
    "qa_pairs": [],
    "is_hidden": false,
    "is_starred": false,
    "flag": true,
    "published_date": "2026-01-30T08:02:33Z",
    "created_at": "2026-02-03T15:53:06.231959",
    "updated_at": "2026-02-03T15:53:06.231968"
}