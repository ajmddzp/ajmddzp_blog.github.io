{
    "id": "2601.14617v1",
    "title": "UniCon: A Unified System for Efficient Robot Learning Transfers",
    "authors": [
        "Yunfeng Lin",
        "Li Xu",
        "Yong Yu",
        "Jiangmiao Pang",
        "Weinan Zhang"
    ],
    "abstract": "由于平台差异、接口不一致以及中间件效率低下，基于学习的控制器在异构机器人间的部署面临挑战。为解决这些问题，我们提出了UniCon——一个轻量级框架，通过标准化平台间的状态、控制流与仪器接口，将工作流分解为可复用组件构成的执行图，并将系统状态与控制逻辑分离，实现跨不同机器人形态的即插即用部署。与传统中间件不同，该框架通过批量向量化数据流优先保障效率，最小化通信开销并提升推理延迟。这种模块化、数据导向的方法能够以极少的重新设计实现从仿真到实物的无缝迁移。实验表明，UniCon在迁移工作流时能减少代码冗余，相比基于ROS的系统具有更高的推理效率。该框架已在7家制造商的超过12种机器人模型上完成部署，并成功集成到多项持续进行的研究项目中，验证了其在真实场景中的有效性。",
    "url": "https://arxiv.org/abs/2601.14617v1",
    "html_url": "https://arxiv.org/html/2601.14617v1",
    "html_content": "UniCon: A Unified System for Efficient Robot Learning Transfers\nYunfeng Lin\nlinyunfeng@sjtu.edu.cn\nShanghai Jiao Tong University\nShanghai Artificial Intelligence Laboratory\nShanghai, China\n&Li Xu\nlixu@changan.com.cn\nAI Laboratory,\nChongqing Changan Automobile Co. Ltd.\nChongqing, China\n&Yong Yu\nyyu@apex.sjtu.edu.cn\nShanghai Jiao Tong University\nShanghai, China\n&Jiangmiao Pang\npangjiangmiao@pjlab.org.cn\nShanghai Artificial Intelligence Laboratory\nShanghai, China\n&Weinan Zhang\nwnzhang@sjtu.edu.cn\nShanghai Jiao Tong University\nShanghai Artificial Intelligence Laboratory\nShanghai, China\nCorresponding author.\nAbstract\nDeploying learning-based controllers across heterogeneous robots is challenging due to platform differences, inconsistent interfaces, and inefficient middleware.\nTo address these issues, we present UniCon, a lightweight framework that standardizes states, control flow, and instrumentation across platforms.\nIt decomposes workflows into execution graphs with reusable components, separating system states from control logic to enable plug-and-play deployment across various robot morphologies.\nUnlike traditional middleware, it prioritizes efficiency through batched, vectorized data flow, minimizing communication overhead and improving inference latency.\nThis modular, data-oriented approach enables seamless sim-to-real transfer with minimal re-engineering.\nWe demonstrate that UniCon reduces code redundancy when transferring workflows and achieves higher inference efficiency compared to ROS-based systems.\nDeployed on over 12 robot models from 7 manufacturers, it has been successfully integrated into ongoing research projects, proving its effectiveness in real-world scenarios.\nFigure 1\n:\nRepresentative use cases of UniCon:\nLeft:\nsynchronized and reusable locomotion across heterogeneous robots.\nMiddle:\nModular interoperation of RL policies with VR teleoperation.\nRight:\nReal‑to‑sim data recording and analysis for diagnosing transfer gaps.\nData and control flow are standardized across platforms, reducing integration effort and improving efficiency.\n1\nIntroduction\nDeploying learning‑based controllers across heterogeneous robots remains costly due to platform differences and tightly coupled interfaces.\nThese incompatibilities force developers to repeatedly re-implement the same functionalities for each combination of algorithms, robots and simulators.\nWhile domain randomization and related sim-to-real techniques\n(\nrandomization1\n;\nrandomization2\n)\nshrink the dynamics gap, they do not simplify this last-mile integration.\nWidely used middleware such as ROS and ROS 2\n(\nros\n;\nros2\n)\nattempt to provide a standardized communication layer between customized components, but their general‑purpose design introduces\nlatency and overhead\nthat hinder high‑frequency policy inference\n(\npytorch\n;\nAnsel2024PyTorch2F\n;\nonnx\n)\n.\nAt the same time, robot manufacturers complicate the ecosystem further by shipping\ninconsistent interfaces\n, making integration and transferability difficult.\nTo address above challenges, we present UniCon, a lightweight framework for robot learning deployments that provides the unifying infrastructure needed to standardize states, control flow, and instrumentation across platforms.\nUniCon decomposes workflows into execution graphs with reusable basic units, and separates system states – such as proprioceptive, exteroceptive, and control signals – from the logic that consumes them.\nThis enables\nplug‑and‑play deployment\nacross diverse morphologies including quadrupeds, humanoids, and manipulators, while unifying hardware with simulators for seamless transfer.\nCompared to ROS, our architecture adopt a data-oriented modular paradigm with separation between runtime states and control logic.\nTo maximize efficiency, we favor single-threaded computing\n(\nros2compose\n)\nover multiprocessing, and vectorized data flow over message passing.\nOn the other hand, interoperability with existing software is still guaranteed by extending the underlying states storage to multiple communication backends\n(\nzeromq2010\n;\nddsfoundation2025\n)\n.\nWe show that this reduces code redundancy and improves inference latency in our cross-embodiment experiments.\nOur contributions are threefold:\n•\nUnified control framework:\nWe introduce UniCon, a lightweight and efficient framework that bridges mainstream simulators and physical hardware for robot learning.\n•\nModular, data-oriented design:\nWe demonstrate that UniCon enables efficient sim-to-real transfer across diverse robot embodiments with little to no re-engineering effort.\n•\nImproved inference efficiency:\nWe show that UniCon achieves higher inference efficiency compared to ROS-based and ad-hoc framework stacks by reducing interfacing and communication overhead.\nUniCon has already been deployed on over\n12 robot models\nspanning\n7 manufacturers\n, and has supported\n3 research projects\nongoing in the Shanghai Artificial Intelligence Laboratory, demonstrating its versatility in real research scenarios.\nWe release our framework as open-source at\nhttps://github.com/creeperlin/unicon\n.\n2\nFramework\nA key obstacle in sim‑to‑real and cross-embodiment transfer is the tight coupling of system data flows with customized control logic.\nMiddleware such as ROS enforce a message passing pattern but incurs latency, making it unsuitable for learning‑based controllers.\nOur design instead adopts a modular, data‑oriented paradigm that cleanly separates states from logic, emphasizing reusability and efficiency.\nThis approach contrasts with object‑oriented programming practices\n(\n10.5555/1407387\n)\n, where data and routines are encapsulated together, and instead aligns more closely with the Entity Component System architecture widely used in the game industry\n(\noverwatch2017gdc\n)\nand modern simulation engines\n(\nshacklett23madrona\n)\n.\nFigure 2\n:\nArchitecture of UniCon: (a) global system states with switchable storage backends; (b) modular control blocks covering platform and inference; (c) control flow graph primitives for workflow composition; and (d) unified integration with simulators and hardware.\n2.1\nVectorized States\nWe formulate all runtime states of a robot workflow as global array objects of numerical data types under different labels.\nThis comes from the fact that the data passed in structured messages often take a fixed format for each channel if the hardware participants remains constant.\nTherefore, rather than transmitting full self‑describing objects, only the essential multidimensional data are exchanged, eliminating unnecessary encapsulation and aligning with contiguous memory layouts favored by simulators and hardware interfaces.\nTypically, the states includes robot sensory inputs such as motor position and velocities, as well as orientation and angular velocity reported by the IMU.\nSimilarly, motor commands such as position and torque controls are also states which are written to by controllers and read from by hardware interfaces.\nIn the case where state definitions of custom components differ from the actual hardware, transparent mappings with efficient vectorized indexing operations is inserted to align properties such as joint order.\n2.2\nModularized Logic\nFollowing the vectorized formulation, we break down workflows into reusable Control Blocks (CB) bridged by global states.\nFor example, operations like receiving hardware states, executing policy inference, handling user inputs, and sending hardware commands are split into individual blocks and connected into an execution graph through standardized control flow.\nThis grants users the ability to shift between controllers, policies and hardware by switching between CBs, without changing the rest of the graph.\nFormally, we assume the global state space\nS\n=\n{\ns\na\n,\ns\nb\n,\n…\n,\ns\nn\n}\n,\ns\ni\n∈\nℛ\nk\ni\nS=\\{s_{a},s_{b},\\dots,s_{n}\\},s_{i}\\in{\\mathcal{R}}^{k_{i}}\nis the common domain of all operating logic.\nThen we define a CB as a pure function with regard to\nS\nS\n.\nIt can read a subset of\nS\nS\nas inputs and outputs updated values of some other elements in\nS\nS\n, and a boolean\nr\nr\nindicating its termination.\nf\n:\nS\ni\n​\nn\n↦\nS\no\n​\nu\n​\nt\n×\n{\n0\n,\n1\n}\n,\nS\ni\n​\nn\n,\nS\no\n​\nu\n​\nt\n⊆\nS\n.\nf:S_{in}\\mapsto S_{out}\\times\\{0,1\\},S_{in},S_{out}\\subseteq S.\n(1)\nStepping the function results in a sequence of calls:\nT\nf\n=\n(\nf\n1\n,\nf\n2\n,\n…\n,\nf\nn\n)\n.\nT_{f}=(f_{1},f_{2},\\dots,f_{n}).\n(2)\nA workflow is then constructed by nesting the CBs, forming an execution graph.\nWe provide basic control flow components in similar fasion to functional programming\n(\nHughes1989WhyFP\n)\nfor composing customized workflows.\nFor example,\nloop\nterminates the inner block when the predicate is satisfied,\nzip\nexecutes multiple blocks in sequence, and\nchain\nexhausts nested blocks in order until they all halts.\nloop\n⁡\n(\nT\ng\n,\np\n)\n\\displaystyle\\operatorname{loop}(T_{g},p)\n=\n(\ng\n1\n,\ng\n2\n,\n…\n,\ng\nk\n)\n,\np\n​\n(\nk\n)\n=\n1\n,\n\\displaystyle=(g_{1},g_{2},\\dots,g_{k}),p(k)=1,\n(3)\nzip\n⁡\n(\nT\ng\n,\nT\nh\n)\n\\displaystyle\\operatorname{zip}(T_{g},T_{h})\n=\n(\n(\ng\n1\n,\nh\n1\n)\n,\n(\ng\n2\n,\nh\n2\n)\n,\n…\n,\n(\ng\nn\n,\nh\nn\n)\n)\n,\n\\displaystyle=((g_{1},h_{1}),(g_{2},h_{2}),\\dots,(g_{n},h_{n})),\nchain\n⁡\n(\nT\ng\n,\nT\nh\n)\n\\displaystyle\\operatorname{chain}(T_{g},T_{h})\n=\n(\ng\n1\n,\n…\n,\ng\nm\n,\nh\n1\n,\n…\n,\nh\nn\n)\n.\n\\displaystyle=(g_{1},\\dots,g_{m},h_{1},\\dots,h_{n}).\nThis enables configurations via text formats and possibly GUIs, while also leaves directives for code generation.\n2.3\nSoftware Interoperability\nCommunications.\nUniCon connects its state storage backend to external clients with consistent semantics: writing to arrays publishes data, reading retrieves the latest values.\nMultiple backends provide flexible performance: lock‑free local or shared memory for zero‑copy access\n(\nPoehnl2019Iceoryx\n)\n, message queues for distributed setups\n(\nzeromq2010\n)\n, and ROS bridges for legacy integration.\nPlatform support.\nSimulation and hardware platforms are integrated uniformly as state readers and writers.\nEach platform adapter provides three callable blocks:\nrecv\nfor updating states,\nsend\nfor sending controls, and\nclose\nfor teardown, while automatically aligning parameters such as PID gains and DoF limits to ensure consistent control semantics\n(\nChitta2017roscontrolAG\n)\n.\nSupported platforms are summarized in Table\n1\n.\nPeripherals.\nWe also incoporate frequently used peripheral tools and devices as plug-and-play CBs.\nInput devices such as joysticks\n(\nlinuxinput2025\n)\nand VR\n(\nvuer\n)\nare supported with multiple implementations for coverage,\nwhile sensors including RGBD\n(\nrealsense\n)\ncameras and LiDARs are connected either through platform proxy or standalone clients.\nVisualizers such as Foxglove and Meshcat\n(\nqin2023anyteleop\n)\nare also ready to be wired to selected states.\n2.4\nProgramming Interface\nUniCon exposes states as typed NumPy\n(\nharris2020array\n)\narrays, enabling users to perform vectorized operations in Python.\nWorkflows can be defined either programmatically or textually, with user logic seamlessly integrated via parameter-less boolean functions following our CB design.\nThis causes minimal intrusion while allowing users to fully customize their control flow as needed.\n2.5\nWorkflow Transfers\nUniCon enables seamless tranfer between three workflows:\nSim-to-Sim\nvalidation,\nSim-to-Real\ndeployment, and\nReal-to-Sim\ninstrumentation, all operating on a unified data abstraction.\nSim-to-Sim and Sim-to-Real are trivial since the system CBs remain interchangeable within the execution graph.\nFor real deployments, additional safety blocks can be inserted to handle startup, shutdown, and runtime monitoring without altering the rest of the graph.\nReal-to-Sim uses recorder and replay blocks on physical states and built‑in metrics to quantify the reality gap.\nFor open‑loop and repeatable rollouts, mean squared error (MSE) performs step‑wise comparison since inputs are exactly replayed.\nFor closed‑loop controls like locomotion, we propose to unfold the MSE loss to prevent misalignments:\nℒ\n=\n1\nn\n​\nmin\nj\n​\n∑\ni\n=\n0\nn\n‖\nT\ni\n+\nj\n−\nT\n^\ni\n‖\n2\n+\n1\nn\n​\nmin\nj\n​\n∑\ni\n=\n0\nn\n‖\nT\ni\n−\nT\n^\ni\n+\nj\n‖\n2\n.\n\\mathcal{L}=\\frac{1}{n}\\min_{j}\\sum_{i=0}^{n}\\|T_{i+j}-\\hat{T}_{i}\\|_{2}+\\frac{1}{n}\\min_{j}\\sum_{i=0}^{n}\\|T_{i}-\\hat{T}_{i+j}\\|_{2}.\n(4)\n3\nEvaluation\nTable 1\n:\nSupported simulators and hardware platforms in UniCon.\nSimulators\nHumanoids\nQuadrupeds\nIsaacGym\n(\nisaacgym\n)\nUnitree H1\n(\nunitree\n)\nUnitree A1\nIsaacSim\n(\nnvidia2023isaacsim\n)\nUnitree G1\nUnitree Aliengo\nIsaacLab\n(\norbit\n)\nUnitree H1-2\nUnitree Go2\nMuJoCo\n(\nmujoco\n)\nFourier GR1\n(\nfftai\n)\nMuJoCo MJX\n(\nmujoco_playground_2025\n)\nFourier N1\nManipulators\nPyBullet\n(\npybullet\n)\nAgiBot X2\n(\nagibot2023x2\n)\nARX\n(\narxroboticsx2025github\n)\nWebots\n(\nMichel2004CyberboticsLW\n)\nDobot Atom\n(\natom\n)\nROHand\n(\nrohand2025oymotion\n)\nGenesis\n(\nGenesis\n)\nPND Adam\n(\npnd\n)\nUnitree Dex3-1\nGazebo\n(\nKoenig2004DesignAU\n)\nAzureLoong\n(\noghr2\n)\nNewton\n(\nnewton2025github\n)\nBooster T1\n(\nt1\n)\nWe evaluate our framework on deployment tasks across quadrupeds, humanoids, and manipulators,\nfocusing on transfer effort, inference efficiency and workflow usability.\n3.1\nTransfer Effort\nWe target the locomotion task for humanoids and quadrupeds where policies with the same training paradigm are deployed on multiple platforms\n(\nxue2025unified\n)\n.\nWithout a framework, the inference often need to be re‑implemented due to vendor‑specific stacks.\nWe report the Source Lines of Code (SLOC) required to transfer the original workflow on Unitree H1 to the MuJoCo simulator and other robots.\nAs shown in Table\n2\n, the Ad‑hoc code needs substantial efforts to transfer, especially for the PND Adam model with its completely different APIs, while UniCon remains lightweight and requires no extra effort when switching deployment targets.\nTable 2\n:\nComparison of transfer effort across workflows (code changes, in SLOC).\nFramework\nComponents\nInference workflows\nH1\nSim\nG1\nAdam\nNN\nH1\nSim\nG1\nAdam\nAd-hoc\n852 (original code base for H1)\n0\n507\n627\n770\nUniCon (ours)\n393\n382\n35\n394\n350\n0\n0\n0\n0\n3.2\nFramework Efficiency\nWe measure the framework efficiency in the form of operation latency overhead.\nThe evaluation runs on the same H1 model with identity joint position control (\nq\nd\n=\nq\nq_{d}=q\n) at 50Hz in place of actual inference.\nFor this robot, system states are refreshed at around 500Hz by the SDK\n(\nunitreeSDK2python2025\n)\n.\nThe synchronous (Sync) setup queries the global buffer directly at each control cycle, while the asynchronous (Async) setup uses a callback to receive the latest states.\nIn the table,\nRecv\ndenotes the time to obtain the latest system states,\nSend\ndenotes the time to transmit the resulting control signal, and\nEnd-to-end\nmeasures the latency between sending a control signal and the timestamp of the dependent states.\nBecause the state timestamp originates from a monotonic clock on another onboard system, we manually align clocks with an inferred time origin for this row.\nResults in Table\n3\nshow that UniCon introduces near‑zero overhead compared to SDK implementations and significantly outperforms ROS.\nThis efficiency arises from binding global state buffers into the data reader/writer and compiling\n(\npybind11github\n;\nRoboJuDo\n)\nalongside the SDK to eliminate redundant data copies.\nDuring actual inference, control blocks can be arranged so that the critical path contains only the data producers required by the policy, deferring non‑critical communication and synchronization.\nTable 3\n:\nComparison of framework efficiency on H1 (operation latency, in\nμ\n\\mu\ns).\nOperation\nFrameworks\nSDK (Sync)\nSDK (Async)\nROS 2\nUniCon (ours)\nRecv\n1261\n±\n\\pm\n150\n-\n50\n±\n\\pm\n88\n63\n±\n\\pm\n15\nSend\n1011\n±\n\\pm\n72\n1001\n±\n\\pm\n65\n587\n±\n\\pm\n179\n190\n±\n\\pm\n45\nEnd-to-end\n1\n1\nfootnotemark:\n1\n1805\n±\n\\pm\n1559\n1447\n±\n\\pm\n936\n1658\n±\n\\pm\n882\n732\n±\n\\pm\n749\n1\n1\nfootnotemark:\n1\nTime between send and state timestamp, applying an inferred offset due to relative system clocks.\n3.3\nWorkflow Usability\nWhile ROS is the go-to choice for building complex robotic application, UniCon offers comparable usability with built-in connection to mainstream sensors, input devices, motion libraries and messaging layers including ROS itself.\nWe demonstrate this by extending the inference pipeline to wholebody control, incorporating inverse kinematics\n(\nBuss2004IntroductionTI\n;\npink\n)\n, dexterous hand retargeting\n(\nqin2023anyteleop\n)\n, and VR teleoperation\n(\nCheng2024OpenTeleVisionTW\n)\n, all modularized and distributed across onboard and LAN workstations.\nWe further showcase real‑to‑sim analysis by comparing recorded and replayed trajectories across systems.\nUsing the built‑in analyzer, discrepancies can be measured element‑wise and frame‑wise to identify sources of the reality gap.\nAs shown in Figure\n3\n, a bipedal policy stable in the IsaacGym simulation but failing on the A1 robot exhibits significant deviation in the rear left calf joint, leading to overheating and eventual loss of balance.\nIn contrast, the Go2 model shows a smaller gap under similar settings.\nFigure 3\n:\nReal-to-sim analysis of inference trajectories.\nLeft & Middle:\nReality gap quantified per joint position using built-in metrics, showing deviations in the A1’s rear left calf joint.\nRight:\nStable Go2 standing (top) and A1 just before fallover (bottom).\n4\nRelated Work\n4.1\nLearning-based Robot Controllers\nLearning-based controllers, particularly reinforcement learning (RL), have enabled locomotion across quadrupeds\n(\nlee2020learning\n;\nsmith2022\n;\nrma\n;\nhoeller2024anymal\n)\n, wheeled robots\n(\nlee2024learning\n)\n, and humanoids\n(\ngu2024advancing\n;\nxue2025unified\n;\nwang2025beamdojo\n;\nhuang2025learning\n)\n, achieving agile gaits\n(\namp-wu\n;\nhe2024agile\n)\n, terrain adaptation\n(\ntert\n;\nparkour1\n;\nparkour2\n;\nLai2024WorldMP\n)\n, whole-body control\n(\ncheng2024express\n;\nji2024exbody2\n)\n, and motion tracking\n(\namp\n;\nyin2025unitrackerlearninguniversalwholebody\n)\n.\nThese advances highlight the promise of RL for scalable locomotion, but also the challenge of sim-to-real transfer: policies trained in simulation often fail to generalize due to discrepancies in dynamics and perception\n(\ncomparesim\n;\nda2025survey\n)\n.\nTo address this, domain randomization\n(\nrandomization1\n;\nOpenAI2019SolvingRC\n;\nrandomization2\n;\ncampanaro2022\n)\nand adaptation\n(\nminimizing\n)\nimprove robustness, while real-to-sim system identification (SysId) methods calibrate simulators with real-world data\n(\ndong2024easi\n;\nhe2025asap\n;\nxu2025deal\n)\n.\nUniCon complements these strategies by introducing a normalization pipeline and hardware-agnostic interface abstraction, enabling cross-platform inference, data gathering and analysis.\n4.2\nRobot Application Middleware\nRobot application middleware provides critical abstractions and communication infrastructure for integrating perception, planning, and control components across heterogeneous robotic systems.\nFrameworks such as the Robot Operating System (ROS) have become de facto standards in academia and industry due to their modularity, device driver ecosystem, and support for distributed computing\n(\nros\n;\nros2\n;\nChitta2012MoveItT\n)\n.\nSimilarly, PX4\n(\nMeier2015PX4AN\n)\noffers a full-stack flight control system for aerial robotics, facilitating high-performance real-time control with rich simulation integration.\nWhile these middleware platforms simplify software development and system orchestration, they generally lack standardized abstractions for cross-platform strategy deployment or sim-to-real policy learning.\nUniCon complements these frameworks by introducing a domain-aware control layer specifically tailored for learning-based policy modularization and transferability. Rather than replacing existing middleware, UniCon operates orthogonally – interfacing with existing environments to unify and reuse control logic across embodiments.\n5\nConclusion\nUniCon offers a unified control layer in robot learning deployments by separating vectorized global states from modular control blocks, greatly reducing hardware transfer effort and enabling low-latency inference.\nIts successful use across robots and research projects show strong potentials for broader community adoption.\nFuture works include multi‑language APIs and code generation to broaden platform coverage.\nAcknowledgments\nThe Shanghai Jiao Tong University team is partially supported by National Natural Science Foundation of China (62322603).\nWe also thank Fourier Intelligence and ByteDance Seed for their early support with hardware and experiments.\nReferences",
    "preview_text": "Deploying learning-based controllers across heterogeneous robots is challenging due to platform differences, inconsistent interfaces, and inefficient middleware. To address these issues, we present UniCon, a lightweight framework that standardizes states, control flow, and instrumentation across platforms. It decomposes workflows into execution graphs with reusable components, separating system states from control logic to enable plug-and-play deployment across various robot morphologies. Unlike traditional middleware, it prioritizes efficiency through batched, vectorized data flow, minimizing communication overhead and improving inference latency. This modular, data-oriented approach enables seamless sim-to-real transfer with minimal re-engineering. We demonstrate that UniCon reduces code redundancy when transferring workflows and achieves higher inference efficiency compared to ROS-based systems. Deployed on over 12 robot models from 7 manufacturers, it has been successfully integrated into ongoing research projects, proving its effectiveness in real-world scenarios.\n\nUniCon: A Unified System for Efficient Robot Learning Transfers\nYunfeng Lin\nlinyunfeng@sjtu.edu.cn\nShanghai Jiao Tong University\nShanghai Artificial Intelligence Laboratory\nShanghai, China\n&Li Xu\nlixu@changan.com.cn\nAI Laboratory,\nChongqing Changan Automobile Co. Ltd.\nChongqing, China\n&Yong Yu\nyyu@apex.sjtu.edu.cn\nShanghai Jiao Tong University\nShanghai, China\n&Jiangmiao Pang\npangjiangmiao@pjlab.org.cn\nShanghai Artificial Intelligence Laboratory\nShanghai, China\n&Weinan Zhang\nwnzhang@sjtu.edu.cn\nShanghai Jiao Tong University\nShanghai Artificial Intelligence Laboratory\nShanghai, China\nCorresponding author.\nAbstract\nDeploying learning-based controllers across heterogeneous robots is challenging due to platform differences, inconsistent interfaces, and inefficient middleware.\nTo address these issues, we present UniCon, a lightweight framework that standardizes states, control flow, and instrumentation acr",
    "is_relevant": false,
    "relevance_score": 2.0,
    "extracted_keywords": [
        "robot learning",
        "framework",
        "sim-to-real transfer",
        "efficiency",
        "modular"
    ],
    "one_line_summary": "UniCon是一个轻量级框架，通过标准化状态和控制流，实现跨异构机器人的高效学习控制器部署和模拟到真实环境的转移。",
    "detailed_summary": "",
    "qa_pairs": [],
    "is_hidden": false,
    "is_starred": false,
    "flag": true,
    "published_date": "2026-01-21T03:19:32Z",
    "created_at": "2026-01-27T15:53:16.191826",
    "updated_at": "2026-01-27T15:53:16.191832"
}