{
    "id": "2601.10340v1",
    "title": "CHORAL: Traversal-Aware Planning for Safe and Efficient Heterogeneous Multi-Robot Routing",
    "authors": [
        "David Morilla-Cabello",
        "Eduardo Montijano"
    ],
    "abstract": "ä½¿ç”¨è‡ªä¸»æœºå™¨äººç›‘æµ‹å¹¿é˜”ã€æœªçŸ¥ä¸”å¤æ‚çš„ç¯å¢ƒå¸¦æ¥äº†æ˜¾è‘—çš„å¯¼èˆªæŒ‘æˆ˜ï¼Œè€Œéƒ¨ç½²å…·æœ‰äº’è¡¥èƒ½åŠ›çš„å¼‚æ„æœºå™¨äººå›¢é˜Ÿå¯å¤§å¹…æå‡ä»»åŠ¡æ‰§è¡Œæ€§èƒ½ä¸å¯è¡Œæ€§ã€‚ç„¶è€Œï¼Œè¦æœ‰æ•ˆå»ºæ¨¡ä¸åŒæœºå™¨äººå¹³å°ä¸ç¯å¢ƒçš„äº¤äº’ï¼Œéœ€è¦ä¸°å¯Œçš„è¯­ä¹‰åœºæ™¯ç†è§£èƒ½åŠ›ã€‚å°½ç®¡å­˜åœ¨è¿™ä¸€éœ€æ±‚ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸å‡è®¾æœºå™¨äººå›¢é˜Ÿä¸ºåŒæ„ç±»å‹ï¼Œæˆ–ä»…å…³æ³¨ç¦»æ•£ä»»åŠ¡å…¼å®¹æ€§è€Œéè¿ç»­è·¯å¾„è§„åˆ’ï¼Œå¯¼è‡´åœºæ™¯ç†è§£æœªèƒ½å……åˆ†èå…¥è·¯å¾„å†³ç­–ä¸­ï¼Œé™åˆ¶äº†ç³»ç»Ÿå¯¹ç¯å¢ƒå˜åŒ–çš„é€‚åº”èƒ½åŠ›åŠå„æœºå™¨äººä¼˜åŠ¿çš„å‘æŒ¥ã€‚æœ¬æ–‡æå‡ºä¸€ç§é›†æˆè¯­ä¹‰æ„ŸçŸ¥çš„å¼‚æ„æœºå™¨äººååŒæ¡†æ¶ï¼šé€šè¿‡ä¾¦å¯Ÿé£è¡Œæ„å»ºåŸºäºå¼€æ”¾è¯æ±‡è§†è§‰æ¨¡å‹çš„åº¦é‡-è¯­ä¹‰åœ°å›¾ï¼Œæ®æ­¤è¯†åˆ«éœ€ç²¾ç»†æ¢æŸ¥çš„åŒºåŸŸï¼Œå¹¶ä¸ºå„å¹³å°è§„åˆ’èƒ½åŠ›æ„ŸçŸ¥çš„æŠµè¾¾è·¯å¾„ã€‚è¿™äº›ä¿¡æ¯éšåè¢«çº³å…¥å¼‚æ„è½¦è¾†è·¯å¾„è§„åˆ’æ¨¡å‹ï¼Œå®ç°å·¡æ£€ä»»åŠ¡åˆ†é…ä¸æœºå™¨äººè½¨è¿¹çš„è”åˆä¼˜åŒ–ã€‚é€šè¿‡ä»¿çœŸå®éªŒåŠåŒ…å«ä¸‰ç§æœºå™¨äººå¹³å°çš„çœŸå®å·¡æ£€ä»»åŠ¡éªŒè¯ï¼Œæœ¬æ–¹æ³•é€šè¿‡æ˜¾å¼è€ƒé‡å„å¹³å°çš„å¯¼èˆªèƒ½åŠ›ï¼Œèƒ½å¤Ÿè§„åˆ’å‡ºæ›´å®‰å…¨é«˜æ•ˆçš„è·¯å¾„ã€‚æˆ‘ä»¬å°†æ¡†æ¶CHORALå¼€æºå‘å¸ƒï¼Œä»¥æ”¯æŒå¼‚æ„æœºå™¨äººå›¢é˜Ÿçš„å¯å¤ç°ç ”ç©¶ä¸åº”ç”¨éƒ¨ç½²ã€‚",
    "url": "https://arxiv.org/abs/2601.10340v1",
    "html_url": "https://arxiv.org/html/2601.10340v1",
    "html_content": "\\useunder\n\\ul\nCHORAL: Traversal-Aware Planning for Safe and Efficient Heterogeneous Multi-Robot Routing\nDavid Morilla-Cabello, and Eduardo Montijano\nThis work was partially funded by Spanish grant FPU20-06563, project T45_23R, by grants AIA2025-163563-C31, PID2024-159284NB-I00 funded by MCIN/AEI/10.13039/501100011033 and ERDF, and the Office of Naval Research Global grant N62909-24-1-2081. D. Morilla-Cabello and E. Montijano are with the Instituto de InvestigaciÃ³n en IngenierÃ­a de AragÃ³n, Universidad de Zaragoza, Spain.\nCorresponding:\ndavidmc@unizar.es\nAbstract\nMonitoring large, unknown, and complex environments with autonomous robots poses significant navigation challenges, where deploying teams of heterogeneous robots with complementary capabilities can substantially improve both mission performance and feasibility. However, effectively modeling how different robotic platforms interact with the environment requires rich, semantic scene understanding.\nDespite this, existing approaches often assume homogeneous robot teams or focus on discrete task compatibility rather than continuous routing. Consequently, scene understanding is not fully integrated into routing decisions, limiting their ability to adapt to the environment and to leverage each robotâ€™s strengths.\nIn this paper, we propose an integrated semantic-aware framework for coordinating heterogeneous robots. Starting from a reconnaissance flight, we build a metric-semantic map using open-vocabulary vision models and use it to identify regions requiring closer inspection and capability-aware paths for each platform to reach them. These are then incorporated into a heterogeneous vehicle routing formulation that jointly assigns inspection tasks and computes robot trajectories.\nExperiments in simulation and in a real inspection mission with three robotic platforms demonstrate the effectiveness of our approach in planning safer and more efficient routes by explicitly accounting for each platformâ€™s navigation capabilities. We release our framework, CHORAL, as open source to support reproducibility and deployment of diverse robot teams.\nI\nIntroduction\nModern mobile robotic platforms, including wheeled, legged, and aerial systems, can now operate with remarkable autonomy, each offering distinct mobility and endurance characteristics\n[\n29\n,\n36\n]\n.\nLeveraging these complementary strengths in heterogeneous teams has the potential to expand the scale, safety, and efficiency of missions such as search and rescue, environmental monitoring, and large-area industrial inspection\n[\n38\n,\n25\n]\n.\nIn these scenarios, robots must not only cover vast and often unknown environments, but also identify which regions merit fine-grained inspection and determine which robot is best suited to visit them (Fig.\n1\n).\nDespite this need, existing high-level coordination strategies address only parts of the problem. Classical routing approaches, such as the Vehicle Routing Problem (VRP), environment decomposition, or iterative allocation\n[\n30\n,\n43\n,\n19\n]\ntypically assume homogeneous teams and optimize only total distance or completion time.\nConversely, task-assignment methods that incorporate compatibility or precedence constraints\n[\n32\n,\n14\n]\ntreat routing simplistically and do not reason about how terrain, obstacles, or platform-specific mobility affect accessibility. Moreover, existing approaches do not integrate semantic scene understanding, limiting their applicability to complex and realistic inspection missions involving heterogeneous platforms.\nFigure 1\n:\nOur framework for heterogeneous multi-robot inspection in a real-world deployment. A metric-semantic map of the environment is built from a reconnaissance flight, enabling the automatic identification of inspection targets and the computation of platform-specific, traversal-aware routes.\nGround robots\navoid regions with\npoor traversability\nwith pebbles or cables, while\naerial robots\nplan safer trajectories that maintain clearance from obstacles.\nRecent advances in scene understanding have enabled robots to build rich metricâ€“semantic representations of their environment. Open-vocabulary vision models can reason about semantic concepts involving terrain, obstacles, or relevant objects\n[\n13\n,\n41\n,\n12\n]\n.\nHowever, despite the growing availability of such flexible perceptual tools, their direct integration into multi-robot planning frameworks remains largely unexplored\n[\n32\n,\n28\n,\n3\n]\n.\nIn this work, we introduce a semantic-aware coordination framework, CHORAL, which unifies environment understanding and heterogeneous routing for multi-robot inspection. Our system begins with a reconnaissance aerial survey from which we construct an open-vocabulary metricâ€“semantic map using state-of-the-art vision models. This representation enables the automatic identification of inspection regions while providing terrain context for planning that reflects each robotâ€™s navigation capabilities.\nWe then formulate a Heterogeneous Vehicle Routing Problem that explicitly incorporates traversal information into robot-specific path costs, allowing the planner to leverage platform heterogeneity to compute safe and efficient task assignments and routes.\nFigure 2\n:\nOverview of our framework for heterogeneous multi-robot routing. (a) An inspection mission is defined in an unknown environment based on user-specified task classes. (b) A surveying aerial platform constructs a metric-semantic map using open-vocabulary vision models. (c) The map is processed to identify inspection targets, compute feasible connections between tasks, and extract platform-specific traversal costs. (d) A heterogeneous vehicle routing problem is formulated and solved to generate safe and efficient routes tailored to the capabilities of each robot. (e) The resulting plans are executed using standardized navigation stacks.\nWe evaluate our framework in simulated environments of varying size and complexity, and we further demonstrate real-world deployment using three robotic platforms in a ROS 2-based inspection mission.\nOur experiments demonstrate that our proposed framework obtains safer and more efficient routes for each robot. Additionally, we validate the applicability of our system to a real scenario, being able to model the environment and plan accounting for varied platforms.\nThe full system, including open-vocabulary semantic mapping and heterogeneous route planning, is containerized and released as open source\n1\n1\n1\nSoftware will be released upon acceptance\n, supporting reproducibility and accelerating research on large-scale heterogeneous multi-robot coordination.\nII\nRelated Work\nDeploying multi-robot teams for inspection, exploration, and mapping improves operational efficiency in large environments\n[\n29\n,\n36\n]\n, but introduces significant challenges in routing and coordination. Scene-reconstruction and inspection pipelines often adopt hierarchical strategies that partition the environment and assign viewpoints through greedy allocation, followed by refinement via Traveling Salesman Problem (TSP)\n[\n19\n]\nor Vehicle Routing Problem (VRP) variants. These include minâ€“max and capacitated VRPs\n[\n30\n,\n43\n]\n, consistent multiple depot multiple TSP\n[\n42\n]\n, and efficient graph-based approaches for cluttered spaces\n[\n40\n]\n. While effective for structured inspection tasks, these methods assume homogeneous teams and rely primarily on distance-based costs, limiting their ability to exploit differences in robot dynamics.\nHeterogeneous coordination is increasingly studied due to the complementary strengths of aerial and ground platforms\n[\n36\n,\n28\n,\n22\n]\n, as demonstrated in the DARPA Subterranean Challenge\n[\n38\n]\n. However, routing in such contexts remains largely restricted to simplified task assignment or environment partitioning rather than fine-grained, cost-aware planning. In parallel, the Heterogeneous VRP introduces vehicle-dependent costs\n[\n16\n]\nand has been extensively explored in logistics through heuristics, tabu search, and genetic algorithms\n[\n7\n,\n21\n,\n23\n]\n. These methods primarily target mixed-fleet transportation systems\n[\n15\n,\n34\n]\n, with limited adoption in robotics.\nIn robotics, heterogeneous coordination is predominantly framed as a task assignment problem, emphasizing taskâ€“platform compatibility and resilience\n[\n32\n,\n26\n]\n. While heuristic methods\n[\n4\n]\n, Mixed-Integer Programs\n[\n17\n]\n, and learning-based approaches\n[\n6\n]\nprovide effective allocation of individual tasks, they typically simplify or defer the routing component that is critical in inspection missions. Moreover, these formulations often assume known task compatibilities or rely on predefined energy maps, and are primarily validated.\nBeyond task assignment, several works attempt to incorporate routing considerations more explicitly. Some combine allocation with distance-based costs\n[\n33\n]\nor integrate platform-specific energy consumption into route planning\n[\n14\n,\n2\n,\n3\n]\n. Others account for platform size to ensure access in constrained environments\n[\n5\n]\nor formulate cooperative UAVâ€“UGV routing through compatibility constraints rather than full cost modeling\n[\n27\n]\n. These approaches, however, typically depend on tailored optimization problems, limited-scale validation, or restrictive assumptions, standing in contrast to the robust, industry-grade routing frameworks widely used in inspection\n[\n20\n,\n35\n]\n.\nEnvironmental awareness is essential for safe and feasible routing, as terrain constrains ground platforms and obstacles pose risks to aerial robots. Novel deep learning models for extracting language aligned features from images have shown impressive results in building open vocabulary models to obtain rich environmental awareness\n[\n37\n,\n1\n]\n. Prior work models risk using metric maps\n[\n18\n]\n, probabilistic terrain analysis based on geometry and using CVaR for modeling costs\n[\n8\n]\n, or perception-based traversability estimation using semantics and self-supervision\n[\n13\n,\n41\n]\n, with collaborative estimation explored across UAVs and UGVs\n[\n12\n]\n. However, these techniques are applied to individual robot navigation. Furthermore, recent advances in deep learning have enabled the extraction of language-aligned features from images, providing rich semantic understanding of the environment\n[\n37\n,\n1\n]\n. Our work integrates open-vocabulary environmental awareness directly into the routing process, enabling heterogeneous multi-robot systems to plan inspection missions that account for platform dynamics and environmental constraints, improving mission efficiency and feasibility.\nIII\nSemantic-aware Heterogeneous Coordination Framework\nOur framework for heterogeneous multi-robot coordination is illustrated in Fig.\n2\n. An initial reconnaissance flight is used to construct an open-vocabulary metric-semantic map, which flexibly integrates user-defined inspection tasks, environment characteristics relevant to platform traversability, and obstacle information. This map enables both the identification of inspection targets and the estimation of platform-specific traversal costs. These elements are then incorporated into a heterogeneous vehicle routing problem formulation that jointly assigns tasks and computes routes, yielding safe and efficient plans that explicitly leverage the complementary capabilities of each robot in the team.\nIII-A\nMetric-semantic map construction\nOur approach begins with a reconnaissance flight over the unknown area to construct an open-vocabulary metricâ€“semantic map.\nThis is performed by a localized aerial platform that surveys the environment along a fixed or exploratory trajectory, ensuring full coverage.\nWe leverage and adapt several off-the-shelf tools, described in detail in Section\nIV\n, to build a 3D voxel-based representation of the environment.\nEach voxel contains geometry, represented as the probability of occupancy, and semantic information, encoded as a vector of features extracted using an open-vocabulary vision model. Our method supports two types of semantic representations:\n(i)\na categorical probability vector\nÎ“\n=\n{\nÎ³\n1\n,\nâ€¦\n,\nÎ³\nn\n}\n\\Gamma=\\{\\gamma_{1},\\dots,\\gamma_{n}\\}\nover an arbitrary set of semantic classes predefined by user prompts (e.g., grass, path, road, mud), seeÂ Fig.\n2\n; and\n(ii)\ntext-aligned raw semantic embeddings, which provide richer information online at the cost of increased memory usage, seeÂ Fig.\n3\n. We assume that the user prompts are divided into two categories, tasks\nğ’¯\n\\mathcal{T}\nand environment characteristics\nâ„°\n\\mathcal{E}\n, which will be used later on to identify places to inspect and the cost to reach them.\nFigure 3\n:\nOpen vocabulary map built with our mapping module, showing the flexibility in specifying semantically rich classes.\nFigure 4\n:\nPRM construction. From left to right: the tasks are shown in blue and obstacles in black, the covisible tasks are connected, disjoint sets are detected and merged using RRT*.\nFor efficient planning, we process the 3D map into a 2D grid representation. The semantic information of each 3D voxel is reduced to a categorical label based on the set of user-defined text queries. Raw semantic embeddings are assigned to the class whose text embedding has the largest cosine similarity. Categorical probabilities are assigned the label with the highest probability,\narg\nâ¡\nmax\nâ¡\nÎ“\n.\n\\arg\\max\\Gamma.\nThe voxel labels are then collapsed vertically onto the 2D grid using a precedence rule: voxels above a height threshold are treated as obstacles; otherwise, task-related classes take priority, followed by environment characteristics that impede traversability, and finally free space. Each resulting 2D cell,\nm\nâˆˆ\nâ„³\n,\nm\\in\\mathcal{M},\nstores a semantic label,\nÎ³\nâ€‹\n(\nm\n)\n,\n\\gamma(m),\nand the distance to the nearest obstacle\nd\nâ€‹\n(\nm\n)\n,\nd(m),\ncomputed from an Euclidean Distance Field (EDF) of the grid.\nIII-B\nTask identification\nTask-related semantic classes are used to identify regions in the 2D map that require fine-grained inspection. Individual inspection tasks are extracted by clustering grid cells classified as tasks using DBSCAN\n[\n9\n]\n, followed by outlier removal based on a minimum cluster size. The centroid represents a single task point. An inspection point is selected as the point along the robotâ€™s inspection path that is closest to the task point while maintaining a desired separation distance for safety.\nLet\nğ’±\n\\mathcal{V}\ndenote the resulting set of inspection tasks. For each pair of inspection tasks,\ni\ni\nand\nj\nj\n, we generate a path,\nÏ€\ni\nâ€‹\nj\n\\pi_{ij}\nwith an efficient, fully connected Probabilistic Roadmap (PRM), as illustrated inÂ Fig.\n4\n.\nFirst, all mutually visible tasks are connected with straight-line edges when no obstacles obstruct the line of sight.\nNext, disconnected components are identified using a flood-fill algorithm.\nTo connect these components, we employ RRT* to find feasible paths between the closest tasks in disjoint sets.\nThis procedure ensures that every task is reachable from any other through free space.\nFinally, A* search is applied to compute the shortest paths between all task pairs.\nNote that paths might potentially be composed of multiple PRM segments.\nOur experiments show that this PRM construction is efficient even in large, cluttered environments.\nMoreover, maintaining a PRM structure allows for fast updates, such as node repositioning or edge recomputation, in response to changes in the environment.\nIII-C\nHeterogeneous costs definition\nWe consider a team of\nk\nâˆˆ\nK\nk\\in K\ndifferent robots for the fine-grained inspection of the tasks. By combining information from the metricâ€“semantic map with each platformâ€™s capabilities, we define traversal costs that accurately reflect the suitability of each robot for navigating between inspection targets.\nThe cost for robot\nk\nk\nto go from task\ni\ni\nto task\nj\nj\nis defined as\nc\ni\nâ€‹\nj\nk\n=\nc\ntime\nâ€‹\n(\nÏ€\ni\nâ€‹\nj\n,\nk\n)\n+\nÎ±\nâ€‹\nc\nsafe\nâ€‹\n(\nÏ€\ni\nâ€‹\nj\n,\nk\n)\n,\nc_{ij}^{k}=c_{\\text{time}}(\\pi_{ij},k)+\\alpha c_{\\text{safe}}(\\pi_{ij},k),\n(1)\nwhere\nÎ±\n\\alpha\nbalances the importance of safety relative to traversal time.\nIII-C\n1\nTime cost\nThe time cost captures both the path geometry and the dynamic agility of each platform.\nWhile it could also account for maneuvering requirements such as speed reductions along sharp turns, we approximate it using the nominal velocity of each robot,\nv\nk\nv^{k}\n. Denoting the path length of\nÏ€\ni\nâ€‹\nj\n\\pi_{ij}\nby\nd\ni\nâ€‹\nj\nd_{ij}\n, the traversal cost is defined as\nc\ntime\nâ€‹\n(\nÏ€\ni\nâ€‹\nj\n,\nk\n)\n=\nd\ni\nâ€‹\nj\nv\nk\n.\nc_{\\text{time}}(\\pi_{ij},k)=\\frac{d_{ij}}{v^{k}}.\n(2)\nIII-C\n2\nSafety costs\nWe model the safety costs via a statistical survival formulation along the path, assuming accidents follow a Poisson process (i.e., independent and infrequent) with respect to distance.\nWe use\nğ±\nk\nâˆˆ\nğ’³\n\\mathbf{x}^{k}\\in\\mathcal{X}\nto denote the state of robot\nk\nk\n, including its position and characteristics. We also define\nM\nâ€‹\n(\nğ±\nk\n)\n:\nğ’³\nâ†’\nâ„³\nM(\\mathbf{x}^{k}):\\mathcal{X}\\to\\mathcal{M}\nas the transformation from robot position to grid cell, denoted as\nm\nk\nâˆˆ\nâ„³\nm^{k}\\in\\mathcal{M}\nfor brevity. The probability that robot\nk\nk\n, successfully traverses\nÏ€\ni\nâ€‹\nj\n\\pi_{ij}\nis\nc\nsafe\nâ€‹\n(\nÏ€\ni\nâ€‹\nj\n,\nk\n)\n=\n1\nâˆ’\nexp\nâ¡\n(\nâˆ’\nâˆ‘\nğ±\nk\nâˆˆ\nÏ€\ni\nâ€‹\nj\nÎ»\nâ€‹\n(\nğ±\nk\n,\nm\nk\n)\n)\n.\nc_{\\text{safe}}(\\pi_{ij},k)=1-\\exp\\left(-\\sum_{\\mathbf{x}^{k}\\in\\pi_{ij}}\\lambda(\\mathbf{x}^{k},m^{k})\\right).\n(3)\nwhere\nÎ»\nâ€‹\n(\nğ±\nk\n,\nm\nk\n)\n\\lambda(\\mathbf{x}^{k},m^{k})\nis the platform-specific accident rate per unit distance in a certain map cell. The accident rate depends on both environmental factors (e.g., terrain type, proximity to obstacles) and the robotâ€™s specific characteristics.\nTo account for platform-specific risks associated with their motion in the environment, we model the expected accident rate of robot\nk\nk\nvisiting\nm\nm\n, as a function of environmental features derived from the metric-semantic map.\nIn particular, our formulation combines traversability and collision risks,\nÎ»\n(\nğ±\nk\n,\nm\nk\n)\n=\nÎ»\ntrav\n(\nğ±\nk\n,\nm\nk\n)\n)\n+\nÎ»\ncoll\n(\nğ±\nk\n,\nm\nk\n)\n,\n\\lambda(\\mathbf{x}^{k},m^{k})=\\lambda_{\\text{trav}}(\\mathbf{x}^{k},m^{k}))+\\lambda_{\\text{coll}}(\\mathbf{x}^{k},m^{k}),\n(4)\nor, more generally, a weighted combination to account for the relative importance of terrain and collision hazards.\nIII-C\n3\nTraversability\nTraversability captures the likelihood of accidents due to terrain, primarily affecting ground robots.\nWe define the expected accident rate per unit distance as\nÎ»\ntrav\nâ€‹\n(\nğ±\nk\n,\nm\nk\n)\n:=\np\nâ€‹\n(\naccident\nâˆ£\nğ±\nk\n,\nÎ³\nâ€‹\n(\nm\nk\n)\n)\n,\n\\lambda_{\\text{trav}}(\\mathbf{x}^{k},m^{k}):=p(\\text{accident}\\mid\\mathbf{x}^{k},\\gamma(m^{k})),\n(5)\nwhich can be estimated from experimental studies or manufacturer specifications. We consider a constant value per terrain type and robot.\nNevertheless, note that this formulation can be readily extended to incorporate additional semantic features or advanced risk-assessment metrics for traversability\n[\n8\n,\n13\n]\n.\nIII-C\n4\nCollision\nCollision captures the likelihood of accidents due to proximity to obstacles. This is particularly relevant for aerial platforms, which are sensitive to control errors, wind gusts, or other uncertainties when operating near surfaces. We define the collision-related accident rate using a logistic function,\nÎ»\ncoll\nâ€‹\n(\nğ±\nk\n,\nm\nk\n)\n:\n\\displaystyle\\lambda_{\\text{coll}}(\\mathbf{x}^{k},m^{k}):\n=\np\nâ€‹\n(\naccident\nâˆ£\nğ±\nk\n,\nd\nâ€‹\n(\nm\nk\n)\n)\n\\displaystyle=p(\\text{accident}\\mid\\mathbf{x}^{k},d(m^{k}))\n(6)\n=\n1\n1\n+\ne\nÎ²\nâ€‹\n(\nd\nâ€‹\n(\nm\nk\n)\nâˆ’\nd\n0.5\n)\n,\n\\displaystyle=\\frac{1}{1+e^{\\beta(d(m^{k})-d_{0.5})}},\n(7)\nwhere\nÎ²\n\\beta\ncontrols the decay of risk with distance, and\nd\n0.5\nd_{0.5}\nis the distance at which the probability of collision reaches 0.5.\nIII-D\nHeterogeneous Vehicle Routing\nLastly, we need to compute a solution for the robots to perform all the inspection tasks efficiently.\nWe formulate this as an asymmetric, capacitated Heterogeneous Vehicle Routing Problem.\nThe VRP represents the tasks\nv\nâˆˆ\nV\nv\\in V\nas nodes and edges\ne\nâˆˆ\nE\ne\\in E\nweighted by the costs,\nc\ni\nâ€‹\nj\nk\n,\nc^{k}_{ij},\nof the different robots to move from one to another, as described before.\nThe goal is to find routes for agents\nk\nâˆˆ\nK\nk\\in K\nthat depart from a depot, visit all locations exactly once, and return to the depot.\nAsymmetry is introduced by omitting return costs to the depot.\nEach agent has a capacity\nC\nk\nC^{k}\nthat limits the cumulative route cost, and to balance workload, we adopt a minâ€“max objective, minimizing the maximum route cost rather than the total cost.\nAltogether yields the following optimization problem,\nmin\nx\ni\nâ€‹\nj\nk\nâ¡\nmax\nk\nâˆˆ\nK\nâ€‹\nâˆ‘\ni\nâˆ‘\nj\nc\ni\nâ€‹\nj\nk\nâ€‹\nx\ni\nâ€‹\nj\nk\n,\ns\n.\nt\n.\n\\displaystyle\\min_{x_{ij}^{k}}\\max_{k\\in K}\\sum_{i}\\sum_{j}c_{ij}^{k}x^{k}_{ij},\\quad s.t.\n(8a)\nâˆ‘\nk\nâˆ‘\ni\nx\ni\nâ€‹\nj\nk\n=\n1\nâˆ€\nj\nâˆˆ\nV\nâˆ–\n{\n0\n}\n,\n\\displaystyle\\sum_{k}\\sum_{i}x^{k}_{ij}=1\\quad\\quad\\forall j\\in V\\setminus\\{0\\},\n(8b)\nâˆ‘\nk\nâˆ‘\nj\nx\ni\nâ€‹\nj\nk\n=\n1\nâˆ€\ni\nâˆˆ\nV\nâˆ–\n{\n0\n}\n,\n\\displaystyle\\sum_{k}\\sum_{j}x^{k}_{ij}=1\\quad\\quad\\forall i\\in V\\setminus\\{0\\},\n(8c)\nâˆ‘\nk\nâˆ‘\ni\nx\ni\nâ€‹\n0\nk\n=\nâˆ‘\nk\nâˆ‘\nj\nx\n0\nâ€‹\nj\nk\n=\n|\nK\n|\n,\n\\displaystyle\\sum_{k}\\sum_{i}x^{k}_{i0}=\\sum_{k}\\sum_{j}x^{k}_{0j}=\\left|{K}\\right|,\n(8d)\nâˆ‘\ni\n,\nj\nâˆˆ\nS\nx\ni\n,\nj\nk\nâ‰¤\n|\nS\n|\nâˆ’\n1\n,\nâˆ€\nS\nâŠ‚\nV\nâˆ–\n{\n0\n}\n,\nS\nâ‰ \nâˆ…\n,\n\\displaystyle\\sum_{i,j\\in S}x^{k}_{i,j}\\leq\\left|{S}\\right|-1,\\quad\\forall S\\subset V\\setminus\\{0\\},S\\neq\\emptyset,\n(8e)\nâˆ‘\ni\nâˆ‘\nj\nc\ni\nâ€‹\nj\nk\nâ€‹\nx\ni\nâ€‹\nj\nk\nâ‰¤\nC\nk\n,\nâˆ€\nk\nâˆˆ\nK\n\\displaystyle\\sum_{i}\\sum_{j}c_{ij}^{k}x_{ij}^{k}\\leq C^{k},\\quad\\forall k\\in K\n(8f)\nx\ni\nâ€‹\nj\nk\nâˆˆ\n{\n0\n,\n1\n}\nâˆ€\ni\n,\nj\nâˆˆ\nV\n,\n\\displaystyle x^{k}_{ij}\\in\\{0,1\\}\\quad\\quad\\forall i,j\\in V,\n(8g)\nwhere\nx\ni\nâ€‹\nj\nk\nx^{k}_{ij}\nare binary decision variables indicating whether agent\nk\nk\ntraverses from\ni\ni\nto\nj\nj\n. Constraints (\n8b\n)â€“(\n8c\n) enforce that each location is visited exactly once, (\n8d\n) ensures all routes start and end at the depot, (\n8e\n) eliminates sub-tours that do not include the depot, (\n8f\n) imposes capacity limits used to prevent infeasible routes, and (\n8g\n) enforces binary variables. Importantly, limiting each agentâ€™s capacity enables constraining routes through infeasible paths due to safety costs.\nThe resulting paths are sent to each robot, where the platformsâ€™ navigation stacks handle low-level motion execution and local collision avoidance during task execution.\nFigure 5\n:\nDiagram of the ROS 2 system implementation provided, indicating the components in our framework. Yellow means the component was fully developed for this article. Gray means the component was adapted and integrated into our system.\nIV\nImplementation\nWe implement our heterogeneous coordination framework in a modular architecture, illustrated in Fig.\n5\n, where our components are shown in yellow and integrated third-party tools in gray. Although specific packages are used in our implementation, the interfaces are generic and interchangeable (e.g., GPS can replace motion-captureâ€“based localization).\nWe consider a surveyor drone, localized in space and equipped with an RGB camera and a depth sensor (e.g., RGB-D or learning-based depth estimation\n[\n39\n]\n), is used to acquire visual data. Semantic features are extracted through\nsensors_tools\n, which integrates Trident\n[\n37\n]\nfor class probability vectors and RayFrontâ€™s semantic encoder\n[\n1\n]\nfor raw feature embeddings.\nSemantic observations are projected into 3D using depth and sensor pose. Our metric-semantic voxel map,\nbloomxai\n, extends Bonxai\n[\n10\n]\n, which uses voxel hashing for efficient large-scale occupancy mapping. Probabilities are fused via Bayesian fusion with regularization\n[\n31\n]\n, while raw embeddings are averaged. The resulting 3D representation is processed into a 2D grid map for planning.\nPlanning is handled by\nmr_het_coord\n, which integrates PRM construction with RRT* and A* over the 2D grid. Routing is formulated as a heterogeneous extension of the classical VRP and solved using the industry-grade OR-Tools solver\n[\n35\n]\n. The formulation incorporates per-agent cost models while retaining support for common VRP extensions such as time windows and task compatibility constraints.\nAll components are orchestrated within a ROSÂ 2 framework and deployed in Docker containers to ensure reproducibility and portability across hardware platforms. Platform-specific navigation and execution are delegated to established stacks, Nav2\n[\n24\n]\nfor ground robots and Aerostack2\n[\n11\n]\nfor aerial vehicles, providing standardized interfaces for control and navigation. This containerized, modular design enables scalable coordination of heterogeneous robot teams while simplifying integration of new platforms and capabilities.\nV\nExperiments & Results\nWe evaluate our heterogeneous coordination framework through extensive virtual experiments and a real-world multi-robot deployment. The virtual experiments demonstrate, under varying scenarios, the benefits of our heterogeneous coordination framework for safer and more efficient planning compared to existing routing solutions\n[\n30\n,\n43\n]\n. The real-world experiment validates the complete pipeline, from semantic mapping to task execution, showing the practicality of the proposed system under real sensing, planning, and execution constraints.\nV-A\nVirtual experiment\nTABLE I\n:\nParameters of the virtual maps and time required to obtain the distance and costs matrices. We report the average and standard deviation over 5 runs. The planner is only executed at the start, scales well to a large number of goals and enables online replanning in case of map updates since only local parts need to be recomputed.\nMap\nSize [\nm\n\\text{\\,}\\mathrm{m}\n]\nNum\nTasks\nBuild\nPRM [\nms\n\\text{\\,}\\mathrm{ms}\n]\nCompute\ndist. [\nms\n\\text{\\,}\\mathrm{ms}\n]\nCompute het.\ncosts [\nms\n\\text{\\,}\\mathrm{ms}\n]\nOrchard\n24\nÃ—\n12\n24\\times 12\n110\n2.4\nÂ±\n0.5\n2.4\\pm 0.5\n167.2\nÂ±\n7.3\n167.2\\pm 7.3\n95.2\nÂ±\n3.3\n95.2\\pm 3.3\nForest\n32.5\nÃ—\n17.5\n32.5\\times 17.5\n58\n2.6\nÂ±\n0.5\n2.6\\pm 0.5\n31.6\nÂ±\n1.51\n31.6\\pm 1.51\n28.6\nÂ±\n1.1\n28.6\\pm 1.1\nPark\n44.5\nÃ—\n34\n44.5\\times 34\n94\n4.4\nÂ±\n0.8\n4.4\\pm 0.8\n118.4\nÂ±\n1.8\n118.4\\pm 1.8\n36.0\nÂ±\n1.6\n36.0\\pm 1.6\nCave\n280\nÃ—\n180\n280\\times 180\n266\n17.6\nÂ±\n3.6\n17.6\\pm 3.6\n3590.2\nÂ±\n28.7\n3590.2\\pm 28.7\n873.2\nÂ±\n17.7\n873.2\\pm 17.7\n(a)\nOrchard\n(b)\nForest\n(c)\nPark\n(d)\nCave\nFigure 6\n:\nVirtual environments with variable sizes and complexity. Black represents obstacles, brown represents regions of limited traversability. Pink dots are the tasks, and red stars are the starting positions for the robot team.\nFigure 7\n:\nRelative gap for the resulting cost of the VRP solution to the converged solution against the time budget of the OR-Tools solver with respect to\n1\ns\n1\\text{\\,}\\mathrm{s}\nfor a team with one drone and one ground robot. Since the solver can be initialized from a previous solution, the maximum time for planning is below\n2\nmin\n2\\text{\\,}\\mathrm{min}\n.\nThe virtual experiments assume a known 2D grid map to validate the proposed heterogeneous cost modeling and planning components across environments of varying size and complexity (Fig.\n6\n). In these maps, white cells denote free space, black cells represent obstacles, and gray regions indicate terrain with limited traversability for ground robots. The selected environments reflect representative inspection scenarios, including areas that are inaccessible to certain platforms due to terrain or narrow passages. The dimensions of each map and the number of inspection tasks are summarized in Table\nI\n.\nWe first measure the time required to construct the PRM graph and compute distances and costs for the full VRP. As shown in Table\nI\n, this step completes well under a minute, even for large and complex maps.\nThe OR-Tools solver is combinatorial and heuristic, with a global initialization phase followed by a time-limited local search. We evaluate solver performance for varying local search durations on all virtual maps using a droneâ€“ground robot team. As shown in Fig.\n7\n, solutions reach over 90% of the maximum performance within a few seconds for most maps. Since the solver can initialize from a previous solution, only the first planning iteration requires the full computation, typically under\n2\nmin\n2\\text{\\,}\\mathrm{min}\n. These results indicate that our planning framework is efficient even for a large number of tasks.\nFor the remaining experiments, we set the solver time to\n120\ns\n120\\text{\\,}\\mathrm{s}\nto ensure consistent convergence across maps.\nWe then solve the inspection mission paths for the different maps using different robot configurations for aerial (A) and ground (G) platforms of 2 and 4. We compare our method against the standard distance-based formulation used in the literature\n[\n30\n,\n43\n]\n. For each map and team configuration, we report the maximum planned distance and time, as those define the total mission performance; and the worst case accident probability for traversability and collision.\nTABLE II\n:\nResults for the virtual experiments. Worst-case (maximum) team performance is reported. Homogeneous (Hom) is the standard method used in the literature for coordination\n[\n30\n,\n43\n]\n. Heterogeneous (Het) corresponds to our proposed planning.\nMetric\nMethod / Team\nOrchard\nForest\nPark\nCave\nDistance [m]\nâ†“\n\\downarrow\nHom (G,A)\n80\n86\n148\n1542\nHet (G,A)\n115\n116\n233\n1989\nHom (2G,2A)\n45\n43\n75\n696\nHet (2G,2A)\n66\n63\n120\n1195\nTime [s]\nâ†“\n\\downarrow\nHom (G,A)\n160\n172\n295\n3083\nHet (G,A)\n115\n163\n237\n2098\nHom (2G,2A)\n90\n86\n149\n1391\nHet (2G,2A)\n68\n75\n126\n1195\nTraversability\naccident\nprobability\nâ†“\n\\downarrow\nHom (G,A)\n0.16\n0.61\n0.91\n1.00\nHet (G,A)\n0.07\n0.00\n0.11\n0.04\nHom (2G,2A)\n0.24\n0.40\n0.68\n0.97\nHet (2G,2A)\n0.10\n0.00\n0.11\n0.01\nCollision\naccident\nprobability\nâ†“\n\\downarrow\nHom (G,A)\n0.37\n0.67\n0.45\n0.70\nHet (G,A)\n0.05\n0.29\n0.12\n0.12\nHom (2G,2A)\n0.24\n0.63\n0.22\n0.64\nHet (2G,2A)\n0.02\n0.12\n0.06\n0.09\nWe set the ground robotâ€™s terrain-dependent accident rate\nÎ»\ntrav\n\\lambda_{\\text{trav}}\nin Eq.\n5\nto\n0.05\n0.05\nfor difficult terrain and\n1\nÃ—\n10\nâˆ’\n5\n1\\text{\\times}{10}^{-5}\nfor all other terrain classes\n2\n2\n2\nA ratio of\n0.05\n0.05\nrepresents 1 accidents per\n20\nm\n20\\text{\\,}\\mathrm{m}\n, and\n1\nÃ—\n10\nâˆ’\n5\n1\\text{\\times}{10}^{-5}\none per\n100\nkm\n100\\text{\\,}\\mathrm{km}\n. Obstacle-related safety costs are set with\nÎ²\n=\n10\n\\beta=10\nand\nd\n0.5\n=\n0.5\nm\nd_{0.5}=$0.5\\text{\\,}\\mathrm{m}$\n. This configuration penalizes ground robots traversing rough terrain while favoring task assignments near obstacles when safe, and restricts drones from flying close to obstacles unless necessary.\nTable\nII\nreports the resulting distances, traversal times, and accident probabilities for each platform and map. Compared to the standard distance-based formulation\n[\n30\n,\n43\n]\n, our heterogeneous planning method achieves higher efficiency in traversal time, despite increasing the total distance. This improvement is due to incorporating platform-specific velocities when computing paths. Moreover, the resulting routes exhibit lower accident probabilities, both from terrain-related traversability and proximity to obstacles, demonstrating that our cost-aware formulation effectively balances mission speed and safety across heterogeneous robots. Noticeably, the accident probability can be configured in how much we value risk of the mission. Increasing the importance of the safety costs in risk averse situations can reduce the accident probability to\n0\nwhen possible, returning that the mission is not feasible if no routes are found. The following real experiment shows this behavior.\nFigure 8\n:\nResults for planning with standard homogeneous planning (top) and\nour heterogeneous\nmethod (bottom) for virtual environments. Thanks to considering platform-specific costs, ground robots minimize traversing through rough terrain, and aerial robots attend inspection tasks far from obstacles.\nV-B\nReal-world experiment\nWe validated our framework in a real-world inspection mission with a heterogeneous team of robots, shown in Fig.\n1\n, using the system architecture in Fig.\n5\n. The inspection area spans\n6\nÃ—\n5.5\nâ€‹\nm\n6\\times 5.5~$\\mathrm{m}$\nand contains five inspection targets represented by animal plushes. Tall objects were placed as obstacles, while smaller elements such as cables and pebbles were used to impede ground robot traversability without constituting hard obstacles.\nA surveyor drone equipped with a downward-facing RealSense D435i RGB-D camera performed a reconnaissance flight following a lawn-mower trajectory. The drone uses a Pixhawk flight controller with an Nvidia Orin Nano companion computer and is localized using an OptiTrack motion capture system. RGB-D streams were processed in real time on a ground station with an Nvidia RTX4080 GPU to extract open-vocabulary semantic features using Trident. The text queries used for semantic extraction are shown in Figure\n2\nand were expanded using OpenAI ImageNet templates.\nWhile semantic inference and map construction are offloaded due to the surveyor droneâ€™s onboard compute constraints, recent work has shown that comparable semantic mapping pipelines can run fully onboard robots equipped with more powerful hardware\n[\n1\n]\n.\nFigure 9\n:\nResults for variations in mission specification in the real experiment. (Left) Using two ground platforms instead of one results in our method still avoiding traversal through rough terrain, with the aerial platform assuming more tasks due to its higher velocity. (Right) Fine-grained task and terrain specifications enable rich and flexible mission definition.\nFor this deployment, traversability costs\nÎ»\ntrav\n\\lambda_{\\text{trav}}\nfor the ground platform were set to\n5\n5\nfor the classes\npebbles\nand\ncables\n, effectively preventing traversal of these regions due to capacity limits in the heterogeneous routing formulation. Inspection tasks were defined from the\nanimal\nclass. The resulting traversability and signed distance field maps used for cost evaluation are shown in Figure\n2\n. The Heterogeneous Vehicle Routing Problem was solved on the ground station with a\n3\nâ€‹\ns\n3~$\\mathrm{s}$\nplanning horizon to generate paths for each robot.\nThe inspection team consisted of a Turtlebot2 with an Intel NUC and a DJI Tello controlled remotely from the ground station. Nominal planning velocities were set to\n0.25\n0.25\nand\n0.5\nâ€‹\nm\ns\nâˆ’\n1\n0.5~$\\mathrm{m}\\text{\\,}{\\mathrm{s}}^{-1}$\nfor the ground and aerial platforms, respectively. Both robots relied on OptiTrack for localization and executed the planned routes through their respective navigation stacks. As shown in Figure\n2\n, the resulting solution balances workload between the platforms, assigning\n20\nâ€‹\ns\n20~$\\mathrm{s}$\nto the ground robot and\n14\nâ€‹\ns\n14~$\\mathrm{s}$\nto the drone, while avoiding traversability-impaired regions for the ground platform and narrow corridors for the aerial robot. Actual execution times, after a short path processing delay from the platforms, were around\n25\nâ€‹\ns\n25~$\\mathrm{s}$\nfor the ground robot and\n10\nâ€‹\ns\n10~$\\mathrm{s}$\nfor the drone. A video of the deployment is provided in the supplementary material.\nThis deployment demonstrates the frameworkâ€™s capability to safely and efficiently coordinate heterogeneous robots in real environments, leveraging RGB-D perception for informed, platform-aware planning.\nFinally, we evaluated variations in mission specification derived from the same metric-semantic map, with results shown in Fig.\n9\n. On the left, we demonstrate a mission involving two ground robots and one drone, resulting in a shorter, balanced mission while still respecting platform-specific constraints. On the right, we illustrate fine-grained task definitions using individual semantic classes (\ndinosaur, simba, lynx, toon plush\n), excluding\nladybug\n, and treating\ncardboard\nas traversability-impeding terrain. These variations highlight the flexibility of our semantic scene understanding in enabling rich, adaptable mission definitions without modifying the underlying planning framework.\nVI\nConclusion and Future Work\nIn this work, we present a semantic-aware coordination framework for heterogeneous multi-robot inspection that integrates environment understanding with platform-aware routing. Leveraging metric-semantic maps built from RGB-D perception and open-vocabulary vision models, our system identifies arbitrary inspection tasks, estimates platform-specific traversability and collision costs, and computes safe, optimized routes through a Heterogeneous Vehicle Routing Problem formulation. Extensive simulations demonstrated the efficiency and safety improvements of our approach compared to conventional distance-based homogeneous coordination, while the real-world deployment validated its practical feasibility in coordinating aerial and ground platforms. Our framework extends the possibilities for coordinated multi-robot applications with a modular, open-source solution integrating semantic perception with heterogeneous multi-robot planning. Future work will focus on extending the framework to outdoor and larger-scale environments, supporting more complex mission specifications, and exploring learning-based approaches to automatically infer inspection tasks and traversal costs from high-level platform and mission descriptions.\nReferences\n[1]\nO. Alama, A. Bhattacharya, H. He, S. Kim, Y. Qiu, W. Wang, C. Ho, N. Keetha, and S. Scherer\n(2025)\nRayFronts: open-set semantic ray frontiers for online scene understanding and exploration\n.\narXiv preprint arXiv:2504.06994\n.\nCited by:\nÂ§II\n,\nÂ§IV\n,\nÂ§\nV-B\n.\n[2]\nA. Caballero, F. J. Roman-Escorza, I. Maza, and A. Ollero\n(2024)\nA multi-uav route planning method for fast inspection of electric power transmission lines\n.\nProc.Â of the Intl.Â Conf.Â on Unmanned Aircraft Systems (ICUAS)\n,\npp.Â 835â€“842\n.\nExternal Links:\nISBN 9798350357882\nCited by:\nÂ§II\n.\n[3]\nX. Cai, B. Schlotfeldt, K. Khosoussi, N. Atanasov, G. J. Pappas, and J. P. How\n(2023)\nEnergy-aware, collision-free information gathering for heterogeneous robot teams\n.\nIEEE Trans.Â on Robotics\n39\n(\n4\n),\npp.Â 2585â€“2602\n.\nCited by:\nÂ§I\n,\nÂ§II\n.\n[4]\nA. Calvo, G. Silano, and J. Capitan\n(2022)\nMission planning and execution in heterogeneous teams of aerial robots supporting power line inspection operations\n.\nProc.Â of the Intl.Â Conf.Â on Unmanned Aircraft Systems (ICUAS)\n,\npp.Â 1644â€“1649\n.\nExternal Links:\nISBN 9781665405935\nCited by:\nÂ§II\n.\n[5]\nM. Cihlarova, V. Pritzl, and M. Saska\n(2024)\nCooperative indoor exploration leveraging a mixed-size uav team with heterogeneous sensors\n.\nProc.Â of the Intl.Â Conf.Â on Automation Science and Engineering (CASE)\n,\npp.Â 3850â€“3857\n.\nCited by:\nÂ§II\n.\n[6]\nW. Dai, U. Rai, J. Chiun, Y. Cao, and G. Sartoretti\n(2025)\nHeterogeneous multi-robot task allocation and scheduling via reinforcement learning\n.\nIEEE Robotics and Automation Letters\n10\n,\npp.Â 2654â€“2661\n.\nExternal Links:\nISSN 23773766\nCited by:\nÂ§II\n.\n[7]\nM. Desrochers and T. W. Verhoog\n(1991-01)\nA new heuristic for the fleet size and mix vehicle routing problem\n.\nComputers & Operations Research\n18\n,\npp.Â 263â€“274\n.\nExternal Links:\nISSN 0305-0548\nCited by:\nÂ§II\n.\n[8]\nA. Dixit, D. D. Fan, K. Otsu, S. Dey, A. Agha-Mohammadi, and J. W. Burdick\n(2024-12)\nSTEP: stochastic traversability evaluation and planning for risk-aware navigation; results from the darpa subterranean challenge\n.\nIEEE Trans.Â on Field Robotics\n2\n,\npp.Â 81â€“99\n.\nCited by:\nÂ§II\n,\nÂ§\nIII-C\n3\n.\n[9]\nM. Ester, H. Kriegel, J. Sander, and X. Xu\n(1996)\nA density-based algorithm for discovering clusters in large spatial databases with noise\n.\nIn\nInt. Conf. on Data Mining\n,\npp.Â 226â€“231\n.\nCited by:\nÂ§\nIII-B\n.\n[10]\nD. Faconti\n(2025)\nBonxai: Fast, hierarchical, sparse Voxel Grid\n.\nNote:\nGitHub Repository\nExternal Links:\nLink\nCited by:\nÂ§IV\n.\n[11]\nM. Fernandez-Cortizas, M. Molina, P. Arias-Perez, R. Perez-Segui, D. Perez-Saura, and P. Campoy\n(2024)\nAerostack2: a software framework for developing multi-robot aerial systems\n.\nExternal Links:\n2303.18237\nCited by:\nÂ§IV\n.\n[12]\nJ. Fortin, O. Gamache, W. Fecteau, E. Daum, W. LarrivÃ©e-Hardy, F. Pomerleau, and P. GiguÃ¨re\n(2025-05)\nUAV-assisted self-supervised terrain awareness for off-road navigation\n.\nProc.Â of the IEEE Intl.Â Conf.Â on Robotics & Automation\n,\npp.Â 1â€“7\n.\nExternal Links:\nISBN 979-8-3315-4139-2\nCited by:\nÂ§I\n,\nÂ§II\n.\n[13]\nJ. Frey, M. Mattamala, N. Chebrolu, C. Cadena, M. Fallon, and M. Hutter\n(2023)\nFast Traversability Estimation for Wild Visual Navigation\n.\nIn\nProceedings of Robotics: Science and Systems\n,\nCited by:\nÂ§I\n,\nÂ§II\n,\nÂ§\nIII-C\n3\n.\n[14]\nB. Fu, W. Smith, D. M. Rizzo, M. Castanier, M. Ghaffari, and K. Barton\n(2023-04)\nRobust task scheduling for heterogeneous robot teams under capability uncertainty\n.\nIEEE Trans.Â on Robotics\n39\n,\npp.Â 1087â€“1105\n.\nExternal Links:\nISSN 19410468\nCited by:\nÂ§I\n,\nÂ§II\n.\n[15]\nD. Goeke and M. Schneider\n(2015-08)\nRouting a mixed fleet of electric and conventional vehicles\n.\nEuropean Journal of Operational Research\n245\n,\npp.Â 81â€“99\n.\nExternal Links:\nISSN 0377-2217\nCited by:\nÂ§II\n.\n[16]\nB. Golden, A. Assad, L. Levy, and F. Gheysens\n(1984-01)\nThe fleet size and mix vehicle routing problem\n.\nComputers & Operations Research\n11\n,\npp.Â 49â€“66\n.\nExternal Links:\nDocument\n,\nISSN 0305-0548\nCited by:\nÂ§II\n.\n[17]\nW. Gosrich, S. Agarwal, K. Garg, S. Mayya, M. Malencia, M. Yim, and V. Kumar\n(2025)\nOnline multi-robot coordination and cooperation with task precedence relationships\n.\nIEEE Trans.Â on Robotics\n,\npp.Â 1â€“20\n.\nExternal Links:\nISSN 1552-3098\nCited by:\nÂ§II\n.\n[18]\nA. Hakobyan, G. C. Kim, and I. Yang\n(2019)\nRisk-aware motion planning and control using cvar-constrained optimization\n.\nIEEE Robotics and Automation Letters\n4\n(\n4\n),\npp.Â 3924â€“3931\n.\nCited by:\nÂ§II\n.\n[19]\nG. Hardouin, J. Moras, F. Morbidi, J. Marzat, and E. M. Mouaddib\n(2023-08)\nA multirobot system for 3-d surface reconstruction with centralized and distributed architectures\n.\nIEEE Trans.Â on Robotics\n39\n,\npp.Â 2623â€“2638\n.\nExternal Links:\nISSN 19410468\nCited by:\nÂ§I\n,\nÂ§II\n.\n[20]\nK. Helsgaun\n(2017-12)\nAn extension of the lin-kernighan-helsgaun tsp solver for constrained traveling salesman and vehicle routing problems: technical report\n.\nRoskilde Universitet\n,\nDepartment of People and TechnologyProgramming, Logic and Intelligent Systems\n.\nCited by:\nÂ§II\n.\n[21]\nD. S.W. Lai, O. C. Demirag, and J. M.Y. Leung\n(2016-02)\nA tabu search heuristic for the heterogeneous vehicle routing problem on a multigraph\n.\nTransp. Research: Logistics and Transportation Review\n86\n,\npp.Â 32â€“52\n.\nExternal Links:\nISSN 1366-5545\nCited by:\nÂ§II\n.\n[22]\nZ. Li, P. Xu, L. Ding, J. Shan, W. Yang, Z. Deng, H. Gao, T. Liu, and H. Yang\n(2024)\nEnhancing cooperative exploration and planning: uav-legged robot synergy\n.\nIEEE Robotics and Automation Letters\n9\n,\npp.Â 10367â€“10374\n.\nExternal Links:\nISSN 23773766\nCited by:\nÂ§II\n.\n[23]\nS. Liu, W. Huang, and H. Ma\n(2009-05)\nAn effective genetic algorithm for the fleet size and mix vehicle routing problems\n.\nTransportation Research: Logistics and Transportation Review\n45\n,\npp.Â 434â€“445\n.\nExternal Links:\nISSN 1366-5545\nCited by:\nÂ§II\n.\n[24]\nS. Macenski, F. Martin, R. White, and J. GinÃ©s Clavero\n(2020)\nThe marathon 2: a navigation system\n.\nIn\nProc.Â of the IEEE/RSJ Intl.Â Conf.Â on Intelligent Robots and Systems\n,\nCited by:\nÂ§IV\n.\n[25]\nM. V. R. Malladi, N. Chebrolu, I. Scacchetti, L. Lobefaro, T. Guadagnino, B. Casseau, H. Oh, L. FreiÃŸmuth, M. Karppinen, J. Schweier, S. Leutenegger, J. Behley, C. Stachniss, and M. Fallon\n(2025)\nDigiforests: a longitudinal lidar dataset for forestry robotics\n.\nIn\nProc.Â of the IEEE Intl.Â Conf.Â on Robotics & Automation\n,\nVol.\n,\npp.Â 1459â€“1466\n.\nCited by:\nÂ§I\n.\n[26]\nZ. Mao, D. Liu, K. Ju, B. Jiang, and X. G. Yan\n(2025)\nTask search and allocation strategy for heterogeneous multiagent systems under communication constraints\n.\nProc.Â of the IEEE Intl.Â Conf.Â on Systems, Man, and Cybernetics (SMC)\n55\n,\npp.Â 550â€“562\n.\nExternal Links:\nISSN 21682232\nCited by:\nÂ§II\n.\n[27]\nN. Mathew, S. L. Smith, and S. L. Waslander\n(2015-10)\nPlanning paths for package delivery in heterogeneous multirobot teams\n.\nIEEE Transactions on Automation Science and Engineering\n12\n,\npp.Â 1298â€“1308\n.\nExternal Links:\nISSN 15455955\nCited by:\nÂ§II\n.\n[28]\nI. D. Miller, F. Cladera, T. Smith, C. J. Taylor, and V. Kumar\n(2022-10)\nStronger together: air-ground robotic collaboration using semantics\n.\nIEEE Robotics and Automation Letters\n7\n,\npp.Â 9643â€“9650\n.\nExternal Links:\nDocument\n,\nISSN 23773766\nCited by:\nÂ§I\n,\nÂ§II\n.\n[29]\nP. H.C. Morais, K. C.T. Vivaldini, E. R.R. Kato, and R. S. Inoue\n(2025)\nA review of robot fleet management\n.\nIEEE Access\n13\n,\npp.Â 118975â€“119003\n.\nExternal Links:\nISSN 21693536\nCited by:\nÂ§I\n,\nÂ§II\n.\n[30]\nD. Morilla-Cabello, L. Bartolomei, L. Teixeira, E. Montijano, and M. Chli\n(2022)\nSweep-your-map: efficient coverage planning for aerial teams in large-scale environments\n.\nIEEE Robotics and Automation Letters\n7\n(\n4\n),\npp.Â 10810â€“10817\n.\nCited by:\nÂ§I\n,\nÂ§II\n,\nÂ§\nV-A\n,\nÂ§\nV-A\n,\nTABLE II\n,\nTABLE II\n,\nÂ§V\n.\n[31]\nD. Morilla-Cabello, L. Mur-Labadia, R. Martinez-Cantin, and E. Montijano\n(2023)\nRobust fusion for bayesian semantic mapping\n.\nIn\nProc.Â of the IEEE/RSJ Intl.Â Conf.Â on Intelligent Robots and Systems\n,\npp.Â 76â€“81\n.\nCited by:\nÂ§IV\n.\n[32]\nG. Notomista, S. Mayya, Y. Emam, C. Kroninger, A. Bohannon, S. Hutchinson, and M. Egerstedt\n(2022-02)\nA resilient and energy-aware task allocation framework for heterogeneous multirobot systems\n.\nIEEE Trans.Â on Robotics\n38\n,\npp.Â 159â€“179\n.\nExternal Links:\nISSN 19410468\nCited by:\nÂ§I\n,\nÂ§I\n,\nÂ§II\n.\n[33]\nJ. Park, A. Messing, H. Ravichandar, and S. Hutchinson\n(2023)\nRisk-tolerant task allocation and scheduling in heterogeneous multi-robot teams\n.\nProc.Â of the IEEE/RSJ Intl.Â Conf.Â on Intelligent Robots and Systems\n,\npp.Â 5372â€“5379\n.\nCited by:\nÂ§II\n.\n[34]\nP. H. V. Penna, H. M. Afsar, C. Prins, and C. Prodhon\n(2016-01)\nA hybrid iterative local search algorithm for the electric fleet size and mix vehicle routing problem with time windows and recharging stations\n.\nIFAC-PapersOnLine\n49\n,\npp.Â 955â€“960\n.\nExternal Links:\nISSN 2405-8963\nCited by:\nÂ§II\n.\n[35]\nOR-tools\nGoogle\n.\nExternal Links:\nLink\nCited by:\nÂ§II\n,\nÂ§IV\n.\n[36]\nJ. P. Queralta, J. Taipalmaa, B. C. Pullinen, V. K. Sarker, T. N. Gia, H. Tenhunen, M. Gabbouj, J. Raitoharju, and T. Westerlund\n(2020)\nCollaborative multi-robot search and rescue: planning, coordination, perception, and active vision\n.\nIEEE Access\n8\n,\npp.Â 191617â€“191643\n.\nExternal Links:\nISSN 21693536\nCited by:\nÂ§I\n,\nÂ§II\n,\nÂ§II\n.\n[37]\nY. Shi, M. Dong, and C. Xu\n(2025)\nHarnessing vision foundation models for high-performance, training-free open vocabulary segmentation\n.\nIn\nProc.Â of the IEEE/CVF Intl.Â Conf.Â on Computer Vision\n,\npp.Â 23487â€“23497\n.\nCited by:\nÂ§II\n,\nÂ§IV\n.\n[38]\nM. Tranzatto, M. Dharmadhikari, L. Bernreiter, M. Camurri, S. Khattak, F. Mascarich, P. Pfreundschuh, D. Wisth, S. Zimmermann, M. Kulkarni,\net al.\n(2024-05)\nTeam cerberus wins the darpa subterranean challenge: technical overview and lessons learned\n.\nField Robotics\n4\n,\npp.Â 349â€“312\n.\nCited by:\nÂ§I\n,\nÂ§II\n.\n[39]\nJ. Wang, M. Chen, N. Karaev, A. Vedaldi, C. Rupprecht, and D. Novotny\n(2025)\nVGGT: visual geometry grounded transformer\n.\nIn\nProc.Â of the IEEE/CVF Conf.Â on Computer Vision and Pattern Recognition\n,\npp.Â 5294â€“5306\n.\nCited by:\nÂ§IV\n.\n[40]\nG. Xu, Y. Wu, S. Tao, Y. Yang, T. Liu, T. Huang, H. Wu, and Y. Liu\n(2025)\nEfficient multi-robot task and path planning in large-scale cluttered environments\n.\nIEEE Robotics and Automation Letters\n.\nExternal Links:\nISSN 23773766\nCited by:\nÂ§II\n.\n[41]\nH. S. Yoon, J. H. Hwang, C. Kim, E. I. Son, S. W. Yoo, and S. W. Seo\n(2024)\nAdaptive robot traversability estimation based on self-supervised online continual learning in unstructured environments\n.\nIEEE Robotics and Automation Letters\n9\n,\npp.Â 4902â€“4909\n.\nExternal Links:\nISSN 23773766\nCited by:\nÂ§I\n,\nÂ§II\n.\n[42]\nM. Zhang, C. Feng, Z. Li, G. Zheng, Y. Luo, Z. Wang, J. Zhou, S. Shen, and B. Zhou\n(2024)\nSOAR: simultaneous exploration and photographing with heterogeneous uavs for fast autonomous reconstruction\n.\nProc.Â of the IEEE/RSJ Intl.Â Conf.Â on Intelligent Robots and Systems\n,\npp.Â 10975â€“10982\n.\nExternal Links:\nISBN 9798350377705\n,\nISSN 21530866\nCited by:\nÂ§II\n.\n[43]\nB. Zhou, H. Xu, and S. Shen\n(2023-06)\nRACER: rapid collaborative exploration with a decentralized multi-uav system\n.\nIEEE Trans.Â on Robotics\n39\n,\npp.Â 1816â€“1835\n.\nExternal Links:\nISSN 19410468\nCited by:\nÂ§I\n,\nÂ§II\n,\nÂ§\nV-A\n,\nÂ§\nV-A\n,\nTABLE II\n,\nTABLE II\n,\nÂ§V\n.",
    "preview_text": "Monitoring large, unknown, and complex environments with autonomous robots poses significant navigation challenges, where deploying teams of heterogeneous robots with complementary capabilities can substantially improve both mission performance and feasibility. However, effectively modeling how different robotic platforms interact with the environment requires rich, semantic scene understanding. Despite this, existing approaches often assume homogeneous robot teams or focus on discrete task compatibility rather than continuous routing. Consequently, scene understanding is not fully integrated into routing decisions, limiting their ability to adapt to the environment and to leverage each robot's strengths. In this paper, we propose an integrated semantic-aware framework for coordinating heterogeneous robots. Starting from a reconnaissance flight, we build a metric-semantic map using open-vocabulary vision models and use it to identify regions requiring closer inspection and capability-aware paths for each platform to reach them. These are then incorporated into a heterogeneous vehicle routing formulation that jointly assigns inspection tasks and computes robot trajectories. Experiments in simulation and in a real inspection mission with three robotic platforms demonstrate the effectiveness of our approach in planning safer and more efficient routes by explicitly accounting for each platform's navigation capabilities. We release our framework, CHORAL, as open source to support reproducibility and deployment of diverse robot teams.\n\n\\useunder\n\\ul\nCHORAL: Traversal-Aware Planning for Safe and Efficient Heterogeneous Multi-Robot Routing\nDavid Morilla-Cabello, and Eduardo Montijano\nThis work was partially funded by Spanish grant FPU20-06563, project T45_23R, by grants AIA2025-163563-C31, PID2024-159284NB-I00 funded by MCIN/AEI/10.13039/501100011033 and ERDF, and the Office of Naval Research Global grant N62909-24-1-2081. D. Morilla-Cabello and E. Montijano are with the In",
    "is_relevant": false,
    "relevance_score": 2.0,
    "extracted_keywords": [
        "heterogeneous multi-robot routing",
        "semantic-aware planning",
        "traversal-aware",
        "vision models",
        "vehicle routing formulation"
    ],
    "one_line_summary": "è¯¥è®ºæ–‡æå‡ºä¸€ä¸ªè¯­ä¹‰æ„ŸçŸ¥æ¡†æ¶CHORALï¼Œç”¨äºå¼‚æ„å¤šæœºå™¨äººè·¯ç”±è§„åˆ’ï¼Œé€šè¿‡è§†è§‰æ¨¡å‹æ„å»ºåœ°å›¾å¹¶æ•´åˆæœºå™¨äººå¯¼èˆªèƒ½åŠ›ï¼Œä»¥æé«˜å®‰å…¨æ€§å’Œæ•ˆç‡ã€‚",
    "detailed_summary": "",
    "qa_pairs": [],
    "is_hidden": false,
    "is_starred": false,
    "flag": true,
    "published_date": "2026-01-15T12:34:22Z",
    "created_at": "2026-01-20T17:49:55.051168",
    "updated_at": "2026-01-20T17:49:55.051176"
}