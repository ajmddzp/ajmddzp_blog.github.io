{
    "id": "2601.11394v1",
    "title": "The Mini Wheelbot Dataset: High-Fidelity Data for Robot Learning",
    "authors": [
        "Henrik Hose",
        "Paul Brunzema",
        "Devdutt Subhasish",
        "Sebastian Trimpe"
    ],
    "abstract": "为不稳定系统开发鲁棒的学习型控制算法需要高质量的真实世界数据，然而专业机器人硬件的获取仍是许多研究者的主要障碍。本文为Mini Wheelbot——一种开源准对称平衡反作用轮独轮机器人——构建了全面的动力学数据集。该数据集以1kHz频率提供同步数据，涵盖所有板载传感器读数、状态估计值、运动捕捉系统的真实位姿数据以及第三方视频记录。为确保数据多样性，我们通过伪随机二进制激励、非线性模型预测控制和强化学习智能体等多种控制范式，在多个硬件实例和不同表面材质上进行了实验。我们提供了动力学模型学习、状态估计和时间序列分类的若干应用示例，以展示可在本数据集上进行基准测试的常见机器人算法。",
    "url": "https://arxiv.org/abs/2601.11394v1",
    "html_url": "https://arxiv.org/html/2601.11394v1",
    "html_content": "The Mini Wheelbot Dataset: High-Fidelity Data for Robot Learning\nHenrik Hose\n∗\nPaul Brunzema\n∗\nDevdutt Subhasish\nSebastian Trimpe\n∗\nEqual contribution.This work is funded in part by the German Research Foundation (DFG) – RTG 2236/2 (UnRAVeL) and the German Federal Ministry of Research, Technology and Space under the Robotics Institute Germany (RIG).All authors are with the Institute for Data Science in Mechanical Engineering (DSME), RWTH Aachen University, Germany (e-mail: {henrik.hose, brunzema, trimpe}@dsme.rwth-aachen.de)\nAbstract\nThe development of robust learning-based control algorithms for unstable systems requires high-quality, real-world data, yet access to specialized robotic hardware remains a significant barrier for many researchers.\nThis paper introduces a comprehensive dynamics dataset for the Mini Wheelbot, an open-source, quasi-symmetric balancing reaction wheel unicycle.\nThe dataset provides 1 kHz synchronized data encompassing all onboard sensor readings, state estimates, ground-truth poses from a motion capture system, and third-person video logs.\nTo ensure data diversity, we include experiments across multiple hardware instances and surfaces using various control paradigms, including pseudo-random binary excitation, nonlinear model predictive control, and reinforcement learning agents.\nWe include several example applications in dynamics model learning, state estimation, and time-series classification to illustrate common robotics algorithms that can be benchmarked on our dataset.\ngithub.com/wheelbot/dataset\npip install wheelbot-dataset\nI\nIntroduction\nRecent advances in data-driven modeling and learning-based control\nhave enabled robotic systems to solve complex control problems\nby directly learning control policies from experience\n[\n1\n,\n2\n]\n.\nResearch in such methods critically depends on diverse, high-quality training data, yet surprisingly few real-world datasets of\nfast, unstable, nonlinear, underactuated\nrobots exist beyond perception-focused vehicles\n[\n3\n,\n4\n]\nand well-linearizable quadcopters\n[\n5\n]\n.\nIn this paper, we hope to democratize robotics research and enable reproducible benchmarks by introducing a high-fidelity dataset for the recently developed Mini Wheelbot\n[\n6\n]\n:\nAn open-source, quasi-symmetric balancing reaction wheel unicycle robot.\nThe Mini Wheelbot balances with a linear state-feedback controller using its driving wheel similar to a segway (pitch) and its reaction wheel for roll stabilization.\nHowever, the yaw angle of the Mini Wheelbot is linearly uncontrollable,\nnecessitating nonlinear methods like model predictive control (MPC) or reinforcement learning (RL).\nThe robot can stand up from any initial orientation using its driving and reaction wheels.\nThis allows for automatic environment resets after failed experiments.\nThe Mini Wheelbot is designed for experimental ease, featuring a rugged aluminum housing, a\n45\nmin\n45\\text{\\,}\\frac{\\mathrm{min}}{}\nbattery runtime, and a Linux single-board computer (Raspberry Pi CM4) running all controllers onboard.\nFigure 1\n:\nExperimental recording setup for the Mini Wheelbot dataset.\nThe contribution of this paper is a large, high-quality dynamics dataset of the Mini Wheelbot.\nThe dataset contains\n1\nkHz\n1\\text{\\,}\\frac{\\mathrm{kHz}}{}\ndata of all onboard sensor readings, the estimated state, ground-truth pose measurements from a motion capture system, and third-person view videos of each experiment.\nWe perform a variety of experiments using pseudo-random binary excitation signals (PRBS) as setpoints of a linear controller, an MPC for driving, and an RL policy that races along tracks.\nExperiments are performed across multiple hardware instances and on different surfaces.\nWith this dataset, we hope to encourage researchers to use the Mini Wheelbot to benchmark their learning-based control methods, even without access to the real hardware.\nWe include example implementations illustrating the use of the dataset for dynamics learning, state estimation, and time-series classification.\nTABLE I\n:\nExperiments in the Mini Wheelbot dataset.\nGroup\nController\nReference\n# Trajs.\nΣ\n\\Sigma\nDur. [min]\n# Crashes\nPitch\nLQR\nPRBS\n16\n6.0\n11\nRoll\nLQR\nPRBS\n45\n21.1\n20\nVel + Roll\nLQR\nPRBS\n29\n2.6\n16\nVel + Pitch\nLQR\nPRBS\n13\n1.7\n2\nYaw Random\nAMPC\nPRBS\n50\n38.0\n5\nYaw Circles\nAMPC\nGeometric\n89\n53.2\n4\nYaw Eight\nAMPC\nGeometric\n104\n77.5\n14\nHuman\nAMPC\nGeometric\n7\n13.6\n0\nRacetrack\nRL\nTrack\n(Available soon)\nAll\n383\n219.7\n80\nII\nA Dataset for Dynamics Learning\nWe record our dataset with different controllers tracking random and deterministic references to excite all relevant Mini Wheelbot’s dynamics.\nAn overview of the experiments contained in the dataset is given in Tab.\nI\n: Individual and combined roll and pitch references (with and without driving velocity reference) are recorded using PRBS as standard for system identification.\nFor these experiments, we use the linear state-feedback controller with decoupled roll and pitch in\n[\n7\n]\nthat does not control the yaw angle.\nHowever, the free system response in yaw is recorded and can be readily used for dynamics modeling.\nExperiments based on human direction and velocity commands and geometric references are recorded using a nonlinear MPC that is approximated using a neural network (AMPC)\n[\n8\n,\n6\n,\n9\n]\n.\nThese experiments exhibit smaller excitation in roll and pitch direction, but represent a state distribution relevant for meaningful tasks such as driving.\nWe include sequences that lead to a crash as these can contain valuable information right before the crash occurs.\nFinally, we record data of the Mini Wheelbot racing along predefined tracks using an RL policy.\nBasic Usage\nZenodo\nFigure 2\n:\nLeft:\nThe same reference (Yaw Circles) on the three different surfaces contained in the dataset.\nRight:\nPython snippet on how to load the dataset.\nAll data in the dataset is logged at\n1\nkHz\n1\\text{\\,}\\frac{\\mathrm{kHz}}{}\ndirectly onboard the robot, thus it is as time-synchronized as the controller would receive it, yet some sensors might provide an updated measurement at a lower rate.\nFields in the comma-separated values format\n.csv\nare summarized in Tab.\nII\n.\nAll coordinates are aligned with the robot body frame, where the\nx\nx\n-axis points forward, the\ny\ny\n-axis sideways and the\nz\nz\n-axis upwards (see Fig.\n1\n).\nMetadata fields in JSON (\n.json\n) are\nexperiment_status\nindicating if the robot crashed,\nwheelbot\nwhich contains the hardware id,\nsurface\non which the experiment was conducted, and a unique identifier\nuuid\n. Third-person view videos (\n.mp4\n) document how an experiment looks for visual inspection.\nTABLE II\n:\nOverview of dataset fields and signal semantics.\nField\nDescription\nData rate [Hz]\n_time\nTimestamp [s]\n1000\n/gyroi/x,y,z\nBody-frame angular rate from IMUs (\ni\n=\n0\n​\n…\n​\n3\ni=0...3\n), [rad/s]\n1000\n/acceli/x,y,z\nBody-frame acceleration incl. gravity from IMUs [m/s\n2\n]\n200\n/q_yrp/yaw,roll,pitch\nEstimated robot orientation as yaw, roll, pitch angles [rad]\n1000\n/dq_yrp/*\nTime derivatives of yaw, roll, and pitch angles [rad/s]\n1000\n/q_DR/*\n,\n/dq_DR/*\n,\n/ddq_DR/*\nAngle, velocity, accel. of both wheels [rad, rad/s, rad/s\n2\n]\n1000\n/tau_DR_command/*\nCommanded actuator torques [Nm]\n167\n/setpoint/*\nReferences for orientation, rates, wheel\nangle and velocities\n–\n/vicon_position/*\nGlobal position in world frame from motion capture [m]\n100\n/vicon_orientation_wxyz/*\nRobot orientation from motion capture, quaternion [w,x,y,z]\n100\nbattery/voltage\nMeasured battery voltage [V]\n0.5\nIII\nUsage Examples\nDynamics Learning.\nWe provide an example of dynamics model learning using a multi-layer perceptron (MLP).\nThe MLP is trained to predict the next state based on the state\ns\ns\n, action\na\na\n, and context\nc\nc\nat time\nt\nt\n:\ns\nt\n+\n1\n=\nMLP\n​\n(\ns\nt\n,\na\nt\n,\nc\nt\n)\ns_{t+1}=\\mathrm{MLP}(s_{t},a_{t},c_{t})\n.\nWe use body orientations, angular velocities, wheel positions, and velocities in the state\ns\ns\n, commanded torques as\na\na\n, and\nsub-sample at\n100\nHz\n100\\text{\\,}\\frac{\\mathrm{Hz}}{}\n.\nWe train on multi-step rollouts, i.e., we roll out the MLP autoregressively for 50 steps starting at\ns\n0\ns_{0}\nfrom the dataset and then compute a mean squared error loss of the model rollout and the real-world data.\nFig.\n3\nshows the autoregressive predictions of the final model on a hold-out test trajectory.\nFull Example\nFigure 3\n:\nAutoregressive rollout of learned model vs. measured data (MD).\nState Estimation.\nDue to the availability of ground truth motion capture data, the dataset can be used to benchmark estimators.\nWe implement the orientation estimator from\n[\n7\n]\nas an example in pure Python and compare it with ground-truth from motion capture in Fig.\n4\n.\nFull Example\nFigure 4\n:\nOffline evaluation of an estimator against Vicon ground truth data.\nTime-series Transformer Classifier.\nIn this example, we train a small time-series transformer classification model that predicts the floor, human or geometric reference, and robot instance from sequences of accelerometer and gyroscope readings.\nWe report the resulting classification accuracy over the sequence length in Fig.\n5\n.\nFull Example\nFigure 5\n:\nClassification accuracies over sequence lengths.\nIV\nConclusion and Outlook\nWe present a large (\n11\nGB\n11\\text{\\,}\\frac{\\mathrm{GB}}{}\n; 13 mio. state transitions) and diverse dataset of the Mini Wheelbot accompanied by a Python package and example implementations.\nWe hope to foster reproducibility of results and become a benchmark for learning algorithms targeting fast, unstable, nonlinear dynamics.\nWe aim to expand the dataset with LiDAR and vision after respective hardware updates to the Mini Wheelbot.\nReferences\n[1]\nJ. Kober, J. A. Bagnell, and J. Peters, “Reinforcement learning in robotics: A survey,”\nThe International Journal of Robotics Research\n, vol. 32, no. 11, pp. 1238–1274, 2013.\n[2]\nS. Levine, C. Finn, T. Darrell, and P. Abbeel, “End-to-end training of deep visuomotor policies,”\nJournal of Machine Learning Research\n, vol. 17, no. 39, pp. 1–40, 2016.\n[3]\nA. Kulkarni, J. Chrosniak, E. Ducote, F. Sauerbeck, A. Saba, U. Chirimar, J. Link, M. Behl, and M. Cellina, “Racecar-the dataset for high-speed autonomous racing,” in\n2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\n. IEEE, 2023.\n[4]\nH. Caesar, V. Bankiti, A. H. Lang, S. Vora, V. E. Liong, Q. Xu, A. Krishnan, Y. Pan, G. Baldan, and O. Beijbom, “nuscenes: A multimodal dataset for autonomous driving,” in\nProceedings of the IEEE/CVF conference on computer vision and pattern recognition\n, 2020, pp. 11 621–11 631.\n[5]\nJ. Delmerico, T. Cieslewski, H. Rebecq, M. Faessler, and D. Scaramuzza, “Are we ready for autonomous drone racing? the UZH-FPV drone racing dataset,” in\nInternational Conference on Robotics and Automation (ICRA)\n. IEEE, 2019, pp. 6713–6719.\n[6]\nH. Hose, J. Weisgerber, and Trimpe, “The Mini Wheelbot: A testbed for learning-based balancing, flips, and articulated driving,” in\nInternational Conference on Robotics and Automation (ICRA)\n, 2025.\n[7]\nA. R. Geist, J. Fiene, N. Tashiro, Z. Jia, and S. Trimpe, “The Wheelbot: A jumping reaction wheel unicycle,”\nIEEE Robotics and Automation Letters\n, vol. 7, no. 4, pp. 9683–9690, 2022.\n[8]\nH. Hose, A. Gräfe, and S. Trimpe, “Parameter-adaptive approximate MPC: Tuning neural-network controllers without retraining,” in\nConference on Learning for Dynamics and Control (L4DC)\n, 2024.\n[9]\nH. Hose, P. Brunzema, A. Von Rohr, A. Gräfe, A. P. Schoellig, and S. Trimpe, “Fine-tuning of neural network approximate MPC without retraining via Bayesian optimization,”\npreprint arXiv:2512.14350\n, 2025.",
    "preview_text": "The development of robust learning-based control algorithms for unstable systems requires high-quality, real-world data, yet access to specialized robotic hardware remains a significant barrier for many researchers. This paper introduces a comprehensive dynamics dataset for the Mini Wheelbot, an open-source, quasi-symmetric balancing reaction wheel unicycle. The dataset provides 1 kHz synchronized data encompassing all onboard sensor readings, state estimates, ground-truth poses from a motion capture system, and third-person video logs. To ensure data diversity, we include experiments across multiple hardware instances and surfaces using various control paradigms, including pseudo-random binary excitation, nonlinear model predictive control, and reinforcement learning agents. We include several example applications in dynamics model learning, state estimation, and time-series classification to illustrate common robotics algorithms that can be benchmarked on our dataset.\n\nThe Mini Wheelbot Dataset: High-Fidelity Data for Robot Learning\nHenrik Hose\n∗\nPaul Brunzema\n∗\nDevdutt Subhasish\nSebastian Trimpe\n∗\nEqual contribution.This work is funded in part by the German Research Foundation (DFG) – RTG 2236/2 (UnRAVeL) and the German Federal Ministry of Research, Technology and Space under the Robotics Institute Germany (RIG).All authors are with the Institute for Data Science in Mechanical Engineering (DSME), RWTH Aachen University, Germany (e-mail: {henrik.hose, brunzema, trimpe}@dsme.rwth-aachen.de)\nAbstract\nThe development of robust learning-based control algorithms for unstable systems requires high-quality, real-world data, yet access to specialized robotic hardware remains a significant barrier for many researchers.\nThis paper introduces a comprehensive dynamics dataset for the Mini Wheelbot, an open-source, quasi-symmetric balancing reaction wheel unicycle.\nThe dataset provides 1 kHz synchronized data encompassing all onboard sensor readings, state estimates, ground-tr",
    "is_relevant": true,
    "relevance_score": 4.0,
    "extracted_keywords": [
        "Reinforcement Learning",
        "locomotion",
        "whole body control"
    ],
    "one_line_summary": "这篇论文介绍了Mini Wheelbot数据集，为机器人学习提供高质量数据，包括强化学习控制范例，适用于不稳定系统的控制算法开发。",
    "detailed_summary": "",
    "qa_pairs": [],
    "is_hidden": false,
    "is_starred": false,
    "flag": true,
    "published_date": "2026-01-16T16:06:32Z",
    "created_at": "2026-01-20T17:50:00.784443",
    "updated_at": "2026-01-20T17:50:00.784453",
    "recommend": 0
}