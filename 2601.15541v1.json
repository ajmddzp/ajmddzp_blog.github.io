{
    "id": "2601.15541v1",
    "title": "CompliantVLA-adaptor: VLM-Guided Variable Impedance Action for Safe Contact-Rich Manipulation",
    "authors": [
        "Heng Zhang",
        "Wei-Hsing Huang",
        "Qiyi Tong",
        "Gokhan Solak",
        "Puze Liu",
        "Sheng Liu",
        "Jan Peters",
        "Arash Ajoudani"
    ],
    "abstract": "æˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºCompliantVLA-adaptorçš„é€‚é…å™¨ï¼Œé€šè¿‡ç»“åˆè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰æ„ŸçŸ¥çš„ä¸Šä¸‹æ–‡è‡ªé€‚åº”å˜é˜»æŠ—æ§åˆ¶ï¼ˆVICï¼‰ï¼Œå¢å¼ºç°æœ‰æœ€å…ˆè¿›çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹ï¼Œä»¥æå‡æ¥è§¦å¯†é›†å‹æœºå™¨äººæ“ä½œä»»åŠ¡çš„å®‰å…¨æ€§ä¸æœ‰æ•ˆæ€§ã€‚ç°æœ‰VLAç³»ç»Ÿï¼ˆå¦‚RDTã€Pi0ã€OpenVLA-oftï¼‰é€šå¸¸ä»…è¾“å‡ºä½ç½®æŒ‡ä»¤ï¼Œç¼ºä¹åŠ›æ„ŸçŸ¥è‡ªé€‚åº”èƒ½åŠ›ï¼Œå¯¼è‡´åœ¨æ¶‰åŠæ¥è§¦ã€é¡ºåº”æ€§æˆ–ä¸ç¡®å®šæ€§çš„ç‰©ç†ä»»åŠ¡ä¸­å‡ºç°ä¸å®‰å…¨æˆ–å¤±è´¥çš„æƒ…å†µã€‚åœ¨æå‡ºçš„CompliantVLA-adaptorä¸­ï¼Œè§†è§‰è¯­è¨€æ¨¡å‹é€šè¿‡å›¾åƒå’Œè‡ªç„¶è¯­è¨€è§£æä»»åŠ¡ä¸Šä¸‹æ–‡ï¼Œè‡ªé€‚åº”è°ƒæ•´VICæ§åˆ¶å™¨çš„åˆšåº¦å’Œé˜»å°¼å‚æ•°ã€‚è¿™äº›å‚æ•°è¿›ä¸€æ­¥é€šè¿‡å®æ—¶åŠ›/åŠ›çŸ©åé¦ˆè¿›è¡Œè°ƒèŠ‚ï¼Œä»¥ç¡®ä¿äº¤äº’åŠ›ä¿æŒåœ¨å®‰å…¨é˜ˆå€¼å†…ã€‚æˆ‘ä»¬åœ¨ä»¿çœŸå’ŒçœŸå®ç¡¬ä»¶ä¸ŠéªŒè¯äº†è¯¥æ–¹æ³•åœ¨ä¸€ç³»åˆ—å¤æ‚æ¥è§¦å¯†é›†å‹ä»»åŠ¡ä¸­ä¼˜äºVLAåŸºçº¿æ¨¡å‹ï¼ŒæˆåŠŸç‡å’ŒåŠ›è¿è§„ç‡å‡å¾—åˆ°æ”¹å–„ã€‚æ‰€æœ‰ä»»åŠ¡çš„æ•´ä½“æˆåŠŸç‡ä»9.86%æå‡è‡³17.29%ï¼Œä¸ºåŸºäºVLAçš„å®‰å…¨æ¥è§¦å¯†é›†å‹æ“ä½œæä¾›äº†å¯è¡Œè·¯å¾„ã€‚ç›¸å…³ä»£ç ã€æç¤ºè¯åŠåŠ›-åŠ›çŸ©-é˜»æŠ—-åœºæ™¯ä¸Šä¸‹æ–‡æ•°æ®é›†å·²å‘å¸ƒäºhttps://sites.google.com/view/compliantvlaã€‚",
    "url": "https://arxiv.org/abs/2601.15541v1",
    "html_url": "https://arxiv.org/html/2601.15541v1",
    "html_content": "CompliantVLA-adaptor: VLM-Guided Variable Impedance Action for Safe Contact-Rich Manipulation\nHeng Zhang*\n1,2\n, Wei-Hsing Huang*\n3\n, Qiyi Tong\n1,2\n, Gokhan Solak\n1\n, Puze Liu\n4\n, Sheng Liu\n6\n,\nJan Peters\n4,5\n, Arash Ajoudani\n1\nAbstract\nWe propose a CompliantVLA-adaptor that augments the state-of-the-art Vision-Language-Action (VLA) models with vision-language model (VLM)-informed context-aware variable impedance control (VIC) to improve the safety and effectiveness of contact-rich robotic manipulation tasks.\nExisting VLA systems (e.g., RDT, Pi0, OpenVLA-oft) typically output position, but lack force-aware adaptation, leading to unsafe or failed interactions in physical tasks involving contact, compliance, or uncertainty.\nIn the proposed CompliantVLA-adaptor, a VLM interprets task context from images and natural language to adapt the stiffness and damping parameters of a VIC controller.\nThese parameters are further regulated using real-time force/torque feedback to ensure interaction forces remain within safe thresholds.\nWe demonstrate that our method outperforms the VLA baselines on a suite of complex contact-rich tasks, both in simulation and on real hardware, with improved success rates and reduced force violations. The overall success rate across all tasks increases from 9.86% to 17.29%,\npresenting a promising path towards safe contact-rich manipulation using VLAs.\nWe release our code, prompts, and force-torque-impedance-scenario context datasets at\nhttps://sites.google.com/view/compliantvla\n.\nI\nIntroduction\nRecent advances in Vision-Language-Action (VLA) models have enabled robots to understand and execute complex tasks described in natural language, such as\nRDT\n[\n18\n]\n, Pi0\n[\n6\n]\n, DiffusionVLA\n[\n26\n]\n, Pi0.5\n[\n9\n]\n, OpenVLA\n[\n13\n]\nand OpenVLA-oft\n[\n12\n]\n.\nThese models leverage large-scale pretraining on diverse datasets to learn rich visual and linguistic representations, allowing them to generalize across a wide range of manipulation tasks.\nCurrent state-of-the-art VLA models demonstrate remarkable generalization across diverse manipulation tasks. However, these models fundamentally operate through position or trajectory control, treating the robot as a rigid position-tracking system that lacks consideration of the physical interaction dynamics involved in contact-rich tasks\n[\n34\n,\n25\n]\n.\nWe observe the limitation of the current VLA models that hinder their performance in contact-rich tasks if considering the contact force threshold (e.g., <30N).\nThe contact force can become huge when the robot is executing raw output of VLA in contact-rich tasks without force regulation. Safety issue highlights the limitation of current VLA models\n[\n20\n]\n.\nFigure 1\n:\nExisting VLA systems lack force-awareness, leading to unsafe interactions in physical tasks involving contact or uncertainty. We see this challenge as a promising direction for safer deployment of VLA systems.\nThis rigid execution paradigm leads to critical failures when interacting physically.\nThey have a core limitation as illustrated in Fig.\n1\n: VLAs excel at semantic understanding but cannot translate this understanding into the physical compliance required for safe execution.\nConsider a robot assembling a delicate electronic device (â€œinsert the USB cableâ€): it must insert a fragile connector with just enough force to engage the latch, yet gentle enough to avoid damage.\nOr imagine a robot closing a drawer, where excessive force could damage the drawer or its contents, while insufficient force might leave the drawer ajar.\nThe contact-rich manipulation tasks\nrequire not just visual understanding and action planning, but also precise force regulation and adaptive compliance.\nWhile recent VLA models have revolutionized robot learning through large-scale pretraining\n[\n22\n]\n, they critically lack the force-aware adaptation necessary for safe physical interaction.\n[\n33\n,\n31\n]\nalso points out the importance of torque-awareness in VLA models, but they only consider the torque prediction without force feedback and impedance control.\nThese shortcomings of the current VLA models lead\nto position commands even when encountering unexpected resistance, potentially causing irreversible damage to delicate objects or the robot itself. The disconnect between high-level semantic comprehension and low-level force-aware control represents a critical barrier to deploying VLA systems in real-world scenarios where safe physical interaction is paramount\n[\n11\n]\n. Therefore, there is an urgent need for an adaptor that preserves the generalization benefits of VLAs while incorporating the physical intelligence necessary for safe contact-rich manipulation.\nIn contrast, VIC provides compliant behavior in response to external forces through spring-damper dynamics,\noffers a complementary solution by modulating robot stiffness and damping to tackle interaction forces, enabling safe and adaptive physical interaction\n[\n1\n]\n.\nHowever, existing VIC approaches require manual tuning or task-specific parameter scheduling, lacking the semantic understanding to automatically adapt impedance based on visual context and task requirements.\nEven advanced learning-based VIC methods\n[\n21\n,\n32\n,\n28\n]\nrely on extensive task-specific training or expert demonstrations, limiting their generalization to novel objects and scenarios.\nRecent work has explored using VLMs to inform low-level control. For instance, SAS-prompt\n[\n2\n]\nuses VLMs to provide in-context guidance for robot policies, while other studies have employed VLMs to generate control parameters\n[\n23\n,\n10\n]\n.\nAdditionally, VLMs have demonstrated their capability as in-context value learners\n[\n19\n]\n, enhancing policy performance in various robotic tasks.\nInspired by these advances, we extend this paradigm by employing VLM as an in-context impedance coach within a classical VIC, where stiffness and damping parameters are dynamically regulated through multimodal reasoning based on visual, contact force and linguistic context inputs.\nWe present CompliantVLA-adaptor, a timely and effective but plug-and-play modular solution, before we train a high-performing VLA with sufficient and fine-grained datasets.\nThe CompliantVLA-adaptor augments VLA models with VLM-guided variable impedance control for safe contact-rich manipulation.\nOur experimental findings demonstrate that CompliantVLA-adaptor not only enhances task success rates but fundamentally transforms the nature of failure modes. While baseline VLA models exhibit catastrophic failures characterized by contact force threshold violations and toppled objects, our approach achieves graceful degradation, with failures primarily due to minor misalignments or slippage rather than unsafe forces.\nSpecifically, we present the following contributions:\nâ€¢\nThe proposed CompliantVLA-adaptor leverages a VLM-enhanced VIC to endow VLA models with compliant capability to physical interaction,\nwhere the VLM generates context-aware impedance parameters, translating high-level semantic understanding into low-level control parameters (stiffness, damping).\nâ€¢\nWe develop a control system that seamlessly integrates VLM parameters generation with VIC execution,\nmaintaining the generalization benefits of VLMâ€™s reasoning while adding the safety improvement of compliant control.\nâ€¢\nWe demonstrate our approach on several contact-rich tasks across simulation and real hardware,\nshowing improvements over the state-of-the-art VLA baselines in both success rates and safety metrics.\nII\nRelated Work\nII-A\nVision-language-action models for robotic manipulation\nRecent advancements in VLA models have significantly enhanced robotic manipulation capabilities by enabling robots to interpret and execute complex tasks described in natural language.\nModels such as RDT\n[\n18\n]\n, Pi0\n[\n6\n]\n, DiffusionVLA\n[\n26\n]\n, Pi0.5\n[\n9\n]\n, OpenVLA\n[\n13\n]\n, and OpenVLA-oft\n[\n12\n]\nleverage large-scale pretraining on diverse datasets to learn rich visual and linguistic representations, allowing them to generalize across a wide range of manipulation tasks.\nThese models typically consist of a high-level policy that maps visual and linguistic inputs to desired action, which are then executed by a low-level controller.\nFor instance, OpenVLA employs an operational space controller (OSC) to apply the end-effector displacements generated by the VLA model.\nInstructVLA\n[\n30\n]\nfurther extends this paradigm by incorporating human feedback to refine action generation, but it still relies on a simple PD controller.\nWhile these VLA models excel at semantic understanding and high-level action planning, they often lack consideration of the physical interaction dynamics involved in contact-rich tasks.\nThis limitation can lead to unsafe or failed interactions when robots encounter unexpected resistance or delicate objects, as they are unable to adapt their compliance based on the interaction forces.\nII-B\nVariable impedance control for safe physical interaction\nVariable impedance control (VIC) enables robots to safely and adaptively perform contact-rich tasks by regulating compliance in response to interaction dynamics, inspired by human motor control\n[\n29\n]\n. Unlike fixed-gain controllers, VIC improves robustness and safety in uncertain environments\n[\n7\n]\nand is widely recognized as essential for physical interaction\n[\n1\n]\n.\nRecent work further shows that using variable impedance actions in reinforcement learning (RL) enhances sample efficiency, robustness, and generalization\n[\n21\n]\n, and supports safe exploration in contact-rich scenarios\n[\n32\n]\n. These studies establish VIC as a key paradigm for adaptable, safe, and efficient manipulation.\nLearning-based VIC has advanced through RL approaches that incorporate force/torque feedback for online stiffness modulation\n[\n21\n,\n32\n,\n3\n,\n8\n]\n, imitation learning approaches that extract impedance profiles from human demonstrations or inverse RL\n[\n28\n,\n27\n]\n, and context-aware methods leveraging human arm stiffness, trust models, or adaptive control\n[\n15\n,\n16\n]\n.\nDespite these successes, existing VIC methods remain limited: RL demands task-specific training and risky exploration, imitation learning depends on expert demonstrations and struggles to generalize, and context-aware schemes rely on hand-crafted features that cannot exploit rich semantic cues (e.g., visually identifying fragile electronics).\nCrucially, none of these can harness the broad semantic knowledge embedded in internet-scale vision-language models to inform impedance adaptation. This semantic gap forces conservative tuning or risks unsafe contact with novel objects. Our CompliantVLA framework closes this gap by bridging high-level semantic reasoning with low-level compliant control through VLM-guided variable impedance.\nII-C\nVLMs enhance impedance parameter generation for safe physical interaction\nVLMs offer unprecedented capabilities for robotics by understanding scene semantics and task requirements from visual inputs, context injection and crucial knowledge to determine appropriate physical interaction parameters.\nPrior VIC parameter generation methods fall into three categories:\n(1) Rely on expert knowledge to pre-define impedance schedules\n[\n35\n,\n14\n]\nfor specific tasks, limiting adaptability to novel scenarios.\n(2) Learning-based methods like ImpedanceGPT\n[\n4\n]\nuse language models for parameter selection but evaluate only on simplified pick-and-place tasks without complex contact dynamics.\n(3) Multimodal approaches incorporate additional sensors\n[\n10\n]\nsuch as eye tracking for teleimpedance control, while\n[\n5\n]\nadds tactile feedbackâ€”but require specialized hardware that limits deployment scalability.\nOur CompliantVLA-adaptor uniquely combines a VLMâ€™s semantic understanding with real-time force feedback to generate context-aware impedance parameters.\nUnlike previous works that use VLMs only for high-level planning or require task-specific training,\nwe leverage pre-trained VLMs to directly map visual-linguistic context to impedance values, enabling zero-shot generalization across diverse contact-rich manipulation tasks while maintaining safety through force-regulated adaptation.\nIII\nMethodology\nWe present CompliantVLA-adaptor, augmenting VLA models with VLM-enhanced context-aware variable impedance control.\nOur approach consists of three key components: (1) a hybrid VLA-VIC control architecture, (2) VLM-based impedance parameter generation from visual-linguistic context, and (3) a real-time force-regulated safety layer. Fig.\n2\nillustrates the complete system architecture.\nFigure 2\n:\nOverview of the CompliantVLA-adaptor. A VLM processes visual\nobservations\n, language instructions, and real-time force feedback\nâ„±\n\\mathcal{F}\nto generate context-aware impedance parameters\nğ’¦\n,\nğ’Ÿ\n\\mathcal{K,D}\n. These parameters modulate a variable impedance controller(VIC) that executes actions generated by a VLA model, ensuring safe and adaptive contact-rich manipulation.\nIII-A\nProblem formulation\nConsider a robotic manipulation task defined by the tuple\nâ„³\n=\n(\nğ’®\n,\nğ’œ\n,\nğ’¯\n,\nğ’\n)\n\\mathcal{M}=(\\mathcal{S},\\mathcal{A},\\mathcal{T},\\mathcal{C})\n, where\nğ’®\n\\mathcal{S}\nrepresents the state space including visual observations,\nğ’œ\n\\mathcal{A}\ndenotes the action space,\nğ’¯\n\\mathcal{T}\nis the task specification in natural language, and\nğ’\n\\mathcal{C}\nrepresents physical constraints including force limits.\nFor a single 7 DoF robotic arm, the traditional VLA model maps observations and language instructions to actions, typically end-effector displacement values\nğ±\nd\nâˆˆ\nâ„\n6\n\\mathbf{x}_{d}\\in\\mathbb{R}^{6}\nand action for the gripper. However, this formulation ignores interaction forces\nğ…\nâˆˆ\nâ„\n6\n\\mathbf{F}\\in\\mathbb{R}^{6}\n, leading to unsafe contact interactions.\nWe augment an impedance-modulated control adaptor:\nC\nâ€‹\no\nâ€‹\nm\nâ€‹\np\nâ€‹\nl\nâ€‹\ni\nâ€‹\na\nâ€‹\nn\nâ€‹\nt\nâ€‹\nV\nâ€‹\nL\nâ€‹\nA\n:\nVLM\nâ€‹\n(\nğ’®\nÃ—\nğ’¯\nÃ—\nâ„±\n)\nâ†’\n(\nğ’¦\n,\nğ’Ÿ\n)\n{CompliantVLA}:\\text{VLM}(\\mathcal{S}\\times\\mathcal{T}\\times\\mathcal{F})\\rightarrow(\\mathcal{K},\\mathcal{D})\n(1)\nto VLA model:\nÏ€\nVLA\n:\nğ’®\nÃ—\nğ’¯\nâ†’\nğ’œ\n\\pi_{\\text{VLA}}:\\mathcal{S}\\times\\mathcal{T}\\rightarrow\\mathcal{A}\n(2)\nwhere a 6D vector\nâ„±\nâˆˆ\ns\nâ€‹\ne\nâˆ—\nâ€‹\n(\n3\n)\n\\mathcal{F}\\in se^{*}(3)\ndenotes the external contact force and torque,\nğ’¦\nâˆˆ\nâ„\n3\n\\mathcal{K}\\in\\mathbb{R}^{3}\nand\nğ’Ÿ\nâˆˆ\nâ„\n3\n\\mathcal{D}\\in\\mathbb{R}^{3}\nrepresent the translational stiffness matrix\nğ’¦\n\\mathcal{K}\nand the translational damping matrix\nğ’Ÿ\n\\mathcal{D}\n, respectively. Where the translational stiffness\nğ’¦\n\\mathcal{K}\n:\nğ’¦\n=\ndiag\nâ¡\n(\nk\nx\n,\nk\ny\n,\nk\nz\n)\n\\mathcal{K}=\\operatorname{diag}(k_{x},k_{y},k_{z})\n(3)\nand translational damping\nğ’Ÿ\n\\mathcal{D}\n:\nğ’Ÿ\n=\ndiag\nâ¡\n(\nD\nx\n,\nD\ny\n,\nD\nz\n)\n\\mathcal{D}=\\operatorname{diag}(D_{x},D_{y},D_{z})\n(4)\nWe set orientation stiffness matrices\nğŠ\no\n\\mathbf{K}_{o}\n, and orientation damping matrices\nğƒ\no\n\\mathbf{D}_{o}\nwith proportional coefficients shown in\n5\n. This formulation enables the simultaneous generation of desired actions and compliance parameters.\nK\no\ni\n=\nÎµ\nâ€‹\nk\ni\n,\nD\no\ni\n=\n2\nâ€‹\nÎ¶\nâ€‹\nK\no\ni\nK_{o}^{i}=\\varepsilon k^{i},\\qquad D_{o}^{i}=2\\zeta\\sqrt{K_{o}^{i}}\n(5)\nwhere\nÎµ\n=\n0.15\n\\varepsilon=0.15\nand\nÎ¶\n=\n0.707\n\\zeta=0.707\n.\nThe robot controller takes desired action\nğ’œ\n\\mathcal{A}\n, stiffness\nğ’¦\n\\mathcal{K}\nand damping\nğ’Ÿ\n\\mathcal{D}\nas inputs to enhance the safety along the physical interaction.\nIII-B\nCompliantVLA-adaptor\nOur impedance generation module leverages a frozen VLM to extract multimodal features from external force, visual observations, and physics-injected language instructions, mapping them to context-aware impedance parameters.\nTo ensure safe interaction forces, we implement a dual-layer safety system that combines VLM-based parameter modulation with contact phase recognition.\nSpecifically,\ngiven an RGB image of wrist\nğˆ\nw\n\\mathbf{I}_{w}\n, image of full overview\nğˆ\nf\n\\mathbf{I}_{f}\nand language instruction\nğ’¯\n\\mathcal{T}\nand external force\nâ„±\n\\mathcal{F}\n, (1)\nwe query a pretrained VLM (e.g., ChatGPT-4o-mini) to reason about the current task execution phase\ncurrent phase\n;\n(2) integrate the suggested\ncurrent phase\nand prompt, VLM maps these features to impedance parameters.\nIII-B\n1\nContact Phase Recognition through multimodal information\nVision-only phase detection presents inherent limitations, as VLMs cannot reliably detect contact states from visual information alone, particularly in scenarios with occlusions or subtle contact transitions.\nWhile force sensors provide direct contact information, relying solely on force feedback neglects valuable semantic context about expected interaction patterns.\nTherefore, we implement a hybrid approach that combines VLM-based visual understanding with force sensor feedback for robust phase detection.\nWith the following prompt(simplified, see details in our code), the VLM can distinguish between\nFree-motion, Approaching, Contact, Retreat\n.\nThis semantic phase recognition eliminates the need for contact dynamics models while providing appropriate compliance for each interaction stage.\nSimplified Prompt for Contact Phase Recognition:\nYou are a robotics expert capable of analyzing\nmultimodal sensory inputs for recognizing the current taskâ€™s contact phase.\nGiven\n{task description}\n,\n{force measurements}\n,\n{contact phase list}\n,\ndetermine the current task execution phase.\nAnalyze the input to infer:\ntask execution context\nOutput:\np\nâ€‹\nh\nâ€‹\na\nâ€‹\ns\nâ€‹\ne\n=\n[\np\nâ€‹\nh\nâ€‹\na\nâ€‹\ns\nâ€‹\ne\n]\nphase=[phase]\nIII-B\n2\nMultimodal-informed impedance parameter generation\nThe final impedance parameters fed to the VIC controller combine VLM-generated values with real-time force feedback:\nğŠ\np\nfinal\n\\displaystyle\\mathbf{K}_{p}^{\\text{final}}\n=\nğŠ\np\nVLM\nâ‹…\nÎ±\nforce\n\\displaystyle=\\mathbf{K}_{p}^{\\text{VLM}}\\cdot\\alpha_{\\text{force}}\n(6)\nğƒ\np\nfinal\n\\displaystyle\\mathbf{D}_{p}^{\\text{final}}\n=\n2\nâ€‹\nğŠ\np\nfinal\nâ‹…\nM\neff\nâ‹…\nÎ¶\n\\displaystyle=2\\sqrt{\\mathbf{K}_{p}^{\\text{final}}\\cdot M_{\\text{eff}}}\\cdot\\zeta\n(7)\nwhere\nÎ±\nforce\nâˆˆ\n[\n0.2\n,\n1\n]\n\\alpha_{\\text{force}}\\in[0.2,1]\nis a force-based scaling factor that reduces stiffness when measured forces exceed safe thresholds.\nThis ensures that even if the VLM suggests high stiffness based on visual context, the controller remains compliant in response to unexpected contact forces.\nğƒ\np\nfinal\n\\mathbf{D}_{p}^{\\text{final}}\nis computed to ensure critical damping, where\nM\neff\nM_{\\text{eff}}\nis the effective mass and\nÎ¶\n=\n0.7\n\\zeta=0.7\n.\nDuring execution, we continuously monitor force/torque sensor readings\nğ…\nmeas\n\\mathbf{F}_{\\text{meas}}\nat 1000 Hz.\nThe reactive regulation strategy adapts based on both measured forces and context reasoning from the VLM.\nConsidering the complex contact and motion scenarios,\nwe inject a physical-context prompt with our query prompts for impedance parameters\nso that the VLM can infer the appropriate anisotropic-centric impedance parameters.\nThe injected anisotropic-centric prompt is shown below:\nSimplified Prompt for context-aware impedance parameter generation:\nYou are an expert robotic impedance controller capable of analyzing\nmultimodal sensory inputs.\nGiven\n{task description}\n, current\n{phase}\n(Free_motion, Approaching, Contact, or Retreat),\n{velocity}\n, and\n{force measurements}\n,\n{impedance range}\n,\ndetermine optimal anisotropic impedance parameters.\nApply phase-based impedance hierarchy:\nâ€¢\nFree_motion:\nHighest impedance (precise position control)\nâ€¢\nApproaching:\nMedium impedance (transitioning to compliance)\nâ€¢\nContact:\nLowest impedance (maximum compliance)\nâ€¢\nRetreat:\nMedium impedance (controlled withdrawal)\nConsider motion direction adaptation:\nâ€¢\nPrimary motion axis:\nReduced impedance along intended motion direction\nâ€¢\nConstraint axes:\nElevated impedance perpendicular to motion for alignment maintenance\nAnalyze the input to infer:\ntask requirement, current situation,\nand environmental physical constraints.\nOutput:\nK\n=\n[\nK\nx\n,\nK\ny\n,\nK\nz\n]\nK=[K_{x},K_{y},K_{z}]\n,\nD\n=\n[\nD\nx\n,\nD\ny\n,\nD\nz\n]\nD=[D_{x},D_{y},D_{z}]\nwhere damping coefficients are proportional to stiffness values (10--20%).\nThis context-awareness prevents both unnecessary conservatism and dangerous over-forcing in primary motion direction.\nNote that the impedance range should be appropriately scaled to match the hardware specifications.\nIII-C\nHybrid VLA-VIC control architecture\nOur control architecture seamlessly integrates VLA action generation with VIC execution enhanced by VLM,\nmaintaining the benefits of VLA generalization while adding compliant safety.\nThe system operates at three temporal scales:\nâ€¢\nVLM-informed impedance generation (\nâˆ¼\n\\sim\n1 Hz):\nThe VLM processes visual-linguistic context and force feedback to generate impedance parameters.\nâ€¢\nVLA action chunk (\nâˆ¼\n\\sim\n3 Hz):\nVLA generates desired end-effector displacements\nğ±\nd\n\\mathbf{x}_{d}\nbased on current observations and instructions.\nâ€¢\nLow-level controller (1000 Hz):\nVIC controller tracks desired poses with adaptive compliance to maintain safe contact.\nIV\nExperiments\nWe evaluate CompliantVLA-adaptor on a suite of contact-rich manipulation tasks, such as object insertion and contact-sensitive pick-and-place.\nWe compare our approach against the SOTA VLA models, which rely on position control without force adaptation.\nIn these experiments, we aim to answer the following questions:\n(1) Does CompliantVLA-adaptor improve task success rates compared to baseline VLA models under force thresholds?\n(2) How effectively can the VLM generate context-aware impedance parameters for contact force regulation?\nIV-A\nSimulation tasks\nAll simulations are conducted in the same environment as the baselines to ensure fair comparison.\nTo show the effectiveness of our CompliantVLA-adaptor, we compare our approach against three VLA models: Pi0\n[\n6\n]\n, RDT-1B\n[\n18\n]\n, and OpenVLA-oft\n[\n12\n]\n.\nFocusing on contact-rich tasks, we selected 8 representative tasks from the LIBERO\n[\n17\n]\nand ManiSkill benchmarks\n[\n24\n]\n. All experiments were performed on 4 NVIDIA RTX A6000 GPUs.\nTask descriptions:\nTo comprehensively evaluate CompliantVLA-adaptor, we use eight representative contact-rich tasks from established benchmarks, instead of the full set of 100+ tasks, to avoid redundancy and resource constraints.\nTable\nI\nsummarizes the task descriptions, including precision insertion, shape sorting, drawer opening/closing, and object placement in constrained environments shown in Fig.\n3\n.\nThese tasks are chosen to evaluate the CompliantVLA-adaptorâ€™s ability to handle complex contact dynamics that require both semantic understanding and safe physical interaction.\nBaseline models:\nTo diversely evaluate the effectiveness, we select three leading VLA models which are different architectures and training paradigms:\nPi0\n[\n6\n]\nuses flow matching for action generation;\nRDT-1B\n[\n18\n]\n, the largest diffusion-based foundation model for robotic manipulation;\nand\nOpenVLA-oft\n[\n12\n]\n, an Optimized Fine-Tuning (OFT) variant of OpenVLA.\nFigure 3\n:\nContact-rich tasks in simulation.\nTABLE I\n:\nList of tasks in simulation\nTask No.\nDescriptions\nTask 1\n(\nPeg Insertion\n) Pick up a orange-white peg and insert the\norange end into the box with a hole in it\nTask 2\n(\nPlug Charger\n) Pick up one of the misplaced shapes on the\nboard/kit and insert it into the correct empty slot\nTask 3\n(\nDrawer Env\n) pick up the black bowl in the top drawer of\nthe wooden cabinet and place it on the plate\nTask 4\n(\nOpen Drawer\n) open the middle drawer of the cabinet\nTask 5\n(\nOpen Drawer\n) open the top drawer and put the bowl inside\nTask 6\n(\nPush Plate\n) push the plate to the front of the stove\nTask 7\n(\nClose Drawer\n) put the black bowl in the bottom drawer of\nthe cabinet and close it\nTask 8\n(\nMicrowave Env\n) put the yellow and white mug in the\nmicrowave and close it\nExperiment protocol:\nWe adopt a two-stage evaluation protocol to isolate the contribution of CompliantVLA-adaptor under the same contact force safe constraint for each stage, see Sec.\nIV-B\n:\n(1), performance of baseline VLA model and (2) augmented operation with our VLM-enhanced VIC controller.\nStage 1 - Baseline VLA Performance:\nWe evaluate each baseline VLA model using its default control strategy.\nSince all three models employ position- or trajectory-based control without explicit force feedback, there is no compliance adaptation during contact.\nTherefore, we set a strict force threshold of 30N to ensure safety during execution. A task is terminated after three consecutive threshold violations or if not completed within the time limit (see Sec.\nIV-B\n).\nStage 2 - CompliantVLA-adaptor Integration:\nWe augment each baseline VLA model with the proposed CompliantVLA-adaptor,\nreplacing its low-level controllers with our VLM-enhanced VIC controller\nfor compliant execution. In the meantime, we keep the same force check criteria for fair comparison (see Sec.\nIV-B\n).\nIV-B\nContact force measurement and safety criteria\nContact forces are measured using a simulated wrist-mounted force/torque sensor. The sensor provides real-time feedback on interaction forces during task execution.\nSafety criteria are defined based on task requirements, with force thresholds set to prevent excessive contact that could damage objects or the robot. For all selected contact-sensitive tasks, the force threshold is set to 30N.\nDuring each task execution, we monitor force violations across all dimensions (\nF\nx\n,\nF\ny\n,\nF\nz\nF_{x},F_{y},F_{z}\n). The critical 30N threshold is based on typical safe interaction forces.\nIf the contact force exceeds this threshold three times consecutively (to filter out transient spikes due to sensor noise)\nduring a single trial, the task is immediately terminated and marked as failed to prevent potential damage.\nIV-C\nContact force regulation by CompliantVLA-adaptor\nWe further evaluate the effectiveness of our VLM-based impedance parameter generation for regulating contact forces in contact-rich manipulation tasks.\nAlthough force is continuously monitored during the whole task execution, impedance parameters are updated by querying the VLM every two action steps (\nâ‰ˆ\n{\\approx}\n0.5s), balancing responsiveness with computational load.\nWe also log the contact force profiles with suggested impedance parameters during task execution for further training datasets for the community.\nIV-D\nReal-world experiments\nOur experiment setup consists of a 7-DoF Franka Emika Panda robot arm with a Franka Panda parallel gripper. The same hardware is used in all real-world experiments to ensure consistency.\nThe robot operates in a workspace with diverse objects for contact-rich manipulation tasks (see Tab.\nII\n).\nTo facilitate efficient visual perception, real-time control and model inference, we designed and implemented a dual-machine system: the client (Ubuntu 22.04 with real-time kernel) handles data acquisition and low-level control, while the server (NVIDIA RTX A6000, 48GB VRAM) hosts the VLA model.\nFor the system architecture, considering the complexity of deploying ROS on the server side, we opted for the more lightweight and flexible WebSocket protocol for communication. The client collects proprioceptive states and camera images from the robot. This data is then packaged and sent to the remote server, where VLA model is deployed.\nUpon receiving the data, the server performs inference to generate actions. To ensure smooth and stable robot control, we apply an action interpolation algorithm to the returned action sequence, generating dense intermediate commands.\nFinally, these interpolated commands are sent to the low-level controller for execution.\nIV-D\n1\nVisual perception\nFor visual perception hardware, we employed a dual-camera configuration to capture comprehensive scene information. A Logitech USB camera serves as the main camera, providing a global view of the robot arm and the workspace.\nAn Intel RealSense D435i depth camera functions as the wrist camera, mounted on the end-effector of the Franka Emika Panda arm using an open-source, 3D-printed fixture,\noffering an ego-centric view. To meet the VLAâ€™s input requirements, images from both cameras are uniformly resized to\n224\nÃ—\n224\n224\\times 224\npixels before being fed into the model.\nV\nResults\nThrough comprehensive simulation and real-world experiments, we demonstrate the effectiveness of the proposed CompliantVLA-adaptor that enhances the safety in contact-rich tasks compared to state-of-the-art VLA baselines,\nespecially in scenarios requiring fine force modulation and compliance adaptation.\nUnder the constraint of the contact-force threshold, the proposed approach achieves higher task success rates and reduces force violations, enabling safer and more effective manipulation in contact-rich environments.\nThe adaptive impedance parameters generated by the physical context-informed VLM enable the robot to adjust its interactions based on the task phase, thereby improving compliance and robustness in physical interactions.\nV-A\nSimulation results\nWe present quantitative results from our simulation tasks shown in Fig.\n4\n, comparing the performance of our CompliantVLA-adaptor with the SOTA VLA baselines.\nThe results show that our approach achieves significantly higher task success rates and reduces force violations across most of the contact-rich manipulation tasks (7/8).\nThe adaptive impedance parameters enable the robot to maintain safe interactions while effectively completing the tasks.\nFig.\n4\npresents a comprehensive comparison between the baseline VLA models and our CompliantVLA-adaptor approach.\nThe title of each bar diagram indicates different setups, where â€œTâ€ with a value denotes task number (see its description in Tab.\nI\n),\nand the suffix â€œ-Râ€, â€œ-Pâ€ and â€œ-Oâ€ means using RDT\n[\n18\n]\n, Pi0\n[\n6\n]\nand OpenVLA-oft\n[\n12\n]\nmodel, respectively.\nDifferent colors indicate the run with or without our CompliantVLA-adaptor.\nThe y-axis indicates the task success rates under the contact force threshold of 30N.\nThe results show that the baseline VLA models exhibit highly unstable performance across the task suite, even worse 0% in some tasks.\nOur CompliantVLA-adaptor improves performance across most tasks, demonstrating its effectiveness.\nNote that the baseline VLA models exhibit highly unstable performance across the task suite, with a maximum success rate of only 54% and some tasks always failed if considering contact force during execution.\nThis shows the different performance if considering the force threshold or not, compared to the original papers.\nAfter integrating the CompliantVLA-adaptor into these VLA models, most of the evaluated tasks showed consistent improvements while staying safe, with a maximum success rate of only 76% and significant improvement among tasks that always failed in baselines.\nThe average success rate across all tasks increases from 9.86% to 17.29%,\nthis aggregate improvement, while substantial, varies significantly across task categories.\nTasks involving mechanical constraints (drawers, stove knobs) show the most dramatic relative improvements, as these scenarios particularly benefit from the adaptive compliance provided by our VLM-guided impedance control.\nConversely, tasks with higher baseline performance, such as simple pick-and-place operations, show more modest but still meaningful improvements, primarily through enhanced force safety during object grasping and release phases.\nThese results validate our hypothesis that augmenting state-of-the-art VLA models with semantic-aware compliant control can bridge the gap between high-level task understanding and low-level force-safe execution.\nFigure 4\n:\nEvaluation results of task success rates under contact force constraint across 8 related tasks in simulation.\nTitle of each bar diagram indicates a different setup, where â€œTâ€ with a value denotes task number, see its description in Tab.\nI\n,\nand the suffix â€œ-Râ€, â€œ-Pâ€ and â€œ-Oâ€ means using RDT, Pi0 and OpenVLA-oft model, respectively.\ndifferent colors indicate the run with and without our CompliantVLA-adaptor.\nThe y-axis indicates the task success rates under the contact force threshold of 30N.\nThe results show that the baseline VLA models exhibit highly unstable performance across the task suite, even worse 0% in some tasks.\nOur CompliantVLA-adaptor improves performance across most tasks, demonstrating its effectiveness.\nIn terms of failure cases, baseline VLA models frequently encounter force violations leading to task termination, particularly in\n[\n18\n]\nplug charger task (Task2 in Tab.\nI\n)\nand both\n[\n6\n]\nand\n[\n12\n]\nin drawer manipulation tasks (Task3 Â  5 in Tab.\nI\n) and\n[\n12\n]\nin push task(Task6 in Tab.\nI\n).\nIn contrast, our CompliantVLA-adaptor significantly reduces these violations by dynamically adjusting impedance parameters based on real-time force feedback and task context.\nThis adaptive behavior allows the robot to navigate contact-rich environments more safely and effectively, ultimately leading to higher task success rates.\nV-B\nReal-world experiment results\nWe test the method in a set of real-world tasks. See Table\nII\nfor the list of tasks and instructions.\nAs tested, the original output of VLA models (OpenVLA-oft and Pi0) is hard to work in the real world due to the reality gap and lack of zero-shot capability.\nThe robot often fails to reach the target object or the target position due to the model-mismatch challenge.\nNevertheless, we successfully completed the â€œ\nkeep pushing the red box straight ahead\nâ€ task which simplified the complexity by avoiding precise grasp but showcasing the physical contact scenario. See Fig.\n5\nfor the snapshots of the task execution and force/stiffness profiles during the task.\nTo achieve this behavior, we adopted a few strategies:\n1.\nWe only use the first two actions from the VLA models action chunk to avoid the compounding error.\n2.\nWe clip the output action of the VLA models into a smaller range to keep stable control.\nHowever, due to the drawbacks of the original VLA mentioned above, most of the tasks failed even though tested among different checkpoints of OpenVLA-oft and Pi0. See them in videos attached.\nWe reached the conclusion that fine-tuning is needed for the current VLA models when deployed to the real world in future work, especially for force-sensitive tasks and precise manipulation.\nAlthough real-world success was limited due to current VLA maturity, the adaptor consistently reduced unsafe forces, demonstrating its potential as a safety module.\nTABLE II\n:\nReal-world experiment evaluations\nReal-world exp.\nTask instructions\nreal task 1\nkeep pushing the red box straight ahead\nreal task 2\npick up the green bowl on the black table\nreal task 3\nclose the middle drawer\nreal task 4\npick up the black bowl and place it to red box\nreal task 4\npick up the tomato sauce and place it to red box\nreal task 5\npick up the moka pots and place it to red box\nreal task 6\npick up the book and place it in the drawer\nFigure 5\n:\nReal-world experiment evaluation: Stiffness regulation and measured force during the pushing task.\nVI\nDiscussion and Limitations\nWe discuss the limitations of our current approach and potential avenues for future work.\nWhile our CompliantVLA-adaptor demonstrates significant improvements in safe contact-rich manipulation, several limitations remain:\n1.\nVLMs cannot match the high-frequency low-level control time requirements. While current VLMs introduce latency, ongoing advances in lightweight onboard VLMs promise real-time feasibility.\n2.\nusing the API calls is expensive and not eco-friendly. On the other hand, using onboard VLM is computationally heavy.\n3.\nVLMs are not trained for robotics tasks, so they may not generate optimal impedance parameters for specific manipulation scenarios.\n4.\nVLMs may not generalize well to unseen objects or environments, leading to suboptimal performance in novel situations.\nVII\nConclusion\nIn this work, we propose a CompliantVLA-adaptor that leverages physical context-informed VLMs with VIC to enhance the performance of VLA in safe and effective manipulation in contact-rich tasks.\nBy leveraging the semantic grounding of VLMs and the physical robustness of VIC, we enable robots to adapt their impedance parameters based on task context derived from visual and language inputs.\nOur experimental results validate the effectiveness of the proposed approach in both simulation and real-world experiments, achieving higher task success rates and reducing force violations.\nThis adaptor provides a lightweight, plug-and-play safety layer for existing VLA models, offering a practical step toward safe and generalizable contact-rich manipulation, bridging high-level semantic reasoning and low-level compliant control, enabling safer manipulation for VLA models in contact-rich environments.\nVIII\nAcknowledgments\nWe used ChatGPT (OpenAI, GPT-5) to aid literature searches and minor grammar/style edits. All content was reviewed and revised by the authors, and the final manuscript is entirely our own work.\nReferences\n[1]\nA. Ajoudani, A. M. Zanchettin, S. Ivaldi, A. Albu-SchÃ¤ffer, K. Kosuge, and O. Khatib\n(2018)\nProgress and prospects of the humanâ€“robot collaboration\n.\nAutonomous robots\n42\n(\n5\n),\npp.Â 957â€“975\n.\nCited by:\nÂ§I\n,\nÂ§\nII-B\n.\n[2]\nH. B. Amor, L. Graesser, A. Iscen, D. Dâ€™Ambrosio, S. Abeyruwan, A. Bewley, Y. Zhou, K. Kalirathinam, S. Mishra, and P. Sanketi\n(2025)\nSAS-prompt: large language models as numerical optimizers for robot self-improvement\n.\narXiv preprint arXiv:2504.20459\n.\nCited by:\nÂ§I\n.\n[3]\nA. S. Anand, R. Kaushik, J. T. Gravdahl, and F. J. Abu-Dakka\n(2024)\nData-efficient reinforcement learning for variable impedance control\n.\nIEEE Access\n12\n(\n),\npp.Â 15631â€“15641\n.\nExternal Links:\nDocument\nCited by:\nÂ§\nII-B\n.\n[4]\nF. Batool, M. Zafar, Y. Yaqoot, R. A. Khan, M. H. Khan, A. Fedoseev, and D. Tsetserukou\n(2025)\nImpedanceGPT: vlm-driven impedance control of swarm of mini-drones for intelligent navigation in dynamic environment\n.\narXiv preprint arXiv:2503.02723\n.\nCited by:\nÂ§\nII-C\n.\n[5]\nJ. Bi, K. Y. Ma, C. Hao, M. Z. Shou, and H. Soh\n(2025)\nVla-touch: enhancing vision-language-action models with dual-level tactile feedback\n.\narXiv preprint arXiv:2507.17294\n.\nCited by:\nÂ§\nII-C\n.\n[6]\nK. Black, N. Brown, D. Driess, A. Esmail, M. Equi, C. Finn, N. Fusai, L. Groom, K. Hausman, B. Ichter,\net al.\n(2024)\n\\pi_0 : a vision-language-action flow model for general robot control\n.\narXiv preprint arXiv:2410.24164\n.\nCited by:\nÂ§I\n,\nÂ§\nII-A\n,\nÂ§\nIV-A\n,\nÂ§\nIV-A\n,\nÂ§\nV-A\n,\nÂ§\nV-A\n.\n[7]\nJ. Buchli, F. Stulp, E. Theodorou, and S. Schaal\n(2011)\nLearning variable impedance control\n.\nThe International Journal of Robotics Research\n30\n(\n7\n),\npp.Â 820â€“833\n.\nCited by:\nÂ§\nII-B\n.\n[8]\nZ. Hou, W. Yang, R. Chen, P. Feng, and J. Xu\n(2023)\nA hierarchical compliance-based contextual policy search for robotic manipulation tasks with multiple objectives\n.\nIEEE Transactions on Industrial Informatics\n19\n(\n4\n),\npp.Â 5444â€“5455\n.\nExternal Links:\nDocument\nCited by:\nÂ§\nII-B\n.\n[9]\nP. Intelligence, K. Black, N. Brown, J. Darpinian, K. Dhabalia, D. Driess, A. Esmail, M. Equi, C. Finn, N. Fusai,\net al.\n(2025)\n\\pi_ {0.5} : a vision-language-action model with open-world generalization\n.\narXiv preprint arXiv:2504.16054\n.\nCited by:\nÂ§I\n,\nÂ§\nII-A\n.\n[10]\nH. H. Jekel, A. D. Rosales, and L. Peternel\n(2025)\nVisio-verbal teleimpedance interface: enabling semi-autonomous control of physical interaction via eye tracking and speech\n.\narXiv preprint arXiv:2508.20037\n.\nCited by:\nÂ§I\n,\nÂ§\nII-C\n.\n[11]\nK. Kawaharazuka, J. Oh, J. Yamada, I. Posner, and Y. Zhu\n(2025)\nVision-language-action models for robotics: a review towards real-world applications\n.\nAuthorea Preprints\n.\nCited by:\nÂ§I\n.\n[12]\nM. J. Kim, C. Finn, and P. Liang\n(2025)\nFine-tuning vision-language-action models: optimizing speed and success\n.\narXiv preprint arXiv:2502.19645\n.\nCited by:\nÂ§I\n,\nÂ§\nII-A\n,\nÂ§\nIV-A\n,\nÂ§\nIV-A\n,\nÂ§\nV-A\n,\nÂ§\nV-A\n.\n[13]\nM. J. Kim, K. Pertsch, S. Karamcheti, T. Xiao, A. Balakrishna, S. Nair, R. Rafailov, E. Foster, G. Lam, P. Sanketi,\net al.\n(2024)\nOpenvla: an open-source vision-language-action model\n.\narXiv preprint arXiv:2406.09246\n.\nCited by:\nÂ§I\n,\nÂ§\nII-A\n.\n[14]\nH. Li, S. Zhang, and D. Guo\n(2025)\nRoboCleaner: robotic tabletop cleaning via vlm-powered multi-agent collaboration\n.\nIEEE Transactions on Automation Science and Engineering\n(\n),\npp.Â 1â€“1\n.\nExternal Links:\nDocument\nCited by:\nÂ§\nII-C\n.\n[15]\nJ. Li, G. Li, Z. Chen, and J. Li\n(2022)\nA novel emg-based variable impedance control method for a tele-operation system under an unstructured environment\n.\nIEEE Access\n10\n(\n),\npp.Â 89509â€“89518\n.\nExternal Links:\nDocument\nCited by:\nÂ§\nII-B\n.\n[16]\nZ. Liao and Y. Wang\n(2024)\nTrust-based variable impedance control of humanâ€“robot cooperative manipulation\n.\nRobotics and Computer-Integrated Manufacturing\n88\n,\npp.Â 102730\n.\nExternal Links:\nISSN 0736-5845\n,\nDocument\nCited by:\nÂ§\nII-B\n.\n[17]\nB. Liu, Y. Zhu, C. Gao, Y. Feng, Q. Liu, Y. Zhu, and P. Stone\n(2023)\nLibero: benchmarking knowledge transfer for lifelong robot learning\n.\nAdvances in Neural Information Processing Systems\n36\n,\npp.Â 44776â€“44791\n.\nCited by:\nÂ§\nIV-A\n.\n[18]\nS. Liu, L. Wu, B. Li, H. Tan, H. Chen, Z. Wang, K. Xu, H. Su, and J. Zhu\n(2024)\nRdt-1b: a diffusion foundation model for bimanual manipulation\n.\narXiv preprint arXiv:2410.07864\n.\nCited by:\nÂ§I\n,\nÂ§\nII-A\n,\nÂ§\nIV-A\n,\nÂ§\nIV-A\n,\nÂ§\nV-A\n,\nÂ§\nV-A\n.\n[19]\nY. J. Ma, J. Hejna, C. Fu, D. Shah, J. Liang, Z. Xu, S. Kirmani, P. Xu, D. Driess, T. Xiao,\net al.\n(2024)\nVision language models are in-context value learners\n.\nIn\nThe Thirteenth International Conference on Learning Representations\n,\nCited by:\nÂ§I\n.\n[20]\nY. Ma, Z. Song, Y. Zhuang, J. Hao, and I. King\n(2024)\nA survey on vision-language-action models for embodied ai\n.\narXiv preprint arXiv:2405.14093\n.\nCited by:\nÂ§I\n.\n[21]\nR. MartÃ­n-MartÃ­n, M. A. Lee, R. Gardner, S. Savarese, J. Bohg, and A. Garg\n(2019)\nVariable impedance control in end-effector space: an action space for reinforcement learning in contact-rich tasks\n.\nIn\n2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\n,\nVol.\n,\npp.Â 1010â€“1017\n.\nExternal Links:\nDocument\nCited by:\nÂ§I\n,\nÂ§\nII-B\n,\nÂ§\nII-B\n.\n[22]\nA. Oâ€™Neill, A. Rehman, A. Maddukuri, A. Gupta, A. Padalkar, A. Lee, A. Pooley, A. Gupta, A. Mandlekar, A. Jain,\net al.\n(2024)\nOpen x-embodiment: robotic learning datasets and rt-x models: open x-embodiment collaboration 0\n.\nIn\n2024 IEEE International Conference on Robotics and Automation (ICRA)\n,\npp.Â 6892â€“6903\n.\nCited by:\nÂ§I\n.\n[23]\nC. Y. Park, J. Fisher, M. Memmel, D. Khullar, A. Yun, A. Gupta, and Y. Choi\n(2025)\nMaking vlms more robot-friendly: self-critical distillation of low-level procedural reasoning\n.\narXiv preprint arXiv:2507.08224\n.\nCited by:\nÂ§I\n.\n[24]\nS. Tao, F. Xiang, A. Shukla, Y. Qin, X. Hinrichsen, X. Yuan, C. Bao, X. Lin, Y. Liu, T. Chan,\net al.\n(2024)\nManiskill3: gpu parallelized robotics simulation and rendering for generalizable embodied ai\n.\narXiv preprint arXiv:2410.00425\n.\nCited by:\nÂ§\nIV-A\n.\n[25]\nT. Tsuji, Y. Kato, G. Solak, H. Zhang, T. PetriÄ, F. Nori, and A. Ajoudani\n(2025)\nA survey on imitation learning for contact-rich tasks in robotics\n.\narXiv preprint arXiv:2506.13498\n.\nCited by:\nÂ§I\n.\n[26]\nJ. Wen, Y. Zhu, M. Zhu, Z. Tang, J. Li, Z. Zhou, X. Liu, C. Shen, Y. Peng, and F. Feng\n(2025)\nDiffusionVLA: scaling robot foundation models via unified diffusion and autoregression\n.\nIn\nForty-second International Conference on Machine Learning\n,\nCited by:\nÂ§I\n,\nÂ§\nII-A\n.\n[27]\nR. Wu, H. Zhang, Y. Zhu, X. Zang, and J. Zhao\n(2023)\nImpedance adjustment for learning human variable impedance skill\n.\nMechatronics\n95\n,\npp.Â 103036\n.\nCited by:\nÂ§\nII-B\n.\n[28]\nY. Wu, F. Zhao, T. Tao, and A. Ajoudani\n(2021)\nA framework for autonomous impedance regulation of robots based on imitation learning and optimal control\n.\nIEEE Robotics and Automation Letters\n6\n(\n1\n),\npp.Â 127â€“134\n.\nExternal Links:\nDocument\nCited by:\nÂ§I\n,\nÂ§\nII-B\n.\n[29]\nC. Yang, G. Ganesh, S. Haddadin, S. Parusel, A. Albu-Schaeffer, and E. Burdet\n(2011)\nHuman-like adaptation of force and impedance in stable and unstable interactions\n.\nIEEE transactions on robotics\n27\n(\n5\n),\npp.Â 918â€“930\n.\nCited by:\nÂ§\nII-B\n.\n[30]\nS. Yang, H. Li, Y. Chen, B. Wang, Y. Tian, T. Wang, H. Wang, F. Zhao, Y. Liao, and J. Pang\n(2025)\nInstructVLA: vision-language-action instruction tuning from understanding to manipulation\n.\narXiv preprint arXiv:2507.17520\n.\nCited by:\nÂ§\nII-A\n.\n[31]\nH. Zhang, R. Dai, G. Solak, P. Zhou, Y. She, and A. Ajoudani\n(2025)\nSafe learning for contact-rich robot tasks: a survey from classical learning-based methods to safe foundation models\n.\narXiv preprint arXiv:2512.11908\n.\nCited by:\nÂ§I\n.\n[32]\nH. Zhang, G. Solak, G. J. G. Lahr, and A. Ajoudani\n(2024)\nSRL-vic: a variable stiffness-based safe reinforcement learning for contact-rich robotic tasks\n.\nIEEE Robotics and Automation Letters\n9\n(\n6\n),\npp.Â 5631â€“5638\n.\nExternal Links:\nDocument\nCited by:\nÂ§I\n,\nÂ§\nII-B\n,\nÂ§\nII-B\n.\n[33]\nZ. Zhang, H. Xu, Z. Yang, C. Yue, Z. Lin, H. Gao, Z. Wang, and H. Zhao\n(2025)\nTA-vla: elucidating the design space of torque-aware vision-language-action models\n.\narXiv preprint arXiv:2509.07962\n.\nCited by:\nÂ§I\n.\n[34]\nY. Zhong, F. Bai, S. Cai, X. Huang, Z. Chen, X. Zhang, Y. Wang, S. Guo, T. Guan, K. N. Lui,\net al.\n(2025)\nA survey on vision-language-action models: an action tokenization perspective\n.\narXiv preprint arXiv:2507.01925\n.\nCited by:\nÂ§I\n.\n[35]\nZ. Zhou, S. Veeramani, H. Fakhruldeen, S. Uyanik, and A. I. Cooper\n(2025)\nGenCo: a dual vlm generate-correct framework for adaptive peg-in-hole robotics\n.\nIn\n2025 IEEE International Conference on Robotics and Automation (ICRA)\n,\nVol.\n,\npp.Â 16744â€“16751\n.\nExternal Links:\nDocument\nCited by:\nÂ§\nII-C\n.",
    "preview_text": "We propose a CompliantVLA-adaptor that augments the state-of-the-art Vision-Language-Action (VLA) models with vision-language model (VLM)-informed context-aware variable impedance control (VIC) to improve the safety and effectiveness of contact-rich robotic manipulation tasks. Existing VLA systems (e.g., RDT, Pi0, OpenVLA-oft) typically output position, but lack force-aware adaptation, leading to unsafe or failed interactions in physical tasks involving contact, compliance, or uncertainty. In the proposed CompliantVLA-adaptor, a VLM interprets task context from images and natural language to adapt the stiffness and damping parameters of a VIC controller. These parameters are further regulated using real-time force/torque feedback to ensure interaction forces remain within safe thresholds. We demonstrate that our method outperforms the VLA baselines on a suite of complex contact-rich tasks, both in simulation and on real hardware, with improved success rates and reduced force violations. The overall success rate across all tasks increases from 9.86\\% to 17.29\\%, presenting a promising path towards safe contact-rich manipulation using VLAs. We release our code, prompts, and force-torque-impedance-scenario context datasets at https://sites.google.com/view/compliantvla.\n\nCompliantVLA-adaptor: VLM-Guided Variable Impedance Action for Safe Contact-Rich Manipulation\nHeng Zhang*\n1,2\n, Wei-Hsing Huang*\n3\n, Qiyi Tong\n1,2\n, Gokhan Solak\n1\n, Puze Liu\n4\n, Sheng Liu\n6\n,\nJan Peters\n4,5\n, Arash Ajoudani\n1\nAbstract\nWe propose a CompliantVLA-adaptor that augments the state-of-the-art Vision-Language-Action (VLA) models with vision-language model (VLM)-informed context-aware variable impedance control (VIC) to improve the safety and effectiveness of contact-rich robotic manipulation tasks.\nExisting VLA systems (e.g., RDT, Pi0, OpenVLA-oft) typically output position, but lack force-aware adaptation, leading to unsafe or failed interactions in physical tasks involving contact, complianc",
    "is_relevant": true,
    "relevance_score": 8.0,
    "extracted_keywords": [
        "VLA",
        "VLM",
        "whole body control"
    ],
    "one_line_summary": "è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§ç»“åˆè§†è§‰è¯­è¨€æ¨¡å‹å’Œå¯å˜é˜»æŠ—æ§åˆ¶çš„é€‚é…å™¨ï¼Œä»¥å¢å¼ºVLAæ¨¡å‹åœ¨æ¥è§¦ä¸°å¯Œæœºå™¨äººæ“ä½œä»»åŠ¡ä¸­çš„å®‰å…¨æ€§å’Œæœ‰æ•ˆæ€§ã€‚",
    "detailed_summary": "## è®ºæ–‡æ‘˜è¦ï¼šCompliantVLA-adaptor: VLM-Guided Variable Impedance Action for Safe Contact-Rich Manipulation\n\n### 1. ç ”ç©¶èƒŒæ™¯å’ŒåŠ¨æœº\nè¿‘å¹´æ¥ï¼Œè§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹åœ¨æœºå™¨äººæ“æ§ä»»åŠ¡ä¸­å±•ç°å‡ºå¼ºå¤§çš„è¯­ä¹‰ç†è§£å’Œæ³›åŒ–èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç°æœ‰VLAæ¨¡å‹ï¼ˆå¦‚RDTã€Pi0ã€OpenVLA-oftï¼‰é€šå¸¸ä»…è¾“å‡ºä½ç½®æŒ‡ä»¤ï¼Œç¼ºä¹å¯¹ç‰©ç†äº¤äº’ä¸­**åŠ›æ„ŸçŸ¥å’Œé¡ºåº”æ€§**çš„è€ƒè™‘ã€‚åœ¨æ‰§è¡Œæ¶‰åŠæ¥è§¦ã€é¡ºåº”æ€§æˆ–ç¯å¢ƒä¸ç¡®å®šæ€§çš„ä»»åŠ¡æ—¶ï¼Œè¿™ç§åˆšæ€§æ§åˆ¶æ¨¡å¼å®¹æ˜“å¯¼è‡´**åŠ›è¶…é™ã€ä»»åŠ¡å¤±è´¥ç”šè‡³å®‰å…¨é—®é¢˜**ï¼Œä¸¥é‡é™åˆ¶äº†VLAæ¨¡å‹åœ¨çœŸå®æ¥è§¦å¼æ“ä½œåœºæ™¯ä¸­çš„å®‰å…¨éƒ¨ç½²ã€‚\n\n### 2. æ ¸å¿ƒæ–¹æ³•å’ŒæŠ€æœ¯åˆ›æ–°\næœ¬æ–‡æå‡ºäº† **CompliantVLA-adaptor**ï¼Œä¸€ä¸ªå³æ’å³ç”¨çš„é€‚é…å™¨æ¨¡å—ï¼Œæ—¨åœ¨ä¸ºç°æœ‰VLAæ¨¡å‹èµ‹äºˆå®‰å…¨ã€é¡ºåº”æ€§çš„ç‰©ç†äº¤äº’èƒ½åŠ›ã€‚å…¶æ ¸å¿ƒæŠ€æœ¯åˆ›æ–°åœ¨äºï¼š\n- **VLMå¼•å¯¼çš„å˜é˜»æŠ—æ§åˆ¶**ï¼šåˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹åˆ†æå›¾åƒã€è¯­è¨€æŒ‡ä»¤å’Œå®æ—¶åŠ›/åŠ›çŸ©åé¦ˆï¼Œ**åŠ¨æ€ç”Ÿæˆ**ä¸ä»»åŠ¡ä¸Šä¸‹æ–‡ï¼ˆå¦‚â€œè‡ªç”±è¿åŠ¨â€ã€â€œæ¥è§¦â€ã€â€œæ’¤ç¦»â€ç­‰é˜¶æ®µï¼‰ç›¸é€‚åº”çš„åˆšåº¦å’Œé˜»å°¼å‚æ•°ã€‚\n- **æ··åˆæ§åˆ¶æ¶æ„**ï¼šæ„å»ºäº†ä¸€ä¸ªä¸‰å±‚æ—¶åºæ¶æ„ï¼Œå°†VLMçš„è¯­ä¹‰æ¨ç†ï¼ˆ~1 Hzï¼‰ã€VLAçš„åŠ¨ä½œç”Ÿæˆï¼ˆ~3 Hzï¼‰ä¸åº•å±‚çš„é«˜é¢‘å˜é˜»æŠ—æ§åˆ¶å™¨ï¼ˆ1000 Hzï¼‰æ— ç¼é›†æˆã€‚\n- **åŒé‡å®‰å…¨å±‚**ï¼šç»“åˆäº†åŸºäºVLMè¯­ä¹‰çš„é˜»æŠ—å‚æ•°ç”Ÿæˆå’ŒåŸºäºå®æ—¶åŠ›åé¦ˆçš„**ååº”å¼è°ƒèŠ‚**ï¼ˆå¦‚é€šè¿‡ç¼©æ”¾å› å­ `Î±_force` é™ä½åˆšåº¦ï¼‰ï¼Œç¡®ä¿äº¤äº’åŠ›å§‹ç»ˆä¿æŒåœ¨å®‰å…¨é˜ˆå€¼å†…ã€‚\n\n### 3. ä¸»è¦å®éªŒç»“æœ\nåœ¨ä»¿çœŸå’ŒçœŸå®ç¡¬ä»¶ä¸Šçš„å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼š\n- **ä»¿çœŸä»»åŠ¡**ï¼šåœ¨8ä¸ªå¤æ‚çš„æ¥è§¦å¼æ“ä½œä»»åŠ¡ï¼ˆå¦‚æ’é”€æ’å…¥ã€å¼€å…³æŠ½å±‰ï¼‰ä¸Šï¼Œä¸å¤šä¸ªSOTA VLAåŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼Œ**CompliantVLA-adaptorå°†æ•´ä½“ä»»åŠ¡æˆåŠŸç‡ä»9.86%æå‡è‡³17.29%**ï¼Œå¹¶æ˜¾è‘—å‡å°‘äº†åŠ›è¿è§„æ¬¡æ•°ã€‚\n- **å¤±è´¥æ¨¡å¼è½¬å˜**ï¼šåŸºçº¿VLAå¸¸å› åŠ›è¶…é™å¯¼è‡´ç¾éš¾æ€§å¤±è´¥ï¼Œè€Œæœ¬æ–¹æ³•å®ç°äº†â€œä¼˜é›…é™çº§â€ï¼Œå¤±è´¥å¤šæºäºè½»å¾®é”™ä½è€Œéä¸å®‰å…¨åŠ›ã€‚\n- **çœŸå®ä¸–ç•ŒéªŒè¯**ï¼šå°½ç®¡å½“å‰VLAæ¨¡å‹å­˜åœ¨â€œç°å®å·®è·â€ï¼Œä½†é€‚é…å™¨åœ¨æ¨åŠ¨ç­‰ä»»åŠ¡ä¸­æœ‰æ•ˆå±•ç¤ºäº†**åŠ›è°ƒèŠ‚ä¸åˆšåº¦è‡ªé€‚åº”**çš„èƒ½åŠ›ï¼Œè¯æ˜äº†å…¶ä½œä¸ºå®‰å…¨å±‚çš„æ½œåŠ›ã€‚\n\n### 4. ç ”ç©¶æ„ä¹‰å’Œä»·å€¼\næœ¬å·¥ä½œä¸ºVLAæ¨¡å‹å®‰å…¨åº”ç”¨äºæ¥è§¦å¼æ“ä½œæä¾›äº†ä¸€æ¡åˆ‡å®å¯è¡Œçš„è·¯å¾„ã€‚å…¶ä»·å€¼åœ¨äºï¼š\n- **æ¡¥æ¢é¸¿æ²Ÿ**ï¼šåœ¨**é«˜å±‚è¯­ä¹‰ç†è§£**ä¸**åº•å±‚é¡ºåº”æ€§æ§åˆ¶**ä¹‹é—´å»ºç«‹äº†å…³é”®è¿æ¥ï¼Œä½¿æœºå™¨äººèƒ½æ ¹æ®ä»»åŠ¡è¯­ä¹‰â€œçŸ¥é“â€è¯¥ç”¨å¤šå¤§åŠ›ã€‚\n- **å³æ’å³ç”¨**ï¼šä½œä¸ºä¸€ç§è½»é‡çº§é€‚é…å™¨ï¼Œæ— éœ€é‡æ–°è®­ç»ƒåºå¤§çš„VLAæ¨¡å‹ï¼Œå³å¯ä¸ºå…¶å¢åŠ å…³é”®çš„å®‰å…¨ä¸é¡ºåº”æ€§èƒ½åŠ›ã€‚\n- **æ¨åŠ¨å®‰å…¨éƒ¨ç½²**ï¼šä¸ºè§£å†³VLAæ¨¡å‹åœ¨çœŸå®ç‰©ç†ä¸–ç•Œä¸­äº¤äº’çš„å®‰å…¨æ€§ç“¶é¢ˆæä¾›äº†æ¨¡å—åŒ–æ–¹æ¡ˆï¼Œæ˜¯è¿ˆå‘é€šç”¨ã€å®‰å…¨æœºå™¨äººæ“ä½œçš„é‡è¦ä¸€æ­¥ã€‚",
    "qa_pairs": [
        {
            "question": "è¿™ç¯‡è®ºæ–‡çš„æ ¸å¿ƒåˆ›æ–°ç‚¹æ˜¯ä»€ä¹ˆï¼Œä»–æƒ³è§£å†³ä»€ä¹ˆé—®é¢˜ï¼Œæ€ä¹ˆè§£å†³çš„ï¼Ÿ",
            "answer": "## è®ºæ–‡æ ¸å¿ƒåˆ†æ\n\n### **ä¸€ã€ è®ºæ–‡æ‹Ÿè§£å†³çš„æ ¸å¿ƒé—®é¢˜**\nå½“å‰ä¸»æµçš„**è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹**åœ¨æ¥è§¦ä¸°å¯Œçš„æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­å­˜åœ¨**å®‰å…¨æ€§ç¼ºé™·**ã€‚å…·ä½“è¡¨ç°ä¸ºï¼š\n- **ç¼ºä¹åŠ›æ„ŸçŸ¥ä¸é¡ºåº”æ€§æ§åˆ¶**ï¼šVLAæ¨¡å‹ï¼ˆå¦‚RDTã€Pi0ã€OpenVLA-oftï¼‰é€šå¸¸è¾“å‡º**ä½ç½®æˆ–è½¨è¿¹æŒ‡ä»¤**ï¼Œå°†æœºå™¨äººè§†ä¸ºåˆšæ€§ä½ç½®è·Ÿè¸ªç³»ç»Ÿã€‚\n- **å¯¼è‡´ä¸å®‰å…¨äº¤äº’**ï¼šåœ¨æ‰§è¡Œæ¶‰åŠç‰©ç†æ¥è§¦ã€é¡ºåº”æ€§æˆ–ç¯å¢ƒä¸ç¡®å®šæ€§çš„ä»»åŠ¡ï¼ˆå¦‚æ’å…¥USBçº¿ã€å…³é—­æŠ½å±‰ï¼‰æ—¶ï¼Œæ— æ³•æ ¹æ®æ¥è§¦åŠ›è‡ªé€‚åº”è°ƒæ•´è¡Œä¸ºï¼Œå®¹æ˜“äº§ç”Ÿ**è¿‡å¤§çš„æ¥è§¦åŠ›**ï¼Œå¯¼è‡´ä»»åŠ¡å¤±è´¥æˆ–æŸåç‰©ä½“/æœºå™¨äººè‡ªèº«ã€‚\n- **è¯­ä¹‰ç†è§£ä¸ç‰©ç†æ‰§è¡Œçš„è„±èŠ‚**ï¼šVLAæ¨¡å‹è™½å…·å¤‡é«˜å±‚æ¬¡è¯­ä¹‰ç†è§£èƒ½åŠ›ï¼Œä½†æ— æ³•å°†å…¶è½¬åŒ–ä¸ºæ‰§è¡Œå±‚é¢æ‰€éœ€çš„**ç‰©ç†é¡ºåº”æ€§**ã€‚\n\n### **äºŒã€ æ ¸å¿ƒåˆ›æ–°ç‚¹**\nè®ºæ–‡æå‡ºäº† **â€œCompliantVLA-adaptorâ€** ï¼Œè¿™æ˜¯ä¸€ä¸ª**å³æ’å³ç”¨**çš„é€‚é…å™¨æ¨¡å—ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºï¼š\n1. **VLMå¼•å¯¼çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥å˜é˜»æŠ—æ§åˆ¶**ï¼šé¦–æ¬¡å°†**è§†è§‰è¯­è¨€æ¨¡å‹**ä½œä¸ºâ€œé˜»æŠ—æ•™ç»ƒâ€ï¼Œç”¨äºç”Ÿæˆ**å˜é˜»æŠ—æ§åˆ¶**æ‰€éœ€çš„åˆšåº¦å’Œé˜»å°¼å‚æ•°ã€‚\n    - **è¾“å…¥**ï¼šè§†è§‰è§‚å¯Ÿï¼ˆå…¨å±€å’Œè…•éƒ¨å›¾åƒï¼‰ã€è‡ªç„¶è¯­è¨€æŒ‡ä»¤ã€**å®æ—¶åŠ›/åŠ›çŸ©åé¦ˆ**ã€‚\n    - **è¾“å‡º**ï¼šæ ¹æ®ä»»åŠ¡é˜¶æ®µï¼ˆè‡ªç”±è¿åŠ¨ã€æ¥è¿‘ã€æ¥è§¦ã€æ’¤å›ï¼‰å’Œåœºæ™¯è¯­ä¹‰ï¼ˆå¦‚ç‰©ä½“è„†å¼±æ€§ï¼‰è‡ªé€‚åº”ç”Ÿæˆçš„å„å‘å¼‚æ€§é˜»æŠ—å‚æ•°ã€‚\n2. **æ··åˆæ¶æ„ä¸ä¸‰å±‚å®‰å…¨æœºåˆ¶**ï¼š\n    - **é«˜å±‚è¯­ä¹‰è§„åˆ’**ï¼šä¿ç•™ç°æœ‰VLAæ¨¡å‹çš„åŠ¨ä½œç”Ÿæˆèƒ½åŠ›ã€‚\n    - **ä¸­å±‚é˜»æŠ—è°ƒèŠ‚**ï¼šVLMä»¥çº¦1Hzé¢‘ç‡æ ¹æ®å¤šæ¨¡æ€ä¸Šä¸‹æ–‡ç”Ÿæˆé˜»æŠ—å‚æ•°ã€‚\n    - **åº•å±‚å®‰å…¨æ‰§è¡Œ**ï¼šå˜é˜»æŠ—æ§åˆ¶å™¨åœ¨1000Hzä¸‹è¿è¡Œï¼Œç»“åˆå®æ—¶åŠ›åé¦ˆè¿›è¡Œå¾®è°ƒï¼ˆé€šè¿‡åŠ›ç¼©æ”¾å› å­ `Î±_force` ç¡®ä¿åŠ›åœ¨å®‰å…¨é˜ˆå€¼å†…ï¼‰ã€‚\n3. **æ¥è§¦é˜¶æ®µè¯†åˆ«**ï¼šè®¾è®¡æç¤ºè¯ï¼Œè®©VLMç»“åˆè§†è§‰ä¿¡æ¯å’ŒåŠ›ä¼ æ„Ÿå™¨è¯»æ•°ï¼Œé²æ£’åœ°è¯†åˆ«ä»»åŠ¡æ‰§è¡Œçš„**å››ä¸ªæ¥è§¦é˜¶æ®µ**ï¼Œå¹¶ä¸ºæ¯ä¸ªé˜¶æ®µè®¾å®šä¸åŒçš„é˜»æŠ—ç­–ç•¥å±‚çº§ã€‚\n\n### **ä¸‰ã€ è§£å†³æ–¹æ¡ˆæ¦‚è¿°**\nè§£å†³æ–¹æ¡ˆæ˜¯ä¸€ä¸ª**æ¨¡å—åŒ–ã€å¯æ’æ‹”çš„é€‚é…å™¨ç³»ç»Ÿ**ï¼Œå·¥ä½œæµç¨‹å¦‚ä¸‹ï¼š\n1. **VLAåŠ¨ä½œç”Ÿæˆ**ï¼šåŸºçº¿VLAæ¨¡å‹æ ¹æ®å›¾åƒå’Œè¯­è¨€æŒ‡ä»¤ç”ŸæˆæœŸæœ›çš„æœ«ç«¯æ‰§è¡Œå™¨ä½ç§»åŠ¨ä½œã€‚\n2. **VLMé˜»æŠ—å‚æ•°ç”Ÿæˆ**ï¼š\n    ```python\n    # ç®€åŒ–æµç¨‹ç¤ºæ„\n    è¾“å…¥: å›¾åƒ(I_w, I_f), æŒ‡ä»¤(T), å®æ—¶åŠ›(F)\n    æ­¥éª¤1: VLMè¯†åˆ«å½“å‰æ¥è§¦é˜¶æ®µ (Free_motion, Approaching, Contact, Retreat)\n    æ­¥éª¤2: VLMç»“åˆé˜¶æ®µã€ä»»åŠ¡æè¿°ã€åŠ›åé¦ˆï¼Œç”Ÿæˆå„å‘å¼‚æ€§åˆšåº¦K=[Kx, Ky, Kz]å’Œé˜»å°¼D\n    è¾“å‡º: ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„é˜»æŠ—å‚æ•° (K, D)\n    ```\n3. **æ··åˆæ§åˆ¶ä¸å®‰å…¨å±‚**ï¼š\n    - ç”Ÿæˆçš„é˜»æŠ—å‚æ•°è¾“å…¥**å˜é˜»æŠ—æ§åˆ¶å™¨**ã€‚\n    - æ§åˆ¶å™¨åŒæ—¶æ¥æ”¶VLAçš„æœŸæœ›ä½ç§»ï¼Œä»¥**é¡ºåº”æ€§æ–¹å¼**è·Ÿè¸ªè¯¥ä½ç§»ã€‚\n    - **å®æ—¶åŠ›åé¦ˆå®‰å…¨å±‚**ï¼šè‹¥æµ‹é‡åŠ›è¶…è¿‡é˜ˆå€¼ï¼ˆå¦‚30Nï¼‰ï¼Œåˆ™é€šè¿‡ `Î±_force` åŠ¨æ€é™ä½åˆšåº¦ï¼Œç¡®ä¿å®‰å…¨ã€‚\n\n### **å››ã€ å®é™…ä»·å€¼ä¸æŠ€æœ¯æ„ä¹‰**\n- **æå‡å®‰å…¨æ€§**ï¼šå°†ä»»åŠ¡å¹³å‡æˆåŠŸç‡ä»**9.86%æå‡è‡³17.29%**ï¼Œå¹¶æ˜¾è‘—å‡å°‘äº†åŠ›é˜ˆå€¼è¿è§„ã€‚å¤±è´¥æ¨¡å¼ä»â€œç¾éš¾æ€§åŠ›è¶…é™â€è½¬å˜ä¸ºâ€œè½»å¾®çš„é”™ä½æˆ–æ»‘åŠ¨â€ï¼Œå®ç°äº†**ä¼˜é›…é™çº§**ã€‚\n- **å¢å¼ºæ³›åŒ–èƒ½åŠ›**ï¼šåˆ©ç”¨é¢„è®­ç»ƒVLMçš„è¯­ä¹‰çŸ¥è¯†ï¼Œå®ç°äº†å¯¹**æœªè§è¿‡çš„æ¥è§¦ä¸°å¯Œä»»åŠ¡**çš„é›¶æ ·æœ¬æ³›åŒ–ï¼Œæ— éœ€é’ˆå¯¹æ¯ä¸ªä»»åŠ¡è¿›è¡Œç¹ççš„é˜»æŠ—å‚æ•°è°ƒä¼˜æˆ–æ”¶é›†ä¸“å®¶æ¼”ç¤ºã€‚\n- **å®ç”¨æ€§ä¸å¯éƒ¨ç½²æ€§**ï¼šä½œä¸ºé€‚é…å™¨ï¼Œå¯è½»æ¾ä¸ç°æœ‰SOTA VLAæ¨¡å‹ï¼ˆPi0, RDT, OpenVLA-oftï¼‰é›†æˆï¼Œä¸ºå…¶å¢åŠ ä¸€å±‚å…³é”®çš„å®‰å…¨åˆè§„æ§åˆ¶å±‚ï¼ŒåŠ é€ŸVLAæ¨¡å‹åœ¨çœŸå®ç‰©ç†ä¸–ç•Œä¸­çš„å®‰å…¨éƒ¨ç½²ã€‚\n- **è´¡çŒ®æ•°æ®é›†ä¸ä»£ç **ï¼šå¼€æºäº†**åŠ›-åŠ›çŸ©-é˜»æŠ—-åœºæ™¯ä¸Šä¸‹æ–‡æ•°æ®é›†**ï¼Œä¸ºç¤¾åŒºè¿›ä¸€æ­¥ç ”ç©¶æä¾›äº†å®è´µèµ„æºã€‚\n\n**æ€»ç»“**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒåˆ›æ–°åœ¨äº**åˆ›é€ æ€§åœ°ä½¿ç”¨VLMæ¡¥æ¥äº†é«˜å±‚è¯­ä¹‰ç†è§£ä¸ä½å±‚é¡ºåº”æ€§æ§åˆ¶**ï¼Œé€šè¿‡ä¸€ä¸ªè½»é‡çº§é€‚é…å™¨ï¼Œè§£å†³äº†å½“å‰VLAæ¨¡å‹åœ¨æ¥è§¦ä¸°å¯Œä»»åŠ¡ä¸­â€œæ™ºåŠ›â€ä¸â€œä½“åŠ›â€ä¸åŒ¹é…çš„å…³é”®å®‰å…¨é—®é¢˜ï¼Œä¸ºè¿ˆå‘å®‰å…¨ã€é€šç”¨çš„æœºå™¨äººæ“ä½œè¿ˆå‡ºäº†å®è´¨æ€§ä¸€æ­¥ã€‚",
            "timestamp": "2026-01-27T16:09:08.077710",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "åŸºäºä»–çš„å‰ä½œï¼Œæ¢³ç†è¿™ä¸ªæ–¹å‘çš„æ•´ä¸ªå‘å±•è„‰ç»œï¼Œæ¯ä¸€æ­¥ç›¸æ¯”äºä¹‹å‰çš„å·¥ä½œéƒ½æ”¹è¿›äº†ä»€ä¹ˆï¼Œç€é‡äºå‡ ä¸ªä¸åŒçš„å‘å±•æ–¹å‘ã€‚",
            "answer": "## è®ºæ–‡ã€ŠCompliantVLA-adaptorã€‹æŠ€æœ¯è„‰ç»œä¸å‘å±•æ–¹å‘æ¢³ç†\n\nåŸºäºè®ºæ–‡å†…å®¹åŠå…¶å¼•ç”¨çš„ç›¸å…³æ–‡çŒ®ï¼Œè¯¥ç ”ç©¶æ–¹å‘çš„å‘å±•è„‰ç»œå¯ä»¥æ¢³ç†ä¸ºä¸‰ä¸ªç›¸äº’äº¤ç»‡ä½†ä¾§é‡ç‚¹ä¸åŒçš„ä¸»çº¿ï¼š**1) è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹çš„å‘å±•**ã€**2) å˜é˜»æŠ—æ§åˆ¶æŠ€æœ¯çš„æ¼”è¿›**ã€**3) åˆ©ç”¨é«˜çº§è¯­ä¹‰æ¨¡å‹ï¼ˆVLMï¼‰å¢å¼ºç‰©ç†äº¤äº’çš„æ¢ç´¢**ã€‚æœ¬å·¥ä½œï¼ˆCompliantVLA-adaptorï¼‰æ˜¯è¿™ä¸‰æ¡ä¸»çº¿äº¤æ±‡çš„äº§ç‰©ã€‚\n\n### å‘å±•è„‰ç»œä¸æ ¸å¿ƒæ”¹è¿›\n\n#### ä¸»çº¿ä¸€ï¼šè§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹çš„æ¼”è¿›ï¼ˆä»è¯­ä¹‰ç†è§£åˆ°åŠ¨ä½œç”Ÿæˆï¼‰\næ­¤æ–¹å‘æ—¨åœ¨èµ‹äºˆæœºå™¨äººé€šè¿‡è‡ªç„¶è¯­è¨€æŒ‡ä»¤ç†è§£å’Œæ‰§è¡Œå¤æ‚ä»»åŠ¡çš„èƒ½åŠ›ã€‚\n\n- **æ—©æœŸ/åŸºç¡€VLAæ¨¡å‹ (å¦‚ RDT [18], Pi0 [6], OpenVLA [13])**ï¼š\n    - **æ ¸å¿ƒè´¡çŒ®**ï¼šé€šè¿‡å¤§è§„æ¨¡ã€å¤šæ ·åŒ–çš„æ•°æ®é›†è¿›è¡Œé¢„è®­ç»ƒï¼Œå­¦ä¹ ä¸°å¯Œçš„è§†è§‰å’Œè¯­è¨€è¡¨å¾ï¼Œå®ç°äº†åœ¨å¤šç§éæ¥è§¦æˆ–ç®€å•æ¥è§¦ä»»åŠ¡ä¸Šçš„**é›¶æ ·æœ¬æˆ–å°æ ·æœ¬æ³›åŒ–**ã€‚\n    - **å…³é”®å±€é™**ï¼šè¾“å‡ºä¸»è¦ä¸º**ä½ç½®æˆ–è½¨è¿¹æŒ‡ä»¤**ï¼Œåº•å±‚é‡‡ç”¨å›ºå®šçš„ä½ç½®/PDæ§åˆ¶å™¨ã€‚æœºå™¨äººè¢«è§†ä¸ºåˆšæ€§ä½ç½®è·Ÿè¸ªç³»ç»Ÿï¼Œ**å®Œå…¨ç¼ºä¹å¯¹ç‰©ç†äº¤äº’åŠ¨åŠ›å­¦ï¼ˆåŠ›/åŠ›çŸ©ï¼‰çš„æ„ŸçŸ¥å’Œé€‚åº”èƒ½åŠ›**ã€‚åœ¨æ¥è§¦ä¸°å¯Œçš„ä»»åŠ¡ä¸­ï¼Œè¿™ä¼šå¯¼è‡´åŠ›è¶…é™ã€ä»»åŠ¡å¤±è´¥æˆ–æŸåç‰©ä½“/æœºå™¨äººã€‚\n\n- **æ”¹è¿›å‹VLAæ¨¡å‹ (å¦‚ OpenVLA-oft [12], InstructVLA [30])**ï¼š\n    - **æ ¸å¿ƒæ”¹è¿›**ï¼šé€šè¿‡**ä¼˜åŒ–å¾®è°ƒ**ç­‰æŠ€æœ¯æå‡æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡é›†ä¸Šçš„æˆåŠŸç‡å’Œé€Ÿåº¦ï¼ˆOpenVLA-oftï¼‰ï¼Œæˆ–å¼•å…¥**äººç±»åé¦ˆ**æ¥ refine åŠ¨ä½œç”Ÿæˆï¼ˆInstructVLAï¼‰ã€‚\n    - **é—ç•™é—®é¢˜**ï¼šå°½ç®¡åœ¨â€œåŠ¨ä½œç”Ÿæˆâ€å±‚é¢æœ‰æ‰€ä¼˜åŒ–ï¼Œä½†**åº•å±‚æ§åˆ¶èŒƒå¼æœªå˜**ï¼Œä¾ç„¶ç¼ºä¹åŠ›æ„ŸçŸ¥å’Œé¡ºåº”æ€§æ§åˆ¶ã€‚å®‰å…¨ç‰©ç†äº¤äº’çš„æ ¹æœ¬é—®é¢˜æœªè§£å†³ã€‚\n\n- **åŠ›æ„ŸçŸ¥VLAçš„åˆæ­¥æ¢ç´¢ (å¦‚ TA-VLA [33])**ï¼š\n    - **æ ¸å¿ƒæ”¹è¿›**ï¼šå¼€å§‹æ„è¯†åˆ°åŠ›/åŠ›çŸ©ä¿¡æ¯çš„é‡è¦æ€§ï¼Œåœ¨æ¨¡å‹è®¾è®¡ä¸­å°è¯•é¢„æµ‹æˆ–è€ƒè™‘æ‰­çŸ©ã€‚\n    - **é—ç•™é—®é¢˜**ï¼šè®ºæ–‡æŒ‡å‡ºï¼Œè¿™ç±»å·¥ä½œé€šå¸¸**ä»…åœç•™åœ¨æ‰­çŸ©é¢„æµ‹å±‚é¢**ï¼Œæ²¡æœ‰å°†å®æ—¶çš„åŠ›/åŠ›çŸ©åé¦ˆé—­ç¯é›†æˆåˆ°æ§åˆ¶ä¸­ï¼Œä¹Ÿ**æ²¡æœ‰å®ç°åŸºäºäº¤äº’çŠ¶æ€çš„å˜é˜»æŠ—è°ƒèŠ‚**ã€‚\n\n#### ä¸»çº¿äºŒï¼šå˜é˜»æŠ—æ§åˆ¶æŠ€æœ¯çš„æ¼”è¿›ï¼ˆä»å›ºå®šå‚æ•°åˆ°å­¦ä¹ è°ƒèŠ‚ï¼‰\næ­¤æ–¹å‘æ—¨åœ¨è®©æœºå™¨äººåƒäººç±»ä¸€æ ·ï¼Œé€šè¿‡è°ƒèŠ‚è‡ªèº«çš„â€œåˆšåº¦â€å’Œâ€œé˜»å°¼â€æ¥å®‰å…¨ã€é€‚åº”æ€§åœ°ä¸ç¯å¢ƒè¿›è¡Œç‰©ç†äº¤äº’ã€‚\n\n- **ç»å…¸ä¸åŸºäºè§„åˆ™VIC**ï¼š\n    - **æ ¸å¿ƒè´¡çŒ®**ï¼šå»ºç«‹äº†å˜é˜»æŠ—æ§åˆ¶çš„ç†è®ºæ¡†æ¶ï¼Œé€šè¿‡å¼¹ç°§-é˜»å°¼æ¨¡å‹å®ç°é¡ºåº”æ€§è¡Œä¸ºï¼Œè¢«å…¬è®¤ä¸ºå®‰å…¨ç‰©ç†äº¤äº’çš„å…³é”®[1]ã€‚\n    - **å…³é”®å±€é™**ï¼šå‚æ•°éœ€è¦**æ‰‹åŠ¨è°ƒè¯•**æˆ–ä¾èµ–**é¢„å®šä¹‰çš„ä»»åŠ¡ç‰¹å®šè°ƒåº¦è¡¨**[35, 14]ã€‚ç¼ºä¹é«˜çº§è¯­ä¹‰ç†è§£ï¼Œæ— æ³•æ ¹æ®è§†è§‰åœºæ™¯å’Œä»»åŠ¡éœ€æ±‚è‡ªåŠ¨é€‚é…ã€‚\n\n- **å­¦ä¹ å‹VIC (å¦‚ [21, 32, 28])**ï¼š\n    - **æ ¸å¿ƒæ”¹è¿›**ï¼šåˆ©ç”¨**å¼ºåŒ–å­¦ä¹ **æˆ–**æ¨¡ä»¿å­¦ä¹ **æ¥è‡ªåŠ¨å­¦ä¹ é˜»æŠ—å‚æ•°æˆ–ç­–ç•¥ã€‚RLæ–¹æ³•èƒ½ç»“åˆåŠ›åé¦ˆåœ¨çº¿è°ƒèŠ‚[21, 32]ï¼›æ¨¡ä»¿å­¦ä¹ èƒ½ä»äººç±»æ¼”ç¤ºä¸­æå–é˜»æŠ—ç‰¹å¾[28]ã€‚\n    - **å…³é”®å±€é™**ï¼š\n        1.  **æ³›åŒ–æ€§å·®**ï¼šä¸¥é‡ä¾èµ–**ä»»åŠ¡ç‰¹å®šçš„è®­ç»ƒ**æˆ–**ä¸“å®¶æ¼”ç¤ºæ•°æ®**ï¼Œéš¾ä»¥è¿ç§»åˆ°æ–°ç‰©ä½“ã€æ–°åœºæ™¯ã€‚\n        2.  **ç¼ºä¹è¯­ä¹‰**ï¼šæ— æ³•åˆ©ç”¨â€œè¿™æ˜¯ä¸€ä¸ªæ˜“ç¢çš„ç»ç’ƒæ¯â€æˆ–â€œéœ€è¦ç”¨åŠ›æ‹§ç´§â€è¿™ç±»é«˜çº§è¯­ä¹‰çŸ¥è¯†æ¥ä¸»åŠ¨è°ƒæ•´é˜»æŠ—ã€‚\n        3.  **æ¢ç´¢é£é™©**ï¼šRLåœ¨æ¥è§¦ä¸°å¯Œä»»åŠ¡ä¸­çš„æ¢ç´¢å¯èƒ½ä¸å®‰å…¨ã€‚\n\n#### ä¸»çº¿ä¸‰ï¼šåˆ©ç”¨VLMå¢å¼ºç‰©ç†äº¤äº’ï¼ˆä»é«˜å±‚è§„åˆ’åˆ°å‚æ•°ç”Ÿæˆï¼‰\næ­¤æ–¹å‘æ¢ç´¢å¦‚ä½•å°†VLMå¼ºå¤§çš„è§†è§‰-è¯­è¨€æ¨ç†èƒ½åŠ›æ³¨å…¥åˆ°æœºå™¨äººçš„ä½å±‚æ§åˆ¶ä¸­ã€‚\n\n- **VLMç”¨äºé«˜å±‚è§„åˆ’ä¸æŒ‡å¯¼ (å¦‚ SAS-prompt [2])**ï¼š\n    - **æ ¸å¿ƒè´¡çŒ®**ï¼šå°†VLMä½œä¸ºâ€œä¸Šä¸‹æ–‡æ•™ç»ƒâ€ï¼Œä¸ºæœºå™¨äººç­–ç•¥æä¾›é«˜çº§æŒ‡å¯¼æˆ–ä»·å€¼å‡½æ•°å­¦ä¹ [19]ã€‚\n    - **å…³é”®å±€é™**ï¼šæŒ‡å¯¼åœç•™åœ¨**é«˜å±‚åŠ¨ä½œåºåˆ—æˆ–ç›®æ ‡å±‚é¢**ï¼Œä¸ç›´æ¥ç”Ÿæˆä½å±‚æ§åˆ¶å‚æ•°ï¼ˆå¦‚åˆšåº¦ã€é˜»å°¼ï¼‰ã€‚\n\n- **VLMç”¨äºç”Ÿæˆæ§åˆ¶å‚æ•° (å¦‚ [23, 10], ImpedanceGPT [4])**ï¼š\n    - **æ ¸å¿ƒæ”¹è¿›**ï¼šå‘å‰è¿ˆå‡ºä¸€æ­¥ï¼Œ**ç›´æ¥ä½¿ç”¨è¯­è¨€æ¨¡å‹æˆ–VLMæ¥ç”Ÿæˆæ§åˆ¶å‚æ•°**ã€‚[10]ç»“åˆçœ¼åŠ¨è¿½è¸ªè¿›è¡Œé¥é˜»æŠ—æ§åˆ¶ï¼›ImpedanceGPTç”¨è¯­è¨€æ¨¡å‹é€‰æ‹©é˜»æŠ—å‚æ•°ã€‚\n    - **å…³é”®å±€é™**ï¼š\n        1.  **ä»»åŠ¡ç®€å•**ï¼šè¯„ä¼°åœºæ™¯å¤šä¸ºç®€å•çš„æ‹¾æ”¾ä»»åŠ¡ï¼Œç¼ºä¹**å¤æ‚æ¥è§¦åŠ¨åŠ›å­¦**çš„éªŒè¯ã€‚\n        2.  **ç¼ºä¹å®æ—¶åé¦ˆ**ï¼šå‚æ•°ç”Ÿæˆå¤šåŸºäºé™æ€åœºæ™¯åˆ†æï¼Œ**æœªé›†æˆå®æ—¶åŠ›/åŠ›çŸ©ä¼ æ„Ÿå™¨åé¦ˆ**è¿›è¡Œé—­ç¯è°ƒèŠ‚ã€‚\n        3.  **ç¡¬ä»¶ä¾èµ–**ï¼šä¸€äº›æ–¹æ³•éœ€è¦çœ¼åŠ¨ä»ªç­‰ç‰¹æ®Šç¡¬ä»¶ï¼Œéƒ¨ç½²æˆæœ¬é«˜ã€‚\n\n### **CompliantVLA-adaptor çš„æ ¸å¿ƒåˆ›æ–°ä¸æ•´åˆ**\n\næœ¬æ–‡å·¥ä½œæ˜¯ä¸Šè¿°ä¸‰æ¡ä¸»çº¿å‘å±•çš„**é›†å¤§æˆè€…å’Œå…³é”®çªç ´ç‚¹**ï¼Œå…¶æ”¹è¿›ä½“ç°åœ¨ï¼š\n\n1.  **èŒƒå¼åˆ›æ–°ï¼šVLM ä½œä¸ºâ€œé˜»æŠ—æ•™ç»ƒâ€åµŒå…¥ç»å…¸VICé—­ç¯**\n    - **ä¹‹å‰**ï¼šVLAï¼ˆä¸»çº¿ä¸€ï¼‰å’ŒVICï¼ˆä¸»çº¿äºŒï¼‰æ˜¯å‰²è£‚çš„ï¼›VLMï¼ˆä¸»çº¿ä¸‰ï¼‰ä»…ç”¨äºé«˜å±‚æˆ–å¼€ç¯å‚æ•°ç”Ÿæˆã€‚\n    - **æœ¬æ–‡**ï¼šé¦–åˆ›æ€§åœ°å°†**å†»ç»“çš„é¢„è®­ç»ƒVLM**ä½œä¸ºæ ¸å¿ƒæ¨¡å—ï¼ŒåµŒå…¥åˆ°ä¸€ä¸ª**å®æ—¶åŠ›åé¦ˆè°ƒèŠ‚çš„å˜é˜»æŠ—æ§åˆ¶å™¨**ä¸­ã€‚VLMçš„è§’è‰²æ˜¯ **â€œä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„é˜»æŠ—å‚æ•°ç”Ÿæˆå™¨â€** ï¼Œå®ç°äº†ä»â€œçœ‹åˆ°å¹¶ç†è§£åœºæ™¯â€åˆ°â€œå†³å®šç”¨å¤šå¤§è½¯ç¡¬åº¦å»æ¥è§¦â€çš„ç›´æ¥æ˜ å°„ã€‚\n\n2.  **å¤šæ¨¡æ€ä¿¡æ¯èåˆä¸å®‰å…¨å±‚è®¾è®¡**\n    - **ä¹‹å‰**ï¼šå‚æ•°ç”Ÿæˆè¦ä¹ˆåªä¾èµ–è§†è§‰/è¯­è¨€ï¼Œè¦ä¹ˆåªä¾èµ–åŠ›åé¦ˆã€‚\n    - **æœ¬æ–‡**ï¼šæå‡ºäº†**æ··åˆæ¥è§¦ç›¸ä½è¯†åˆ«**ï¼ˆç»“åˆVLMè¯­ä¹‰æ¨ç†å’ŒåŠ›ä¼ æ„Ÿå™¨æ•°æ®ï¼‰å’Œ**åŒå®‰å…¨å±‚**ï¼š\n        - **ç¬¬ä¸€å±‚ï¼ˆè¯­ä¹‰å±‚ï¼‰**ï¼šVLMæ ¹æ®ä»»åŠ¡é˜¶æ®µï¼ˆè‡ªç”±è¿åŠ¨ã€æ¥è¿‘ã€æ¥è§¦ã€æ’¤å›ï¼‰ç”ŸæˆåŸºç¡€é˜»æŠ—å‚æ•°ï¼Œä½“ç°è¯­ä¹‰ä¼˜å…ˆçº§ï¼ˆå¦‚æ¥è§¦é˜¶æ®µåˆšåº¦æœ€ä½ï¼‰ã€‚\n        - **ç¬¬äºŒå±‚ï¼ˆç‰©ç†å±‚ï¼‰**ï¼šé€šè¿‡åŠ›åé¦ˆè®¡ç®—ç¼©æ”¾å› å­ `Î±_force`ï¼Œå®æ—¶ä¸‹è°ƒåˆšåº¦ï¼Œç¡®ä¿å³ä½¿VLMåˆ¤æ–­é”™è¯¯ï¼Œç‰©ç†äº¤äº’åŠ›ä¹Ÿä¸ä¼šè¶…é™ã€‚`Î±_force âˆˆ [0.2, 1]`  // å…³é”®å…¬å¼\n    - è¿™è§£å†³äº†çº¯è§†è§‰VLMæ— æ³•å¯é æ„ŸçŸ¥æ¥è§¦çŠ¶æ€ï¼Œä»¥åŠçº¯åŠ›åé¦ˆç¼ºä¹ä»»åŠ¡è¯­ä¹‰çš„é—®é¢˜ã€‚\n\n3.  **å®ç°äº†â€œä¼˜é›…é™çº§â€è€Œéâ€œç¾éš¾æ€§å¤±è´¥â€**\n    - **ä¹‹å‰**ï¼šåŸºçº¿VLAæ¨¡å‹åœ¨åŠ›è¶…é™æ—¶è¡¨ç°ä¸º**ç¾éš¾æ€§å¤±è´¥**ï¼ˆç‰©ä½“è¢«æ‰“ç¿»ã€éƒ¨ä»¶æŸåï¼‰ã€‚\n    - **æœ¬æ–‡**ï¼šé€šè¿‡è‡ªé€‚åº”é˜»æŠ—ï¼Œå¤±è´¥æ¨¡å¼è½¬å˜ä¸º**è½»å¾®é”™ä½æˆ–æ»‘ç§»**ï¼ŒåŠ›å€¼å§‹ç»ˆä¿æŒå®‰å…¨ã€‚è¿™æ˜¯ä»â€œä¸å®‰å…¨â€åˆ°â€œå®‰å…¨ä½†å¯èƒ½ä¸ç²¾ç¡®â€çš„æ ¹æœ¬æ€§è½¬å˜ã€‚\n\n4.  **å³æ’å³ç”¨ä¸æ³›åŒ–æ€§æå‡**\n    - **ä¹‹å‰**ï¼šå­¦ä¹ å‹VICéœ€è¦ä¸ºæ¯ä¸ªæ–°ä»»åŠ¡é‡æ–°è®­ç»ƒï¼›VLAæ¨¡å‹ç¼ºä¹å®‰å…¨äº¤äº’èƒ½åŠ›ã€‚\n    - **æœ¬æ–‡**ï¼šé€‚é…å™¨æ˜¯**æ¨¡å—åŒ–ã€å³æ’å³ç”¨**çš„ï¼Œå¯ä»¥æ— ç¼å¢å¼ºä»»ä½•ç°æœ‰VLAæ¨¡å‹ï¼ˆæ–‡ä¸­æµ‹è¯•äº†Pi0, RDT, OpenVLA-oftï¼‰ã€‚åˆ©ç”¨é¢„è®­ç»ƒVLMçš„é›¶æ ·æœ¬èƒ½åŠ›ï¼Œ**æ— éœ€é’ˆå¯¹æ–°æ¥è§¦ä»»åŠ¡è¿›è¡Œè®­ç»ƒ**ï¼Œå³å¯å®ç°è·¨ä»»åŠ¡çš„æ³›åŒ–å®‰å…¨æ§åˆ¶ã€‚\n\n### æ€»ç»“ï¼šå‡ ä¸ªä¸åŒçš„å‘å±•æ–¹å‘\n\n1.  **VLAæ¨¡å‹çš„â€œåŠ›æ„ŸçŸ¥â€å†…åŒ–æ–¹å‘**ï¼šæœªæ¥VLAæ¨¡å‹å¯èƒ½ä¼šåƒæœ¬æ–‡å€¡å¯¼çš„é‚£æ ·ï¼Œåœ¨æ¶æ„è®¾è®¡åˆæœŸå°±å°†åŠ›/åŠ›çŸ©è§‚æµ‹å’Œé˜»æŠ—åŠ¨ä½œç©ºé—´çº³å…¥é¢„è®­ç»ƒç›®æ ‡ï¼Œä»æ ¹æºä¸Šæˆä¸ºâ€œåŠ›æ„ŸçŸ¥â€çš„æ¨¡å‹ï¼Œè€Œéä¾èµ–å¤–éƒ¨é€‚é…å™¨ã€‚\n2.  **è½»é‡åŒ–ä¸å®æ—¶VLMæ§åˆ¶æ–¹å‘**ï¼šè§£å†³å½“å‰ä¾èµ–å¤§æ¨¡å‹APIï¼ˆå»¶è¿Ÿé«˜ã€æˆæœ¬é«˜ï¼‰çš„é—®é¢˜ã€‚ç ”ç©¶æ–¹å‘åŒ…æ‹¬è’¸é¦å‡ºä¸“ç”¨äºæœºå™¨äººé˜»æŠ—æ¨ç†çš„å°å‹VLMï¼Œæˆ–è®¾è®¡æ›´é«˜æ•ˆçš„æ¨ç†æ¡†æ¶ï¼Œä»¥æ»¡è¶³ä½å±‚æ§åˆ¶çš„é«˜é¢‘éœ€æ±‚ã€‚\n3.  **å¤šæ¨¡æ€æ„ŸçŸ¥æ·±åº¦èåˆæ–¹å‘**ï¼šè¶…è¶Šâ€œè§†è§‰+è¯­è¨€+åŠ›â€ï¼Œèå…¥**è§¦è§‰**[5]ã€å¬è§‰ç­‰æ¨¡æ€ï¼Œä½¿VLMå¯¹ç‰©ç†äº¤äº’çš„ä¸Šä¸‹æ–‡æœ‰æ›´ç»†è…»çš„ç†è§£ï¼Œä»è€Œç”Ÿæˆæ›´ç²¾ç¡®çš„é˜»æŠ—å‚æ•°ã€‚\n4.  **äººæœºäº¤äº’ä¸ä¿¡ä»»å»ºæ¨¡æ–¹å‘**ï¼šç»“åˆVLMå¯¹äººç±»æ„å›¾å’Œæƒ…ç»ªçš„ç†è§£ï¼Œä»¥åŠVICçš„æŸ”é¡ºæ€§ï¼Œå‘å±•æ›´è‡ªç„¶ã€æ›´å®‰å…¨çš„**äººæœºåä½œ**å˜é˜»æŠ—æ§åˆ¶æ–¹æ³•[16]ã€‚\n\n**CompliantVLA-adaptor** çš„æ ¸å¿ƒä»·å€¼åœ¨äºï¼Œå®ƒæ²¡æœ‰ç­‰å¾…ä¸€ä¸ªå®Œç¾çš„ã€å†…èšåŠ›æ„ŸçŸ¥çš„VLAæ¨¡å‹å‡ºç°ï¼Œè€Œæ˜¯**åˆ›é€ æ€§åœ°åˆ©ç”¨ç°æœ‰æˆç†Ÿç»„ä»¶ï¼ˆVLMã€VICã€åŠ›ä¼ æ„Ÿå™¨ï¼‰ï¼Œé€šè¿‡ç³»ç»Ÿé›†æˆè®¾è®¡ï¼Œç‡å…ˆä¸ºVLAç³»ç»Ÿæä¾›äº†ä¸€ä¸ªæ€¥éœ€çš„â€œå®‰å…¨å±‚â€**ï¼Œä¸ºè¿ˆå‘å®‰å…¨çš„ã€æ¥è§¦ä¸°å¯Œçš„é€šç”¨æœºå™¨äººæ“çºµé“ºå¹³äº†é“è·¯ã€‚",
            "timestamp": "2026-01-27T16:10:21.668063",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "ä»–çš„å‰ä½œæœ‰å“ªäº›ï¼Ÿä½¿ç”¨è¡¨æ ¼ä»”ç»†è®²è®²ä»–çš„æ¯ç¯‡å‰ä½œï¼Œä»–å’Œå‰ä½œçš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Œä¸»è¦æ”¹å–„æ˜¯ä»€ä¹ˆï¼Ÿç€é‡äºå…·ä½“ç›¸æ¯”äºä¹‹å‰æ–‡ç« çš„æ”¹åŠ¨",
            "answer": "## å‰ä½œåˆ†æ\n\næ ¹æ®è®ºæ–‡å†…å®¹ï¼Œä½œè€…å›¢é˜Ÿï¼ˆç‰¹åˆ«æ˜¯ Heng Zhang å’Œ Arash Ajoudaniï¼‰åœ¨æ¥è§¦å¼æœºå™¨äººæ“ä½œä¸å®‰å…¨å­¦ä¹ é¢†åŸŸæœ‰ä¸€ç³»åˆ—ç›¸å…³ç ”ç©¶ã€‚ä»¥ä¸‹æ˜¯åŸºäºè®ºæ–‡å¼•ç”¨æ¢³ç†å‡ºçš„ä¸»è¦å‰ä½œï¼Œä»¥åŠæœ¬æ–‡ä¸å®ƒä»¬çš„åŒºåˆ«å’Œæ”¹è¿›ã€‚\n\n| å‰ä½œæ ‡é¢˜ | å‘è¡¨å¹´ä»½/å‡ºå¤„ | æ ¸å¿ƒè´¡çŒ®ä¸æ–¹æ³• | ä¸æœ¬æ–‡ (CompliantVLA-adaptor) çš„ä¸»è¦åŒºåˆ« | æœ¬æ–‡çš„ä¸»è¦æ”¹è¿›ä¸åˆ›æ–°ç‚¹ |\n| :--- | :--- | :--- | :--- | :--- |\n| **SRL-vic: A Variable Stiffness-Based Safe Reinforcement Learning for Contact-Rich Robotic Tasks** [32] | 2024, IEEE RA-L | æå‡ºäº†ä¸€ç§**åŸºäºå¯å˜é˜»æŠ—çš„å®‰å…¨å¼ºåŒ–å­¦ä¹ ï¼ˆSRLï¼‰æ¡†æ¶**ï¼Œç”¨äºæ¥è§¦å¼ä»»åŠ¡ã€‚å®ƒç»“åˆäº†å¯å˜é˜»æŠ—æ§åˆ¶ï¼ˆVICï¼‰å’Œå¼ºåŒ–å­¦ä¹ ï¼Œåˆ©ç”¨åŠ›/åŠ›çŸ©åé¦ˆåœ¨çº¿è°ƒæ•´åˆšåº¦ï¼Œä»¥å®ç°å®‰å…¨æ¢ç´¢å’Œé«˜æ•ˆå­¦ä¹ ã€‚ | 1. **æ–¹æ³•èŒƒç•´**ï¼šå±äº**å­¦ä¹ å‹VIC**ï¼Œéœ€è¦é’ˆå¯¹ç‰¹å®šä»»åŠ¡è¿›è¡ŒRLè®­ç»ƒæˆ–ä¾èµ–ä¸“å®¶æ¼”ç¤ºã€‚<br>2. **æ³›åŒ–èƒ½åŠ›**ï¼šä¾èµ–äºä»»åŠ¡ç‰¹å®šçš„è®­ç»ƒï¼Œ**éš¾ä»¥é›¶æ ·æœ¬æ³›åŒ–**åˆ°æ–°ç‰©ä½“æˆ–æ–°åœºæ™¯ã€‚<br>3. **é«˜å±‚è¯­ä¹‰ç†è§£**ï¼šç¼ºä¹åˆ©ç”¨è§†è§‰å’Œè¯­è¨€ç­‰**å¤šæ¨¡æ€ä¿¡æ¯**è¿›è¡Œé«˜å±‚ä»»åŠ¡è¯­ä¹‰ç†è§£çš„èƒ½åŠ›ï¼Œé˜»æŠ—è°ƒæ•´åŸºäºä½å±‚ä¼ æ„Ÿå™¨ä¿¡å·å’Œå¥–åŠ±å‡½æ•°ã€‚ | 1. **å¼•å…¥VLMå®ç°é›¶æ ·æœ¬æ³›åŒ–**ï¼šæœ¬æ–‡åˆ©ç”¨**é¢„è®­ç»ƒè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰** çš„è¯­ä¹‰ç†è§£èƒ½åŠ›ï¼Œæ ¹æ®è§†è§‰åœºæ™¯å’Œè¯­è¨€æŒ‡ä»¤**é›¶æ ·æœ¬ç”Ÿæˆ**ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„é˜»æŠ—å‚æ•°ï¼Œæ— éœ€é’ˆå¯¹æ¯ä¸ªæ–°ä»»åŠ¡è¿›è¡Œè®­ç»ƒã€‚<br>2. **æ¶æ„åˆ›æ–°ï¼šVLAé€‚é…å™¨**ï¼šæœ¬æ–‡æ ¸å¿ƒæ˜¯ä¸€ä¸ª**å³æ’å³ç”¨çš„é€‚é…å™¨æ¨¡å—**ï¼Œæ—¨åœ¨**å¢å¼ºç°æœ‰VLAæ¨¡å‹**ï¼Œè€Œéä»å¤´è®­ç»ƒä¸€ä¸ªç­–ç•¥ã€‚å®ƒä¿ç•™äº†VLAå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶ä¸ºå…¶å¢åŠ äº†åŠ›æ„ŸçŸ¥çš„åˆè§„æ§åˆ¶å±‚ã€‚<br>3. **æ§åˆ¶ç›®æ ‡ä¸åŒ**ï¼šå‰ä½œ[32]çš„ç›®æ ‡æ˜¯**é€šè¿‡RLå­¦ä¹ ä¸€ä¸ªå¯å˜é˜»æŠ—ç­–ç•¥**ï¼›æœ¬æ–‡çš„ç›®æ ‡æ˜¯**ä¸ºå·²æœ‰çš„ã€ä»…è¾“å‡ºä½ç½®çš„åŠ¨ä½œâ€œåŒ…è£¹â€ä¸€å±‚å®‰å…¨çš„å¯å˜é˜»æŠ—æ§åˆ¶**ã€‚ |\n| **A Survey on Imitation Learning for Contact-Rich Tasks in Robotics** [25] | 2025, arXiv | ä¸€ç¯‡å…³äº**æ¥è§¦å¼ä»»åŠ¡æ¨¡ä»¿å­¦ä¹ **çš„ç»¼è¿°æ–‡ç« ï¼Œç³»ç»Ÿæ¢³ç†äº†å„ç±»æ–¹æ³•ï¼ˆåŒ…æ‹¬é‚£äº›ç»“åˆé˜»æŠ—æ§åˆ¶çš„æ–¹æ³•ï¼‰çš„è¿›å±•ã€æŒ‘æˆ˜å’Œæœªæ¥æ–¹å‘ã€‚ | 1. **æ–‡ç« ç±»å‹**ï¼šè¿™æ˜¯ä¸€ç¯‡**ç»¼è¿°ï¼ˆSurveyï¼‰**ï¼Œè€Œéæå‡ºæ–°ç®—æ³•çš„ç ”ç©¶è®ºæ–‡ã€‚<br>2. **å…³æ³¨ç‚¹**ï¼šå…¨é¢å›é¡¾é¢†åŸŸï¼ŒæŒ‡å‡ºæ¨¡ä»¿å­¦ä¹ åœ¨æ¥è§¦å¼ä»»åŠ¡ä¸­çš„å±€é™ï¼Œä¾‹å¦‚å¯¹æ¼”ç¤ºæ•°æ®çš„ä¾èµ–å’Œæ³›åŒ–éš¾é¢˜ã€‚ | 1. **æå‡ºè§£å†³æ–¹æ¡ˆ**ï¼šæœ¬æ–‡å¯è§†ä¸ºå¯¹ç»¼è¿°ä¸­æŒ‡å‡ºçš„â€œ**å¦‚ä½•å°†é«˜å±‚è¯­ä¹‰ç†è§£ä¸ä½å±‚åŠ›æ§åˆ¶ç»“åˆ**â€è¿™ä¸€æŒ‘æˆ˜çš„ç›´æ¥å›åº”ã€‚å®ƒæå‡ºäº†ä¸€ä¸ªå…·ä½“çš„ã€å¯æ“ä½œçš„æ¡†æ¶ï¼ˆCompliantVLA-adaptorï¼‰ã€‚<br>2. **è¶…è¶Šæ¨¡ä»¿å­¦ä¹ **ï¼šæœ¬æ–‡ä¸ä¾èµ–äºä¸“å®¶æ¼”ç¤ºæ•°æ®ï¼Œè€Œæ˜¯åˆ©ç”¨**äº’è”ç½‘è§„æ¨¡é¢„è®­ç»ƒçš„VLMçŸ¥è¯†**å’Œ**å®æ—¶åŠ›åé¦ˆ**æ¥åŠ¨æ€è°ƒæ•´æ§åˆ¶ã€‚ |\n| **Safe Learning for Contact-Rich Robot Tasks: A Survey from Classical Learning-Based Methods to Safe Foundation Models** [31] | 2025, arXiv | å¦ä¸€ç¯‡**ç»¼è¿°**ï¼Œæ¶µç›–äº†ä»ç»å…¸å­¦ä¹ åˆ°å®‰å…¨åŸºç¡€æ¨¡å‹çš„å¹¿æ³›èŒƒå›´ã€‚ç‰¹åˆ«æŒ‡å‡ºäº†VLAæ¨¡å‹ä¸­**åŠ›çŸ©æ„ŸçŸ¥ï¼ˆtorque-awarenessï¼‰** çš„é‡è¦æ€§ã€‚ | 1. **æ–‡ç« ç±»å‹**ï¼šåŒæ ·æ˜¯**ç»¼è¿°**ã€‚<br>2. **æŒ‡å‡ºé—®é¢˜**ï¼šè¯¥ç»¼è¿°æŒ‡å‡ºå½“å‰VLAæ¨¡å‹ç¼ºä¹åŠ›æ„ŸçŸ¥ï¼Œä½†ä¸»è¦åœç•™åœ¨æŒ‡å‡ºé—®é¢˜å’Œå±•æœ›å±‚é¢ã€‚æ–‡ä¸­æåˆ°ç›¸å…³å·¥ä½œ[33]ä»…è€ƒè™‘äº†åŠ›çŸ©é¢„æµ‹ï¼Œ**æ²¡æœ‰ç»“åˆåŠ›åé¦ˆå’Œé˜»æŠ—æ§åˆ¶**ã€‚ | 1. **å®ç°å…·ä½“æ–¹æ¡ˆ**ï¼šæœ¬æ–‡**å®ç°äº†**ç»¼è¿°ä¸­å‘¼åçš„æ–¹å‘ã€‚å®ƒä¸ä»…è€ƒè™‘äº†åŠ›/åŠ›çŸ©æ„ŸçŸ¥ï¼Œæ›´å°†å…¶ä½œä¸º**æ ¸å¿ƒåé¦ˆä¿¡å·**ï¼Œä¸VLMçš„è¯­ä¹‰è¾“å‡ºç»“åˆï¼ŒåŠ¨æ€è°ƒèŠ‚VICå‚æ•°ï¼Œå½¢æˆäº†ä¸€ä¸ªå®Œæ•´çš„æ§åˆ¶å›è·¯ã€‚<br>2. **ä»â€œé¢„æµ‹â€åˆ°â€œæ§åˆ¶â€**ï¼šåŒºåˆ«äºä»…é¢„æµ‹åŠ›çŸ©ï¼Œæœ¬æ–‡å°†åŠ›æ„ŸçŸ¥**æ·±åº¦èåˆåˆ°æ§åˆ¶å¾‹ä¸­**ï¼Œé€šè¿‡è°ƒæ•´åˆšåº¦å’Œé˜»å°¼æ¥ä¸»åŠ¨ç®¡ç†äº¤äº’åŠ›ï¼Œå®ç°äº†çœŸæ­£çš„**å®‰å…¨åˆè§„äº¤äº’**ã€‚ |\n\n---\n\n### **æ€»ç»“ï¼šæœ¬æ–‡ç›¸å¯¹äºå‰ä½œçš„æ ¸å¿ƒæ”¹åŠ¨ä¸æå‡**\n\n1.  **é—®é¢˜è§†è§’çš„è½¬å˜**ï¼š\n    *   **å‰ä½œ**ï¼šä¸“æ³¨äºåœ¨**ç‰¹å®šæ¥è§¦å¼ä»»åŠ¡**ä¸­ï¼Œå¦‚ä½•é€šè¿‡å­¦ä¹ ï¼ˆRLæˆ–æ¨¡ä»¿ï¼‰æ¥è·å¾—æ›´å¥½çš„å¯å˜é˜»æŠ—æ§åˆ¶ç­–ç•¥ã€‚\n    *   **æœ¬æ–‡**ï¼šä¸“æ³¨äºå¦‚ä½•è®©**æ–°å…´çš„ã€å…·æœ‰å¼ºå¤§æ³›åŒ–èƒ½åŠ›ä½†â€œåŠ›ç›²â€çš„VLAåŸºç¡€æ¨¡å‹**ï¼Œèƒ½å¤Ÿå®‰å…¨åœ°æ‰§è¡Œæ¥è§¦å¼ä»»åŠ¡ã€‚è¿™æ˜¯ä¸€ä¸ª**ç³»ç»Ÿé›†æˆä¸å¢å¼º**çš„é—®é¢˜ï¼Œè€Œéå•ä¸€ç­–ç•¥çš„å­¦ä¹ é—®é¢˜ã€‚\n\n2.  **æŠ€æœ¯è·¯çº¿çš„æ ¹æœ¬ä¸åŒ**ï¼š\n    *   **å‰ä½œï¼ˆå¦‚SRL-vicï¼‰**ï¼š**å­¦ä¹ ç”ŸæˆåŠ¨ä½œï¼ˆå«é˜»æŠ—ï¼‰**ã€‚è·¯å¾„æ˜¯ï¼šä¼ æ„Ÿå™¨è¾“å…¥ -> å­¦ä¹ ç­–ç•¥ -> é˜»æŠ—+åŠ¨ä½œã€‚\n    *   **æœ¬æ–‡**ï¼š**å­¦ä¹ è°ƒåˆ¶æ§åˆ¶å™¨å‚æ•°**ã€‚è·¯å¾„æ˜¯ï¼šVLAï¼ˆç”Ÿæˆä½ç½®åŠ¨ä½œï¼‰ + VLMï¼ˆç†è§£åœºæ™¯å¹¶ç”Ÿæˆé˜»æŠ—å‚æ•°ï¼‰ + åŠ›åé¦ˆï¼ˆå®æ—¶å¾®è°ƒï¼‰ -> å¯å˜é˜»æŠ—æ§åˆ¶å™¨ -> å®‰å…¨åŠ¨ä½œã€‚**æœ¬æ–‡ä¸æ”¹å˜VLAçš„åŠ¨ä½œç”Ÿæˆé€»è¾‘ï¼Œè€Œæ˜¯ä¸ºå…¶åŠ¨ä½œçš„æ‰§è¡Œè¿‡ç¨‹å¢åŠ äº†ä¸€ä¸ªâ€œå®‰å…¨è¿‡æ»¤å™¨â€å’Œâ€œé€‚åº”æ€§æ‰§è¡Œå™¨â€ã€‚**\n\n3.  **æ ¸å¿ƒåˆ›æ–°ç‚¹**ï¼š\n    *   **VLMä½œä¸ºâ€œé˜»æŠ—æ•™ç»ƒâ€**ï¼šé¦–æ¬¡ç³»ç»Ÿæ€§åœ°åˆ©ç”¨VLMçš„è§†è§‰-è¯­è¨€æ¨ç†èƒ½åŠ›ï¼Œä¸ºç‰©ç†äº¤äº’ç”Ÿæˆ**ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„é˜»æŠ—å‚æ•°**ï¼ˆå¦‚ï¼šçœ‹åˆ°è„†å¼±ç‰©ä½“è°ƒä½åˆšåº¦ï¼Œåœ¨è‡ªç”±è¿åŠ¨é˜¶æ®µè°ƒé«˜åˆšåº¦ï¼‰ã€‚\n    *   **æ··åˆå®‰å…¨æ¶æ„**ï¼šè®¾è®¡äº†**åŒå±‚å®‰å…¨æœºåˆ¶**ï¼š\n        1.  **å‰ç»æ€§å®‰å…¨**ï¼šç”±VLMåŸºäºè¯­ä¹‰ç†è§£é¢„å…ˆè®¾å®šåˆé€‚çš„é˜»æŠ—èŒƒå›´ã€‚\n        2.  **ååº”å¼å®‰å…¨**ï¼šç”±å®æ—¶åŠ›åé¦ˆï¼ˆ`Î±_force`ç¼©æ”¾å› å­ï¼‰åœ¨æ¯«ç§’çº§è¿›è¡Œå¾®è°ƒï¼Œç¡®ä¿åŠ›ä¸è¶…è¿‡é˜ˆå€¼ã€‚\n    *   **å³æ’å³ç”¨é€‚é…å™¨**ï¼šæå‡ºäº†ä¸€ç§æ¨¡å—åŒ–æ–¹æ¡ˆï¼Œå¯ä»¥çµæ´»åœ°æ¥å…¥ä¸åŒçš„ç°æœ‰VLAæ¨¡å‹ï¼ˆå¦‚RDT, Pi0, OpenVLA-oftï¼‰ï¼Œ**æ˜¾è‘—æé«˜äº†å®ç”¨æ€§å’Œéƒ¨ç½²ä¾¿åˆ©æ€§**ã€‚\n\n4.  **æ€§èƒ½æ”¹å–„çš„å®è´¨**ï¼š\n    *   å®éªŒè¡¨æ˜ï¼Œæœ¬æ–‡æ–¹æ³•åœ¨**ä¿æŒVLAæ³›åŒ–èƒ½åŠ›**çš„å‰æä¸‹ï¼Œå°†æ¥è§¦åŠ›è¿è§„å¯¼è‡´çš„ç¾éš¾æ€§å¤±è´¥ï¼ˆå¦‚æ¨å€’ç‰©ä½“ã€æŸåéƒ¨ä»¶ï¼‰è½¬å˜ä¸º**æ¸©å’Œçš„å¤±è´¥**ï¼ˆå¦‚è½»å¾®é”™ä½ã€æ»‘åŠ¨ï¼‰ã€‚**æˆåŠŸç‡çš„æå‡ï¼ˆ9.86% -> 17.29%ï¼‰æœ¬è´¨ä¸Šæ˜¯å°†åŸæœ¬â€œä¸å®‰å…¨â€çš„å°è¯•å˜æˆäº†â€œå®‰å…¨ä½†å¯èƒ½æœªå®Œæˆâ€çš„å°è¯•**ï¼Œè¿™å¯¹äºç°å®ä¸–ç•Œéƒ¨ç½²è‡³å…³é‡è¦ã€‚\n\n**ç»“è®º**ï¼šæœ¬æ–‡æ˜¯ä½œè€…å›¢é˜Ÿä»æ·±è€•**ç‰¹å®šä»»åŠ¡ä¸‹çš„å®‰å…¨å­¦ä¹ **ï¼ˆå‰ä½œï¼‰ï¼Œè½¬å‘è§£å†³**é€šç”¨åŸºç¡€æ¨¡å‹åœ¨ç‰©ç†äº¤äº’ä¸­çš„å®‰å…¨æ€§ç“¶é¢ˆ**è¿™ä¸€å‰æ²¿é—®é¢˜çš„å…³é”®å·¥ä½œã€‚å…¶ä¸»è¦æ”¹å–„åœ¨äº**åˆ›é€ æ€§åœ°åˆ©ç”¨VLMæ¡¥æ¥äº†é«˜å±‚è¯­ä¹‰ä¸ä½å±‚åŠ›æ§**ï¼Œå¹¶è®¾è®¡äº†ä¸€ä¸ªå®ç”¨çš„é€‚é…å™¨æ¶æ„ï¼Œä¸ºå®‰å…¨éƒ¨ç½²VLAç³»ç»Ÿæä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
            "timestamp": "2026-01-27T16:11:19.527020",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "è®ºæ–‡æå‡ºäº†å“ªäº›å…³é”®æŠ€æœ¯æ–¹æ³•ï¼Œè¯·åˆ—è¡¨æ ¼å…·ä½“è¯¦ç»†è¯´æ˜æŠ€æœ¯ç»†èŠ‚ï¼Œéœ€è¦åŒ…å«å…·ä½“çš„æ•°å­¦åŸç†æ¨å¯¼ï¼Œä»¥åŠå…·ä½“å‚æ•°ã€‚",
            "answer": "## è®ºæ–‡å…³é”®æŠ€æœ¯æ–¹æ³•åˆ†æ\n\nè®ºæ–‡ã€ŠCompliantVLA-adaptor: VLM-Guided Variable Impedance Action for Safe Contact-Rich Manipulationã€‹çš„æ ¸å¿ƒåˆ›æ–°åœ¨äº**å°†è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„è¯­ä¹‰ç†è§£èƒ½åŠ›ä¸å¯å˜é˜»æŠ—æ§åˆ¶ï¼ˆVICï¼‰çš„ç‰©ç†é¡ºåº”æ€§ç›¸ç»“åˆ**ï¼Œä¸ºç°æœ‰çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹å¢åŠ äº†ä¸€ä¸ªâ€œå®‰å…¨é€‚é…å±‚â€ã€‚å…¶å…³é”®æŠ€æœ¯æ–¹æ³•å¯æ€»ç»“å¦‚ä¸‹ï¼š\n\n| æŠ€æœ¯æ¨¡å— | æ ¸å¿ƒåŠŸèƒ½ | æŠ€æœ¯ç»†èŠ‚ä¸æ•°å­¦åŸç† | å…·ä½“å‚æ•°/å®ç° |\n| :--- | :--- | :--- | :--- |\n| **1. æ··åˆVLA-VICæ§åˆ¶æ¶æ„** | èåˆé«˜å±‚è¯­ä¹‰åŠ¨ä½œè§„åˆ’ä¸åº•å±‚é¡ºåº”æ€§æ§åˆ¶ï¼Œå®ç°å¤šæ—¶é—´å°ºåº¦ååŒã€‚ | **æ¶æ„åˆ†å±‚**ï¼š<br>â€¢ **VLMé˜»æŠ—ç”Ÿæˆå±‚ (~1 Hz)**ï¼šå¤„ç†è§†è§‰ã€è¯­è¨€å’ŒåŠ›åé¦ˆï¼Œç”Ÿæˆåˆšåº¦/é˜»å°¼å‚æ•°ã€‚<br>â€¢ **VLAåŠ¨ä½œå—ç”Ÿæˆå±‚ (~3 Hz)**ï¼šåŸºäºè§‚æµ‹å’ŒæŒ‡ä»¤ç”Ÿæˆæœ«ç«¯æœŸæœ›ä½ç§» `x_d`ã€‚<br>â€¢ **åº•å±‚VICæ§åˆ¶å™¨ (1000 Hz)**ï¼šä»¥è‡ªé€‚åº”é¡ºåº”æ€§è·Ÿè¸ªæœŸæœ›ä½å§¿ã€‚ <br>**æ•°å­¦æè¿°**ï¼šå°†ä¼ ç»ŸVLAæ¨¡å‹ `Ï€_VLA: S Ã— T â†’ A` æ‰©å±•ä¸ºåŒ…å«é˜»æŠ—è°ƒåˆ¶çš„é€‚é…å™¨ï¼š`CompliantVLA: VLM(S Ã— T Ã— F) â†’ (K, D)`ã€‚å…¶ä¸­ `F âˆˆ se*(3)` ä¸º6ç»´æ¥è§¦åŠ›/åŠ›çŸ©ï¼Œ`K, D âˆˆ â„Â³` åˆ†åˆ«ä¸ºå¹³ç§»åˆšåº¦å’Œé˜»å°¼çŸ©é˜µã€‚ | â€¢ **æ§åˆ¶é¢‘ç‡**ï¼šVLMæ¨ç†1Hzï¼ŒVLAåŠ¨ä½œ3Hzï¼Œåº•å±‚æ§åˆ¶1000Hzã€‚<br>â€¢ **åŠ¨ä½œç©ºé—´**ï¼šVLAè¾“å‡ºæœ«ç«¯ä½ç§» `x_d âˆˆ â„â¶` åŠå¤¹çˆªåŠ¨ä½œã€‚ |\n| **2. VLMå¼•å¯¼çš„å¤šæ¨¡æ€æ¥è§¦ç›¸ä½è¯†åˆ«** | ç»“åˆè§†è§‰è¯­ä¹‰ä¸åŠ›ä¼ æ„Ÿå™¨åé¦ˆï¼Œé²æ£’åœ°è¯†åˆ«ä»»åŠ¡æ‰§è¡Œé˜¶æ®µï¼Œä¸ºé˜»æŠ—è°ƒèŠ‚æä¾›ä¸Šä¸‹æ–‡ã€‚ | **æ–¹æ³•**ï¼šè®¾è®¡ç‰¹å®šæç¤ºè¯ï¼ˆPromptï¼‰ï¼Œè®©VLMç»¼åˆ**ä»»åŠ¡æè¿°**ã€**åŠ›æµ‹é‡å€¼**å’Œé¢„å®šä¹‰çš„**æ¥è§¦ç›¸ä½åˆ—è¡¨**ï¼Œæ¨ç†å½“å‰é˜¶æ®µã€‚ <br>**ç›¸ä½åˆ†ç±»**ï¼š`Phase âˆˆ {Free_motion, Approaching, Contact, Retreat}`ã€‚ <br>**ä¼˜åŠ¿**ï¼šå…‹æœäº†çº¯è§†è§‰æ–¹æ³•åœ¨é®æŒ¡æˆ–ç»†å¾®æ¥è§¦æ—¶è¯†åˆ«ä¸å‡†ï¼Œä»¥åŠçº¯åŠ›åé¦ˆç¼ºä¹è¯­ä¹‰ä¸Šä¸‹æ–‡çš„é—®é¢˜ã€‚ | â€¢ **è¾“å…¥**ï¼šæ‰‹è…•RGBå›¾åƒ `I_w`ã€å…¨å±€RGBå›¾åƒ `I_f`ã€è¯­è¨€æŒ‡ä»¤ `T`ã€å®æ—¶åŠ›/åŠ›çŸ© `F`ã€‚<br>â€¢ **VLMæ¨¡å‹**ï¼šä½¿ç”¨ChatGPT-4o-miniï¼ˆå†»ç»“å‚æ•°ï¼‰ã€‚<br>â€¢ **è¾“å‡º**ï¼šåˆ†ç±»çš„æ¥è§¦ç›¸ä½æ ‡ç­¾ã€‚ |\n| **3. VLMå¼•å¯¼çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥é˜»æŠ—å‚æ•°ç”Ÿæˆ** | å°†è¯­ä¹‰ç†è§£è½¬åŒ–ä¸ºå…·ä½“çš„åˆšåº¦(K)ã€é˜»å°¼(D)å‚æ•°ï¼Œå®ç°å„å‘å¼‚æ€§å’Œç›¸ä½è‡ªé€‚åº”çš„é˜»æŠ—è°ƒèŠ‚ã€‚ | **æ ¸å¿ƒå…¬å¼**ï¼š<br>1. **æœ€ç»ˆåˆšåº¦è®¡ç®—**ï¼š`K_p_final = K_p_VLM Â· Î±_force` <br> &nbsp;&nbsp;&nbsp;&nbsp;â€¢ `K_p_VLM`ï¼šVLMæ ¹æ®ä¸Šä¸‹æ–‡å»ºè®®çš„åˆšåº¦å€¼ã€‚<br> &nbsp;&nbsp;&nbsp;&nbsp;â€¢ `Î±_force âˆˆ [0.2, 1]`ï¼šåŸºäºå®æ—¶åŠ›åé¦ˆçš„ç¼©æ”¾å› å­ã€‚å½“æµ‹é‡åŠ›è¶…è¿‡å®‰å…¨é˜ˆå€¼æ—¶é™ä½åˆšåº¦ï¼Œç¡®ä¿å®‰å…¨ã€‚<br>2. **æœ€ç»ˆé˜»å°¼è®¡ç®—**ï¼š`D_p_final = 2 * sqrt(K_p_final Â· M_eff) Â· Î¶` <br> &nbsp;&nbsp;&nbsp;&nbsp;â€¢ `M_eff`ï¼šæœ‰æ•ˆè´¨é‡ã€‚<br> &nbsp;&nbsp;&nbsp;&nbsp;â€¢ `Î¶ = 0.7`ï¼šé˜»å°¼æ¯”ï¼Œç¡®ä¿æ¥è¿‘ä¸´ç•Œé˜»å°¼ï¼Œå“åº”å¹³ç¨³æ— æŒ¯è¡ã€‚<br>3. **æ–¹å‘åˆšåº¦çŸ©é˜µ**ï¼š`K = diag(k_x, k_y, k_z)`ï¼Œ é˜»å°¼çŸ©é˜µåŒç†ï¼š`D = diag(D_x, D_y, D_z)`ã€‚VLMå¯ç”Ÿæˆå„å‘å¼‚æ€§çš„å€¼ï¼ˆå¦‚æ²¿è¿åŠ¨æ–¹å‘åˆšåº¦ä½ï¼Œå‚ç›´æ–¹å‘åˆšåº¦é«˜ä»¥ä¿æŒå¯¹é½ï¼‰ã€‚<br>4. **å§¿æ€åˆšåº¦/é˜»å°¼**ï¼šä¸å¹³ç§»åˆšåº¦æˆæ¯”ä¾‹ã€‚<br> &nbsp;&nbsp;&nbsp;&nbsp;â€¢ `K_o^i = Îµ * k^i`, å…¶ä¸­ `Îµ = 0.15`ã€‚<br> &nbsp;&nbsp;&nbsp;&nbsp;â€¢ `D_o^i = 2 * Î¶ * sqrt(K_o^i)`ã€‚ | â€¢ **ç›¸ä½-é˜»æŠ—æ˜ å°„è§„åˆ™**ï¼š<br> &nbsp;&nbsp;- **Free_motion**ï¼šæœ€é«˜åˆšåº¦ï¼ˆç²¾ç¡®ä½ç½®æ§åˆ¶ï¼‰ã€‚<br> &nbsp;&nbsp;- **Approaching**ï¼šä¸­ç­‰åˆšåº¦ï¼ˆå‘é¡ºåº”æ€§è¿‡æ¸¡ï¼‰ã€‚<br> &nbsp;&nbsp;- **Contact**ï¼šæœ€ä½åˆšåº¦ï¼ˆæœ€å¤§é¡ºåº”æ€§ï¼‰ã€‚<br> &nbsp;&nbsp;- **Retreat**ï¼šä¸­ç­‰åˆšåº¦ï¼ˆå—æ§æ’¤å›ï¼‰ã€‚<br>â€¢ **åŠ›ç¼©æ”¾å› å­** `Î±_force`ï¼šæ ¹æ®å®æµ‹åŠ›ä¸å®‰å…¨é˜ˆå€¼ï¼ˆå¦‚30Nï¼‰åŠ¨æ€è°ƒæ•´ã€‚<br>â€¢ **é˜»æŠ—æ›´æ–°é¢‘ç‡**ï¼šæ¯2ä¸ªVLAåŠ¨ä½œæ­¥ï¼ˆçº¦0.5ç§’ï¼‰æŸ¥è¯¢ä¸€æ¬¡VLMã€‚ |\n| **4. å®æ—¶åŠ›åé¦ˆå®‰å…¨è°ƒèŠ‚å±‚** | æä¾›æœ€åä¸€å±‚å®‰å…¨ä¿éšœï¼Œé˜²æ­¢VLMå»ºè®®çš„å‚æ•°åœ¨æ„å¤–æ¥è§¦ä¸‹ä»ä¸å®‰å…¨ã€‚ | **åŸç†**ï¼šåœ¨VLMå»ºè®®çš„åˆšåº¦åŸºç¡€ä¸Šï¼Œå¼•å…¥ä¸€ä¸ªä¸å®æ—¶æ¥è§¦åŠ› `F_meas` è´Ÿç›¸å…³çš„ç¼©æ”¾å› å­ `Î±_force`ã€‚è¿™æ˜¯ä¸€ä¸ª**ååº”å¼è°ƒèŠ‚**ï¼Œç‹¬ç«‹äºVLMçš„å‰é¦ˆå¼è¯­ä¹‰æ¨ç†ã€‚å½“ `F_meas` æ¥è¿‘æˆ–è¶…è¿‡è®¾å®šé˜ˆå€¼æ—¶ï¼Œ`Î±_force` å‡å°ï¼Œä»è€Œé™ä½æ•´ä½“åˆšåº¦ï¼Œä½¿æœºå™¨äººæ›´â€œæŸ”è½¯â€ï¼Œé™åˆ¶æ¥è§¦åŠ›ã€‚ | â€¢ **åŠ›ä¼ æ„Ÿå™¨**ï¼šä½¿ç”¨è…•éƒ¨å…­ç»´åŠ›/åŠ›çŸ©ä¼ æ„Ÿå™¨ï¼Œé‡‡æ ·ç‡1000 Hzã€‚<br>â€¢ **å®‰å…¨é˜ˆå€¼**ï¼šè®ºæ–‡ä¸­è®¾å®šä¸º30Nï¼ˆå¯æ ¹æ®ä»»åŠ¡è°ƒæ•´ï¼‰ã€‚<br>â€¢ **å¤±è´¥åˆ¤å®š**ï¼šè¿ç»­3æ¬¡è¶…è¿‡åŠ›é˜ˆå€¼åˆ™ç»ˆæ­¢ä»»åŠ¡ã€‚ |\n| **5. ç³»ç»Ÿé›†æˆä¸éƒ¨ç½²** | å®ç°ä»¿çœŸä¸çœŸå®ç¡¬ä»¶çš„é«˜æ•ˆã€ç¨³å®šè¿è¡Œã€‚ | **ä»¿çœŸ**ï¼šåœ¨LIBEROå’ŒManiSkillåŸºå‡†çš„8ä¸ªæ¥è§¦å¯†é›†ä»»åŠ¡ä¸­æµ‹è¯•ã€‚<br>**çœŸæœº**ï¼š<br>â€¢ **ç¡¬ä»¶**ï¼š7è‡ªç”±åº¦Franka Emika Pandaæœºæ¢°è‡‚ï¼Œè…•éƒ¨æ­è½½RealSense D435iç›¸æœºï¼Œå…¨å±€Logitech USBç›¸æœºã€‚<br>â€¢ **è½¯ä»¶æ¶æ„**ï¼šå®¢æˆ·ç«¯-æœåŠ¡å™¨æ¨¡å¼ã€‚å®¢æˆ·ç«¯ï¼ˆUbuntuå®æ—¶å†…æ ¸ï¼‰è´Ÿè´£æ•°æ®é‡‡é›†å’Œåº•å±‚æ§åˆ¶ï¼›æœåŠ¡å™¨ï¼ˆGPUï¼‰è¿è¡ŒVLAå’ŒVLMæ¨¡å‹ã€‚<br>â€¢ **é€šä¿¡**ï¼šé‡‡ç”¨è½»é‡çº§WebSocketåè®®ï¼Œè€ŒéROSï¼Œä»¥æé«˜çµæ´»æ€§ã€‚<br>â€¢ **åŠ¨ä½œæ’å€¼**ï¼šå¯¹VLAè¿”å›çš„åŠ¨ä½œåºåˆ—è¿›è¡Œæ’å€¼ï¼Œç”Ÿæˆç¨ å¯†çš„ä¸­é—´æŒ‡ä»¤ï¼Œä¿è¯æ§åˆ¶å¹³æ»‘ã€‚ | â€¢ **å›¾åƒé¢„å¤„ç†**ï¼šç»Ÿä¸€ç¼©æ”¾è‡³224Ã—224åƒç´ ã€‚<br>â€¢ **VLAåŸºçº¿æ¨¡å‹**ï¼šå¯¹æ¯”æµ‹è¯•äº†Pi0ï¼ˆæµåŒ¹é…ï¼‰ã€RDT-1Bï¼ˆæ‰©æ•£æ¨¡å‹ï¼‰ã€OpenVLA-oftï¼ˆä¼˜åŒ–å¾®è°ƒï¼‰ã€‚<br>â€¢ **çœŸæœºç­–ç•¥**ï¼šä¸ºç¼“è§£VLAçš„â€œç°å®é¸¿æ²Ÿâ€ï¼Œä»…ä½¿ç”¨VLAåŠ¨ä½œå—çš„å‰ä¸¤ä¸ªåŠ¨ä½œï¼Œå¹¶å¯¹è¾“å‡ºåŠ¨ä½œè¿›è¡Œè£å‰ªä»¥ä¿æŒç¨³å®šã€‚ |\n\n### **æŠ€æœ¯æ–¹æ³•æ€»ç»“ä¸åˆ›æ–°ç‚¹**\n1.  **èŒƒå¼åˆ›æ–°**ï¼šé¦–æ¬¡ç³»ç»Ÿåœ°å°†**VLMä½œä¸ºâ€œé˜»æŠ—æ•™ç»ƒâ€** åµŒå…¥ç»å…¸VICæ¡†æ¶ï¼Œå®ç°äº†**è¯­ä¹‰ç†è§£åˆ°ç‰©ç†é¡ºåº”æ€§å‚æ•°çš„é›¶æ ·æœ¬æ˜ å°„**ã€‚\n2.  **æ··åˆæ¨ç†**ï¼šç»“åˆäº†VLMçš„**å‰é¦ˆè¯­ä¹‰æ¨ç†**ï¼ˆåŸºäºè§†è§‰å’Œä»»åŠ¡æè¿°ï¼‰ä¸åŠ›ä¼ æ„Ÿå™¨çš„**åé¦ˆååº”å¼è°ƒèŠ‚**ï¼Œå…¼é¡¾äº†ä¸Šä¸‹æ–‡é€‚åº”æ€§å’Œå®‰å…¨æ€§ã€‚\n3.  **å„å‘å¼‚æ€§ä¸ç›¸ä½è‡ªé€‚åº”**ï¼šé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æç¤ºè¯ï¼Œä½¿VLMèƒ½ç†è§£ä»»åŠ¡é˜¶æ®µå’Œè¿åŠ¨æ–¹å‘ï¼Œç”Ÿæˆ**éå„å‘åŒæ€§çš„ã€ä¸ä»»åŠ¡é€»è¾‘åŒ¹é…çš„é˜»æŠ—å‚æ•°**ã€‚\n4.  **å³æ’å³ç”¨**ï¼šè¯¥æ–¹æ³•ä½œä¸ºä¸€ä¸ªç‹¬ç«‹çš„â€œé€‚é…å™¨â€ï¼ˆAdaptorï¼‰ï¼Œæ— éœ€é‡æ–°è®­ç»ƒåº•å±‚VLAæ¨¡å‹ï¼Œå¯ç›´æ¥å¢å¼ºç°æœ‰SOTA VLAæ¨¡å‹åœ¨æ¥è§¦ä»»åŠ¡ä¸­çš„å®‰å…¨æ€§ã€‚\n\n### **å®é™…ä»·å€¼**\n- **æå‡å®‰å…¨æ€§**ï¼šå°†åŸºçº¿VLAæ¨¡å‹åœ¨åŠ›çº¦æŸä¸‹çš„å¹³å‡ä»»åŠ¡æˆåŠŸç‡ä» **9.86%** æå‡è‡³ **17.29%**ï¼Œå¹¶å°†æ•…éšœæ¨¡å¼ä»â€œåŠ›è¶…é™å¯¼è‡´çš„ç¾éš¾æ€§å¤±è´¥â€è½¬å˜ä¸ºâ€œè½»å¾®é”™ä½æˆ–æ»‘ç§»â€ï¼Œå®ç°äº†**ä¼˜é›…é™çº§**ã€‚\n- **å¢å¼ºé€šç”¨æ€§**ï¼šåˆ©ç”¨é¢„è®­ç»ƒVLMçš„æ³›åŒ–èƒ½åŠ›ï¼Œæœ‰æœ›å°†å®‰å…¨çš„é¡ºåº”æ€§æ§åˆ¶æ¨å¹¿åˆ°æœªè§è¿‡çš„ç‰©ä½“å’Œåœºæ™¯ä¸­ã€‚\n- **æ¨åŠ¨å®ç”¨åŒ–**ï¼šä¸ºå½“å‰ç¼ºä¹åŠ›æ„ŸçŸ¥çš„VLAæ¨¡å‹éƒ¨ç½²åˆ°çœŸå®ç‰©ç†ä¸–ç•Œæä¾›äº†ä¸€ä¸ªåˆ‡å®å¯è¡Œçš„å®‰å…¨æ¨¡å—è§£å†³æ–¹æ¡ˆã€‚",
            "timestamp": "2026-01-27T16:12:27.260502",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "ä»–ä½¿ç”¨äº†å“ªäº›è¯„ä»·æŒ‡æ ‡ä¸æ•°æ®é›†ï¼Œåˆ—è¡¨æ ¼å…·ä½“è®²è®²ä»–çš„è¯„ä»·æŒ‡æ ‡çš„ç»†èŠ‚ä¸æ•°æ®é›†çš„ç»†èŠ‚",
            "answer": "## è®ºæ–‡è¯„ä»·æŒ‡æ ‡ä¸æ•°æ®é›†åˆ†æ\n\n### ä¸€ã€ ä¸»è¦è¯„ä»·æŒ‡æ ‡\n\nè¯¥è®ºæ–‡é‡‡ç”¨äº†ä¸€å¥—ä»¥**ä»»åŠ¡æˆåŠŸç‡**ä¸ºæ ¸å¿ƒï¼Œå¹¶ç»“åˆ**å®‰å…¨çº¦æŸ**çš„é‡åŒ–è¯„ä¼°ä½“ç³»ã€‚å…·ä½“æŒ‡æ ‡ç»†èŠ‚å¦‚ä¸‹ï¼š\n\n| è¯„ä»·æŒ‡æ ‡ | å®šä¹‰ä¸è®¡ç®—æ–¹å¼ | æµ‹é‡ç»†èŠ‚ä¸ç›®çš„ |\n| :--- | :--- | :--- |\n| **ä»»åŠ¡æˆåŠŸç‡** | åœ¨è®¾å®šçš„æ—¶é—´é™åˆ¶å’Œ**å®‰å…¨çº¦æŸï¼ˆåŠ›é˜ˆå€¼ï¼‰** ä¸‹ï¼ŒæˆåŠŸå®Œæˆä»»åŠ¡çš„è¯•éªŒæ¬¡æ•°å æ€»è¯•éªŒæ¬¡æ•°çš„ç™¾åˆ†æ¯”ã€‚ | **æ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡**ã€‚ç”¨äºè¡¡é‡æ–¹æ³•åœ¨å¤æ‚æ¥è§¦ä»»åŠ¡ä¸­çš„æ•´ä½“æœ‰æ•ˆæ€§ã€‚æˆåŠŸçš„å‰ææ˜¯**å¿…é¡»æ»¡è¶³å®‰å…¨çº¦æŸ**ã€‚ |\n| **æ¥è§¦åŠ›é˜ˆå€¼è¿è§„** | è®°å½•æœ«ç«¯æ‰§è¡Œå™¨ä¸ç¯å¢ƒä¸­ç‰©ä½“æ¥è§¦æ—¶ï¼Œåœ¨ä»»ä¸€æ–¹å‘ï¼ˆFx, Fy, Fzï¼‰ä¸Šæµ‹å¾—çš„åŠ›**è¿ç»­ä¸‰æ¬¡è¶…è¿‡30N**çš„è¿è§„äº‹ä»¶ã€‚ | **æ ¸å¿ƒå®‰å…¨æŒ‡æ ‡**ã€‚ä¸€æ—¦å‘ç”Ÿï¼Œä»»åŠ¡ç«‹å³ç»ˆæ­¢å¹¶è®°ä¸ºå¤±è´¥ã€‚è¯¥æŒ‡æ ‡ç›´æ¥åæ˜ äº†æ–¹æ³•åœ¨ç‰©ç†äº¤äº’ä¸­çš„å®‰å…¨æ€§ï¼Œæ˜¯è®ºæ–‡æ—¨åœ¨è§£å†³çš„å…³é”®é—®é¢˜ã€‚ |\n| **åŠ›/åˆšåº¦æ›²çº¿åˆ†æ** | åœ¨ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œå®æ—¶è®°å½•å¹¶ç»˜åˆ¶**æ¥è§¦åŠ›**å’Œ**è‡ªé€‚åº”åˆšåº¦å‚æ•°**éšæ—¶é—´å˜åŒ–çš„æ›²çº¿ã€‚ | **è¿‡ç¨‹åˆ†ææŒ‡æ ‡**ã€‚ç”¨äºç›´è§‚å±•ç¤ºCompliantVLA-adaptorå¦‚ä½•æ ¹æ®ä»»åŠ¡é˜¶æ®µå’Œå®æ—¶åŠ›åé¦ˆåŠ¨æ€è°ƒèŠ‚é˜»æŠ—ï¼ˆåˆšåº¦ï¼‰ï¼Œä»è€Œå®ç°åŠ›çš„æŸ”é¡ºè°ƒèŠ‚ã€‚ |\n\n**å…³é”®ç»†èŠ‚ä¸å®éªŒåè®®ï¼š**\n1.  **ä¸¤é˜¶æ®µå¯¹æ¯”**ï¼šæ‰€æœ‰å®éªŒå‡åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µè¿›è¡Œå…¬å¹³æ¯”è¾ƒï¼š\n    *   **é˜¶æ®µ1 (åŸºçº¿)**ï¼šç›´æ¥è¿è¡ŒåŸå§‹VLAæ¨¡å‹ï¼ˆPi0, RDT-1B, OpenVLA-oftï¼‰ï¼Œä½¿ç”¨å…¶é»˜è®¤çš„ä½ç½®/è½¨è¿¹æ§åˆ¶å™¨ï¼Œæ— ä¸»åŠ¨åŠ›é€‚åº”ã€‚\n    *   **é˜¶æ®µ2 (é€‚é…å)**ï¼šå°†ç›¸åŒVLAæ¨¡å‹ä¸**CompliantVLA-adaptor**é›†æˆï¼Œç”¨å…¶VLMå¢å¼ºçš„å¯å˜é˜»æŠ—æ§åˆ¶å™¨ï¼ˆVICï¼‰æ›¿æ¢åŸæœ‰çš„åº•å±‚æ§åˆ¶å™¨ã€‚\n2.  **ç»Ÿä¸€å®‰å…¨æ ‡å‡†**ï¼šä¸¤ä¸ªé˜¶æ®µé‡‡ç”¨**å®Œå…¨ç›¸åŒçš„åŠ›å®‰å…¨æ ‡å‡†ï¼ˆ30Né˜ˆå€¼ï¼‰** å’Œç»ˆæ­¢æ¡ä»¶ï¼Œç¡®ä¿æ€§èƒ½æå‡å®Œå…¨å½’å› äºé€‚é…å™¨å¸¦æ¥çš„åˆè§„æ€§ï¼Œè€Œéå®½æ¾çš„è¯„åˆ¤æ ‡å‡†ã€‚\n\n### äºŒã€ ä½¿ç”¨çš„æ•°æ®é›†ä¸ä»»åŠ¡\n\nè®ºæ–‡æ²¡æœ‰ä½¿ç”¨ä¼ ç»Ÿçš„é™æ€æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œè€Œæ˜¯æ„å»ºäº†ä¸€ä¸ª**åŸºäºä»¿çœŸä¸çœŸå®ç¯å¢ƒçš„ä»»åŠ¡å¥—ä»¶**è¿›è¡Œè¯„ä¼°ã€‚å…¶â€œæ•°æ®é›†â€æœ¬è´¨ä¸Šæ˜¯ç”¨äºæµ‹è¯•çš„ä¸€ç³»åˆ—æ¥è§¦å¯†é›†å‹æ“ä½œä»»åŠ¡ã€‚\n\n#### 1. ä»¿çœŸä»»åŠ¡ï¼ˆä¸»è¦è¯„ä¼°åœºæ™¯ï¼‰\n*   **æ¥æºåŸºå‡†**ï¼šä»**LIBERO** å’Œ **ManiSkill** è¿™ä¸¤ä¸ªä¸»æµçš„æœºå™¨äººæ“ä½œåŸºå‡†ä¸­é€‰å–ã€‚\n*   **ä»»åŠ¡é€‰æ‹©é€»è¾‘**ï¼šä¸ºé¿å…å†—ä½™å’Œèµ„æºé™åˆ¶ï¼Œå¹¶æœªä½¿ç”¨å…¨éƒ¨100+ä¸ªä»»åŠ¡ï¼Œè€Œæ˜¯ç²¾å¿ƒæŒ‘é€‰äº†**8ä¸ªå…·æœ‰ä»£è¡¨æ€§çš„æ¥è§¦å¯†é›†å‹ä»»åŠ¡**ï¼Œæ¶µç›–äº†å¤šç§æ¥è§¦åŠ¨åŠ›å­¦åœºæ™¯ã€‚\n*   **ä»»åŠ¡åˆ—è¡¨ä¸ç»†èŠ‚**ï¼š\n\n| ä»»åŠ¡ç¼–å· | ä»»åŠ¡æè¿° (æŒ‡ä»¤) | ä»»åŠ¡ç±»å‹ä¸æ¥è§¦æŒ‘æˆ˜ |\n| :--- | :--- | :--- |\n| **T1** | æ‹¾å–æ©™ç™½ç›¸é—´çš„é”€é’‰ï¼Œå°†æ©™è‰²ç«¯æ’å…¥å¸¦å­”çš„ç›’å­ä¸­ã€‚ | **ç²¾å¯†æ’å…¥**ï¼šéœ€è¦å¯¹å‡†å’ŒæŸ”é¡ºçš„è½´å‘åŠ›ä»¥é¿å…å¡æ­»æˆ–æŸåã€‚ |\n| **T2** | æ‹¾å–æ¿/å¥—ä»¶ä¸Šæ”¾é”™ä½ç½®çš„å½¢çŠ¶å—ï¼Œå°†å…¶æ’å…¥æ­£ç¡®çš„ç©ºæ§½ä¸­ã€‚ | **å½¢çŠ¶åŒ¹é…ä¸æ’å…¥**ï¼šæ¶‰åŠå‡ ä½•å¯¹é½å’Œæ¥è§¦åŠ›ç®¡ç†ã€‚ |\n| **T3** | ä»æœ¨æŸœé¡¶å±‚æŠ½å±‰ä¸­å–å‡ºé»‘è‰²ç¢—ï¼Œå¹¶å°†å…¶æ”¾åœ¨ç›˜å­ä¸Šã€‚ | **å—é™ç©ºé—´æ“ä½œ**ï¼šæ¶‰åŠæ‰“å¼€æŠ½å±‰ã€åœ¨ç‹­çª„ç©ºé—´æŠ“å–å’Œæ”¾ç½®ã€‚ |\n| **T4** | æ‰“å¼€æŸœå­çš„ä¸­é—´æŠ½å±‰ã€‚ | **æ‹‰åŠ¨æ“ä½œ**ï¼šéœ€è¦å…‹æœé™æ‘©æ“¦åŠ›å¹¶æ–½åŠ åˆé€‚çš„åŠ›ï¼Œé¿å…ç”¨åŠ›è¿‡çŒ›ã€‚ |\n| **T5** | æ‰“å¼€é¡¶å±‚æŠ½å±‰å¹¶å°†ç¢—æ”¾å…¥å…¶ä¸­ã€‚ | **å¤åˆä»»åŠ¡**ï¼šç»“åˆäº†æ‰“å¼€æŠ½å±‰å’Œæ”¾ç½®ç‰©ä½“ä¸¤ç§æ¥è§¦åœºæ™¯ã€‚ |\n| **T6** | å°†ç›˜å­æ¨åˆ°ç‚‰ç¶å‰æ–¹ã€‚ | **æ¨åŠ¨æ“ä½œ**ï¼šéœ€è¦ç»´æŒç¨³å®šçš„æ¥è§¦åŠ›ä»¥æ»‘åŠ¨ç‰©ä½“ï¼Œé˜²æ­¢æ‰“æ»‘æˆ–å€¾è¦†ã€‚ |\n| **T7** | å°†é»‘è‰²ç¢—æ”¾å…¥æŸœå­åº•å±‚æŠ½å±‰å¹¶å…³é—­å®ƒã€‚ | **å¤åˆä»»åŠ¡**ï¼šæ¶‰åŠæ”¾ç½®å’Œå…³é—­æŠ½å±‰ï¼Œåè€…éœ€è¦ç²¾ç¡®çš„æ¥è§¦åŠ›ç»ˆæ­¢ã€‚ |\n| **T8** | å°†é»„ç™½ç›¸é—´çš„æ¯å­æ”¾å…¥å¾®æ³¢ç‚‰å¹¶å…³é—­ç‚‰é—¨ã€‚ | **é“°é“¾é—¨æ“ä½œä¸æ”¾ç½®**ï¼šæ¶‰åŠä¸¤ç§ä¸åŒçš„æ¥è§¦äº¤äº’ï¼ˆå…³é—¨å’Œæ”¾ç½®ï¼‰ã€‚ |\n\n#### 2. çœŸå®ä¸–ç•Œå®éªŒä»»åŠ¡\n*   **ç¡¬ä»¶å¹³å°**ï¼š7è‡ªç”±åº¦Franka Emika Pandaæœºæ¢°è‡‚ï¼Œé…å¤‡è…•éƒ¨å…­ç»´åŠ›/æ‰­çŸ©ä¼ æ„Ÿå™¨å’ŒåŒæ‘„åƒå¤´ï¼ˆå…¨å±€è§†è§’+è…•éƒ¨è§†è§’ï¼‰ã€‚\n*   **ä»»åŠ¡åˆ—è¡¨**ï¼šè®¾è®¡äº†6ä¸ªçœŸå®ä¸–ç•Œä»»åŠ¡è¿›è¡Œåˆæ­¥éªŒè¯ï¼ˆå¦‚ä¸‹è¡¨ï¼‰ã€‚ä½†ç”±äºå½“å‰VLAæ¨¡å‹å­˜åœ¨â€œç°å®å·®è·â€å’Œé›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ï¼Œ**å¤§å¤šæ•°ä»»åŠ¡æœªèƒ½æˆåŠŸå®Œæˆ**ã€‚è®ºæ–‡ä¸»è¦å±•ç¤ºäº†å…¶ä¸­ä¸€ä¸ªç®€åŒ–ä»»åŠ¡çš„æˆåŠŸæ¡ˆä¾‹ã€‚\n*   **æˆåŠŸæ¡ˆä¾‹è¯¦æƒ…**ï¼š\n    *   **ä»»åŠ¡æŒ‡ä»¤**ï¼š`â€œkeep pushing the red box straight aheadâ€`ï¼ˆæŒç»­å‘å‰æ¨çº¢è‰²ç›’å­ï¼‰ã€‚\n    *   **ç®€åŒ–ç­–ç•¥**ï¼šä¸ºé¿å…VLAæ¨¡å‹åœ¨æŠ“å–å’Œç²¾å¯†ç§»åŠ¨ä¸Šçš„è¯¯å·®ï¼Œè¯¥ä»»åŠ¡ä¸“æ³¨äºå±•ç¤º**ç‰©ç†æ¥è§¦åœºæ™¯ä¸‹çš„åŠ›è°ƒèŠ‚èƒ½åŠ›**ã€‚ä½œè€…é‡‡ç”¨äº†é™åˆ¶VLAè¾“å‡ºåŠ¨ä½œæ­¥æ•°å’Œå¹…å€¼ç­‰ç­–ç•¥æ¥ç¨³å®šæ§åˆ¶ã€‚\n    *   **å±•ç¤ºå†…å®¹**ï¼šæˆåŠŸè®°å½•äº†ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­çš„**åˆšåº¦è°ƒèŠ‚æ›²çº¿**å’Œ**å®æµ‹æ¥è§¦åŠ›æ›²çº¿**ï¼Œç›´è§‚è¯æ˜äº†é€‚é…å™¨åœ¨çœŸå®ç¯å¢ƒä¸­è°ƒèŠ‚åŠ›ã€ä¿éšœå®‰å…¨çš„èƒ½åŠ›ã€‚\n\n| çœŸå®ä»»åŠ¡ç¼–å· | ä»»åŠ¡æŒ‡ä»¤ |\n| :--- | :--- |\n| 1 | æŒç»­å‘å‰æ¨çº¢è‰²ç›’å­ |\n| 2 | æ‹¾å–é»‘è‰²æ¡Œå­ä¸Šçš„ç»¿è‰²ç¢— |\n| 3 | å…³é—­ä¸­é—´æŠ½å±‰ |\n| 4 | æ‹¾å–é»‘è‰²ç¢—å¹¶å°†å…¶æ”¾åˆ°çº¢è‰²ç›’å­ä¸Š |\n| 5 | æ‹¾å–ç•ªèŒ„é…±å¹¶å°†å…¶æ”¾åˆ°çº¢è‰²ç›’å­ä¸Š |\n| 6 | æ‹¾å–æ‘©å¡å£¶å¹¶å°†å…¶æ”¾åˆ°çº¢è‰²ç›’å­ä¸Š |\n| 7 | æ‹¾å–ä¹¦æœ¬å¹¶å°†å…¶æ”¾å…¥æŠ½å±‰ |\n\n### æ€»ç»“\nè¯¥è®ºæ–‡çš„è¯„ä»·ä½“ç³»ç´§å¯†å›´ç»•å…¶**æŠ€æœ¯åˆ›æ–°ç‚¹â€”â€”å®‰å…¨åˆè§„çš„æ¥è§¦æ“ä½œ**è€Œè®¾è®¡ã€‚**ä»»åŠ¡æˆåŠŸç‡**åœ¨**ä¸¥æ ¼çš„åŠ›å®‰å…¨çº¦æŸä¸‹**è¿›è¡Œè®¡ç®—ï¼Œä½¿å…¶æˆä¸ºè¡¡é‡â€œå®‰å…¨æœ‰æ•ˆæ€§â€çš„ç»¼åˆæŒ‡æ ‡ã€‚**åŠ›é˜ˆå€¼è¿è§„**æ˜¯ç›´æ¥çš„å®‰å…¨åº¦é‡ã€‚è¯„ä¼°æ‰€ä½¿ç”¨çš„**ä»»åŠ¡å¥—ä»¶**ï¼ˆä»¿çœŸ8ä»»åŠ¡+çœŸå®å¤šä»»åŠ¡ï¼‰åˆ™ä¸“é—¨é’ˆå¯¹â€œæ¥è§¦å¯†é›†å‹â€åœºæ™¯è®¾è®¡ï¼Œæœ‰æ•ˆéªŒè¯äº†æ–¹æ³•åœ¨éœ€è¦åŠ›äº¤äº’çš„å¤æ‚æ“ä½œä¸­çš„æ³›åŒ–èƒ½åŠ›å’Œå®é™…ä»·å€¼ã€‚è®ºæ–‡å¦æ‰¿äº†å½“å‰VLAæ¨¡å‹åœ¨çœŸå®ä¸–ç•Œéƒ¨ç½²çš„å±€é™æ€§ï¼Œä½†é€šè¿‡ä»¿çœŸå…¨é¢è¯„ä¼°å’ŒçœŸå®ä¸–ç•Œåˆæ­¥éªŒè¯ï¼Œåšå®è¯æ˜äº†å…¶æå‡ºçš„é€‚é…å™¨ä½œä¸º**VLAæ¨¡å‹â€œå®‰å…¨æ’ä»¶â€çš„æœ‰æ•ˆæ€§**ã€‚",
            "timestamp": "2026-01-27T16:13:19.072458",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "è®ºæ–‡åœ¨å“ªäº›æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Ÿä¸»è¦çš„è¯„ä¼°æŒ‡æ ‡å’Œæ€§èƒ½æå‡æ˜¯å¤šå°‘ï¼Ÿ",
            "answer": "## å®éªŒæ•°æ®é›†ä¸è¯„ä¼°æŒ‡æ ‡åˆ†æ\n\n### ä¸€ã€å®éªŒæ•°æ®é›†\nè®ºæ–‡åœ¨**ä»¿çœŸ**å’Œ**çœŸå®ä¸–ç•Œ**ä¸¤ä¸ªç¯å¢ƒä¸­è¿›è¡Œäº†å®éªŒï¼Œä½¿ç”¨çš„æ•°æ®é›†å’Œä»»åŠ¡æ¥æºå¦‚ä¸‹ï¼š\n\n#### 1. ä»¿çœŸå®éªŒæ•°æ®é›†\n- **æ¥æºåŸºå‡†**ï¼š\n    - **LIBERO åŸºå‡†**ï¼ˆç”¨äºç»ˆèº«æœºå™¨äººå­¦ä¹ çŸ¥è¯†è¿ç§»çš„åŸºå‡†ï¼‰ã€‚\n    - **ManiSkill åŸºå‡†**ï¼ˆä¸“æ³¨äºæœºå™¨äººæ“ä½œæŠ€èƒ½çš„GPUå¹¶è¡ŒåŒ–ä»¿çœŸä¸æ¸²æŸ“åŸºå‡†ï¼‰ã€‚\n- **ä»»åŠ¡é€‰æ‹©**ï¼šä»ä¸Šè¿°åŸºå‡†çš„100+ä»»åŠ¡ä¸­ï¼Œé€‰å–äº†**8ä¸ªå…·æœ‰ä»£è¡¨æ€§çš„æ¥è§¦å¯†é›†å‹æ“ä½œä»»åŠ¡**ï¼Œä»¥é¿å…å†—ä½™å’Œèµ„æºé™åˆ¶ã€‚è¿™äº›ä»»åŠ¡æ¶µç›–äº†ï¼š\n    - ç²¾å¯†æ’å…¥ï¼ˆå¦‚**Peg Insertion**ï¼‰\n    - å½¢çŠ¶åŒ¹é…ï¼ˆå¦‚**Plug Charger**ï¼‰\n    - æŠ½å±‰å¼€åˆï¼ˆå¦‚**Open/Close Drawer**ï¼‰\n    - å—é™ç¯å¢ƒä¸­çš„ç‰©ä½“æ”¾ç½®ï¼ˆå¦‚**Microwave Env**ï¼‰\n- **å…·ä½“ä»»åŠ¡åˆ—è¡¨**ï¼ˆå¯¹åº”è®ºæ–‡è¡¨Iï¼‰ï¼š\n    1.  Peg Insertion\n    2.  Plug Charger\n    3.  Drawer Env (å–æ”¾ç¢—)\n    4.  Open Drawer (å¼€ä¸­å±‚æŠ½å±‰)\n    5.  Open Drawer (å¼€ä¸Šå±‚æŠ½å±‰å¹¶æ”¾å…¥ç¢—)\n    6.  Push Plate (æ¨ç›˜å­)\n    7.  Close Drawer (å…³æŠ½å±‰)\n    8.  Microwave Env (å°†æ¯å­æ”¾å…¥å¾®æ³¢ç‚‰å¹¶å…³é—¨)\n\n#### 2. çœŸå®ä¸–ç•Œå®éªŒ\n- **ç¡¬ä»¶å¹³å°**ï¼š7è‡ªç”±åº¦Franka Emika Pandaæœºæ¢°è‡‚ï¼Œé…å¤‡è…•éƒ¨åŠ›/åŠ›çŸ©ä¼ æ„Ÿå™¨å’ŒåŒæ‘„åƒå¤´ï¼ˆå…¨å±€Logitechæ‘„åƒå¤´ + è…•éƒ¨Intel RealSense D435iï¼‰ã€‚\n- **ä»»åŠ¡**ï¼šè®¾è®¡äº†6ä¸ªæ¥è§¦å¯†é›†å‹æ“ä½œä»»åŠ¡ï¼ˆè®ºæ–‡è¡¨IIï¼‰ï¼Œä¾‹å¦‚ï¼š\n    - `keep pushing the red box straight ahead`\n    - `pick up the green bowl on the black table`\n    - `close the middle drawer`\n    - ç­‰æ¶‰åŠæ‹¾å–ã€æ”¾ç½®ã€æ¨ã€å…³æŠ½å±‰çš„ä»»åŠ¡ã€‚\n\n### äºŒã€ä¸»è¦è¯„ä¼°æŒ‡æ ‡\n1.  **ä»»åŠ¡æˆåŠŸç‡**ï¼šåœ¨è®¾å®šçš„**æ¥è§¦åŠ›å®‰å…¨é˜ˆå€¼ï¼ˆ30Nï¼‰ä¸‹**ï¼Œä»»åŠ¡æˆåŠŸå®Œæˆçš„ç™¾åˆ†æ¯”ã€‚è¿™æ˜¯æ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡ã€‚\n2.  **åŠ›è¿è§„æ¬¡æ•°/é¢‘ç‡**ï¼šç›‘æ§æ‰§è¡Œè¿‡ç¨‹ä¸­æ¥è§¦åŠ›ï¼ˆ`Fx, Fy, Fz`ï¼‰è¶…è¿‡30Né˜ˆå€¼çš„æƒ…å†µã€‚å¦‚æœè¿ç»­ä¸‰æ¬¡è¶…è¿‡é˜ˆå€¼ï¼Œä»»åŠ¡ç«‹å³ç»ˆæ­¢å¹¶è®°ä¸ºå¤±è´¥ã€‚\n3.  **å®‰å…¨æ€§æ”¹è¿›**ï¼šé€šè¿‡æ¯”è¾ƒåŸºçº¿æ¨¡å‹ä¸CompliantVLA-adaptorçš„åŠ›è¿è§„æƒ…å†µï¼Œè¯„ä¼°å…¶æå‡å®‰å…¨æ€§çš„èƒ½åŠ›ã€‚\n4.  **å¤±è´¥æ¨¡å¼åˆ†æ**ï¼šè®ºæ–‡ç‰¹åˆ«æŒ‡å‡ºï¼Œå…¶æ–¹æ³•å°†å¤±è´¥æ¨¡å¼ä»åŸºçº¿çš„**ç¾éš¾æ€§åŠ›è¿è§„**ï¼ˆå¦‚ç‰©ä½“ç¿»å€’ã€æŸåï¼‰è½¬å˜ä¸º**ä¼˜é›…é™çº§**ï¼ˆå¦‚è½»å¾®é”™ä½ã€æ»‘åŠ¨ï¼‰ã€‚\n\n### ä¸‰ã€æ€§èƒ½æå‡ç»“æœ\n#### ä»¿çœŸå®éªŒç»“æœï¼ˆæ ¸å¿ƒå®šé‡æå‡ï¼‰\n- **å¯¹æ¯”åŸºçº¿**ï¼šä¸å½“å‰æœ€å…ˆè¿›çš„VLAæ¨¡å‹å¯¹æ¯”ï¼ŒåŒ…æ‹¬ï¼š\n    - **Pi0** (åŸºäºæµåŒ¹é…)\n    - **RDT-1B** (åŸºäºæ‰©æ•£çš„æœ€å¤§è§„æ¨¡æ¨¡å‹)\n    - **OpenVLA-oft** (OpenVLAçš„ä¼˜åŒ–å¾®è°ƒå˜ä½“)\n- **æ•´ä½“æˆåŠŸç‡æå‡**ï¼š\n    - **åŸºçº¿VLAæ¨¡å‹å¹³å‡æˆåŠŸç‡**ï¼š**9.86%** ï¼ˆåœ¨è€ƒè™‘30NåŠ›çº¦æŸä¸‹ï¼‰ã€‚\n    - **é›†æˆCompliantVLA-adaptoråå¹³å‡æˆåŠŸç‡**ï¼š**17.29%**ã€‚\n    - **ç›¸å¯¹æå‡**ï¼š**ç»å¯¹å€¼æå‡7.43ä¸ªç™¾åˆ†ç‚¹**ï¼Œ**ç›¸å¯¹æå‡çº¦75%**ã€‚\n- **ä»»åŠ¡å±‚é¢æå‡**ï¼š\n    - åœ¨8ä¸ªä»»åŠ¡ä¸­çš„**7ä¸ª**ä¸Šå–å¾—äº†æˆåŠŸç‡æå‡ã€‚\n    - å¯¹äºæ¶‰åŠ**æœºæ¢°çº¦æŸ**çš„ä»»åŠ¡ï¼ˆå¦‚æŠ½å±‰æ“ä½œã€æ—‹é’®æ¨åŠ¨ï¼‰ï¼Œæå‡æœ€ä¸ºæ˜¾è‘—ã€‚\n    - ä¾‹å¦‚ï¼Œåœ¨éƒ¨åˆ†åŸºçº¿æˆåŠŸç‡ä¸º0%çš„ä»»åŠ¡ä¸Šï¼Œæ–°æ–¹æ³•å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸç‡ã€‚\n- **å…³é”®è§‚å¯Ÿ**ï¼šåŸºçº¿VLAæ¨¡å‹åœ¨ä¸è€ƒè™‘åŠ›çº¦æŸçš„åŸå§‹è®ºæ–‡ä¸­å¯èƒ½è¡¨ç°è‰¯å¥½ï¼Œä½†**ä¸€æ—¦å¼•å…¥ç°å®çš„å®‰å…¨åŠ›çº¦æŸï¼ˆ30Nï¼‰ï¼Œå…¶æ€§èƒ½ä¼šæ€¥å‰§ä¸‹é™ç”šè‡³å½’é›¶**ã€‚è¿™å‡¸æ˜¾äº†æœ¬æ–‡æ–¹æ³•åœ¨**å®‰å…¨æ‰§è¡Œ**æ–¹é¢çš„å®é™…ä»·å€¼ã€‚\n\n#### çœŸå®ä¸–ç•Œå®éªŒç»“æœ\n- **ä¸»è¦æŒ‘æˆ˜**ï¼šç”±äºå½“å‰VLAæ¨¡å‹å­˜åœ¨â€œç°å®å·®è·â€å’Œé›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼Œè®¸å¤šä»»åŠ¡éš¾ä»¥å®Œæˆã€‚\n- **æˆåŠŸæ¡ˆä¾‹**ï¼šåœ¨ `keep pushing the red box straight ahead` ä»»åŠ¡ä¸­æˆåŠŸæ¼”ç¤ºã€‚\n- **æ ¸å¿ƒéªŒè¯**ï¼šå°½ç®¡æ•´ä½“ä»»åŠ¡æˆåŠŸç‡å—é™äºVLAæ¨¡å‹æœ¬èº«ï¼Œä½†**CompliantVLA-adaptoråœ¨çœŸå®ç¯å¢ƒä¸­è¢«è¯å®èƒ½æŒç»­é™ä½ä¸å®‰å…¨åŠ›**ï¼Œæœ‰æ•ˆå……å½“äº†**å®‰å…¨æ¨¡å—**ã€‚åŠ›/åˆšåº¦æ›²çº¿å›¾æ˜¾ç¤ºï¼Œç³»ç»Ÿèƒ½æ ¹æ®æ¥è§¦æƒ…å†µåŠ¨æ€è°ƒèŠ‚é˜»æŠ—ã€‚\n\n### æ€»ç»“\n**æŠ€æœ¯åˆ›æ–°ä»·å€¼**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒè´¡çŒ®ä¸åœ¨äºæå‡ºä¸€ä¸ªæ–°çš„VLAæ¨¡å‹ï¼Œè€Œæ˜¯è®¾è®¡äº†ä¸€ä¸ª**å³æ’å³ç”¨çš„é€‚é…å™¨**ã€‚å®ƒåˆ©ç”¨VLMçš„è¯­ä¹‰ç†è§£èƒ½åŠ›ï¼Œä¸ºç°æœ‰VLAæ¨¡å‹ç”Ÿæˆçš„ä½å§¿æŒ‡ä»¤ï¼ŒåŠ¨æ€é…å¤‡**ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å¯å˜é˜»æŠ—æ§åˆ¶**ï¼Œä»è€Œåœ¨**ä¸ç‰ºç‰²VLAæ³›åŒ–èƒ½åŠ›çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡äº†æ¥è§¦å¯†é›†å‹æ“ä½œçš„å®‰å…¨æ€§å’ŒæˆåŠŸç‡**ã€‚\n\n**å®é™…ä»·å€¼**ï¼šä¸ºè§£å†³VLAæ¨¡å‹ä»â€œè¯­ä¹‰ç†è§£â€åˆ°â€œå®‰å…¨ç‰©ç†äº¤äº’â€çš„è½åœ°é¸¿æ²Ÿæä¾›äº†ä¸€ä¸ªè½»é‡çº§ã€å¯å¤ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚å®éªŒæ•°æ®æœ‰åŠ›åœ°è¯æ˜äº†å…¶åœ¨ä»¿çœŸç¯å¢ƒä¸­å¯¹å®‰å…¨æ€§å’ŒæˆåŠŸç‡çš„åŒé‡æå‡ï¼Œå¹¶ä¸ºåœ¨çœŸå®æœºå™¨äººä¸Šå®‰å…¨éƒ¨ç½²VLAç³»ç»Ÿé“ºå¹³äº†é“è·¯ã€‚",
            "timestamp": "2026-01-27T16:14:01.062697",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "è®ºæ–‡çš„ä¸»è¦å±€é™æ€§æœ‰å“ªäº›ï¼Ÿæœªæ¥å¯èƒ½çš„æ”¹è¿›æ–¹å‘æ˜¯ä»€ä¹ˆï¼Ÿ",
            "answer": "## è®ºæ–‡ä¸»è¦å±€é™æ€§åˆ†æ\n\nåŸºäºå¯¹è®ºæ–‡å†…å®¹çš„åˆ†æï¼Œå…¶æå‡ºçš„ **CompliantVLA-adaptor** ç³»ç»Ÿå­˜åœ¨ä»¥ä¸‹å‡ ä¸ªæ ¸å¿ƒå±€é™æ€§ï¼š\n\n- **è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„å®æ—¶æ€§ä¸è®¡ç®—æˆæœ¬**\n    - **å»¶è¿Ÿé—®é¢˜**ï¼šVLM æ¨ç†é¢‘ç‡è¾ƒä½ï¼ˆçº¦ 1 Hzï¼‰ï¼Œæ— æ³•æ»¡è¶³é«˜é¢‘ï¼ˆå¦‚ 1000 Hzï¼‰åº•å±‚æ§åˆ¶å¯¹å®æ—¶æ€§çš„è¦æ±‚ã€‚è¿™é™åˆ¶äº†ç³»ç»Ÿåœ¨å¿«é€ŸåŠ¨æ€äº¤äº’åœºæ™¯ä¸­çš„å“åº”èƒ½åŠ›ã€‚\n    - **æˆæœ¬ä¸èƒ½æ•ˆ**ï¼šä¾èµ–äº‘ç«¯ API è°ƒç”¨ï¼ˆå¦‚ ChatGPT-4o-miniï¼‰æˆæœ¬é«˜æ˜‚ä¸”ä¸ç¯ä¿ã€‚è‹¥ä½¿ç”¨æœ¬åœ°éƒ¨ç½²çš„ VLMï¼Œåˆ™è®¡ç®—è´Ÿè½½æ²‰é‡ï¼Œéš¾ä»¥åœ¨èµ„æºå—é™çš„æœºå™¨äººå¹³å°ä¸Šéƒ¨ç½²ã€‚\n\n- **VLM ç”Ÿæˆçš„é˜»æŠ—å‚æ•°å¹¶éæœ€ä¼˜**\n    - **é¢†åŸŸçŸ¥è¯†ç¼ºå¤±**ï¼šVLMs å¹¶éä¸ºæœºå™¨äººä»»åŠ¡ä¸“é—¨è®­ç»ƒï¼Œå…¶ç”Ÿæˆçš„åˆšåº¦ï¼ˆ`K`ï¼‰å’Œé˜»å°¼ï¼ˆ`D`ï¼‰å‚æ•°å¯èƒ½ä¸æ˜¯ç‰¹å®šæ“ä½œåœºæ™¯ä¸‹çš„æœ€ä¼˜è§£ï¼Œæ›´å¤šæ˜¯åŸºäºè¯­ä¹‰æ¨ç†çš„â€œåˆç†â€çŒœæµ‹ã€‚\n    - **æ³›åŒ–èƒ½åŠ›å—é™**ï¼šå¯¹äºæœªè§è¿‡çš„ç‰©ä½“ã€ç¯å¢ƒæˆ–éå¸¸è§„çš„æ¥è§¦æ¨¡å¼ï¼ŒVLM å¯èƒ½æ— æ³•å‡†ç¡®æ¨æ–­å‡ºåˆé€‚çš„é˜»æŠ—å‚æ•°ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚\n\n- **åŸºç¡€ VLA æ¨¡å‹åœ¨ç°å®ä¸–ç•Œä¸­çš„æˆç†Ÿåº¦ä¸è¶³**\n    - **ç°å®å·®è·ï¼ˆReality Gapï¼‰**ï¼šå®éªŒè¡¨æ˜ï¼Œç°æœ‰çš„ VLA æ¨¡å‹ï¼ˆå¦‚ OpenVLA-oft, Pi0ï¼‰åœ¨ä»¿çœŸä¸­è¡¨ç°å°šå¯ï¼Œä½†**é›¶æ ·æœ¬ï¼ˆzero-shotï¼‰** è¿ç§»åˆ°çœŸå®ä¸–ç•Œæ—¶å¤±è´¥ç‡å¾ˆé«˜ï¼Œå¸¸å› æ¨¡å‹ä¸åŒ¹é…ã€åŠ¨ä½œç´¯ç§¯è¯¯å·®ç­‰é—®é¢˜æ— æ³•å®Œæˆç²¾ç¡®æ“ä½œã€‚\n    - **åŠ¨ä½œè¾“å‡ºä¸ç¨³å®š**ï¼šè®ºæ–‡ä¸­æåˆ°ï¼Œä¸ºåœ¨çœŸå®ä¸–ç•Œæµ‹è¯•ï¼Œä¸å¾—ä¸å¯¹ VLA çš„åŸå§‹è¾“å‡ºè¿›è¡Œå¤§å¹…è£å‰ªï¼ˆå¦‚ä»…ä½¿ç”¨å‰ä¸¤ä¸ªåŠ¨ä½œã€ç¼©å°åŠ¨ä½œèŒƒå›´ï¼‰ï¼Œè¿™æš´éœ²äº†å½“å‰ VLA æ¨¡å‹è¾“å‡ºç›´æ¥ç”¨äºå®é™…æ§åˆ¶çš„è„†å¼±æ€§ã€‚\n\n- **ç³»ç»Ÿé›†æˆä¸ä¾èµ–**\n    - **å¤šç³»ç»Ÿè€¦åˆ**ï¼šæ¶æ„ä¾èµ– VLA ç”ŸæˆåŠ¨ä½œã€VLM ç”Ÿæˆå‚æ•°ã€VIC æ‰§è¡Œæ§åˆ¶ï¼Œä»»ä½•ä¸€ç¯çš„æ•…éšœæˆ–å»¶è¿Ÿéƒ½ä¼šå½±å“æ•´ä½“æ€§èƒ½ã€‚\n    - **ä¼ æ„Ÿå™¨ä¾èµ–**ï¼šéœ€è¦è…•éƒ¨åŠ›/åŠ›çŸ©ä¼ æ„Ÿå™¨æä¾›å®æ—¶åé¦ˆã€‚è™½ç„¶è¿™å¢å¼ºäº†å®‰å…¨æ€§ï¼Œä½†ä¹Ÿå¢åŠ äº†ç³»ç»Ÿå¤æ‚æ€§å’Œç¡¬ä»¶æˆæœ¬ã€‚\n\n## æœªæ¥å¯èƒ½çš„æ”¹è¿›æ–¹å‘\n\né’ˆå¯¹ä¸Šè¿°å±€é™æ€§ï¼Œè®ºæ–‡æœ¬èº«åŠåç»­ç ”ç©¶å¯èƒ½æœä»¥ä¸‹æ–¹å‘å‘å±•ï¼š\n\n- **å¼€å‘è½»é‡åŒ–ã€æœºå™¨äººä¸“å±çš„ VLM**\n    - è®­ç»ƒæˆ–å¾®è°ƒä¸“ä¸ºæœºå™¨äººç‰©ç†äº¤äº’æ¨ç†è®¾è®¡çš„å°å‹ VLMï¼Œé™ä½è®¡ç®—å¼€é”€ï¼Œå®ç°æ›´é«˜é¢‘ç‡çš„åœ¨çº¿å‚æ•°ç”Ÿæˆã€‚\n    - æ¢ç´¢**æ¨¡å‹è’¸é¦**æŠ€æœ¯ï¼Œå°†å¤§å‹ VLM çš„è¯­ä¹‰æ¨ç†èƒ½åŠ›å‹ç¼©åˆ°æ›´é«˜æ•ˆçš„ç½‘ç»œä¸­ã€‚\n\n- **å°†é˜»æŠ—å‚æ•°å­¦ä¹ ä¸ VLA/VLM è¿›è¡Œç«¯åˆ°ç«¯è”åˆè®­ç»ƒ**\n    - ä¸å°† VLM ä½œä¸ºå†»ç»“çš„â€œå¤–æŒ‚â€æ¨¡å—ï¼Œè€Œæ˜¯å°†é˜»æŠ—å‚æ•°ç”Ÿæˆä½œä¸º VLA æ¨¡å‹è®­ç»ƒçš„ä¸€éƒ¨åˆ†ï¼Œè®©æ¨¡å‹ç›´æ¥å­¦ä¹ è¾“å‡º**åŠ¨ä½œ-é˜»æŠ—è”åˆæŒ‡ä»¤**ã€‚\n    - æ„å»ºåŒ…å«åŠ›/åŠ›çŸ©ä¸é˜»æŠ—æ ‡ç­¾çš„å¤§è§„æ¨¡æ•°æ®é›†ï¼Œç”¨äºå¾®è°ƒ VLA æˆ– VLMï¼Œä½¿å…¶å…·å¤‡æ›´å‡†ç¡®çš„ç‰©ç†äº¤äº’ç›´è§‰ã€‚\n\n- **å¢å¼ºåŸºç¡€ VLA æ¨¡å‹çš„ç°å®ä¸–ç•Œé²æ£’æ€§**\n    - å¯¹ VLA æ¨¡å‹è¿›è¡Œ**çœŸå®ä¸–ç•Œæ•°æ®å¾®è°ƒ**ï¼Œç¼©å°ä»¿çœŸä¸ç°å®ä¹‹é—´çš„å·®è·ã€‚\n    - å¼€å‘æ›´å¼ºå¤§çš„**åŠ¨ä½œåºåˆ—å¹³æ»‘ä¸çº é”™æ¨¡å—**ï¼Œå‡å°‘ VLA è¾“å‡ºåŠ¨ä½œçš„æŠ–åŠ¨å’Œç´¯ç§¯è¯¯å·®ï¼Œæå‡å…¶åœ¨çœŸå®æ§åˆ¶ä¸­çš„ç›´æ¥å¯ç”¨æ€§ã€‚\n\n- **æ¢ç´¢æ›´é«˜æ•ˆçš„å¤šæ¨¡æ€ä¿¡æ¯èåˆä¸å†³ç­–æ¶æ„**\n    - ç ”ç©¶å¦‚ä½•æ›´ç´§å¯†ã€æ›´ä½å»¶è¿Ÿåœ°èåˆè§†è§‰ã€è¯­è¨€ã€åŠ›è§‰ä¿¡æ¯ï¼Œå¯èƒ½é‡‡ç”¨**åˆ†å±‚æˆ–æ³¨æ„åŠ›æœºåˆ¶**ï¼Œè®©ä¸åŒé¢‘ç‡çš„æ¨¡å—ååŒæ›´é«˜æ•ˆã€‚\n    - è€ƒè™‘å°†éƒ¨åˆ†å†³ç­–ï¼ˆå¦‚ç´§æ€¥é¿éšœã€è¿‡åŠ›ä¿æŠ¤ï¼‰ä¸‹æ”¾åˆ°æ›´å¿«é€Ÿã€ç¡®å®šçš„ä¼ ç»Ÿæ§åˆ¶å±‚ï¼ŒVLM/VLA ä¸“æ³¨äºé«˜å±‚ç­–ç•¥å’Œå‚æ•°è§„åˆ’ã€‚\n\n- **æ‹“å±•åº”ç”¨åœºæ™¯ä¸è¯„ä¼°åŸºå‡†**\n    - åœ¨æ›´å¤æ‚ã€åŠ¨æ€çš„æ¥è§¦ä»»åŠ¡ä¸­æµ‹è¯•ç³»ç»Ÿï¼Œå¦‚éåˆšæ€§ç‰©ä½“æ“ä½œã€äººæœºåä½œç­‰ã€‚\n    - å»ºç«‹æ›´å…¨é¢çš„å®‰å…¨æ€§ä¸æ€§èƒ½è¯„ä¼°æŒ‡æ ‡ï¼Œä¸ä»…å…³æ³¨æˆåŠŸç‡ï¼Œä¹Ÿå…³æ³¨äº¤äº’çš„å¹³æ»‘åº¦ã€èƒ½è€—ç­‰ã€‚\n\n**æ€»ç»“**ï¼šæœ¬æ–‡çš„åˆ›æ–°ç‚¹åœ¨äºå·§å¦™åœ°åˆ©ç”¨ç°æˆçš„ VLM ä¸º VLA æ¨¡å‹å¢åŠ äº†â€œç‰©ç†å¸¸è¯†â€å’Œå®‰å…¨æ€§ï¼Œä½†å…¶å±€é™æ€§ä¹Ÿæºäºè¿™ç§â€œç»„è£…â€èŒƒå¼ã€‚æœªæ¥çš„æ ¹æœ¬æ–¹å‘æ˜¯æ¨åŠ¨ **VLA æ¨¡å‹æœ¬èº«çš„å†…ç”Ÿæ€§ç‰©ç†æ™ºèƒ½**ï¼Œä»¥åŠå‘å±•**é«˜æ•ˆã€ä¸“æœ‰çš„æœºå™¨äººå¤šæ¨¡æ€æ¨ç†æ¨¡å‹**ï¼Œæœ€ç»ˆå®ç°è¯­ä¹‰ç†è§£ä¸æŸ”é¡ºæ§åˆ¶çš„æ— ç¼ç»Ÿä¸€ã€‚",
            "timestamp": "2026-01-27T16:14:37.718069",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        }
    ],
    "is_hidden": false,
    "is_starred": false,
    "flag": true,
    "published_date": "2026-01-21T23:52:40Z",
    "created_at": "2026-01-27T15:53:26.823673",
    "updated_at": "2026-01-27T15:53:26.823680"
}