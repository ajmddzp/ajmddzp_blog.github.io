{
    "id": "2601.13556v1",
    "title": "LogicEnvGen: Task-Logic Driven Generation of Diverse Simulated Environments for Embodied AI",
    "authors": [
        "Jianan Wang",
        "Siyang Zhang",
        "Bin Li",
        "Juan Chen",
        "Jingtao Qi",
        "Zhuo Zhang",
        "Chen Qian"
    ],
    "abstract": "æ¨¡æ‹Ÿç¯å¢ƒåœ¨å…·èº«äººå·¥æ™ºèƒ½ä¸­æ‰®æ¼”ç€å…³é”®è§’è‰²ï¼Œå…¶åŠŸèƒ½ç±»ä¼¼äºè½¯ä»¶å·¥ç¨‹ä¸­çš„æµ‹è¯•ç”¨ä¾‹ã€‚ç„¶è€Œï¼Œç°æœ‰çš„ç¯å¢ƒç”Ÿæˆæ–¹æ³•å¾€å¾€ä¾§é‡äºè§†è§‰çœŸå®æ€§ï¼ˆå¦‚ç‰©ä½“å¤šæ ·æ€§å’Œå¸ƒå±€è¿è´¯æ€§ï¼‰ï¼Œå´å¿½è§†äº†ä¸€ä¸ªå…³é”®ç»´åº¦ï¼šæµ‹è¯•è§†è§’ä¸‹çš„é€»è¾‘å¤šæ ·æ€§ã€‚è¿™é™åˆ¶äº†å¯¹æ™ºèƒ½ä½“åœ¨ä¸åŒæ¨¡æ‹Ÿç¯å¢ƒä¸­é€‚åº”æ€§ä¸è§„åˆ’é²æ£’æ€§çš„å…¨é¢è¯„ä¼°ã€‚ä¸ºå¼¥è¡¥è¿™ä¸€ä¸è¶³ï¼Œæˆ‘ä»¬æå‡ºLogicEnvGenâ€”â€”ä¸€ç§ç”±å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„æ–°å‹æ–¹æ³•ï¼Œé‡‡ç”¨è‡ªé¡¶å‘ä¸‹çš„èŒƒå¼ç”Ÿæˆé€»è¾‘å¤šæ ·åŒ–çš„æ¨¡æ‹Ÿç¯å¢ƒä½œä¸ºæ™ºèƒ½ä½“æµ‹è¯•ç”¨ä¾‹ã€‚ç»™å®šæ™ºèƒ½ä½“ä»»åŠ¡åï¼ŒLogicEnvGené¦–å…ˆåˆ†æå…¶æ‰§è¡Œé€»è¾‘ä»¥æ„å»ºå†³ç­–æ ‘ç»“æ„çš„è¡Œä¸ºè§„åˆ’ï¼Œè¿›è€Œåˆæˆä¸€ç»„é€»è¾‘è½¨è¿¹ã€‚éšåé‡‡ç”¨å¯å‘å¼ç®—æ³•ä¼˜åŒ–è½¨è¿¹é›†åˆä»¥å‡å°‘å†—ä½™æ¨¡æ‹Ÿã€‚æ¯æ¡é€»è¾‘è½¨è¿¹ä»£è¡¨æ½œåœ¨çš„ä»»åŠ¡æƒ…å¢ƒï¼ŒLogicEnvGenä¼šç›¸åº”å®ä¾‹åŒ–å…·ä½“ç¯å¢ƒï¼Œå¹¶ç‰¹åˆ«é‡‡ç”¨çº¦æŸæ±‚è§£ç¡®ä¿ç‰©ç†åˆç†æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºåŒ…å«å››é¡¹é‡åŒ–æŒ‡æ ‡çš„æ–°å‹è¯„æµ‹åŸºå‡†LogicEnvEnvã€‚å®éªŒç»“æœéªŒè¯äº†åŸºçº¿æ–¹æ³•åœ¨é€»è¾‘å¤šæ ·æ€§æ–¹é¢çš„ä¸è¶³ï¼Œå¹¶è¯æ˜LogicEnvGenèƒ½å®ç°1.04-2.61å€çš„å¤šæ ·æ€§æå‡ï¼Œä½¿æ™ºèƒ½ä½“ç¼ºé™·æ£€å‡ºæ€§èƒ½æ˜¾è‘—æé«˜4.00%-68.00%ã€‚",
    "url": "https://arxiv.org/abs/2601.13556v1",
    "html_url": "https://arxiv.org/html/2601.13556v1",
    "html_content": "LogicEnvGen: Task-Logic Driven Generation of Diverse Simulated Environments for Embodied AI\nJianan Wang\n1\n,\nSiyang Zhang\n1\n,\nBin Li\n2âˆ—\n,\nJuan Chen\n1âˆ—\n,\nJingtao Qi\n2\n,\nZhuo Zhang\n2\n,\nChen Qian\n3\n1\nCollege of Computer Science and Technology, National University of Defense Technology\n2\nIntelligent Game and Decision Lab (IGDL), Beijing\n3\nSchool of Artifical Intelligence, Shanghai Jiao Tong University\nwangjianan@nudt.edu.cn\nlibin_bill@126.com\nAbstract\nSimulated environments play an essential role in embodied AI, functionally analogous to test cases in software engineering.\nHowever, existing environment generation methods often emphasize visual realism (e.g.,\nobject diversity and layout coherence\n), overlooking a crucial aspect: logical diversity from the testing perspective.\nThis limits the comprehensive evaluation of agent adaptability and planning robustness in distinct simulated environments.\nTo bridge this gap, we propose\nLogicEnvGen\n, a novel method driven by Large Language Models (LLMs) that adopts a top-down paradigm to generate logically diverse simulated environments as test cases for agents.\nGiven an agent task, LogicEnvGen first analyzes its execution logic to construct decision-tree-structured behavior plans and then synthesizes a set of logical trajectories.\nSubsequently, it adopts a heuristic algorithm to refine the trajectory set, reducing redundant simulation.\nFor each logical trajectory, which represents a potential task situation, LogicEnvGen correspondingly instantiates a concrete environment.\nNotably, it employs constraint solving for physical plausibility.\nFurthermore, we introduce LogicEnvEval, a novel benchmark comprising four quantitative metrics for environment evaluation.\nExperimental results verify the lack of logical diversity in baselines and demonstrate that LogicEnvGen achieves 1.04-2.61x greater diversity, significantly improving the performance in revealing agent faults by 4.00%â€“68.00%.\nLogicEnvGen: Task-Logic Driven Generation of Diverse Simulated Environments for Embodied AI\nJianan Wang\n1\n,\nSiyang Zhang\n1\n,\nBin Li\n2âˆ—\n,\nJuan Chen\n1âˆ—\n,\nJingtao Qi\n2\n,\nZhuo Zhang\n2\n,\nChen Qian\n3\n1\nCollege of Computer Science and Technology, National University of Defense Technology\n2\nIntelligent Game and Decision Lab (IGDL), Beijing\n3\nSchool of Artifical Intelligence, Shanghai Jiao Tong University\nwangjianan@nudt.edu.cn\nlibin_bill@126.com\nâ€ \nâ€ \nfootnotetext:\n*Corresponding authors\n1\nIntroduction\nFigure 1:\nSimulated environments generated by Holodeck\nYang\net al.\n(\n2024c\n)\nand LogicEnvGen. In contrast, LogicEnvGen generates more logically diverse test cases based on the task description, enabling more comprehensive simulation.\nSimulation is essential for developing embodied agents, enabling early testing and iterative refinement, thus reducing the risks and costs associated with physical deployment\nKoenig and Howard (\n2004\n)\n.\nIn this process, simulated environments\nGuo\net al.\n(\n2025\n); Yang\net al.\n(\n2024c\n)\nplay a critical role, functioning similarly to test cases in software engineering\nTang\net al.\n(\n2024b\n)\n.\nThe advancement of embodied AI heightens the demand for agents capable of handling complex logical tasks.\nThis necessitates\nlogically diverse\nsimulated environments that maintain consistent task goals while varying environment states and task conditions, enabling rigorous evaluation of an agentâ€™s adaptability and planning capability across different environment configurations.\nTaking the task in Figure\n1\nas an example, creating environments with varied cup colors is necessary for comprehensive testing.\nTraditional environment generation methods mainly rely on manual design\nKolve\net al.\n(\n2017\n); Deitke\net al.\n(\n2020\n)\n, 3D scanning\nRamakrishnan\net al.\n(\n2021\n)\nand procedural methods\ndeitke2022ï¸\n, which struggle with expensive human effort and limited scalability.\nRecently, generative frameworks such as diffusion models are employed to synthesize 3D environments from various inputs\nYang\net al.\n(\n2024b\n); Tang\net al.\n(\n2024a\n)\n.\nWith the rise of LLMs, some work utilizes LLMs for environment design, including scene layout and object configurations\nWang\net al.\n(\n2024\n); Yang\net al.\n(\n2024c\n)\n.\nMoreover, some text-to-3D generation methods optimize 3D contents based on pre-trained text-to-image models and focus on localized representations like textures\nZhou\net al.\n(\n2024\n); He\net al.\n(\n2023\n)\n.\nWhile these methods present promising capabilities in generating visually realistic simulated environments, they leave logical diversity underexplored, which is pivotal for uncovering agent faults in diverse situations.\nIn addition, LLM-based methods often face challenges in physical plausibility (e.g.,\nobjects floating in air\n).\nTo bridge this gap, we propose LogicEnvGen, an LLM-driven method that traverses the execution logic of the agent task to generate logically diverse simulated environments as test cases, enabling comprehensive detection of agent faults.\nIt adopts a three-phase framework:\n(1)\nBehavior Plan Derivation\n, to utilize LLMs to decompose the task into independent subtasks and generate a decision-tree-structured behavior plan for each subtask, where each root-to-leaf decision path defines a unique subtask logic flow.\n(2)\nLogical Trajectory Collection\n, to synthesize distinct logical trajectories by combining decision paths from each subtask, where each trajectory represents a potential task situation.\nNotably, we employ a heuristic algorithm to prune redundant combinations, thus improving simulation efficiency.\n(3)\nSimulated Environment Construction\n, to leverage LLMs to create an interactive simulated environment for each logical trajectory in a hierarchical and language-guided manner.\nTo ensure physical plausibility, we formalize object placement as a Constraint Satisfaction Problem (CSP) and incorporate a constraint solver to determine object layouts.\nFollowing a top-down paradigm, LogicEnvGen first captures possible task situations at the abstract logical level and then instantiates them into concrete environments with varied configurations, thus enhancing logical diversity in environment generation.\nTo assess LogicEnvGen, we introduce\nLogicEnvEval\n, a novel benchmark to measure methods that generate embodied environments for use as test cases.\nWhile existing benchmarks often focus on single-logic and sequential tasks, LogicEnvEval features 25 household tasks with complex execution logic.\nEach task is paired with four agent policies (one correct, three faulty).\nAdditionally, we introduce a suite of metrics for environment evaluation: Physics Pass Rate, Logic Coverage, Scenario Validity Rate, and Fault Detection Rate.\nThese metrics quantify the quality of the generated environments along three dimensions: physical plausibility, logical diversity, and practical utility as test cases.\nExperimental results demonstrate that LogicEnvGen generates physically plausible environments while exhibiting 1.04-2.61x greater Logic Coverage than baselines.\nThis leads to a significant improvement in Fault Detection Rate, ranging from 4.00% to 68.00%.\nOur contribution can be summarized as follows.\nâ€¢\nWe explore the novel problem of generating logically diverse simulated environments as test cases, improving evaluation of embodied agent adaptability and planning robustness.\nâ€¢\nWe propose LogicEnvGen, an LLM-driven method that adopts a top-down paradigm to traverse task execution logic for diverse environment generation. It incorporates a heuristic algorithm and constraint solver to reduce redundancy and enhance realism.\nâ€¢\nWe establish LogicEnvEval, a benchmark for evaluating simulated environment generation, along with four quantitative metrics.\nâ€¢\nExperimental results show LogicEnvGenâ€™s superior performance in physical plausibility, logical diversity, and effectiveness at efficiently revealing agent faults.\n2\nRelated Work\n2.1\nCode Test Generation\nCode testing, a critical part of software development, involves generating various test cases to detect potential bugs and ensure program execution meets expectations.\nExisting methods encompass search-based test generation\nFraser and Arcuri (\n2011\n); Lukasczyk and Fraser (\n2022\n)\nand symbolic test generation\nSen\net al.\n(\n2005\n)\n. Recently, LLMs have been employed for automated test generation\nSchÃ¤fer\net al.\n(\n2024\n); Ryan\net al.\n(\n2024\n)\n. Common evaluation metrics for test generation include accuracy, coverage, and bug detection rate\nWang\net al.\n(\n2025c\n); Huang\net al.\n(\n2024\n)\n.\nInspired by this field, we conceptualize simulated environments as test cases and propose a novel method for generating diverse simulated test cases to systematically evaluate embodied agents and reveal potential defects.\n2.2\nEmbodied AI Environment Generation\nEarly studies mainly rely on manual design\nLi\net al.\n(\n2024\n)\n, 3D scanning\nDeitke\net al.\n(\n2023a\n)\nand procedural generation\nFu\net al.\n(\n2021\n)\n, which demand substantial domain expertise and exhibit limited interactivity.\nBased on datasets like 3D-FRONT\nFu\net al.\n(\n2021\n)\n, some researchers train generative models to generate scenes\nTang\net al.\n(\n2024a\n); Wu\net al.\n(\n2024\n)\n, which are inherently restricted by the scale and quality of data.\nRecently, several studies use LLMs to automatically generate environments\nWang\net al.\n(\n2024\n); Feng\net al.\n(\n2023\n)\n.\nHowever, they often allow LLMs to directly assign object coordinates, which may violate physical laws like gravity and collision\nJia and Chen (\n2024\n)\n.\nSome work\nYang\net al.\n(\n2024c\n); Littlefair\net al.\n(\n2025\n)\nformalizes object placement as a constraint satisfaction problem to compute feasible solutions.\nOther text-guided 3D scene generation works\nZhou\net al.\n(\n2024\n,\n2025\n)\nfocus on localized representations with limited composability, thus restricting their applicability in embodied AI.\nThese existing methods emphasize rendering fidelity and visual diversity but overlook logical diversityâ€”a gap that our method is designed to address.\nFigure 2:\nOverview.\nPhase â‘ : Behavior Plan Derivation, decomposes the given task into independent subtasks, identifies uncertain environment factors impacting subtask execution, and generates decision-tree-structured behavior plan for each subtask.\nPhase â‘¡: Logical Trajectory Collection, traverses and combines decision paths across trees to synthesize distinct logical trajectories for the entire task, each representing a potential task situation.\nPhase â‘¢: Simulated Environment Construction, instantiates a concrete and physically plausible environment for each situation through three stages: floor plan design, environment object selection and arrangement.\n2.3\nLLM for Embodied AI\nWith rich world knowledge and remarkable reasoning capabilities, LLMs are extensively employed for Embodied AI\nHao\net al.\n(\n2023\n)\n.\nEarly work leverages LLMs as planners to decompose user instructions into action sequences\nAhn\net al.\n(\n2022\n); Yao\net al.\n(\n2023\n)\n.\nSome research generates executable code to bridge high-level task descriptions and low-level execution\nLiang\net al.\n(\n2023\n)\n.\nVision-Language-Action (VLA) models integrate perception and reasoning into a unified framework for end-to-end control\nZitkovich\net al.\n(\n2023\n); Kim\net al.\n(\n2024\n)\n.\nIn this work, rather than using LLMs as planning engines for embodied agents, we utilize them to construct test cases for simulation.\n3\nProblem Formalization\nDefinition 1\n(Logical Diversity).\nConsider a task\nT\nT\ndefined over a state space\nğ’®\n\\mathcal{S}\n, where each state\ns\nâˆˆ\nğ’®\ns\\in\\mathcal{S}\nis defined by a set of variables\nğ’±\n\\mathcal{V}\n.\nLet\nğ’±\nL\nâŠ†\nğ’±\n\\mathcal{V}_{L}\\subseteq\\mathcal{V}\ndenote the subset of variables that govern the execution logic of\nT\nT\n, where each variable\nv\nâˆˆ\nğ’±\nL\nv\\in\\mathcal{V}_{L}\nhas a finite discrete domain\nğ’Ÿ\nv\n\\mathcal{D}_{v}\n.\nThe set of all logically possible atomic conditions of\nT\nT\ncan be represented as\nğ’\ntotal\n=\n{\n(\nv\n,\nd\n)\nâˆ£\nv\nâˆˆ\nğ’±\nL\n,\nd\nâˆˆ\nğ’Ÿ\nv\n}\n\\mathcal{C}_{\\text{total}}=\\{(v,d)\\mid v\\in\\mathcal{V}_{L},d\\in\\mathcal{D}_{v}\\}\n.\nGiven a set of simulated environments\nâ„°\n\\mathcal{E}\n, we define\nğ’\nâ„°\nâŠ†\nğ’\ntotal\n\\mathcal{C}_{\\mathcal{E}}\\subseteq\\mathcal{C}_{\\text{total}}\nas the set of conditions covered by\nâ„°\n\\mathcal{E}\n.\nSpecifically, a condition\n(\nv\n,\nd\n)\n(v,d)\nis in\nğ’\nâ„°\n\\mathcal{C}_{\\mathcal{E}}\nif there exists at least one environment\ne\nâˆˆ\nâ„°\ne\\in\\mathcal{E}\nwhere variable\nv\nv\ntakes the value\nd\nd\n.\nThe logical diversity of\nâ„°\n\\mathcal{E}\nis quantified as the coverage ratio:\nLD\nâ€‹\n(\nâ„°\n)\n=\n|\nğ’\nâ„°\n|\n|\nğ’\ntotal\n|\n\\text{LD}(\\mathcal{E})=\\frac{|\\mathcal{C}_{\\mathcal{E}}|}{|\\mathcal{C}_{\\text{total}}|}\n(1)\n4\nMethod\n4.1\nOverview\nIn this paper, we propose LogicEnvGen, an LLM-driven method to generate logically diverse test cases for the rigorous detection of agent deficiencies.\nAdopting a top-down scheme, LogicEnvGen first captures all potential situations at the abstract logical level and then instantiates concrete environments, enabling coverage of diverse task decision paths.\nAs illustrated in Figure\n2\n, LogicEnvGen comprises three phases.\n4.2\nBehavior Plan Derivation\nGiven an agent task, we utilize LLMs to analyze its execution logic to derive decision-tree-structured behavior plans.\nSpecifically, the process includes three steps: task decomposition, uncertain factor identification and behavior plan generation.\nIn contrast to prior work that primarily divides tasks into sequentially executed subtasks, we decompose the embodied task into mutually independent subtasks without execution order dependencies.\nThis can effectively avoid capturing logically redundant trajectories.\nFor each subtask, we identify the associated uncertain environmental factors that affect the agent execution logic.\nSubsequently, we instruct LLMs to construct a decision-tree-structured, environment-aware task plan based on these factors, which outlines distinct behavior logic for the agent under diverse conditions.\nRepresented in JSON format, its internal nodes are conditional\nqueries\nabout the environment (e.g., â€œ\nIs the window open?\nâ€) and the edges correspond to the associated\nresponses\n(e.g., â€œ\nYes\nâ€, â€œ\nNo\nâ€).\nThe decision path from root to leaf defines a unique logic flow, representing a potential situation for the subtask.\nThe leaf node encapsulates the execution plan of the agent in the corresponding situation.\nTo ensure the reliability and logical consistency of the derived plans, we employ a rule-guided, iterative verification and refinement process. It checks for:\n(a) the mutual independence of subtasks by detecting overlapping uncertain factors, (b) the syntactic correctness of the generated tree-structured plans, and\n(c) the grounding of the treeâ€™s internal nodes in the identified factors.\nAlgorithm 1\nMinimal Trajectory Selection\nInput\n: Trajectory set\nğ’¯\n\\mathcal{T}\nOutput\n: Minimal trajectory set\nğ’¯\nm\nâ€‹\ni\nâ€‹\nn\n\\mathcal{T}_{min}\n1:\nğ’¯\nm\nâ€‹\ni\nâ€‹\nn\n,\nğ’\np\nâ€‹\no\nâ€‹\no\nâ€‹\nl\n,\nğ’¯\nc\nâ€‹\na\nâ€‹\nn\nâ€‹\nd\nâ†\n{\n}\n,\n{\n}\n,\n{\n}\n\\mathcal{T}_{min},\\mathcal{C}_{pool},\\mathcal{T}_{cand}\\leftarrow\\{\\},\\{\\},\\{\\}\nâŠ³\n\\triangleright\ninitialize\n2:\nfor\nt\nâˆˆ\nğ’¯\nt\\in\\mathcal{T}\ndo\n3:\nğ’\nt\nâ†\nsplitConstraints\nâ€‹\n(\nt\n)\n\\mathcal{C}_{t}\\leftarrow\\text{splitConstraints}(t)\n4:\nif\nğ’\nt\nâˆ©\nğ’\np\nâ€‹\no\nâ€‹\no\nâ€‹\nl\n=\nâˆ…\n\\mathcal{C}_{t}\\cap\\mathcal{C}_{pool}=\\emptyset\nthen\n5:\nğ’¯\nm\nâ€‹\ni\nâ€‹\nn\nâ†\nğ’¯\nm\nâ€‹\ni\nâ€‹\nn\nâˆª\n{\nt\n}\n\\mathcal{T}_{min}\\leftarrow\\mathcal{T}_{min}\\cup\\{t\\}\nâŠ³\n\\triangleright\nprioritize\n6:\nğ’\np\nâ€‹\no\nâ€‹\no\nâ€‹\nl\nâ†\nğ’\np\nâ€‹\no\nâ€‹\no\nâ€‹\nl\nâˆª\nğ’\nt\n\\mathcal{C}_{pool}\\leftarrow\\mathcal{C}_{pool}\\cup\\mathcal{C}_{t}\nâŠ³\n\\triangleright\nupdate\n7:\nelse\nif\nğ’\nt\nâŠˆ\nğ’\np\nâ€‹\no\nâ€‹\no\nâ€‹\nl\n\\mathcal{C}_{t}\\not\\subseteq\\mathcal{C}_{pool}\nthen\n8:\nğ’¯\nc\nâ€‹\na\nâ€‹\nn\nâ€‹\nd\nâ†\nğ’¯\nc\nâ€‹\na\nâ€‹\nn\nâ€‹\nd\nâˆª\n{\nt\n}\n\\mathcal{T}_{cand}\\leftarrow\\mathcal{T}_{cand}\\cup\\{t\\}\nâŠ³\n\\triangleright\ncandidate\n9:\nend\nif\n10:\nend\nfor\n11:\nğ’¯\nm\nâ€‹\ni\nâ€‹\nn\nâ†\nUpdate\nâ€‹\n(\nğ’¯\nm\nâ€‹\ni\nâ€‹\nn\n,\nğ’¯\nc\nâ€‹\na\nâ€‹\nn\nâ€‹\nd\n,\nğ’\np\nâ€‹\no\nâ€‹\no\nâ€‹\nl\n)\n\\mathcal{T}_{min}\\leftarrow\\text{Update}(\\mathcal{T}_{min},\\mathcal{T}_{cand},\\mathcal{C}_{pool})\nâŠ³\n\\triangleright\ncheck\n12:\nreturn\nğ’¯\nm\nâ€‹\ni\nâ€‹\nn\n\\mathcal{T}_{min}\n4.3\nLogical Trajectory Collection\nBased on the tree-structured plan of each subtask, we use depth-first search (DFS) to extract the set of decision\npaths\n.\nEach path, comprising multiple query-response pairs, is considered as a\nconstraint\n.\nThe path sets from all subtasks are subsequently integrated to form a set of logical\ntrajectories\nfor the entire task.\nEach trajectory, consisting of several constraints, represents a possible situation that the agent may encounter.\nA direct integration approach is via Cartesian product computation to enumerate all trajectories.\nHowever, it can cause a combinatorial explosion as trajectories scale exponentially with the number of subtasks, necessitating simulation under an excessive number of environmentsâ€”a computationally expensive process.\nThis is also unexpected because most trajectories fail to introduce new constraints and hence are redundant in covering logical diversity.\nTo address this problem, we employ a heuristic Minimal Trajectory Selection algorithm to eliminate redundant trajectories while preserving a minimal subset that covers all constraints, as outlined in Algorithm\n1\n.\nSpecifically, we first initialize a constraint pool as empty.\nBased on the logical trajectory set derived from Cartesian product, we prioritize selecting trajectories whose constituent constraints are entirely disjoint from the current constraint pool, while extracting those exhibiting partial constraint non-overlap into a candidate set.\nAfter each selection, its constituent constraints are added to the constraint pool.\nFinally, we check the candidate set to select any remaining trajectories whose constraints have not yet been integrated into the pool.\nAn example is shown in Figure\n3\n.\nBy constructing the tree-structured behavior plans and collecting all logical trajectories, we achieve a comprehensive capture of potential task situations.\nThis enables the logical diversity of environments to be controlled at an abstract level.\nFurthermore, the employed algorithm ensures diversity coverage with a minimal set of situations, thus reducing redundant simulation and shortening the testing cycle.\nThe ablation and comparative experiment results (Section\n5.4.1\nand\n5.4.2\n) validate the efficacy of the generated tree-structured plans and the superiority of the algorithm.\nFigure 3:\nAlgorithm example. Logical trajectories reduce from 12 to 4 (3 blue, 1 purple).\n4.4\nSimulated Environment Construction\nFor each logical trajectory in the minimal set, we create a text-based test case and instantiate it based on AI2-THOR\nKolve\net al.\n(\n2017\n)\n.\nLeveraging the scene planning capability of LLMs, this process is language-guided and exhibits robust generalization. Adopting a hierarchical design mode, the environment generation is deconstructed into three stages:\n(a)\nFloor plan design\n, which determines the room layouts and the placements of doors and windows;\n(b)\nEnvironment object selection\n, which specifies the environment objects and retrieves their corresponding 3D assets from an asset library;\n(c)\nConstraint-based object arrangement\n, which organizes objects based on the designed spatial relations and real-world physical rules.\n4.4.1\nFloor plan design\nThe floor plan defines the foundational structure of the simulated environment, comprising three components: rooms, doorways, and windows.\nSpecifically, each room is delineated as a rectangle by its vertex coordinates and is characterized by its floor/wall colors and materials.\nDoorways are specified by their types, sizes, and states (e.g.,\nopened\n,\nclosed\n).\nAnd windows are determined by attributes like orientations (e.g.,\nwest\n,\neast\n), types, and states.\n4.4.2\nEnvironment object selection\nObjects serve as spatial infill and are grouped into two types: task-related and environmental enrichment objects.\nThis grouping allows the environment to be tailored to specific task requirements and trajectory constraints, while being enriched by integrating contextually appropriate objects.\nEach object is defined by properties like a textual description, its assigned room, size, and other relevant attributes (e.g.,\non_off_state\n,\nindication_reading\n).\nBased on the textual descriptions (e.g.,\nâ€œa brown two-seater sofaâ€\n), we retrieve the corresponding 3D assets from the Objaverse library\nDeitke\net al.\n(\n2023b\n)\n.\nThis retrieval process is automated through a function that employs CLIP\nRadford\net al.\n(\n2021\n)\nto match descriptions with assets based on text-image similarity scores, as implemented in prior work like Holodeck\nYang\net al.\n(\n2024c\n)\n.\n4.4.3\nConstraint-based object arrangement\nDue to the inherent limitations of LLMs in numerical reasoning, directly generating precise spatial coordinates and orientations for multiple objects often violates task requirements and physical principles.\nTo circumvent this, we utilize a hybrid approach wherein LLMs first define high-level spatial relation constraints, after which a computational constraint solver determines the final object arrangements.\nThis ensures that object placements align with task-specific requirements and trajectory constraints, while maintaining a coherent environment structure and adherence to physical laws.\nWe define four categories of spatial relations:\n(1) Unary: edge, center, mounted on wall;\n(2) Contact: in, on top of;\n(3) Distance: near, far;\n(4) Relative: above, in front of, side of, center aligned, face to.\nHowever, a key challenge is that LLM-generated relations may show logical inconsistencies (e.g.,\nâ€œpen is in drawerâ€\nand\nâ€œpen is on top of bedâ€\n).\nTo address such conflicts, we employ a rule-based physical compatibility checker to evaluate the plausibility of these relations.\nDetected inconsistencies trigger an iterative refinement, prompting the LLM to revise its output based on the feedback provided.\nSubsequently, the object arrangement task is modeled as a constraint satisfaction problem (CSP), using the Z3 solver\n1\n1\n1\nhttps://github.com/Z3Prover/z3\nto compute solutions. Here, 3D positions and directions of objects (along with the doorway and window positions) constitute variables.\nSpatial relations and physical principles (e.g.,\nnon-floating-in-air\n,\nnon-colliding\n) act as constraints.\nNotably, if the solver cannot find a solution satisfying all constraints, we adopt a constraint relaxation mechanism.\nThis mechanism selectively disregards peripheral spatial relations, particularly those involving environmental enrichment objects, to prioritize essential task-related constraints.\nSection\n5.4.3\nshows the efficacy of Z3 via ablation.\n5\nExperiments\n5.1\nBenchmark\nBased on Bode et al.â€™s definition of\nconditional tasks\nBode\net al.\n(\n2024\n)\nâ€”logically complex tasks requiring agents to gather environment information and adapt dynamicallyâ€”we construct LogicEnvEval, a novel benchmark designed to assess the performance of different methods for generating simulation test cases from agent tasks.\nFigure\n4\nshows its composition and the distribution of environment types, task steps, and agent action types.\nSpecifically, we utilize LLMs to design 25 conditional tasks with their ground-truth decision-tree-structured behavior plans, which are subsequently manually verified and refined to ensure their validity.\nThese tasks are long-horizon and related to household activities.\nFor each task, we construct a correct agent policy and three types of faulty policies based on Code-BT\nZhang\net al.\n(\n2025\n)\n.\nGiven the prevalence of behavior trees (BTs) in robotics\nColledanchise and Ã–gren (\n2017\n)\n, we adopt them to represent agent policies.\nBuilt upon the existing taxonomies of faulty policies\nWang\net al.\n(\n2025a\n)\n, we categorize faulty BTs into three types: Counterfactuals, Unreachable, and Lackbranch.\nSee Appendix\nA\nfor more LogicEnvEval information.\nFigure 4:\nLogicEnvEval Benchmark. (a) Task composition. SN: number of subtasks. TN: number of task trajectories (minimal). (b) Environment type distribution of all subtasks. (c) Action step distribution of correct policies. (d) Action type diversity in correct policies.\n5.2\nExperiment Setup\nDimension\nPhysical Constraints\nFloor Plan\nAdjacent rooms must not overlap.\nA door must be placed on the floor and on the wall separating adjacent rooms.\nA window must be embedded in the wall and positioned above the floor.\nEntity\nAn object must be supported by a surface (i.e., not floating), must not collide with other objects, and must be located within its designated room.\nRelation\nThe positions and directions of objects must satisfy the specified spatial relations.\nTable 1:\nThree dimensions of Physics Pass Rate and their associated physical constraints.\n5.2.1\nMetrics\nFollowing the evaluation criteria adopted in code test generation\nRyan\net al.\n(\n2024\n); Huang\net al.\n(\n2024\n)\n, we introduce four novel evaluation metrics for simulated environment generation.\nModel\nMethod\nPhysics Pass Rate (%)\nLogCov\nSceVR\nFault Detection Rate (%)\nST\nFloor Plan\nEntity\nRelation\nAvg\n(%)\n(%)\nCFactuals\nUnreach\nLBranch\nAvg\n(min)\nDeepSeek-v3\nCoT\n96.00\n40.00\n20.00\n52.00\n63.38\n85.71\n64.00\n56.00\n56.00\n58.67\n29.16\nIFG\n90.84\n11.00\n13.04\n38.29\n91.08\n90.72\n92.00\n92.00\n88.00\n90.67\n87.96\nHolodeck\n100.00\n100.00\n100.00\n100.00\n37.05\n76.00\n24.00\n24.00\n32.00\n26.67\n15.67\nLogicEnvGen\n100.00\n100.00\n100.00\n100.00\n99.06\n93.75\n96.00\n92.00\n96.00\n94.67\n49.88\nGemini-2.5-Flash\nCoT\n86.46\n0.00\n4.17\n30.21\n86.10\n79.78\n84.00\n88.00\n68.00\n80.00\n55.20\nIFG\n60.96\n14.16\n17.44\n30.85\n96.11\n89.09\n100.00\n92.00\n88.00\n93.33\n89.52\nHolodeck\n100.00\n100.00\n100.00\n100.00\n37.05\n68.00\n32.00\n24.00\n20.00\n25.33\n17.88\nLogicEnvGen\n100.00\n100.00\n100.00\n100.00\n96.47\n92.78\n96.00\n92.00\n92.00\n93.33\n50.96\nQwen2.5-72B\nCoT\n84.00\n16.00\n26.00\n42.00\n65.47\n73.77\n60.00\n56.00\n52.00\n56.00\n37.60\nIFG\n85.16\n18.52\n25.48\n43.05\n92.64\n75.20\n84.00\n76.00\n92.00\n84.00\n91.64\nHolodeck\n100.00\n100.00\n100.00\n100.00\n37.05\n64.00\n16.00\n12.00\n16.00\n14.67\n13.96\nLogicEnvGen\n100.00\n100.00\n100.00\n100.00\n94.79\n80.18\n84.00\n84.00\n92.00\n86.67\n53.36\nTable 2:\nThe comparative experiment results on the LogicEnvEval benchmark.\nâ€¢\nPhysics Pass Rate (PhyPR)\nThis metric assesses the adherence of environments to physical constraints in three dimensions (Table\n1\n).\nâ€¢\nLogic Coverage (LogCov)\nThis metric measures the extent to which the environments cover the decision paths of the ground-truth decision trees to quantify logical diversity.\nFor automatic evaluation, we develop a rule-based script tool to parse environment metadata to identify the paths covered by an environment.\nâ€¢\nScenario Validity Rate (SceVR)\nThis metric represents the proportion of valid environments where correct agent policies can be simulated and verified as fault-free.\nSpecifically, an environment is invalid if it lacks task-related objects, violates explicit task constraints (e.g.,\na coat is initialized on the bed, but the task requires it to be in the closet\n), etc.\nâ€¢\nFault Detection Rate (FauDR)\nThis metric measures the fault detection efficacy of the generated simulated environments.\nBased on 75 faulty BTs of LogicEnvEval, we conduct BT simulation in the generated environments and compute the proportion of the revealed faulty BTs.\nTo ensure fairness, we exclude invalid test environments and only assess the capability of valid ones to reveal genuine faults.\nThis is because invalid environments invariably report faults due to their configuration errors, which is not effective fault detection.\nFor BT simulation, we employ a behavior simulator\nWang\net al.\n(\n2025a\n)\nto efficiently execute BTs and validate whether they are faulty.\nBesides, we use Simulation Time (ST) to assess the time to verify a BT on the generated test environments.\n5.2.2\nBaselines and Adopted LLMs\nGiven our focus on generating logically diverse simulated environments as test cases, we compare LogicEnvGen against three baselines:\nthe environment generation method Holodeck\nYang\net al.\n(\n2024c\n)\n,\nthe general LLM reasoning method CoT\nWei\net al.\n(\n2022\n)\n,\nand IFG\nAhmed\net al.\n(\n2025\n)\n, a method designed to promote semantic diversity in LLM output.\nFurthermore, the CoT and IFG baselines are adapted for diverse environment generation.\nMore details are in Appendix\nB\n.\nFor fairness, all methods use the same problem setup and 3D asset library.\nTo demonstrate the cross-LLM generalization, we conduct experiments on three well-known LLMs: DeepSeek-v3\nDeepSeek-AI (\n2025\n)\n, Gemini-2.5-Flash\nDeepMind (\n2025a\n)\nand Qwen2.5-72B-Instruct\nYang\net al.\n(\n2024a\n)\n.\n5.3\nMethod Performance\nTable\n2\npresents the performance comparison between LogicEnvGen and baselines.\nThe results show that LogicEnvGen generates physically plausible simulated environments with broader logical coverage and higher validity rate, and achieves superior fault detection with great efficiency.\nIn terms of PhyPR, both Holodeck and LogicEnvGen generate simulated environments adhering to physical constraints.\nIn contrast, CoT and IFG often fail to satisfy physical plausibility, particularly in the Entity and Relation dimensions.\nFor example, the CoT method on Gemini-2.5-Flash exhibits near-zero PhyPR in the two dimensions.\nInterestingly, despite these limitations, it achieves significantly higher diversity than DeepSeek-v3 and Qwen2.5-72B, with the LogCov of 86.10%.\nNotably, LogicEnvGen offers benefits in two key aspects.\nFirst, incorporating constrained trajectory prompts enables finer-grained guidance for LLMs to construct simulated environments, reducing uncertainty and hallucinations.\nThis enhances the SceVR of LogicEnvGen, achieving improvements ranging from 3.69% to 24.78% over three baselines (Gemini-2.5-Flash).\nOur analysis reveals that the environments generated by baselines often exhibit critical deficiencies, such as missing task-related objects or incomplete attribute specifications.\nSecond, LogicEnvGen evenly generates simulation test cases with 1.38, 1.04 and 2.61 times the LogCov of the three baselines, respectively.\nThis demonstrates that constructing tree-structured behavior plans effectively promotes logically diverse test environment generation, consequently facilitating the identification of potential faults in agent policies.\nFor instance, LogicEnvGen achieves an average FauDR of 94.67% across three types of faulty BTs, outperforming CoT by 36.00%, IFG by 4.00% and Holodeck by 68.00% (DeepSeek-v3).\nAdditionally, the IFG method shows commendable performance in the LogCov and FauDR, but its efficiency is significantly hindered by the logical redundancy of the generated cases, causing it to require 1.72 times more simulation time on average per BT than LogicEnvGen (Qwen2.5-72B).\nVisual quality comparisons of LogicEnvGen are in Appendix\nD\n.\n5.4\nAblation Study\nIn this section, we conduct ablation studies to demonstrate the critical roles of the decision-tree-structured behavior plans (DBP), Minimal Trajectory Selection algorithm (MTSA) and constraint-based arrangement solving (CAS) in enhancing test environment generation.\nWe choose DeepSeek-v3 as the base LLM for ablations.\nMoreover, we use a new evaluation metric, Jaccard Index (JI), to quantify the similarity between the generated logical trajectory set and the ground-truth set (minimal).\nThis metric ranges from 0 to 1, with higher values indicating greater similarity.\nMethod\nPhyPR(%)\nLogCov(%)\nSceVR(%)\nFauDR(%)\nJI\nW/O DBP\n100.00\n95.19\n89.70\n93.33\n0.32\nLogicEnvGen\n100.00\n99.06\n93.75\n94.67\n0.88\nTable 3:\nResults of ablation study on the decision-tree-structured behavior plan (DBP).\nMethod\nLogCov(%)\nJI\nTime Complexity\nRunTime(ms)\nExhaustive\n99.06\n0.95\nO(\n2\nN\n2^{N}\n)\n38.12\nW/O MTSA\n99.06\n0.30\n-\n-\nLogicEnvGen\n99.06\n0.88\nO(N)\n0.99\nTable 4:\nResults of comparative and ablation study on the Minimal Trajectory Selection Algorithm (MTSA).\nN\ndenotes the number of trajectories generated by the Cartesian product.\n5.4.1\nEffectiveness of DBP\nTo evaluate the efficacy of DBP, we remove decision tree generation and guide LLMs to directly synthesize logical trajectories by analyzing task logic.\nTable\n3\nshows that the LogCov and FauDR decrease by 3.87% and 1.34%, respectively.\nThis highlights that the decision-tree-structured behavior plan systematically organizes task logic to cover potential situations, facilitating logically diverse environment generation.\nFurthermore, it notably improves JI (+0.56).\nThis confirms that, despite achieving high LogCov after ablation, the generated trajectories exhibits substantial redundancy.\nConversely, the behavior plan derivation followed by the MTSA yields more concise sets, enhancing simulation efficiency while maintaining fault detection effectiveness.\n5.4.2\nEffectiveness of MTSA\nTo assess the importance of MTSA, we directly utilizes the full logical trajectory set derived from Cartesian product for environment construction.\nTable\n4\nreveals a significant decrease of 0.58 in JI, demonstrating the efficacy of our algorithm in eliminating redundant trajectories.\nFurthermore, we compare our algorithm with the Exhaustive algorithm.\nThe exhaustive algorithm theoretically guarantees a minimum set-cover, however, it incurs exponential time complexity.\nIn contrast, our algorithm exhibits superior computational efficiency.\nFigure 5:\nResults of ablation study on the constraint-based arrangement solving (CAS).\n5.4.3\nEffectiveness of CAS\nWe conduct ablation study on CAS by removing the Z3 constraint solver.\nInstead, we instruct LLMs to design asset placements based on physical laws and spatial relations.\nFigure\n5\nindicates a significant decline in PhyPR across three dimensions.\nInterestingly, the ablation variant underperforms CoT, with an average PhyPR 19.92% lower than CoT.\nThis is because LogicEnvGen designs richer objects and spatial relations than CoT, making it more challenging to construct physically plausible environments.\nThese findings show that LLMs face challenges in numerical reasoning and substantiate the efficacy of CAS, which achieves a 67.92% improvement in the PhyPR.\n6\nConclusion\nGenerating logically diverse environments as test cases is crucial for embodied agent simulation, enabling rigorous evaluation of agent adaptability and planning capabilities across various scenarios.\nIn this paper, we propose LogicEnvGen, an LLM-driven framework for the automated generation of logically diverse simulated environments.\nAdopting a top-down paradigm, we first capture all possible task situations at the abstract logical level and then instantiate concrete environment cases, thus yielding the broad coverage of the agent task decision paths.\nBased on the proposed LogicEnvEval, a benchmark for assessing simulated environment generation, we conduct quantitative evaluations across four metrics.\nThe results demonstrate that LogicEnvGen ensures physical plausibility while achieving significant improvements in logical diversity and fault detection effectiveness.\n7\nLimitations\nFirst, this work utilizes decision trees encoded in JSON to represent agent behavior plans.\nWe adopt this representation based on the inspiration from the abstract syntax trees of programming languages and the consistency with the LLMs pretraining data formats, although other alternative representations may exhibit superior performance.\nNext, we employ a behavior simulator to conduct BT simulation to measure the scenario validity rate and fault detection rate of the generated environments.\nWe use this simulator for its high efficiency and reliability.\nHowever, using general physics simulators like Gazebo or Unreal Engine can yield more high-fidelity evaluation results.\nThis highlights the need for future evaluation advancement.\nFinally, while the experiments confirm the effectiveness of this work on LogicEnvEval, we have not evaluated its generalization on more benchmarks.\nAdditionally, It comprises only 25 tasks, which is relatively limited.\nThis issue stems from existing benchmarks focusing on single-logic, sequential tasks, making them insufficient for assessing an agentâ€™s ability to dynamically adapt to diverse scenarios.\nThus, we design LogicEnvEval to concentrate on long-horizon tasks with complex execution logic, effectively evaluating agent adaptability and planning robustness.\nAn important future direction is to expand LogicEnvEval to include more tasks.\n8\nEthics Statement\nWe ensure our study aligns with the Code of Ethics.\nHowever, as an LLM-based application, it may be exploited by malicious individuals or affected by the hallucinations introduced by the specific LLM, which may generate misleading scenarios.\nWe urge users to apply our study responsibly.\nReferences\nE. Ahmed, U. Berdica, M. Elliott, D. Horak, and J. N. Foerster (2025)\nIntent factored generation: unleashing the diversity in your language model\n.\nCoRR\nabs/2506.09659\n.\nExternal Links:\nLink\n,\nDocument\n,\n2506.09659\nCited by:\n2nd item\n,\nAppendix B\n,\nÂ§5.2.2\n.\nM. Ahn, A. Brohan, N. Brown, Y. Chebotar, O. Cortes, B. David, C. Finn, K. Gopalakrishnan, K. Hausman, A. Herzog, D. Ho, J. Hsu, J. Ibarz, B. Ichter, A. Irpan, E. Jang, R. J. Ruano, K. Jeffrey, S. Jesmonth, N. J. Joshi, R. Julian, D. Kalashnikov, Y. Kuang, K. Lee, S. Levine, Y. Lu, L. Luu, C. Parada, P. Pastor, J. Quiambao, K. Rao, J. Rettinghouse, D. Reyes, P. Sermanet, N. Sievers, C. Tan, A. Toshev, V. Vanhoucke, F. Xia, T. Xiao, P. Xu, S. Xu, and M. Yan (2022)\nDo as I can, not as I say: grounding language in robotic affordances\n.\nCoRR\nabs/2204.01691\n.\nExternal Links:\nLink\n,\nDocument\n,\n2204.01691\nCited by:\nÂ§2.3\n.\nJ. Bode, B. PÃ¤tzold, R. Memmesheimer, and S. Behnke (2024)\nA comparison of prompt engineering techniques for task planning and execution in service robotics\n.\nIn\n23rd IEEE-RAS International Conference on Humanoid Robots, Humanoids\n2024, Nancy, France, November 22-24, 2024\n,\npp.Â 309â€“314\n.\nExternal Links:\nLink\n,\nDocument\nCited by:\nÂ§5.1\n.\nM. Colledanchise and P. Ã–gren (2017)\nBehavior trees in robotics and AI: an introduction\n.\nCoRR\nabs/1709.00084\n.\nExternal Links:\nLink\n,\n1709.00084\nCited by:\nÂ§5.1\n.\nG. DeepMind (2025a)\nGemini 2.5 flash: model card.\n.\nhttps://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Flash-Model-Card.pdf\n.\nExternal Links:\nLink\nCited by:\nÂ§5.2.2\n.\nG. DeepMind (2025b)\nGemini 3 pro: model card.\n.\nhttps://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf\n.\nExternal Links:\nLink\nCited by:\nÂ§D.2\n.\nDeepSeek-AI (2025)\nIntroducing deepseek-v3\n.\nhttps://api-docs.deepseek.com/news/news1226\n.\nExternal Links:\nLink\nCited by:\nÂ§5.2.2\n.\nM. Deitke, W. Han, A. Herrasti, A. Kembhavi, E. Kolve, R. Mottaghi, J. Salvador, D. Schwenk, E. VanderBilt, M. Wallingford, L. Weihs, M. Yatskar, and A. Farhadi (2020)\nRoboTHOR: an open simulation-to-real embodied AI platform\n.\nIn\n2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition,\nCVPR 2020, Seattle, WA, USA, June 13-19, 2020\n,\npp.Â 3161â€“3171\n.\nExternal Links:\nLink\n,\nDocument\nCited by:\nÂ§1\n.\nM. Deitke, R. Hendrix, A. Farhadi, K. Ehsani, and A. Kembhavi (2023a)\nPhone2Proc: bringing robust robots into our chaotic world\n.\nIn\n2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition,\nCVPR 2023, Vancouver, BC, Canada, June 17-24, 2023\n,\npp.Â 9665â€“9675\n.\nExternal Links:\nLink\n,\nDocument\nCited by:\nÂ§2.2\n.\nM. Deitke, D. Schwenk, J. Salvador, L. Weihs, O. Michel, E. VanderBilt, L. Schmidt, K. Ehsani, A. Kembhavi, and A. Farhadi (2023b)\nObjaverse: A universe of annotated 3d objects\n.\nIn\n2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition,\nCVPR 2023, Vancouver, BC, Canada, June 17-24, 2023\n,\npp.Â 13142â€“13153\n.\nExternal Links:\nLink\n,\nDocument\nCited by:\nÂ§4.4.2\n.\nW. Feng, W. Zhu, T. Fu, V. Jampani, A. R. Akula, X. He, S. Basu, X. E. Wang, and W. Y. Wang (2023)\nLayoutGPT: compositional visual planning and generation with large language models\n.\nIn\nAdvances in Neural Information Processing Systems 36: Annual Conference\non Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans,\nLA, USA, December 10 - 16, 2023\n,\nA. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine (Eds.)\n,\nExternal Links:\nLink\nCited by:\nÂ§2.2\n.\nG. Fraser and A. Arcuri (2011)\nEvoSuite: automatic test suite generation for object-oriented software\n.\nIn\nSIGSOFT/FSEâ€™11 19th ACM SIGSOFT Symposium on the Foundations of\nSoftware Engineering (FSE-19) and ESECâ€™11: 13th European Software\nEngineering Conference (ESEC-13), Szeged, Hungary, September 5-9,\n2011\n,\nT. GyimÃ³thy and A. Zeller (Eds.)\n,\npp.Â 416â€“419\n.\nExternal Links:\nLink\n,\nDocument\nCited by:\nÂ§2.1\n.\nH. Fu, B. Cai, L. Gao, L. Zhang, J. Wang, C. Li, Q. Zeng, C. Sun, R. Jia, B. Zhao, and H. Zhang (2021)\n3D-front: 3d furnished rooms with layouts and semantics\n.\nIn\n2021 IEEE/CVF International Conference on Computer Vision, ICCV\n2021, Montreal, QC, Canada, October 10-17, 2021\n,\npp.Â 10913â€“10922\n.\nExternal Links:\nLink\n,\nDocument\nCited by:\nÂ§2.2\n.\nZ. Guo, L. Zheng, X. Chen, X. Bai, K. Chen, and M. Zhang (2025)\nMoK-rag: mixture of knowledge paths enhanced retrieval-augmented generation for embodied AI environments\n.\nCoRR\nabs/2503.13882\n.\nExternal Links:\nLink\n,\nDocument\n,\n2503.13882\nCited by:\nÂ§1\n.\nS. Hao, Y. Gu, H. Ma, J. J. Hong, Z. Wang, D. Z. Wang, and Z. Hu (2023)\nReasoning with language model is planning with world model\n.\nIn\nProceedings of the 2023 Conference on Empirical Methods in Natural\nLanguage Processing, EMNLP 2023, Singapore, December 6-10, 2023\n,\nH. Bouamor, J. Pino, and K. Bali (Eds.)\n,\npp.Â 8154â€“8173\n.\nExternal Links:\nLink\n,\nDocument\nCited by:\nÂ§2.3\n.\nY. He, Y. Bai, M. Lin, W. Zhao, Y. Hu, J. Sheng, R. Yi, J. Li, and Y. Liu (2023)\nT\n3\n{}^{\\mbox{3}}\nbench: benchmarking current progress in text-to-3d generation\n.\nCoRR\nabs/2310.02977\n.\nExternal Links:\nLink\n,\nDocument\n,\n2310.02977\nCited by:\nÂ§1\n.\nJ. Hessel, A. Holtzman, M. Forbes, R. L. Bras, and Y. Choi (2021)\nCLIPScore: A reference-free evaluation metric for image captioning\n.\nIn\nProceedings of the 2021 Conference on Empirical Methods in Natural\nLanguage Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican\nRepublic, November 7-11, 2021\n,\nM. Moens, X. Huang, L. Specia, and S. W. Yih (Eds.)\n,\npp.Â 7514â€“7528\n.\nExternal Links:\nLink\n,\nDocument\nCited by:\nÂ§D.2\n.\nD. Huang, J. M. Zhang, M. Du, M. Harman, and H. Cui (2024)\nRethinking the influence of source code on test case generation\n.\nCoRR\nabs/2409.09464\n.\nExternal Links:\nLink\n,\nDocument\n,\n2409.09464\nCited by:\nÂ§2.1\n,\nÂ§5.2.1\n.\nY. Jia and B. Chen (2024)\nClutterGen: A cluttered scene generator for robot learning\n.\nIn\nConference on Robot Learning, November 6-9, 2024, Munich, Germany\n,\nP. Agrawal, O. Kroemer, and W. Burgard (Eds.)\n,\nProceedings of Machine Learning Research\n, Vol.\n270\n,\npp.Â 1782â€“1796\n.\nExternal Links:\nLink\nCited by:\nÂ§2.2\n.\nM. J. Kim, K. Pertsch, S. Karamcheti, T. Xiao, A. Balakrishna, S. Nair, R. Rafailov, E. P. Foster, P. R. Sanketi, Q. Vuong, T. Kollar, B. Burchfiel, R. Tedrake, D. Sadigh, S. Levine, P. Liang, and C. Finn (2024)\nOpenVLA: an open-source vision-language-action model\n.\nIn\nConference on Robot Learning, November 6-9, 2024, Munich, Germany\n,\nP. Agrawal, O. Kroemer, and W. Burgard (Eds.)\n,\nProceedings of Machine Learning Research\n, Vol.\n270\n,\npp.Â 2679â€“2713\n.\nExternal Links:\nLink\nCited by:\nÂ§2.3\n.\nN. P. Koenig and A. Howard (2004)\nDesign and use paradigms for gazebo, an open-source multi-robot simulator\n.\nIn\n2004 IEEE/RSJ International Conference on Intelligent Robots and\nSystems, Sendai, Japan, September 28 - October 2, 2004\n,\npp.Â 2149â€“2154\n.\nExternal Links:\nLink\n,\nDocument\nCited by:\nÂ§1\n.\nE. Kolve, R. Mottaghi, D. Gordon, Y. Zhu, A. Gupta, and A. Farhadi (2017)\nAI2-THOR: an interactive 3d environment for visual AI\n.\nCoRR\nabs/1712.05474\n.\nExternal Links:\nLink\n,\n1712.05474\nCited by:\nAppendix B\n,\nÂ§1\n,\nÂ§4.4\n.\nC. Li, R. Zhang, J. Wong, C. Gokmen, S. Srivastava, R. MartÃ­n-MartÃ­n, C. Wang, G. Levine, W. Ai, B. J. Martinez, H. Yin, M. Lingelbach, M. Hwang, A. Hiranaka, S. Garlanka, A. Aydin, S. Lee, J. Sun, M. Anvari, M. Sharma, D. Bansal, S. Hunter, K. Kim, A. Lou, C. R. Matthews, I. Villa-Renteria, J. H. Tang, C. Tang, F. Xia, Y. Li, S. Savarese, H. Gweon, C. K. Liu, J. Wu, and L. Fei-Fei (2024)\nBEHAVIOR-1K: A human-centered, embodied AI benchmark with 1, 000 everyday activities and realistic simulation\n.\nCoRR\nabs/2403.09227\n.\nExternal Links:\nLink\n,\nDocument\n,\n2403.09227\nCited by:\nÂ§2.2\n.\nJ. Liang, W. Huang, F. Xia, P. Xu, K. Hausman, B. Ichter, P. Florence, and A. Zeng (2023)\nCode as policies: language model programs for embodied control\n.\nIn\nIEEE International Conference on Robotics and Automation, ICRA\n2023, London, UK, May 29 - June 2, 2023\n,\npp.Â 9493â€“9500\n.\nExternal Links:\nLink\n,\nDocument\nCited by:\nÂ§2.3\n.\nG. Littlefair, N. S. Dutt, and N. J. Mitra (2025)\nFlairGPT: repurposing llms for interior designs\n.\nComput. Graph. Forum\n44\n(\n2\n).\nExternal Links:\nLink\n,\nDocument\nCited by:\nÂ§2.2\n.\nS. Lukasczyk and G. Fraser (2022)\nPynguin: automated unit test generation for python\n.\nIn\n44th IEEE/ACM International Conference on Software Engineering:\nCompanion Proceedings, ICSE Companion 2022, Pittsburgh, PA, USA,\nMay 22-24, 2022\n,\npp.Â 168â€“172\n.\nExternal Links:\nLink\n,\nDocument\nCited by:\nÂ§2.1\n.\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark, G. Krueger, and I. Sutskever (2021)\nLearning transferable visual models from natural language supervision\n.\nIn\nProceedings of the 38th International Conference on Machine Learning,\nICML 2021, July 18-24, 2021, Virtual Event\n,\nM. Meila and T. Zhang (Eds.)\n,\nProceedings of Machine Learning Research\n, Vol.\n139\n,\npp.Â 8748â€“8763\n.\nExternal Links:\nLink\nCited by:\nÂ§4.4.2\n.\nS. K. Ramakrishnan, A. Gokaslan, E. Wijmans, O. Maksymets, A. Clegg, J. M. Turner, E. Undersander, W. Galuba, A. Westbury, A. X. Chang, M. Savva, Y. Zhao, and D. Batra (2021)\nHabitat-matterport 3d dataset (HM3D): 1000 large-scale 3d environments for embodied AI\n.\nIn\nProceedings of the Neural Information Processing Systems Track on\nDatasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021, December\n2021, virtual\n,\nJ. Vanschoren and S. Yeung (Eds.)\n,\nExternal Links:\nLink\nCited by:\nÂ§1\n.\nG. Ryan, S. Jain, M. Shang, S. Wang, X. Ma, M. K. Ramanathan, and B. Ray (2024)\nCode-aware prompting: A study of coverage-guided test generation in regression setting using LLM\n.\nProc. ACM Softw. Eng.\n1\n(\nFSE\n),\npp.Â 951â€“971\n.\nExternal Links:\nLink\n,\nDocument\nCited by:\nÂ§2.1\n,\nÂ§5.2.1\n.\nM. SchÃ¤fer, S. Nadi, A. Eghbali, and F. Tip (2024)\nAn empirical evaluation of using large language models for automated unit test generation\n.\nIEEE Trans. Software Eng.\n50\n(\n1\n),\npp.Â 85â€“105\n.\nExternal Links:\nLink\n,\nDocument\nCited by:\nÂ§2.1\n.\nK. Sen, D. Marinov, and G. Agha (2005)\nCUTE: a concolic unit testing engine for C\n.\nIn\nProceedings of the 10th European Software Engineering Conference held\njointly with 13th ACM SIGSOFT International Symposium on Foundations\nof Software Engineering, 2005, Lisbon, Portugal, September 5-9, 2005\n,\nM. Wermelinger and H. C. Gall (Eds.)\n,\npp.Â 263â€“272\n.\nExternal Links:\nLink\n,\nDocument\nCited by:\nÂ§2.1\n.\nJ. Tang, Y. Nie, L. Markhasin, A. Dai, J. Thies, and M. NieÃŸner (2024a)\nDiffuScene: denoising diffusion models for generative indoor scene synthesis\n.\nIn\nIEEE/CVF Conference on Computer Vision and Pattern Recognition,\nCVPR 2024, Seattle, WA, USA, June 16-22, 2024\n,\npp.Â 20507â€“20518\n.\nExternal Links:\nLink\n,\nDocument\nCited by:\nÂ§1\n,\nÂ§2.2\n.\nS. Tang, Z. Zhang, J. Zhou, L. Lei, Y. Zhou, and Y. Xue (2024b)\nLeGEND: A top-down approach to scenario generation of autonomous driving systems assisted by large language models\n.\nIn\nProceedings of the 39th IEEE/ACM International Conference on Automated\nSoftware Engineering, ASE 2024, Sacramento, CA, USA, October 27\n- November 1, 2024\n,\nV. Filkov, B. Ray, and M. Zhou (Eds.)\n,\npp.Â 1497â€“1508\n.\nExternal Links:\nLink\n,\nDocument\nCited by:\nÂ§1\n.\nJ. Wang, B. Li, J. Qi, X. Wang, F. Li,\net al.\n(2025a)\nBeSimulator: a large language model powered text-based behavior simulator\n.\nIn\nProceedings of the 2025 Conference on Empirical Methods in Natural\nLanguage Processing, EMNLP 2025, Suzhou, China, November 5-9, 2025\n,\npp.Â 4736â€“4754\n.\nExternal Links:\nLink\n,\nDocument\nCited by:\nAppendix A\n,\nÂ§5.1\n,\nÂ§5.2.1\n.\nW. Wang, Z. Gao, L. Gu, H. Pu, L. Cui, X. Wei, Z. Liu, L. Jing, S. Ye, J. Shao, Z. Wang, Z. Chen, H. Zhang, G. Yang, H. Wang, Q. Wei, J. Yin, W. Li, E. Cui, G. Chen, Z. Ding, C. Tian, Z. Wu, J. Xie, Z. Li, B. Yang, Y. Duan, X. Wang, Z. Hou, H. Hao, T. Zhang, S. Li, X. Zhao, H. Duan, N. Deng, B. Fu, Y. He, Y. Wang, C. He, B. Shi, J. He, Y. Xiong, H. Lv, L. Wu, W. Shao, K. Zhang, H. Deng, B. Qi, J. Ge, Q. Guo, W. Zhang, S. Zhang, M. Cao, J. Lin, K. Tang, J. Gao, H. Huang, Y. Gu, C. Lyu, H. Tang, R. Wang, H. Lv, W. Ouyang, L. Wang, M. Dou, X. Zhu, T. Lu, D. Lin, J. Dai, W. Su, B. Zhou, K. Chen, Y. Qiao, W. Wang, and G. Luo (2025b)\nInternVL3.5: advancing open-source multimodal models in versatility, reasoning, and efficiency\n.\nCoRR\nabs/2508.18265\n.\nExternal Links:\nLink\n,\nDocument\n,\n2508.18265\nCited by:\nÂ§D.2\n.\nW. Wang, C. Yang, Z. Wang, Y. Huang, Z. Chu, D. Song, L. Zhang, A. R. Chen, and L. Ma (2025c)\nTESTEVAL: benchmarking large language models for test case generation\n.\nIn\nFindings of the Association for Computational Linguistics: NAACL\n2025, Albuquerque, New Mexico, USA, April 29 - May 4, 2025\n,\nL. Chiruzzo, A. Ritter, and L. Wang (Eds.)\n,\npp.Â 3547â€“3562\n.\nExternal Links:\nLink\n,\nDocument\nCited by:\nÂ§2.1\n.\nY. Wang, Z. Xian, F. Chen, T. Wang, Y. Wang, K. Fragkiadaki, Z. Erickson, D. Held, and C. Gan (2024)\nRoboGen: towards unleashing infinite data for automated robot learning via generative simulation\n.\nIn\nForty-first International Conference on Machine Learning, ICML 2024,\nVienna, Austria, July 21-27, 2024\n,\nExternal Links:\nLink\nCited by:\nÂ§1\n,\nÂ§2.2\n.\nJ. Wei, X. Wang, D. Schuurmans, M. Bosma, B. Ichter, F. Xia, E. H. Chi, Q. V. Le, and D. Zhou (2022)\nChain-of-thought prompting elicits reasoning in large language models\n.\nIn\nAdvances in Neural Information Processing Systems 35: Annual Conference\non Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans,\nLA, USA, November 28 - December 9, 2022\n,\nS. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh (Eds.)\n,\nExternal Links:\nLink\nCited by:\nAppendix B\n,\nÂ§5.2.2\n.\nZ. Wu, Y. Rubanova, R. Kabra, D. A. Hudson, I. Gilitschenski, Y. Aytar, S. van Steenkiste, K. R. Allen, and T. Kipf (2024)\nNeural assets: 3d-aware multi-object scene synthesis with image diffusion models\n.\nIn\nAdvances in Neural Information Processing Systems 38: Annual Conference\non Neural Information Processing Systems 2024, NeurIPS 2024, Vancouver,\nBC, Canada, December 10 - 15, 2024\n,\nA. Globersons, L. Mackey, D. Belgrave, A. Fan, U. Paquet, J. M. Tomczak, and C. Zhang (Eds.)\n,\nExternal Links:\nLink\nCited by:\nÂ§2.2\n.\nA. Yang, B. Yang, B. Zhang, B. Hui, B. Zheng, B. Yu, C. Li, D. Liu, F. Huang, H. Wei, H. Lin, J. Yang, J. Tu, J. Zhang, J. Yang, J. Yang, J. Zhou, J. Lin, K. Dang, K. Lu, K. Bao, K. Yang, L. Yu, M. Li, M. Xue, P. Zhang, Q. Zhu, R. Men, R. Lin, T. Li, T. Xia, X. Ren, X. Ren, Y. Fan, Y. Su, Y. Zhang, Y. Wan, Y. Liu, Z. Cui, Z. Zhang, and Z. Qiu (2024a)\nQwen2.5 technical report\n.\nCoRR\nabs/2412.15115\n.\nExternal Links:\nLink\n,\nDocument\n,\n2412.15115\nCited by:\nÂ§5.2.2\n.\nY. Yang, B. Jia, P. Zhi, and S. Huang (2024b)\nPhyScene: physically interactable 3d scene synthesis for embodied AI\n.\nIn\nIEEE/CVF Conference on Computer Vision and Pattern Recognition,\nCVPR 2024, Seattle, WA, USA, June 16-22, 2024\n,\npp.Â 16262â€“16272\n.\nExternal Links:\nLink\n,\nDocument\nCited by:\nÂ§1\n.\nY. Yang, F. Sun, L. Weihs, E. VanderBilt, A. Herrasti, W. Han, J. Wu, N. Haber, R. Krishna, L. Liu, C. Callison-Burch, M. Yatskar, A. Kembhavi, and C. Clark (2024c)\nHolodeck: language guided generation of 3d embodied AI environments\n.\nIn\nIEEE/CVF Conference on Computer Vision and Pattern Recognition,\nCVPR 2024, Seattle, WA, USA, June 16-22, 2024\n,\npp.Â 16277â€“16287\n.\nExternal Links:\nLink\n,\nDocument\nCited by:\nAppendix B\n,\nFigure 1\n,\nÂ§1\n,\nÂ§1\n,\nÂ§2.2\n,\nÂ§4.4.2\n,\nÂ§5.2.2\n.\nS. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. R. Narasimhan, and Y. Cao (2023)\nReAct: synergizing reasoning and acting in language models\n.\nIn\nThe Eleventh International Conference on Learning Representations,\nICLR 2023, Kigali, Rwanda, May 1-5, 2023\n,\nExternal Links:\nLink\nCited by:\nÂ§2.3\n.\nS. Zhang, B. Li, J. Qi, X. Wang, F. Li, J. Wang, E. Zhu, and J. Sun (2025)\nCode-bt: A code-driven approach to behavior tree generation for robot tasks planning with large language models\n.\nIn\nProceedings of the Thirty-Fourth International Joint Conference on\nArtificial Intelligence, IJCAI 2025, Montreal, Canada, August 16-22,\n2025\n,\npp.Â 8814â€“8822\n.\nExternal Links:\nLink\n,\nDocument\nCited by:\nAppendix A\n,\nÂ§5.1\n.\nX. Zhou, X. Ran, Y. Xiong, J. He, Z. Lin, Y. Wang, D. Sun, and M. Yang (2024)\nGALA3D: towards text-to-3d complex scene generation via layout-guided generative gaussian splatting\n.\nIn\nForty-first International Conference on Machine Learning, ICML 2024,\nVienna, Austria, July 21-27, 2024\n,\nExternal Links:\nLink\nCited by:\nÂ§1\n,\nÂ§2.2\n.\nY. Zhou, Z. He, Q. Li, and C. Wang (2025)\nLAYOUTDREAMER: physics-guided layout for text-to-3d compositional scene generation\n.\nCoRR\nabs/2502.01949\n.\nExternal Links:\nLink\n,\nDocument\n,\n2502.01949\nCited by:\nÂ§2.2\n.\nB. Zitkovich, T. Yu, S. Xu, P. Xu, T. Xiao, F. Xia, J. Wu, P. Wohlhart, S. Welker, A. Wahid, Q. Vuong, V. Vanhoucke, H. T. Tran, R. Soricut, A. Singh, J. Singh, P. Sermanet, P. R. Sanketi, G. Salazar, M. S. Ryoo, K. Reymann, K. Rao, K. Pertsch, I. Mordatch, H. Michalewski, Y. Lu, S. Levine, L. Lee, T. E. Lee, I. Leal, Y. Kuang, D. Kalashnikov, R. Julian, N. J. Joshi, A. Irpan, B. Ichter, J. Hsu, A. Herzog, K. Hausman, K. Gopalakrishnan, C. Fu, P. Florence, C. Finn, K. A. Dubey, D. Driess, T. Ding, K. M. Choromanski, X. Chen, Y. Chebotar, J. Carbajal, N. Brown, A. Brohan, M. G. Arenas, and K. Han (2023)\nRT-2: vision-language-action models transfer web knowledge to robotic control\n.\nIn\nConference on Robot Learning, CoRL 2023, November 6-9, 2023, Atlanta,\nGA, USA\n,\nJ. Tan, M. Toussaint, and K. Darvish (Eds.)\n,\nProceedings of Machine Learning Research\n, Vol.\n229\n,\npp.Â 2165â€“2183\n.\nExternal Links:\nLink\nCited by:\nÂ§2.3\n.\nAppendix A\nLogicEnvEval\nIn this section, we provide a detailed description of the LogicEnvEval benchmark.\nLogicEnvEval comprises 25 long-horizon household tasks, each designed with complex conditional logic.\nFor every task, LogicEnvEval defines a natural language task description, a ground-truth behavior plan, and four distinct agent policies represented as Behavior Trees (BTs)â€”one correct policy and three faulty variations.\nSpecifically, given a task, we first employ Code-BT\nZhang\net al.\n(\n2025\n)\nto synthesize a correct agent policy. Subsequently, drawing upon the existing taxonomy of faulty BTs\nWang\net al.\n(\n2025a\n)\n, we construct three faulty policies by altering some nodes within the correct policy.\nFor each policy, we conduct multiple rounds of manual verification and refinement to ensure its availability.\nThe four agent policies are categorized based on their adherence to physical and logical constraints.\nTo be specific, the faulty policy types include Counterfactuals, Unreachable and Lackbranch.\nCounterfactuals denotes that the BT violates real-world causal logic (e.g.,\ntaking an apple from a refrigerator before opening it\n).\nUnreachable means that the BT conforms to real-world logic but fails the task goal (e.g.,\nmerely grasping a book while the goal is to clean it\n).\nThe above two types consider all possible task situations but fail in one, while Lackbranch indicates that the BT omits some situations, thus failing to adapt to diverse environments.\nTo illustrate the structure and data format of the benchmark, we present a task example\nClean Living Room\n, as shown in Table\n6\n.\nThe correct agent policy is illustrated in Figure\n6\n, while the three faulty variations are visualized in Figures\n7\n,\n8\nand\n9\n, respectively.\nAppendix B\nBaseline Methods\nCurrently, there is no specific framework designed for generating logically diverse test environments for embodied agents.\nThus, we compare LogicEnvGen with an environment generation method Holodeck\nYang\net al.\n(\n2024c\n)\n, and two scenario-agnostic methods including Chain of Thought (CoT)\nWei\net al.\n(\n2022\n)\nand IFG\nAhmed\net al.\n(\n2025\n)\n.\nSpecifically, for the CoT and IFG baselines, we generate text-based test cases and then instantiate them in AI2-THOR\nKolve\net al.\n(\n2017\n)\n, aligning with the implementation of our method.\nTo ensure fairness, all methods use the same problem setup, few-shot examples, and asset library.\nâ€¢\nCoT:\nWe prompt LLMs to generate explicit reasoning steps and subsequently design multiple test environments based on the embodied task description to cover all potential task situations.\nâ€¢\nIFG:\nIFG is a two-stage method that first samples intents and then generates responses to promote semantic diversity of LLM output.\nFollowing the official settings\nAhmed\net al.\n(\n2025\n)\n, we set the LLM temperature to 1.1 during the intent stage to generate diverse logical trajectories.\nSubsequently, we lower the temperature to 0.5 during the final generation stage to synthesize test environments conditioned on the embodied task description and the logical trajectories of the first stage.\nâ€¢\nHolodeck:\nHolodeck is a language-guided system capable of generating interactive 3D environments from textual descriptions.\nWe provide Holodeck embodied task descriptions to generate 3D environments.\nAppendix C\nMore Quantitative Results\nIn the Behavior Plan Derivation phase, we leverage LLM to analyze task execution logic and generate decision-tree-structured behavior plans.\nThis process consists of three steps: Task decomposition, Uncertain factor identification, and Behavior plan generation.\nIn this section, we present a detailed quantitative analysis of the LLM stability and accuracy across these three steps.\nSpecifically, we conduct five repeated experiments with the same setup: set the LLM temperature to 0, top-p to 1, and fix the seeds.\nThe results are summarized in Table\n5\n.\nExperimental results indicate that the LLMs are non-deterministic even with the same hyper-parameters.\nNotably, Gemini-2.5-Flash demonstrates superior stability compared to DeepSeek-V3 and Qwen2.5-72B, yielding consistent responses in every run.\nThrough in-depth analysis, we find that LLMs are prone to several issues: incomplete task decomposition, missing uncertain factors and incorrect uncertain factors.\nSpecifically, the LLMs occasionally groups mutually independent subtasks into a single subtask, resulting in the logically redundant simulated environments.\nFurthermore, when identifying uncertain environment factors, the LLMs may overlook specific factors, leading to missed branches; alternatively, they may consider incorrect factors (e.g.,\nthe existence or functionality of an object\n), which undermine the validity of simulated environments.\nModel\nAcc_TD(%)\nAcc_UFI(%)\nAcc_BPG(%)\nDeepSeek-V3\n96.00\nÂ±\n0.00\n96.00\\pm 0.00\n94.56\nÂ±\n0.36\n94.56\\pm 0.36\n95.04\nÂ±\n0.36\n95.04\\pm 0.36\nGemini-2.5-Flash\n97.33\nÂ±\n0.00\n97.33\\pm 0.00\n94.00\nÂ±\n0.00\n94.00\\pm 0.00\n94.00\nÂ±\n0.00\n94.00\\pm 0.00\nQwen2.5-72B\n89.47\nÂ±\n0.73\n89.47\\pm 0.73\n87.07\nÂ±\n1.01\n87.07\\pm 1.01\n87.07\nÂ±\n1.01\n87.07\\pm 1.01\nTable 5:\nQuantitative result of LLM stability and accuracy across the three steps of Behavior Plan Derivation. â€œAcc_TDâ€, â€œAcc_UFIâ€, and â€œAcc_BPGâ€ denote the accuracy of Task Decomposition, Uncertain Factor Identification, and Behavior Plan Generation, respectively.\nTask name\nClean Living Room\nTask description\nYou are in the living room. There are a sofa and a table with a wet mop leaning against it. There may be a book or a toy on the floor. The room has two toy boxes - a red one for dolls and a white one for other toys. There is a dirty mark on the floor, and you may find a pack of wet wipes on the table.\nYour task:\nPlease check the living room floor, if there are items on floor, put them where they belong (e.g., book should be placed on the sofa, toy should be placed in the toy box). Clean the mark, preferably with the wet wipes on the table (if available). If there arenâ€™t any wipes, you can use the wet mop instead.\nDecision-tree-structured\nbehavior plan\n[\n{\n\"There is a toy on the floor?\": {\n\"YES\": {\n\"What is the type of the toy on the floor?\": {\n\"doll\": \"Place the toy in the red box.\",\n\"other types\": \"Place the toy in the white box.\"\n},\n\"NO\": \"Do nothing.\"\n}\n},\n{\n\"There is a book on the floor?\": {\n\"YES\": \"Place the book on the sofa.\",\n\"NO\": \"Do nothing.\"\n}\n},\n{\n\"There is a wet wipe on the table?\": {\n\"YES\": \"Clean stain with the wet wipe.\",\n\"NO\": \"Clean stain with the wet mop.\"\n}\n}\n]\nTable 6:\nTask description and decision-tree-structured behavior plan of the example\nClean Living Room\n.\nFigure 6:\nCorrect policy (Behavior Tree) of the example\nClean Living Room\n.\nFigure 7:\nFaulty policy (Behavior Tree) of the example\nClean Living Room\n, which belongs to the Counterfactuals category. Reason: agent does not pick up the toy (non-doll) before placing it into the white toy box.\nFigure 8:\nFaulty policy (Behavior Tree) of the example\nClean Living Room\n, which belongs to the Unreachable category. Reason: agent picks up the toy (doll) but does not place it into the red toy box.\nFigure 9:\nFaulty policy (Behavior Tree) of the example\nClean Living Room\n, which belongs to the Lackbranch category. Reason: agent fails to plan for situations where wet wipes are absent.\nFigure 10:\nQualitative comparison on two LogicEnvEval tasks. While baseline methods suffer from physical implausibilities (e.g., floating objects), irrational layout or miss task-relevant items, LogicEnvGen generates environments with superior visual fidelity, layout coherence, and strict task alignment.\nAppendix D\nVisual Evaluation\nTo better understand the potential trade-off between logical diversity and visual realism, we conduct the qualitative and quantitative evaluations to compare the visual quality of the environments generated by LogicEnvGen and baselines.\nThree baselines and LogicEnvGen utilize the same Objaverse assets to ensure a fair comparison.\nFor each task in LogicEnvEval, we randomly sample one generated environment from each method.\nWe group the environments of the same task from four methods, resulting in 25 groups of environments for visual evaluation.\nD.1\nQualitative Experiment\nAs shown in Figure\n10\n, we present the visual results of environments generated by four methods across two LogicEnvEval tasks.\nCompared to the three baselines, LogicEnvGen demonstrates significant advantages in visual fidelity, layout coherence, and task alignment.\nSpecifically, while CoT generates necessary task-relevant objects, it suffers from severe violations of physical constraints (e.g.,\nfloating kettles in Task 8\n) and irrational object placements.\nSimilarly, IFG incorporates necessary objects but lacks object diversity and exhibits incoherent spatial arrangements (e.g.,\nlarge furniture not being placed flush against the walls\n).\nHolodeck excels in object richness and layout consistency but struggles to satisfy task constraints, frequently omitting critical task-relevant items (e.g.,\nfood cans in Task 8\n).\nIn contrast, LogicEnvGen achieves visual realism comparable to Holodeck while ensuring adherence to task descriptions.\nD.2\nQuantitative Experiment\nFigure 11:\nVLM evaluation of LogicEnvGen and three baselines across 25 LogicEnvEval tasks. The pie charts show the distribution of VLM preferences. The results from both Gemini 3 Pro and InternVL3_5-38B consistently show LogicEnvGen outperforms three baselines across three criteria.\nSetup.\nTo enable automatic quantitative evaluations, we leverage Vision Language Models (VLMs) as evaluators to provide an objective assessment for the generated environments.\nWe employ two well-known VLMs in the field of closed source and open source, including Gemini 3 Pro\nDeepMind (\n2025b\n)\nand InternVL3_5-38B\nWang\net al.\n(\n2025b\n)\n.\nTo mitigate positional bias, each group of environments is presented to the evaluation model as four shuffled top-down view images.\nThe evaluation model is asked to score the environments on a scale of 1 to 5 based on three criteria:\n(1)\nAsset Selection\n: Which environment selects 3D assets that are more accurate and faithful to the task description and the environment type?\n(2)\nLayout Coherence\n: Which environment arranges 3D assets in a more realistic and logically consistent manner?\n(3)\nOverall Preference\n: Given the environment type and task description, which environment is preferred overall in terms of visual quality (realism and richness) and utility?\nNotably, Layout Coherence assesses pure visual quality, whereas the other two criteria incorporate task alignment.\nFigure\n11\nillustrates a clear preference for LogicEnvGen in two VLM evaluations over the three baselines.\nFor example, Gemini 3 Pro favors LogicEnvGen in Asset Selection (60%), Layout Coherence (60%), and shows a significant preference in Overall Preference (68%).\nThese results demonstrate that LogicEnvGen generates more realistic and task-aligned environments.\nIn addition to VLM evaluation, we utilize CLIP Score\n2\n2\n2\nHere, we use OpenAI ViT-L/14 model. We use cosine similarity times 100 as the CLIP Score.\nHessel\net al.\n(\n2021\n)\nto assess the visual consistency between the top-down view of the environment and its designated environment type, formulated as the text prompt â€œa top-down view of [environment type]â€ (e.g.,\nâ€œa top-down view of bedroomâ€\n).\nWe categorize the tasks in LogicEnvEval into two categories based on task scenario: Single-Room and Multi-Room.\nFigure\n12\ndemonstrates that LogicEnvGen outperforms all three baselines in the Single-Room category.\nIn the Multi-Room category, it achieves performance comparable to Holodeck while surpassing both CoT and IFG.\nThese results validate LogicEnvGenâ€™s capability to generate environments that are visually consistent with the designated environment types.\nThe CLIP Score experiment agrees with the VLM evaluation.\nFigure 12:\nCLIP Score comparison over two scenario categories.\nAppendix E\nCase Study\nIn Figures\n13\n,\n14\nand\n15\n, we show the simulation test cases generated by LogicEnvGen for three embodied tasks.\nFigure 13:\nCase 1. Agent task: Bring me a desk lamp from study if there is a pan in the kitchen. Otherwise, bring me a pillow from the bedroom.\nFigure 14:\nCase 2. Agent task: The bedroom has a bed, possibly with a book or clock on it, along with a bookshelf and a desk. The bookshelfâ€™s three levels hold novels, essays, and other books respectively. Clean items on the bed and put them into their designated storage areas (e.g., book on the shelf, phone on the desk).\nFigure 15:\nCase 3. Agent task: The living room has a sofa, a tea table, and two toy boxesâ€”the blue one for dolls and the white one for other toys. The floor is stained and there might be a sofa pillow or toy on it. Check the floor and put misplaced items (like a pillow or toy) in their proper places. Clean the stain, preferably with the wet wipes on the table (if available), otherwise use the wet mop by the wall.",
    "preview_text": "Simulated environments play an essential role in embodied AI, functionally analogous to test cases in software engineering. However, existing environment generation methods often emphasize visual realism (e.g., object diversity and layout coherence), overlooking a crucial aspect: logical diversity from the testing perspective. This limits the comprehensive evaluation of agent adaptability and planning robustness in distinct simulated environments. To bridge this gap, we propose LogicEnvGen, a novel method driven by Large Language Models (LLMs) that adopts a top-down paradigm to generate logically diverse simulated environments as test cases for agents. Given an agent task, LogicEnvGen first analyzes its execution logic to construct decision-tree-structured behavior plans and then synthesizes a set of logical trajectories. Subsequently, it adopts a heuristic algorithm to refine the trajectory set, reducing redundant simulation. For each logical trajectory, which represents a potential task situation, LogicEnvGen correspondingly instantiates a concrete environment. Notably, it employs constraint solving for physical plausibility. Furthermore, we introduce LogicEnvEval, a novel benchmark comprising four quantitative metrics for environment evaluation. Experimental results verify the lack of logical diversity in baselines and demonstrate that LogicEnvGen achieves 1.04-2.61x greater diversity, significantly improving the performance in revealing agent faults by 4.00%-68.00%.\n\nLogicEnvGen: Task-Logic Driven Generation of Diverse Simulated Environments for Embodied AI\nJianan Wang\n1\n,\nSiyang Zhang\n1\n,\nBin Li\n2âˆ—\n,\nJuan Chen\n1âˆ—\n,\nJingtao Qi\n2\n,\nZhuo Zhang\n2\n,\nChen Qian\n3\n1\nCollege of Computer Science and Technology, National University of Defense Technology\n2\nIntelligent Game and Decision Lab (IGDL), Beijing\n3\nSchool of Artifical Intelligence, Shanghai Jiao Tong University\nwangjianan@nudt.edu.cn\nlibin_bill@126.com\nAbstract\nSimulated environments play an essential role in embo",
    "is_relevant": false,
    "relevance_score": 2.0,
    "extracted_keywords": [
        "LLMs",
        "simulated environments",
        "embodied AI",
        "logical diversity",
        "environment generation",
        "test cases",
        "constraint solving"
    ],
    "one_line_summary": "è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„ä»»åŠ¡é€»è¾‘é©±åŠ¨æ–¹æ³•ï¼Œç”¨äºç”Ÿæˆé€»è¾‘å¤šæ ·åŒ–çš„æ¨¡æ‹Ÿç¯å¢ƒï¼Œä»¥è¯„ä¼°å…·èº«AIä»£ç†çš„é€‚åº”æ€§å’Œè§„åˆ’é²æ£’æ€§ã€‚",
    "detailed_summary": "",
    "qa_pairs": [],
    "is_hidden": false,
    "is_starred": false,
    "flag": true,
    "published_date": "2026-01-20T03:28:07Z",
    "created_at": "2026-01-27T15:53:06.718104",
    "updated_at": "2026-01-27T15:53:06.718111"
}