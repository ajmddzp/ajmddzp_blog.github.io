{
  "id": "2601.11063v1",
  "title": "H-AIM: Orchestrating LLMs, PDDL, and Behavior Trees for Hierarchical Multi-Robot Planning",
  "authors": [
    "Haishan Zeng",
    "Peng Li"
  ],
  "abstract": "In embodied artificial intelligence, enabling heterogeneous robot teams to execute long-horizon tasks from high-level instructions remains a critical challenge. While large language models (LLMs) show promise in instruction parsing and preliminary planning, they exhibit limitations in long-term reasoning and dynamic multi-robot coordination. We propose Hierarchical Autonomous Intelligent Multi-Robot Planning(H-AIM), a novel embodied multi-robot task planning framework that addresses these issues through a three-stage cascaded architecture: 1) It leverages an LLM to parse instructions and generate Planning Domain Definition Language (PDDL) problem descriptions, thereby transforming commands into formal planning problems; 2) It combines the semantic reasoning of LLMs with the search capabilities of a classical planner to produce optimized action sequences; 3) It compiles the resulting plan into behavior trees for reactive control. The framework supports dynamically sized heterogeneous robot teams via a shared blackboard mechanism for communication and state synchronization. To validate our approach, we introduce the MACE-THOR benchmark dataset, comprising 42 complex tasks across 8 distinct household layouts. Experimental results demonstrate that H-AIM achieves a remarkable performance improvement, elevating the task success rate from 12% to 55% and boosting the goal condition recall from 32% to 72% against the strongest baseline, LaMMA-P.",
  "url": "https://arxiv.org/abs/2601.11063v1",
  "html_url": "https://arxiv.org/html/2601.11063v1",
  "html_content": "H-AIM: Orchestrating LLMs, PDDL, and Behavior Trees for Hierarchical Multi-Robot Planning\nHaishan Zeng\n1,2\nPeng Li\n1,2\n1\nUniversity of Chinese Academy of Sciences\n2\nInstitute of Software, Chinese Academy of Sciences\nzenghaishan24@mails.ucas.ac.cn\nlipeng@iscas.ac.cn\nAbstract\nIn embodied artificial intelligence, enabling heterogeneous robot teams to execute long-horizon tasks from high-level instructions remains a critical challenge. While large language models (LLMs) show promise in instruction parsing and preliminary planning, they exhibit limitations in long-term reasoning and dynamic multi-robot coordination. We propose\nH\nierarchical\nA\nutonomous\nI\nntelligent\nM\nulti-Robot Planning(H-AIM), a novel embodied multi-robot task planning framework that addresses these issues through a three-stage cascaded architecture: 1) It leverages an LLM to parse instructions and generate Planning Domain Definition Language (PDDL) problem descriptions, thereby transforming commands into formal planning problems; 2) It combines the semantic reasoning of LLMs with the search capabilities of a classical planner to produce optimized action sequences; 3) It compiles the resulting plan into behavior trees for reactive control. The framework supports dynamically sized heterogeneous robot teams via a shared blackboard mechanism for communication and state synchronization. To validate our approach, we introduce the\nMACE-THOR\nbenchmark dataset, comprising 42 complex tasks across 8 distinct household layouts. Experimental results demonstrate that\nH-AIM\nachieves a remarkable performance improvement, elevating the task success rate from 12% to 55% and boosting the goal condition recall from 32% to 72% against the strongest baseline, LaMMA-P.\n0\n0\nfootnotetext:\nCode and resources are available at:\nhttps://github.com/159357zeng/H-AIM\n1\nIntroduction\nFigure 1\n:\nOverview of H-AIM.\nThe diagram illustrates the core composition of our approach: the technical foundation (LLM, PDDL, BT), the executing heterogeneous robot team, and representative application scenarios.\nMulti-robot systems have been widely deployed in real-world scenarios such as warehouse logistics\n[\n5\n]\n, agricultural management\n[\n24\n,\n7\n]\n, and search and rescue operations\n[\n4\n,\n25\n]\n. These systems are designed for autonomous collaboration, relying on efficient internal coordination to achieve well-defined objectives. Recent advances in Large Language Models (LLMs) have unlocked new potential for robotic task planning\n[\n18\n]\n, enabling the execution of complex, long-horizon household tasks from high-level natural language instructions\n[\n37\n,\n23\n,\n40\n]\n. Ideally, heterogeneous robot teams should be capable of autonomously accomplishing complex tasks entailing diversified collaboration demands, as exemplified in the outer ring of\nFig.\n1\n, based on high-level human instructions. However, reliably executing such long-horizon tasks in dynamic environments remains a critical challenge.\nTraditional multi-robot task planning methods struggle to manage such complexity, especially in environments with diverse tasks and intricate interdependencies between robots\n[\n27\n,\n34\n]\n. They often rely on fixed, pre-defined algorithms that lack the flexibility to handle the intricacies of tasks that unfold over extended durations\n[\n15\n]\n. Although recent approaches\n[\n14\n,\n33\n,\n38\n,\n30\n,\n22\n,\n40\n,\n18\n]\nthat leverage Language Models for multi-agent planning have shown potential, they often falter with long-horizon reasoning and complex task dependencies, particularly in collaborative settings\n[\n35\n]\n, and demonstrate limited generalization across tasks of varying difficulty. These limitations primarily stem from a lack of deep architectural synergy\n[\n14\n,\n38\n,\n32\n]\n: most systems adhere to a single technical pathway, failing to effectively integrate the semantic understanding of LLMs, the rigor of formal planners, and the reactive control capabilities needed for robust execution in dynamic environments\n[\n28\n]\n. This often results in systems with low autonomy, poor fault tolerance, and rigid collaboration mechanisms that cannot accommodate dynamic team sizes or complex synchronization needs.\nTo address these challenges, we propose H-AIM, a Hierarchical Autonomous Intelligent Multi-robot planning framework. Our approach orchestrates LLMs, Planning Domain Definition Language (PDDL)\n[\n2\n]\n, and Behavior Trees through a three-stage cascaded architecture. Its core innovation lies in realizing an end-to-end closed loop from high-level instruction parsing to low-level robust execution, supporting dynamic multi-robot coordination through a shared blackboard-based communication and state synchronization mechanism.\nThe main contributions of this paper are as follows:\nâ€¢\nWe propose\nH-AIM\n, a novel hierarchical multi-robot task planning framework. Its cascaded architecture seamlessly integrates the semantic understanding of LLMs, the formal search of PDDL planners, and the reactive control of Behavior Trees for the first time, providing an end-to-end solution for heterogeneous robot teams executing long-horizon complex tasks.\nâ€¢\nwe construct a new benchmark dataset,\nMACE-THOR\n, providing complex household task scenarios ranging from independent to collaborative tasks within the AI2-THOR\n[\n16\n]\nsimulation environment for evaluating heterogeneous multi-robot task planning.\nâ€¢\nWe conduct extensive experimental evaluations. Compared to the strongest baseline LaMMA-P\n[\n38\n]\n, our method improves the task success rate from 12% to\n55%\nand the goal condition recall from 32% to\n72%\n. We also provide a systematic analysis of the performance using different LLMs.\n2\nRelated Work\nFigure 2\n:\nH-AIM architecture.\nThe framework orchestrates three LLM-driven modules (PFG, HP, BTC) to convert language instructions into executable plans.\nSolving complex tasks requiring sequential multi-step decision-making over extended periods is a core problem in artificial intelligence\n[\n18\n]\n. Traditional methods primarily encompass Hierarchical Task Networks (HTN)\n[\n10\n]\n, PDDL-based planning systems\n[\n13\n,\n5\n]\n, and Monte Carlo Tree Search (MCTS)\n[\n6\n]\n. These methods typically rely on task decomposition or state-space sampling to handle long-horizon planning problems. However, they often suffer from insufficient computational efficiency and scalability bottlenecks when dealing with large-scale, complex environments. Furthermore, existing methods exhibit significant limitations in task generalization and environmental adaptability. While Reinforcement Learning (RL)\n[\n17\n]\nhas shown promise in learning transferable policies, it still faces generalization and scalability challenges akin to traditional methods in long-horizon planning tasks\n[\n20\n]\n.\nThe rapid development of LLMs has catalyzed new paradigms that integrate them with planning systems\n[\n37\n,\n23\n,\n33\n,\n18\n]\n. These approaches leverage the powerful natural language understanding and reasoning capabilities of LLMs to transform abstract task descriptions into structured planning representations. Notably, PDDL-based LLM planning frameworks, which map natural language instructions into formal planning problem descriptions\n[\n19\n,\n29\n,\n21\n,\n39\n,\n8\n,\n11\n,\n31\n,\n36\n]\n, offer new avenues for complex task solving. Existing research has demonstrated how classical planning verifiers can be combined with LLM reasoning capabilities to enhance planning quality through iterative refinement mechanisms\n[\n29\n,\n39\n]\n. Other work has explored multi-agent collaborative planning architectures that improve task execution efficiency through role specialization\n[\n30\n]\n. Nevertheless, these methods still exhibit deficiencies in robot autonomy and collaboration capabilities: most systems are confined to fixed-number robot configurations, individual robots lack autonomous reasoning and decision-making abilities necessary to cope with environmental changes, and inter-robot communication mechanisms are often simplistic, resulting in system performance being highly dependent on the capabilities of the LLM\n[\n18\n]\n.\nIn contrast to prior work\n[\n38\n,\n14\n]\n, the H-AIM framework introduces comprehensive innovations in multi-robot system flexibility, individual robot autonomy, and collaboration mechanisms. Our approach supports dynamically sized heterogeneous robot teams working collaboratively, endows each robot with fundamental reasoning and contingency capabilities through Behavior Trees, and establishes a flexible communication mechanism to handle complex task dependencies. This design significantly enhances the adaptability and robustness of multi-robot teams in dynamic environments by combining formal planning with reactive control, while preserving the advantages of LLM semantic understanding.\n3\nMethods\nOur framework, H-AIM, is designed to address long-horizon task planning for heterogeneous multi-robot teams by orchestrating LLMs, PDDL-based symbolic planning, and Behavior Trees. The core of our approach is a three-stage cascaded architecture designed to systematically transform high-level commands into robust, parallelizable physical executions. The remainder of this section is organized as follows. We first formalize the problem and then elaborate on the three integral components of our framework: the PDDL File Generator(PFG), the Hybrid Planner(HP) and the Behavior Tree Compiler(BTC).\n3.1\nProblem Formulation\nWe focus on a fully observable household task environment\nâ„°\n\\mathcal{E}\n. Within this environment, a team of heterogeneous robots\nâ„›\n=\n{\nR\n1\n,\nR\n2\n,\nâ€¦\n,\nR\nN\n}\n\\mathcal{R}=\\{{R_{1},R_{2},\\ldots,R_{N}}\\}\nmust collaboratively accomplish a daily task (\ne.g\n.\n, tidying items or preparing a meal) specified by a high-level natural language instruction\nI\nI\n. Such instructions are typically abstract and lack explicit specification of concrete action sequences, thus requiring deep semantic understanding, long-horizon task decomposition, sub-task allocation, and temporal logic reasoning. The core objective is to construct a parsing pipeline that translates the natural language instruction\nI\nI\ninto a structured plan\nğ’«\n\\mathcal{P}\n, which serves as an intermediate representation and is ultimately compiled into an executable behavior tree\nğ’¯\n\\mathcal{T}\n. We formalize this as a synchronously collaborative, heterogeneous multi-robot task planning problem.\nAssume we have\nN\nN\nheterogeneous robots, collectively denoted as\nâ„›\n\\mathcal{R}\n. Let\nÎ”\n\\Delta\nrepresent the set of all possible atomic skills. In our framework, each skill\nÏƒ\nâˆˆ\nÎ”\n\\sigma\\in\\Delta\nis encapsulated and implemented as a behavior subtree\nğ’¯\nÏƒ\n\\mathcal{T}_{\\sigma}\n, which can be invoked via predefined system APIs. Each robot\nR\ni\nâˆˆ\nâ„›\nR_{i}\\in\\mathcal{R}\npossesses its own personalized subset of skills\nS\ni\nâŠ†\nÎ”\nS_{i}\\subseteq\\Delta\n. A complex task\nT\nT\n, derived from the instruction\nI\nI\n, can be decomposed into a sequence of sub-tasks\nT\n=\nâŸ¨\nÏ„\n1\n,\nÏ„\n2\n,\nâ€¦\n,\nÏ„\nm\nâŸ©\nT=\\langle\\tau_{1},\\tau_{2},\\ldots,\\tau_{m}\\rangle\nwith potential temporal constraints. Each sub-task\nÏ„\nk\n\\tau_{k}\nis atomic, meaning it can be completed independently by a single robot possessing the requisite capability.We formally model a sub-task\nÏ„\nk\n\\tau_{k}\nas a quintuple:\nÏ„\nk\n=\n(\nR\ni\n,\nS\ni\n,\nÏ•\nk\n,\nÏˆ\nk\n,\nÎ³\nk\n)\n\\tau_{k}=(R_{i},S_{i},\\phi_{k},\\psi_{k},\\gamma_{k})\n, where\nR\ni\nâˆˆ\nâ„›\nR_{i}\\in\\mathcal{R}\ndenotes the robot assigned to execute this sub-task;\nS\ni\nâŠ†\nÎ”\nS_{i}\\subseteq\\Delta\nrepresents the skill set possessed by\nR\ni\nR_{i}\n;\nÏ•\nk\n\\phi_{k}\ndefines the environmental precondition state that must be satisfied for executing\nÏ„\nk\n\\tau_{k}\n;\nÏˆ\nk\n\\psi_{k}\nspecifies the particular skill or action performed during\nÏ„\nk\n\\tau_{k}\n; and\nÎ³\nk\n\\gamma_{k}\ndescribes the environmental goal state achieved upon its successful execution.\nSub-tasks may have synchronization constraints\nC\nsync\nâ€‹\n(\nÏ„\nj\n,\nÏ„\nl\n)\nC_{\\text{sync}}(\\tau_{j},\\tau_{l})\n, requiring certain sub-tasks to be executed concurrently or to satisfy specific temporal relationships. The overall task plan\nğ’«\n\\mathcal{P}\nis ultimately compiled into a parallel behavior tree\nğ’¯\nğ’«\n\\mathcal{T}_{\\mathcal{P}}\nfor execution, which is defined by\nEq.\n1\n.\nğ’¯\nğ’«\n=\nP\nâ€‹\na\nâ€‹\nr\nâ€‹\na\nâ€‹\nl\nâ€‹\nl\nâ€‹\ne\nâ€‹\nl\nâ€‹\n(\nğ’¯\nR\n1\n,\nğ’¯\nR\n2\n,\nâ€¦\n,\nğ’¯\nR\nN\n)\n\\mathcal{T_{P}}=Parallel({{\\mathcal{T}}_{R_{1}}},{{\\mathcal{T}}_{R_{2}}},\\ldots,{{\\mathcal{T}}_{R_{N}}})\n(1)\nwhere\nğ’¯\nR\ni\n\\mathcal{T}_{R_{i}}\nis the behavior subtree assigned to robot\nR\ni\nR_{i}\n, encoding all sub-task sequences allocated to\nR\ni\nR_{i}\nand their logical relationships. Let the initial state of the environment\nâ„°\n\\mathcal{E}\nbe\ns\n0\ns_{0}\n, and the desired goal state be\ns\ng\ns_{g}\n. The successful execution of task\nT\nT\nby the robot team means that executing the behavior tree\nğ’¯\nğ’«\n\\mathcal{T}_{\\mathcal{P}}\ndrives the environment from state\ns\n0\ns_{0}\nto a state satisfying\ns\ng\ns_{g}\n. Formally, the problem is defined by a quintuple\n(\nâ„›\n,\nÎ”\n,\nT\n,\ns\n0\n,\ns\ng\n)\n(\\mathcal{R},\\Delta,T,s_{0},s_{g})\n, with the goal being to compile a correct behavior tree\nğ’¯\nğ’«\n\\mathcal{T}_{\\mathcal{P}}\nsuch that\ns\n0\nâ†’\ns\ng\ns_{0}\\rightarrow s_{g}\n.\n3.2\nArchitectural Design\nTo address complex long-horizon collaborative tasks for heterogeneous robot teams, we propose H-AIM, a hierarchical planning framework designed to transform high-level natural language instructions into precise, robust, and parallelizable physical executions. As illustrated in\nFig.\n2\n, the core of H-AIM is a cascaded, three-stage architecture, comprising the PFG, the HP, and the BTC.This architecture establishes a closed-loop pipeline from instruction parsing to robust execution. It begins with the PFG (\nSec.\n3.3\n), which leverages an LLM to decompose the input instruction, allocate subtasks, and generate structured PDDL problem files\n[\n38\n]\n. The HP (\nSec.\n3.4\n) then takes these problem files, employs a classical planner\n[\n12\n]\nto find optimal sub-plans, and utilizes the LLMâ€™s semantic reasoning to merge them into a globally consistent plan\n[\n38\n]\n, resolving temporal and resource conflicts. Finally, the BTC (\nSec.\n3.5\n) compiles this unified plan into a parallel Behavior Tree, automatically embedding precondition checks, fallback mechanisms, and synchronization nodes to enable reactive and fault-tolerant control in dynamic environments.Collectively, these three modules form a tightly integrated pipeline that synergizes the semantic understanding of LLMs, the formal search of symbolic planners and the reactive control of Behavior Trees, achieving an end-to-end solution for hierarchical multi-robot planning.\n3.3\nPDDL File Generator\nFigure 3\n:\nPFG.\nThis module transforms natural language instructions into structured PDDL problem files by parsing the input, decomposing the task, allocating subtasks, and formalizing planning elements.\nOur proposed\nPFG\nserves as the critical module bridging natural language instructions and formal task planning. This component, powered by an LLM, understands abstract task descriptions and translates them into precise planning problem definitions. Given a natural language instruction\nI\nI\n, the generator performs deep semantic parsing and task reasoning via the LLM. Unlike traditional cascaded processing flows\n[\n38\n,\n14\n]\n, our system adopts a co-optimization strategy for task decomposition and sub-task allocation. In this process, guided by specific prompts, the LLM concurrently performs task structure analysis and robot capability matching, ensuring that each generated sub-task\nÏ„\ni\nâˆˆ\nT\n\\tau_{i}\\in T\nsatisfies the following key properties:\nâ€¢\nAtomicity Guarantee:\nEach sub-task\nÏ„\ni\n\\tau_{i}\ncan be completed independently by a single robot without requiring inter-robot coordination during execution.\nâ€¢\nSkill Matching:\nThe task decomposition process continuously considers the unique capability sets of each robot, ensuring a high degree of fit between the decomposed sub-tasks and the available robotsâ€™ skill sets.\nâ€¢\nParallelism Optimization:\nBy identifying independencies between tasks, it maximizes the potential for overall system parallel execution, reducing inter-task dependency waits.\nSpecifically, as shown in\nFig.\n3\n, the generator first parses the semantic structure of the original instruction to identify complex task goals. Then, based on the skill graph of the available robot team, it decomposes the complex task into a set of semantically complete and well-bounded sub-tasks\nT\n=\nâŸ¨\nÏ„\n1\n,\nÏ„\n2\n,\nâ€¦\n,\nÏ„\nm\nâŸ©\nT=\\langle\\tau_{1},\\tau_{2},\\ldots,\\tau_{m}\\rangle\n. During this process, the LLM intelligently allocates task elements to the most suitable robot type by considering each robotâ€™s physical capabilities, sensor configurations, and manipulation constraints, while simultaneously maximizing the potential for parallel execution among sub-tasks.\nFor each generated sub-task\nÏ„\ni\n\\tau_{i}\n, the generator further derives its complete problem description triple\nP\ni\n=\n(\nS\ni\nâ€‹\nn\nâ€‹\ni\nâ€‹\nt\ni\n,\nO\ni\n,\nS\ng\nâ€‹\no\nâ€‹\na\nâ€‹\nl\ni\n)\nP_{i}=(S_{init}^{i},O_{i},S_{goal}^{i})\n, defining the initial state, involved objects, and goal state, respectively, ultimately outputting a PDDL-compliant problem file, laying the foundation for the subsequent planning stage. This co-optimization approach not only ensures the rationality of task decomposition but also significantly enhances the overall efficiency of the multi-robot system, providing a solid technical foundation for task planning in complex scenarios.\n3.4\nHybrid Planner\nFigure 4\n:\nHP.\nThis module orchestrates classical and LLM-driven planning stages to generate optimized, robust action sequences.\nOur proposed\nHP\nadopts the layered architecture depicted in\nFig.\n4\n, which combines classical symbolic planning with the semantic reasoning capabilities of LLMs\n[\n38\n]\n. The planner receives the set of sub-task problems\nğ’«\n=\n{\nP\nâ€‹\nr\nâ€‹\no\nâ€‹\nb\nâ€‹\nl\nâ€‹\ne\nâ€‹\nm\n1\n,\nâ€¦\n,\nP\nâ€‹\nr\nâ€‹\no\nâ€‹\nb\nâ€‹\nl\nâ€‹\ne\nâ€‹\nm\nn\n}\n\\mathcal{P}=\\{{{Problem}_{1},\\ldots,{Problem}_{n}}\\}\nfrom the PFG and generates a globally optimal plan through a three-stage processing pipeline.\nThe first stage is Semantic Validation and Simplification. Here, the planner uses the LLM to perform semantic enhancement and validation of the generated PDDL problem files. This process can be formalized as a constraint simplification problem, defined in\nEq.\n2\n.\nğ’«\n=\nâ€²\n{\nL\nL\nM\nv\nâ€‹\na\nâ€‹\nl\nâ€‹\ni\nâ€‹\nd\nâ€‹\na\nâ€‹\nt\nâ€‹\ne\n(\nP\ni\n,\nğ’Ÿ\n)\n}\ni\n=\n1\nn\n\\mathcal{P}\\mathcal{{}^{\\prime}}=\\{{LLM_{validate}(}P_{i},\\mathcal{D}){{\\}}_{i=1}^{n}}\n(2)\nwhere\nğ’Ÿ\n\\mathcal{D}\nis the predefined PDDL domain file. The validation process is based on the principle of simplifying preconditions and effects. For each action\na\na\n, its full precondition set\nP\na\nP_{a}\nand effect set\nE\na\nE_{a}\nare simplified into subsets\nP\na\nâ€²\nâŠ†\nP\na\nP^{\\prime}_{a}\\subseteq P_{a}\nand\nE\na\nâ€²\nâŠ†\nE\na\nE^{\\prime}_{a}\\subseteq E_{a}\n, removing non-critical constraints to reduce search complexity.\nNext is the Classical Planner Solving stage. For each simplified sub-task problem\nP\nâ€‹\nr\nâ€‹\no\nâ€‹\nb\nâ€‹\nl\nâ€‹\ne\nâ€‹\nm\ni\nâ€²\nâˆˆ\nğ’«\nâ€²\n{Problem}^{\\prime}_{i}\\in\\mathcal{P}^{\\prime}\n, the planner invokes FastDownward\n[\n12\n]\nfor heuristic search. FastDownward employs a relaxed planning heuristic function, defined in\nEq.\n3\n.\nh\nâ€‹\n(\nI\n,\nG\n)\n=\nmin\nÎ \nâˆˆ\nÎ \nâ€‹\n(\nI\n,\nG\n)\nâ€‹\nâˆ‘\na\nâˆˆ\nÎ \ncost\nâ¡\n(\na\n)\n\\mathrm{h}(\\mathrm{I},\\mathrm{G})=\\min_{\\Pi\\in\\Pi(\\mathrm{I},\\mathrm{G})}\\sum_{\\mathrm{a}\\in\\Pi}\\operatorname{cost}(\\mathrm{a})\n(3)\nwhere\nI\nI\nand\nG\nG\nrepresent the initial state and goal state, respectively,\nÎ \nâ€‹\n(\nI\n,\nG\n)\n\\Pi(I,G)\nis the set of all valid action sequences, and\ncost\nâ€‹\n(\na\n)\n\\text{cost}(a)\nis the execution cost of action\na\na\n. This heuristic, considering only the add effects of actions and ignoring delete effects, constructs an admissible relaxed problem\n[\n12\n]\n. For each sub-task, the planner generates an optimal action sequence\nÏ€\ni\n\\pi_{i}\n, defined in\nEq.\n4\n.\nÏ€\ni\n=\nF\nâ€‹\na\nâ€‹\ns\nâ€‹\nt\nâ€‹\nD\nâ€‹\no\nâ€‹\nw\nâ€‹\nn\nâ€‹\nw\nâ€‹\na\nâ€‹\nr\nâ€‹\nd\nâ€‹\n(\nğ’Ÿ\n,\nP\nâ€‹\nr\nâ€‹\no\nâ€‹\nb\nâ€‹\nl\nâ€‹\ne\nâ€‹\nm\ni\nâ€²\n)\n=\na\nâ€‹\nr\nâ€‹\ng\nâ€‹\nmin\nÎ \nâ€‹\nâˆ‘\na\nâˆˆ\nÎ \nc\nâ€‹\no\nâ€‹\ns\nâ€‹\nt\nâ€‹\n(\na\n)\n\\pi_{i}={FastDownward}(\\mathcal{D},Problem^{\\prime}_{i})={arg{\\min_{\\Pi}\\sum_{\\mathrm{a}\\in\\Pi}{cost}}}(a)\n(4)\nAfter obtaining the set of sub-plans\nÎ \n=\n{\nÏ€\n1\n,\nâ€¦\n,\nÏ€\nn\n\\Pi=\\{{\\pi_{1},\\ldots,\\pi_{n}}\n}, the planner enters the Merging Stage, aiming to produce a globally consistent, conflict-free overall plan\nÎ \nglobal\n\\Pi_{\\text{global}}\n. Differing from traditional merging methods\n[\n38\n]\nbased on probabilistic models, our framework employs a few-shot prompted LLM as a semantic coordinator to synthesize\nÎ \nglobal\n\\Pi_{\\text{global}}\n. The LLM detects conflicts in the sub-plans Î  by analyzing temporal (\ne.g\n.\n, incompatible orderings), resource (\ne.g\n.\n, concurrent object access), and semantic constraints, then resolves them by reordering actions and inserting synchronization nodes, thereby ensuring the logical coherence and executability of the plan. This process is formalized by the coordination function in\nEq.\n5\n.\nÎ \nglobal\n=\nLLM\nmerge\nâ¡\n(\nÎ \n,\ns\n0\n,\ns\ng\n,\nğ’\n)\n{\\Pi_{\\text{global }}=\\operatorname{LLM_{merge}}\\left(\\Pi,s_{0},s_{g},\\mathcal{C}\\right)}\n(5)\nwhere the\nL\nâ€‹\nL\nâ€‹\nM\nm\nâ€‹\ne\nâ€‹\nr\nâ€‹\ng\nâ€‹\ne\nâ€‹\n(\nâ‹…\n)\n{LLM_{merge}}(\\cdot)\nfunction represents the coordinative reasoning performed by the LLM under constraints\nğ’\n\\mathcal{C}\n. The final output\nÎ \nglobal\n\\Pi_{\\text{global}}\nis a unified plan that is semantically coherent, logically self-consistent, and strives for global optimality. This semantic reasoning-based merging strategy preserves the structural advantages of classical planning in state space search while introducing the generalization and coordination capabilities of LLMs, generating a high-quality overall solution for complex multi-robot tasks.\n3.5\nBehavior Tree Compiler\nFigure 5\n:\nMulti-robot Parallel Behavior Tree.\nThe top-level Parallel node coordinates individual robot subtrees, with a shared blackboard enabling communication and state synchronization.\nThe BTC serves as the execution-layer core of our framework, responsible for compiling the globally coordinated linear plan sequence\nÎ \nglobal\n\\Pi_{\\text{global}}\n, produced by the HP, into a parallel behavior tree\nğ’¯\nğ’«\n\\mathcal{T}_{\\mathcal{P}}\nendowed with high fault tolerance and reactive capability. Its compilation process is not a simple one-to-one mapping but transforms the sequential plan into a robust hierarchical control strategy by introducing structured condition checks, fallback mechanisms, and synchronization nodes.\nFor a team comprising N heterogeneous robots, the compiler generates the top-level parallel behavior tree\nğ’¯\nğ’«\n\\mathcal{T}_{\\mathcal{P}}\naccording to\nEq.\n1\n. The compiled parallel behavior tree, whose structure is shown in\nFig.\n5\n, adopts a Parallel control node at the top level to synchronously activate the subtrees of all robots.Each robotâ€™s sub-behavior tree\nğ’¯\nR\ni\n\\mathcal{T}_{R_{i}}\nis a Sequence node defining that robotâ€™s ordered task chain, as defined by\nEq.\n6\n.\nğ’¯\nR\ni\n=\nS\nâ€‹\ne\nâ€‹\nq\nâ€‹\nu\nâ€‹\ne\nâ€‹\nn\nâ€‹\nc\nâ€‹\ne\nâ€‹\n(\nğ’œ\ni\n,\n1\n,\nğ’œ\ni\n,\n2\n,\nâ€¦\n,\nğ’œ\ni\n,\nN\n)\n\\mathcal{T}_{R_{i}}=Sequence({{\\mathcal{A}}_{i,1}},{{\\mathcal{A}}_{i,2}},\\ldots,{{\\mathcal{A}}_{i,N}})\n(6)\nIn our architecture,\nA\ni\n,\nk\nA_{i,k}\nis not a primitive action node but a complex action compiled into a complete behavior subtree\nğ’¯\nA\ni\n,\nk\n\\mathcal{T}_{A_{i,k}}\nwhich encapsulates the full execution logic of the action. We formalize it as a â€Precondition-Execution-Validationâ€ triple, which is defined by\nEq.\n7\n.\nğ’¯\nA\ni\n,\nk\n=\nS\nâ€‹\ne\nâ€‹\nq\nâ€‹\nu\nâ€‹\ne\nâ€‹\nn\nâ€‹\nc\nâ€‹\ne\nâ€‹\n(\nF\nâ€‹\na\nâ€‹\nl\nâ€‹\nl\nâ€‹\nb\nâ€‹\na\nâ€‹\nc\nâ€‹\nk\nâ€‹\n(\nğ’\np\nâ€‹\nr\nâ€‹\ne\n,\nğ’²\n)\n,\nğ’œ\ncore\n,\nğ’±\npost\n)\n\\mathcal{T}_{A_{i,k}}=Sequence(Fallback({{\\mathcal{C}}_{pre}},\\mathcal{W}\\mathrm{),{{\\mathcal{A}}_{core}},{{\\mathcal{V}}_{post}})}\n(7)\nwhere:\nâ€¢\nğ’\np\nâ€‹\nr\nâ€‹\ne\n\\mathcal{C}_{pre}\n: Precondition Check. A condition node that returns success if and only if the environment state\ns\nâˆˆ\nS\ns\\in S\nsatisfies the required conditions for action execution:\nf\np\nâ€‹\nr\nâ€‹\ne\nâ€‹\n(\ns\n)\n=\nT\nâ€‹\nr\nâ€‹\nu\nâ€‹\ne\nf_{pre}(s)={True}\n.\nâ€¢\nğ’²\n\\mathcal{W}\n: Recovery and Retry Mechanism. A subtree activated when\nğ’\np\nâ€‹\nr\nâ€‹\ne\n\\mathcal{C}_{pre}\nfails, aiming to transition the system state\ns\ns\nto a region where\nf\np\nâ€‹\nr\nâ€‹\ne\nâ€‹\n(\ns\n)\n=\nT\nâ€‹\nr\nâ€‹\nu\nâ€‹\ne\nf_{pre}(s)={True}\n.\nâ€¢\nğ’œ\nc\nâ€‹\no\nâ€‹\nr\nâ€‹\ne\n\\mathcal{A}_{core}\n: Core Action Execution. An action node responsible for executing the underlying control logic of the action (e.g., motion planning, grasping), with execution result\nr\nâˆˆ\nSuccess\n,\nFailure\n,\nRunning\nr\\in{\\text{Success},\\text{Failure},\\text{Running}}\n.\nâ€¢\nğ’±\np\nâ€‹\no\nâ€‹\ns\nâ€‹\nt\n\\mathcal{V}_{post}\n: Post-execution Validation. A condition node that verifies whether the execution of\nğ’œ\nc\nâ€‹\no\nâ€‹\nr\nâ€‹\ne\n\\mathcal{A}_{core}\nachieved the intended effect, i.e., checks if the predicate\nf\np\nâ€‹\no\nâ€‹\ns\nâ€‹\nt\nâ€‹\n(\ns\n)\n=\nT\nâ€‹\nr\nâ€‹\nu\nâ€‹\ne\nf_{post}(s)={True}\nholds.\nThis hierarchical structure from\nğ’¯\nt\nâ€‹\ne\nâ€‹\na\nâ€‹\nm\nâ†’\nğ’¯\nR\ni\nâ†’\nğ’¯\nA\ni\n,\nk\n\\mathcal{T}_{{team}}\\rightarrow\\mathcal{T}_{R_{i}}\\rightarrow\\mathcal{T}_{A_{i,k}}\nensures macro-task parallelism and micro-action robustness. Furthermore, the BTC analyzes temporal dependencies within the global plan and automatically inserts synchronization nodes at appropriate positions in the behavior tree via the shared blackboard mechanism, thereby elegantly coordinating the workflows of multiple robots.\n4\nExperiments\nFigure 6\n:\nExecution keyframes from the AI2THOR environment.\nThe sequences exemplify a collaborative kitchen task (top) and a parallel object arrangement task (bottom), with robots and key objects highlighted.\n4.1\nBenchmark Dataset\nDue to the lack of existing datasets providing sufficiently complex and challenging multi-robot tasks, as well as a systematic evaluation of robot team collaboration capabilities, we propose MACE-THORâ€”a multi-robot complex long-horizon task dataset extending the SMART-LLM\n[\n14\n]\nand MAT-THOR benchmarks\n[\n38\n]\n. All experiments are conducted and evaluated within the AI2-THOR\n[\n16\n]\nsimulation environment for H-AIM and baseline methods. MACE-THOR comprises 42 tasks across 8 different indoor floor plans, covering various types of daily household tasks. Characterized by high task complexity and difficulty, this dataset assesses both the collaborative effectiveness of multiple robots and the systemâ€™s capability in decomposition, allocation, and planning for long-horizon complex tasks. The dataset supports testing with configurations of 2 to 4 robots possessing different skill attributes and provides detailed specifications for each task, including task descriptions, available robot resource lists, and clear goal state definitions.\nThe tasks are broadly categorized into two main types:\nâ€¢\nParallel-Independent Tasks:\nThese tasks can be decomposed into multiple mutually independent sub-tasks with no execution dependencies, allowing allocation to multiple robots for fully parallel execution (\ne.g\n.\n, assigning one robot to slice lettuce while another simultaneously washes a tomato).\nâ€¢\nTemporal-Dependent Tasks:\nThese tasks are specifically designed for heterogeneous robot teams, where the decomposed sub-tasks exhibit strong dependencies, requiring certain sub-tasks to wait for specific actions from others to complete before they can start (\ne.g\n.\n, one robot is responsible for slicing lettuce, and another robot needs to wait for the slicing to finish before transporting the lettuce to the refrigerator for storage).\nOur MACE-THOR dataset contains a balanced mix of 21 independent operation tasks and 21 collaborative operation tasks, enabling a comprehensive evaluation of task decomposition, sub-task allocation, path planning, and multi-robot collaborative execution capabilities.\n4.2\nEvaluation Metrics and Baselines\nWe adopt the following three evaluation metrics\n[\n14\n]\n: Success Rate (SR), Goal Condition Recall (GCR) and Executability (Exec). For a specific task, success is determined when all target objects reach their predefined goal states.\nâ€¢\nSR\ncalculates the ratio of successfully completed tasks to the total number of tasks, measuring the effectiveness of action sequence planning and inter-robot collaboration.\nâ€¢\nGCR\ncounts the ratio of successfully transformed states to the total number of goal states, reflecting the degree of completion for specific task goals.\nâ€¢\nExec\ncalculates the ratio of action sequences that can be successfully executed without considering task semantics, indicating the feasibility of the planned actions.\nWe evaluate H-AIM on different tasks using various language models, including GPT-4o\n[\n1\n]\n, Claude-3.5-Sonnet\n[\n3\n]\n, DeepSeek-V3.1\n[\n9\n]\nand Qwen-Max\n[\n26\n]\n. We employ LaMMA-P\n[\n38\n]\nas the state-of-the-art baseline and conduct fair comparisons using GPT-4o where applicable.\n4.3\nResults and Discussion\nTable 1\n:\nComparative Evaluation.\nParallel-Independent\nTemporal-Dependent\nMethods\nSR (\nâ†‘\n\\uparrow\n)\nGCR (\nâ†‘\n\\uparrow\n)\nExec (\nâ†‘\n\\uparrow\n)\nSR (\nâ†‘\n\\uparrow\n)\nGCR (\nâ†‘\n\\uparrow\n)\nExec (\nâ†‘\n\\uparrow\n)\nLaMMA-PÂ (GPT-4o)\n0.14\n0.14\n0.40\n0.40\n0.81\n0.81\n0.10\n0.10\n0.26\n0.26\n0.83\n\\mathbf{0.83}\nOursÂ (Qwen-Max)\n0.05\n0.05\n0.33\n0.33\n1.00\n\\mathbf{1.00}\n0.05\n0.05\n0.31\n0.31\n0.49\n0.49\nOursÂ (Claude-3.5-Sonnet)\n0.57\n0.57\n0.70\n0.70\n0.77\n0.77\n0.33\n0.33\n0.55\n0.55\n0.57\n0.57\nOursÂ (DeepSeek-V3.1)\n0.19\n0.19\n0.38\n0.38\n1.00\n\\mathbf{1.00}\n0.05\n0.05\n0.33\n0.33\n0.49\n0.49\nOursÂ (GPT-4o)\n0.71\n\\mathbf{0.71}\n0.88\n\\mathbf{0.88}\n0.76\n0.76\n0.38\n\\mathbf{0.38}\n0.62\n\\mathbf{0.62}\n0.71\n0.71\nTable 2\n:\nAblation Study of H-AIM.\nParallel-Independent\nTemporal-Dependent\nMethods\nSR (\nâ†‘\n\\uparrow\n)\nGCR (\nâ†‘\n\\uparrow\n)\nExec (\nâ†‘\n\\uparrow\n)\nSR (\nâ†‘\n\\uparrow\n)\nGCR (\nâ†‘\n\\uparrow\n)\nExec (\nâ†‘\n\\uparrow\n)\nOursÂ (No PDG & HP)\n0.43\n0.43\n0.65\n0.65\n0.55\n0.55\n0.14\n0.14\n0.41\n0.41\n0.53\n0.53\nOursÂ (No HP)\n0.43\n0.43\n0.65\n0.65\n0.82\n\\mathbf{0.82}\n0.19\n0.19\n0.22\n0.22\n0.51\n0.51\nOursÂ (No BTC)\n0.14\n0.14\n0.40\n0.40\n0.81\n0.81\n0.10\n0.10\n0.26\n0.26\n0.83\n\\mathbf{0.83}\nOursÂ (GPT-4o)\n0.71\n\\mathbf{0.71}\n0.88\n\\mathbf{0.88}\n0.76\n0.76\n0.38\n\\mathbf{0.38}\n0.62\n\\mathbf{0.62}\n0.71\n0.71\nWe evaluate H-AIM and baseline methods on the MACE-THOR dataset, covering the two distinct task categories: Parallel-Independent Tasks and Temporal-Dependent Tasks. H-AIM consistently demonstrates superior performance over the baseline methods across all task categories.\nQualitative Analysis.\nFig.\n6\nvisualizes the execution process of two representative tasks within the AI2-THOR simulation environment. Each sequence depicts key execution frames with task descriptions provided in the caption. In the collaborative kitchen task, Robot 1 slices tomatoes and lettuce while Robot 2 waits for the slicing completion signal before transporting ingredients, and Robot 3 only acts after all ingredients are plated. This demonstrates strict adherence to predecessor constraints while maintaining parallel efficiency. In the independent object arrangement task, Robots 1 and 2 operate simultaneously, with Robot 2 autonomously initiating local re-planning when temporarily obstructed by Robot 1â€™s path, showcasing real-time collision avoidance. These examples collectively validate our methodâ€™s capability in handling temporal constraints, dynamic obstacle avoidance, and sustained collaboration in complex environments.\nQuantitative Analysis.\nWe evaluated H-AIM and baseline methods on the MACE-THOR benchmark, categorizing tasks into Parallel-Independent and Temporal-Dependent types. Quantitative results demonstrate that H-AIM consistently outperforms the strongest baseline, LaMMA-P (GPT-4o), across all evaluation metrics.Overall, Ours (GPT-4o) elevates the aggregate SR from 12% to 55% and GCR from 32% to 72%. This substantial improvement validates a breakthrough in both the planning accuracy for complex tasks and the robustness of system execution. The performance gains primarily stem from the deep integration within H-AIM, which synergizes the semantic understanding of LLMs, the formal planning of PDDL, and the reactive control of Behavior Trees, enabling global optimization from task decomposition and allocation down to low-level control.Detailed quantitative experimental results are summarized in\nTab.\n1\n.\nFor Parallel-Independent Tasks, ours(GPT-4o) achieves an SR of 0.71 and a GCR of 0.88, substantially surpassing the baseline . This enhancement originates from our frameworkâ€™s efficient task decomposition and allocation, coupled with the autonomous reasoning capability endowed to individual robots, allowing for real-time decision-making and adjustments in dynamic environments. Notably, our Exec score (0.76) is slightly lower than the baselineâ€™s (0.81). This is not a flaw but a direct result of our intentionally designed proactive fault-tolerance mechanism: upon action failure, robots autonomously perform posture adjustments and retries. This strategy trades minor local execution overhead for a fundamental assurance of overall task robustness.For Temporal-Dependent Tasks, ours(GPT-4o) attains an SR of 0.38 and a GCR of 0.62, demonstrating a more pronounced advantage over the baseline . This validates the effectiveness of our multi-robot collaboration architecture. The shared blackboard mechanism for communication and coordination is crucial here, effectively addressing key collaboration issues such as task synchronization under temporal constraints and collision avoidance in dynamic environments, thereby enabling efficient parallel operation in complex scenarios. Meanwhile, our Exec metric remains at a relatively high level of 0.71, indicating an effective balance between collaborative robustness and execution fluency.Performance across different LLMs further corroborates the frameworkâ€™s adaptability. Ours (Claude-3.5-Sonnet) maintains competitive performance in Parallel-Independent tasks . However, when using LLMs with weaker reasoning capabilities like Qwen-Max and DeepSeek-V3.1, significant performance degradation is observed, particularly in tasks requiring tight collaboration. This indicates that while our methodological framework itself possesses a baseline level of task understanding and planning capability, its performance ceiling is ultimately constrained by the core reasoning ability of the employed LLM.\nAblation Study\n. We conduct an ablation study to evaluate the impact of various components of H-AIM on its overall performance. The results, shown in\nTab.\n2\n, demonstrate that removing both the PFG and HP completely disrupts the planning pipeline, confirming that task formalization and planning jointly constitute the foundation of the hierarchical architecture. The PFG converts natural language instructions into precise PDDL representations, while the HP optimizes sub-plans and resolves conflicts.Analyzing the HP individually shows its particular importance in temporal-dependent tasks. Removing the HP causes the GCR for such tasks to drop sharply from 0.62 to 0.22, highlighting the crucial value of its LLM-based semantic merging module in resolving resource competition and temporal constraints. This module intelligently identifies potential workstation contention and action sequencing dependencies, ensuring global plan consistency through reordering and inserting synchronization nodes.The BTC proves to be the core component for ensuring execution robustness. Removing the BTC significantly reduces success rates across all task types, demonstrating that its ability to transform linear plans into fault-tolerant Behavior Trees is essential. By incorporating fallback mechanisms, condition monitoring, and synchronization nodes, the BTC encapsulates complete â€check-execution-verificationâ€ logic for each action.When all components are fully integrated, the method achieves optimal performance, validating the necessity of the co-design of the task-structuring PFG, the collaborative-planning HP, and the robust-execution BTC.\n5\nConclusion\nWe introduced H-AIM, a Hierarchical Autonomous Intelligent Multi-robot planning framework that addresses long-horizon task planning for heterogeneous robot teams. By orchestrating LLMs, PDDL-based symbolic planning, and Behavior Trees through a novel three-stage architecture, H-AIM achieves significant improvements in task success rates and collaborative robustness over existing methods, while supporting dynamic team coordination via a shared blackboard mechanism. Evaluated on our MACE-THOR benchmark, H-AIM elevates the task success rate from 12% to 55% and the goal condition recall from 32% to 72% against the strongest baseline LaMMA-P, demonstrating a breakthrough in complex task planning. The deep integration of semantic reasoning, formal planning, and reactive control enables robust execution under environmental dynamics. While H-AIM shows promising results, it assumes fully observable environments and is validated in simulation. Future work will focus on integrating Visual Language Models for partial observability and developing adaptive re-planning mechanisms for dynamic real-world scenarios.\nReferences\n[1]\nJ. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, F. L. Aleman, D. Almeida, J. Altenschmidt, S. Altman, S. Anadkat,\net al.\n(2023)\nGpt-4 technical report\n.\narXiv preprint arXiv:2303.08774\n.\nCited by:\nÂ§4.2\n.\n[2]\nC. Aeronautiques, A. Howe, C. Knoblock, I. D. McDermott, A. Ram, M. Veloso, D. Weld, D. W. Sri, A. Barrett, D. Christianson,\net al.\n(1998)\nPddl-the planning domain definition language\n.\nTechnical Report, Tech. Rep.\n.\nCited by:\nÂ§1\n.\n[3]\nAnthropic\n(2024-06)\nClaude 3.5 Sonnet Model Card Addendum\n.\nNote:\nOfficial technical documentation detailing performance, vision capabilities, and safety profile (ASL-2). [3, 4, 5]\nExternal Links:\nLink\nCited by:\nÂ§4.2\n.\n[4]\nJ. L. Baxter, E. Burke, J. M. Garibaldi, and M. Norman\n(2007)\nMulti-robot search and rescue: a potential field based approach\n.\nAutonomous robots and agents\n,\npp.Â 9â€“16\n.\nCited by:\nÂ§1\n.\n[5]\nA. Bolu and Ã–. KorÃ§ak\n(2021)\nAdaptive task planning for multi-robot smart warehouse\n.\nIEEE Access\n9\n,\npp.Â 27346â€“27358\n.\nCited by:\nÂ§1\n,\nÂ§2\n.\n[6]\nC. B. Browne, E. Powley, D. Whitehouse, S. M. Lucas, P. I. Cowling, P. Rohlfshagen, S. Tavener, D. Perez, S. Samothrakis, and S. Colton\n(2012)\nA survey of monte carlo tree search methods\n.\nIEEE Transactions on Computational Intelligence and AI in games\n4\n(\n1\n),\npp.Â 1â€“43\n.\nCited by:\nÂ§2\n.\n[7]\nS. Chen, Y. Chen, R. Jain, X. Zhang, Q. Nguyen, and S. K. Gupta\n(2024)\nAccounting for travel time and arrival time coordination during task allocations in legged-robot teams\n.\nIn\n2024 IEEE International Conference on Robotics and Automation (ICRA)\n,\npp.Â 16588â€“16594\n.\nCited by:\nÂ§1\n.\n[8]\nG. Dagan, F. Keller, and A. Lascarides\n(2023)\nDynamic planning with a llm\n.\narXiv preprint arXiv:2308.06391\n.\nCited by:\nÂ§2\n.\n[9]\nDeepSeek-AI, A. Liu, B. Feng, B. Xue, B. Wang, B. Wu, C. Lu, C. Zhao, C. Deng, C. Zhang, C. Ruan, D. Dai, D. Guo, D. Yang, D. Chen, D. Ji, E. Li, F. Lin, F. Dai, F. Luo, G. Hao, G. Chen, G. Li, H. Zhang, H. Bao, H. Xu, H. Wang, H. Zhang, H. Ding, H. Xin, H. Gao, H. Li, H. Qu, J. L. Cai, J. Liang, J. Guo, J. Ni, J. Li, J. Wang, J. Chen, J. Chen, J. Yuan, J. Qiu, J. Li, J. Song, K. Dong, K. Hu, K. Gao, K. Guan, K. Huang, K. Yu, L. Wang, L. Zhang, L. Xu, L. Xia, L. Zhao, L. Wang, L. Zhang, M. Li, M. Wang, M. Zhang, M. Zhang, M. Tang, M. Li, N. Tian, P. Huang, P. Wang, P. Zhang, Q. Wang, Q. Zhu, Q. Chen, Q. Du, R. J. Chen, R. L. Jin, R. Ge, R. Zhang, R. Pan, R. Wang, R. Xu, R. Zhang, R. Chen, S. S. Li, S. Lu, S. Zhou, S. Chen, S. Wu, S. Ye, S. Ye, S. Ma, S. Wang, S. Zhou, S. Yu, S. Zhou, S. Pan, T. Wang, T. Yun, T. Pei, T. Sun, W. L. Xiao, W. Zeng, W. Zhao, W. An, W. Liu, W. Liang, W. Gao, W. Yu, W. Zhang, X. Q. Li, X. Jin, X. Wang, X. Bi, X. Liu, X. Wang, X. Shen, X. Chen, X. Zhang, X. Chen, X. Nie, X. Sun, X. Wang, X. Cheng, X. Liu, X. Xie, X. Liu, X. Yu, X. Song, X. Shan, X. Zhou, X. Yang, X. Li, X. Su, X. Lin, Y. K. Li, Y. Q. Wang, Y. X. Wei, Y. X. Zhu, Y. Zhang, Y. Xu, Y. Xu, Y. Huang, Y. Li, Y. Zhao, Y. Sun, Y. Li, Y. Wang, Y. Yu, Y. Zheng, Y. Zhang, Y. Shi, Y. Xiong, Y. He, Y. Tang, Y. Piao, Y. Wang, Y. Tan, Y. Ma, Y. Liu, Y. Guo, Y. Wu, Y. Ou, Y. Zhu, Y. Wang, Y. Gong, Y. Zou, Y. He, Y. Zha, Y. Xiong, Y. Ma, Y. Yan, Y. Luo, Y. You, Y. Liu, Y. Zhou, Z. F. Wu, Z. Z. Ren, Z. Ren, Z. Sha, Z. Fu, Z. Xu, Z. Huang, Z. Zhang, Z. Xie, Z. Zhang, Z. Hao, Z. Gou, Z. Ma, Z. Yan, Z. Shao, Z. Xu, Z. Wu, Z. Zhang, Z. Li, Z. Gu, Z. Zhu, Z. Liu, Z. Li, Z. Xie, Z. Song, Z. Gao, and Z. Pan\n(2025)\nDeepSeek-v3 technical report\n.\nExternal Links:\n2412.19437\n,\nLink\nCited by:\nÂ§4.2\n.\n[10]\nI. Georgievski and M. Aiello\n(2014)\nAn overview of hierarchical task network planning\n.\narXiv preprint arXiv:1403.7426\n.\nCited by:\nÂ§2\n.\n[11]\nL. Guan, K. Valmeekam, S. Sreedharan, and S. Kambhampati\n(2023)\nLeveraging pre-trained large language models to construct and utilize world models for model-based task planning\n.\nAdvances in Neural Information Processing Systems\n36\n,\npp.Â 79081â€“79094\n.\nCited by:\nÂ§2\n.\n[12]\nM. Helmert\n(2006)\nThe fast downward planning system\n.\nJournal of Artificial Intelligence Research\n26\n,\npp.Â 191â€“246\n.\nCited by:\nÂ§3.2\n,\nÂ§3.4\n,\nÂ§3.4\n.\n[13]\nY. Jiang, S. Zhang, P. Khandelwal, and P. Stone\n(2019)\nTask planning in robotics: an empirical comparison of pddl-and asp-based systems\n.\nFrontiers of Information Technology & Electronic Engineering\n20\n,\npp.Â 363â€“373\n.\nCited by:\nÂ§2\n.\n[14]\nS. S. Kannan, V. L. Venkatesh, and B. Min\n(2024)\nSmart-llm: smart multi-agent robot task planning using large language models\n.\nThe 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\n.\nCited by:\nÂ§1\n,\nÂ§2\n,\nÂ§3.3\n,\nÂ§4.1\n,\nÂ§4.2\n.\n[15]\nA. Khamis, A. Hussein, and A. Elmogy\n(2015)\nMulti-robot task allocation: a review of the state-of-the-art\n.\nCooperative robots and sensor networks 2015\n,\npp.Â 31â€“51\n.\nCited by:\nÂ§1\n.\n[16]\nE. Kolve, R. Mottaghi, W. Han, E. VanderBilt, L. Weihs, A. Herrasti, M. Deitke, K. Ehsani, D. Gordon, Y. Zhu,\net al.\n(2017)\nAi2-thor: an interactive 3d environment for visual ai\n.\narXiv preprint arXiv:1712.05474\n.\nCited by:\n2nd item\n,\nÂ§4.1\n.\n[17]\nL. Kraemer and B. Banerjee\n(2016)\nMulti-agent reinforcement learning as a rehearsal for decentralized planning\n.\nNeurocomputing\n190\n,\npp.Â 82â€“94\n.\nCited by:\nÂ§2\n.\n[18]\nP. Li, Z. An, S. Abrar, and L. Zhou\n(2025)\nLarge language models for multi-robot systems: a survey\n.\nExternal Links:\n2502.03814\n,\nLink\nCited by:\nÂ§1\n,\nÂ§1\n,\nÂ§2\n,\nÂ§2\n.\n[19]\nB. Liu, Y. Jiang, X. Zhang, Q. Liu, S. Zhang, J. Biswas, and P. Stone\n(2023)\nLlm+ p: empowering large language models with optimal planning proficiency\n.\narXiv preprint arXiv:2304.11477\n.\nCited by:\nÂ§2\n.\n[20]\nH. Lu, Z. Wu, J. Xing, J. Li, R. Li, Z. Li, and Y. Shi\n(2025)\nBodyGen: advancing towards efficient embodiment co-design\n.\nExternal Links:\n2503.00533\n,\nLink\nCited by:\nÂ§2\n.\n[21]\nS. Mahdavi, R. Aoki, K. Tang, and Y. Cao\n(2024)\nLeveraging environment interaction for automated pddl generation and planning with large language models\n.\narXiv preprint arXiv:2407.12979\n.\nCited by:\nÂ§2\n.\n[22]\nZ. Mandi, S. Jain, and S. Song\n(2024)\nRoco: dialectic multi-robot collaboration with large language models\n.\nIn\n2024 IEEE International Conference on Robotics and Automation (ICRA)\n,\npp.Â 286â€“299\n.\nCited by:\nÂ§1\n.\n[23]\nS. Nayak, A. M. Orozco, M. T. Have, V. Thirumalai, J. Zhang, D. Chen, A. Kapoor, E. Robinson, K. Gopalakrishnan, J. Harrison,\net al.\n(2024)\nLong-horizon planning for multi-agent robots in partially observable environments\n.\narXiv preprint arXiv:2407.10031\n.\nCited by:\nÂ§1\n,\nÂ§2\n.\n[24]\nL. F. Oliveira, A. P. Moreira, and M. F. Silva\n(2021)\nAdvances in agriculture robotics: a state-of-the-art review and challenges ahead\n.\nRobotics\n10\n(\n2\n),\npp.Â 52\n.\nCited by:\nÂ§1\n.\n[25]\nJ. P. Queralta, J. Taipalmaa, B. C. Pullinen, V. K. Sarker, T. N. Gia, H. Tenhunen, M. Gabbouj, J. Raitoharju, and T. Westerlund\n(2020)\nCollaborative multi-robot search and rescue: planning, coordination, perception, and active vision\n.\nIeee Access\n8\n,\npp.Â 191617â€“191643\n.\nCited by:\nÂ§1\n.\n[26]\nQwen Team\n(2025-09)\nQwen3-Max: Just Scale it\n.\nNote:\nOfficial placeholder citation provided by the Qwen Team for the Qwen3-Max API/announcement, pending a formal technical report. Model features 1 Trillion parameters.[6]\nExternal Links:\nLink\nCited by:\nÂ§4.2\n.\n[27]\nY. Rizk, M. Awad, and E. W. Tunstel\n(2019)\nCooperative heterogeneous multi-robot systems: a survey\n.\nACM Computing Surveys (CSUR)\n52\n(\n2\n),\npp.Â 1â€“31\n.\nCited by:\nÂ§1\n.\n[28]\nJ. Roche, E. SebastiÃ¡n, and E. Montijano\n(2025)\nCurriculum imitation learning of distributed multi-robot policies\n.\nExternal Links:\n2509.25097\n,\nLink\nCited by:\nÂ§1\n.\n[29]\nT. Silver, S. Dan, K. Srinivas, J. B. Tenenbaum, L. Kaelbling, and M. Katz\n(2024)\nGeneralized planning in pddl domains with pretrained large language models\n.\nIn\nProceedings of the AAAI Conference on Artificial Intelligence\n,\nVol.\n38\n,\npp.Â 20256â€“20264\n.\nCited by:\nÂ§2\n.\n[30]\nI. Singh, D. Traum, and J. Thomason\n(2024)\nTwostep: multi-agent task planning using classical planners and large language models\n.\narXiv preprint arXiv:2403.17246\n.\nCited by:\nÂ§1\n,\nÂ§2\n.\n[31]\nK. Valmeekam, M. Marquez, A. Olmo, S. Sreedharan, and S. Kambhampati\n(2024)\nPlanbench: an extensible benchmark for evaluating large language models on planning and reasoning about change\n.\nAdvances in Neural Information Processing Systems\n36\n.\nCited by:\nÂ§2\n.\n[32]\nC. Wang, J. Sun, Y. Zhang, M. Zhang, and C. Wu\n(2025)\nLLM-hbt: dynamic behavior tree construction for adaptive coordination in heterogeneous robots\n.\nExternal Links:\n2510.09963\n,\nLink\nCited by:\nÂ§1\n.\n[33]\nJ. Wang, G. He, and Y. Kantaros\n(2024)\nSafe task planning for language-instructed multi-robot systems using conformal prediction\n.\narXiv preprint arXiv:2402.15368\n.\nCited by:\nÂ§1\n,\nÂ§2\n.\n[34]\nY. Wang, M. Damani, P. Wang, Y. Cao, and G. Sartoretti\n(2022)\nDistributed reinforcement learning for robot teams: a review\n.\nCurrent Robotics Reports\n3\n(\n4\n),\npp.Â 239â€“257\n.\nCited by:\nÂ§1\n.\n[35]\nI. White*, K. Nottingham*, A. Maniar, M. Robinson, H. Lillemark, M. Maheshwari, L. Qin, and P. Ammanabrolu\n(2025)\nCollaborating action by action: a multi-agent llm framework for embodied reasoning\n.\narXiv preprint arXiv:2504.17950\n.\nExternal Links:\nLink\nCited by:\nÂ§1\n.\n[36]\nY. Xie, C. Yu, T. Zhu, J. Bai, Z. Gong, and H. Soh\n(2023)\nTranslating natural language to planning goals with large-language models\n.\narXiv preprint arXiv:2302.05128\n.\nCited by:\nÂ§2\n.\n[37]\nH. Zhang, W. Du, J. Shan, Q. Zhou, Y. Du, J. B. Tenenbaum, T. Shu, and C. Gan\n(2024)\nBuilding cooperative embodied agents modularly with large language models\n.\nInternational Conference on Learning Representations (ICLR)\n.\nCited by:\nÂ§1\n,\nÂ§2\n.\n[38]\nX. Zhang, H. Qin, F. Wang, Y. Dong, and J. Li\n(2025)\nLaMMA-p: generalizable multi-agent long-horizon task allocation and planning with lm-driven pddl planner\n.\nIn\n2025 IEEE International Conference on Robotics and Automation (ICRA)\n,\nCited by:\n3rd item\n,\nÂ§1\n,\nÂ§2\n,\nÂ§3.2\n,\nÂ§3.3\n,\nÂ§3.4\n,\nÂ§3.4\n,\nÂ§4.1\n,\nÂ§4.2\n.\n[39]\nZ. Zhou, J. Song, K. Yao, Z. Shu, and L. Ma\n(2024)\nIsr-llm: iterative self-refined large language model for long-horizon sequential task planning\n.\nIn\n2024 IEEE International Conference on Robotics and Automation (ICRA)\n,\npp.Â 2081â€“2088\n.\nCited by:\nÂ§2\n.\n[40]\nL. Zu, L. Lin, S. Fu, N. Zhao, and P. Zhou\n(2025)\nCollaborative tree search for enhancing embodied multi-agent collaboration\n.\nIn\n2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\n,\nVol.\n,\npp.Â 29513â€“29513\n.\nExternal Links:\nDocument\nCited by:\nÂ§1\n,\nÂ§1\n.",
  "preview_text": "In embodied artificial intelligence, enabling heterogeneous robot teams to execute long-horizon tasks from high-level instructions remains a critical challenge. While large language models (LLMs) show promise in instruction parsing and preliminary planning, they exhibit limitations in long-term reasoning and dynamic multi-robot coordination. We propose Hierarchical Autonomous Intelligent Multi-Robot Planning(H-AIM), a novel embodied multi-robot task planning framework that addresses these issues through a three-stage cascaded architecture: 1) It leverages an LLM to parse instructions and generate Planning Domain Definition Language (PDDL) problem descriptions, thereby transforming commands into formal planning problems; 2) It combines the semantic reasoning of LLMs with the search capabilities of a classical planner to produce optimized action sequences; 3) It compiles the resulting plan into behavior trees for reactive control. The framework supports dynamically sized heterogeneous robot teams via a shared blackboard mechanism for communication and state synchronization. To validate our approach, we introduce the MACE-THOR benchmark dataset, comprising 42 complex tasks across 8 distinct household layouts. Experimental results demonstrate that H-AIM achieves a remarkable performance improvement, elevating the task success rate from 12% to 55% and boosting the goal condition recall from 32% to 72% against the strongest baseline, LaMMA-P.\n\nH-AIM: Orchestrating LLMs, PDDL, and Behavior Trees for Hierarchical Multi-Robot Planning\nHaishan Zeng\n1,2\nPeng Li\n1,2\n1\nUniversity of Chinese Academy of Sciences\n2\nInstitute of Software, Chinese Academy of Sciences\nzenghaishan24@mails.ucas.ac.cn\nlipeng@iscas.ac.cn\nAbstract\nIn embodied artificial intelligence, enabling heterogeneous robot teams to execute long-horizon tasks from high-level instructions remains a critical challenge. While large language models (LLMs) show promise in instruction parsing and preliminary planning, they ",
  "is_relevant": false,
  "relevance_score": 1.0,
  "extracted_keywords": [
    "LLMs",
    "PDDL",
    "Behavior Trees",
    "multi-robot planning",
    "embodied AI"
  ],
  "one_line_summary": "è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§ç»“åˆLLMã€PDDLå’Œè¡Œä¸ºæ ‘çš„åˆ†å±‚å¤šæœºå™¨äººä»»åŠ¡è§„åˆ’æ¡†æ¶ï¼Œç”¨äºè§£å†³å¼‚æ„æœºå™¨äººå›¢é˜Ÿæ‰§è¡Œé•¿æœŸä»»åŠ¡çš„é—®é¢˜ã€‚",
  "detailed_summary": "",
  "qa_pairs": [],
  "is_hidden": false,
  "is_starred": false,
  "flag": "",
  "published_date": "2026-01-16T07:59:50Z",
  "created_at": "2026-01-20T17:49:58.935631",
  "updated_at": "2026-01-20T17:49:58.935637"
}