{
    "id": "2601.14000v1",
    "title": "Group-Invariant Unsupervised Skill Discovery: Symmetry-aware Skill Representations for Generalizable Behavior",
    "authors": [
        "Junwoo Chang",
        "Joseph Park",
        "Roberto Horowitz",
        "Jongmin Lee",
        "Jongeun Choi"
    ],
    "abstract": "æ— ç›‘ç£æŠ€èƒ½å‘ç°æ—¨åœ¨è·å–è¡Œä¸ºåŸºå…ƒï¼Œä»¥æå‡æ¢ç´¢æ•ˆç‡å¹¶åŠ é€Ÿä¸‹æ¸¸ä»»åŠ¡å­¦ä¹ ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å¾€å¾€å¿½ç•¥ç‰©ç†ç¯å¢ƒçš„å‡ ä½•å¯¹ç§°æ€§ï¼Œå¯¼è‡´è¡Œä¸ºå†—ä½™ä¸æ ·æœ¬æ•ˆç‡ä½ä¸‹ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºç¾¤ä¸å˜æŠ€èƒ½å‘ç°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å°†ç¾¤ç»“æ„æ˜¾å¼åµŒå…¥æŠ€èƒ½å‘ç°ç›®æ ‡ä¸­ã€‚æˆ‘ä»¬çš„æ–¹æ³•åŸºäºç†è®ºä¿è¯ï¼šæˆ‘ä»¬è¯æ˜äº†åœ¨ç¾¤å¯¹ç§°ç¯å¢ƒä¸­ï¼Œæ ‡å‡†Wassersteinä¾èµ–åº¦é‡å­˜åœ¨ç”±ç­‰å˜ç­–ç•¥ä¸ç¾¤ä¸å˜è¯„åˆ†å‡½æ•°æ„æˆçš„å…¨å±€æœ€ä¼˜è§£ã€‚å—æ­¤å¯å‘ï¼Œæˆ‘ä»¬æ„å»ºäº†ç¾¤ä¸å˜Wassersteinä¾èµ–åº¦é‡ï¼Œå°†ä¼˜åŒ–è¿‡ç¨‹é™åˆ¶åœ¨è¿™ä¸ªå…·æœ‰å¯¹ç§°æ€§æ„ŸçŸ¥çš„å­ç©ºé—´ä¸­è€Œä¸æŸå¤±æœ€ä¼˜æ€§ã€‚åœ¨å®è·µå±‚é¢ï¼Œæˆ‘ä»¬é‡‡ç”¨ç¾¤å‚…é‡Œå¶è¡¨ç¤ºå‚æ•°åŒ–è¯„åˆ†å‡½æ•°ï¼Œå¹¶é€šè¿‡ç­‰å˜æ½œåœ¨ç‰¹å¾çš„å¯¹é½å®šä¹‰å†…åœ¨å¥–åŠ±ï¼Œç¡®ä¿å‘ç°çš„æŠ€èƒ½åœ¨ç¾¤å˜æ¢ä¸‹å…·æœ‰ç³»ç»Ÿæ€§æ³›åŒ–èƒ½åŠ›ã€‚åœ¨åŸºäºçŠ¶æ€å’ŒåŸºäºåƒç´ çš„è¿åŠ¨åŸºå‡†æµ‹è¯•ä¸­ï¼Œå®éªŒè¡¨æ˜ç›¸è¾ƒäºå¼ºåŸºçº¿æ–¹æ³•ï¼Œè¯¥æ¡†æ¶èƒ½å®ç°æ›´å¹¿é˜”çš„çŠ¶æ€ç©ºé—´è¦†ç›–ï¼Œå¹¶åœ¨ä¸‹æ¸¸ä»»åŠ¡å­¦ä¹ ä¸­å–å¾—æ›´é«˜çš„æ•ˆç‡ã€‚",
    "url": "https://arxiv.org/abs/2601.14000v1",
    "html_url": "https://arxiv.org/html/2601.14000v1",
    "html_content": "Group-Invariant Unsupervised Skill Discovery: Symmetry-aware Skill Representations for Generalizable Behavior\nJunwooÂ Chang\n,\nJosephÂ Park\n,\nRobertoÂ Horowitz\n,\nJongminÂ Lee\n,\nandÂ JongeunÂ Choi\n(Corresponding authors: Jongeun Choi and Jongmin Lee.)Junwoo Chang, Joseph Park, and Jongeun Choi are with the School of Mechanical Engineering,\nYonsei University, Seoul, South Korea (\ne-mails: junwoochang@yonsei.ac.kr;\niamjoseph1129@yonsei.ac.kr; jongeunchoi@yonsei.ac.kr\n).\nJongmin Lee and Jongeun Choi are with the Department of Artificial Intelligence,\nYonsei University, Seoul, South Korea (\ne-mails: jongminlee@yonsei.ac.kr;\njongeunchoi@yonsei.ac.kr\n).\nJongeun Choi and Roberto Horowitz are with the Department of Mechanical Engineering, University of California, Berkeley, CA 94720, USA (\ne-mail: horowitz@berkeley.edu\n)The authors used the ChatGPT large language model (OpenAI)\n[\n23\n]\nto polish texts. All texts written with LLM assistance was reviewed and verified by the authors.This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible.\nAbstract\nUnsupervised skill discovery aims to acquire behavior primitives that improve exploration and accelerate downstream task learning. However, existing approaches often ignore the geometric symmetries of physical environments, leading to redundant behaviors and sample inefficiency. To address this, we introduce Group-Invariant Skill Discovery (GISD), a framework that explicitly embeds group structure into the skill discovery objective. Our approach is grounded in a theoretical guarantee: we prove that in group-symmetric environments, the standard Wasserstein dependency measure admits a globally optimal solution comprised of an equivariant policy and a group-invariant scoring function. Motivated by this, we formulate the Group-Invariant Wasserstein dependency measure, which restricts the optimization to this symmetry-aware subspace without loss of optimality. Practically, we parameterize the scoring function using a group Fourier representation and define the intrinsic reward via the alignment of equivariant latent features, ensuring that the discovered skills generalize systematically under group transformations. Experiments on state-based and pixel-based locomotion benchmarks demonstrate that GISD achieves broader state-space coverage and improved efficiency in downstream task learning compared to a strong baseline.\nI\nIntroduction\nUnsupervised skill discovery has become a central tool for acquiring reusable behavioral primitives that can accelerate downstream task learning. A wide range of methods learn latent skills by maximizing mutual information or distance-based objectives between skills and state trajectories\n[\n9\n,\n35\n,\n20\n,\n28\n,\n26\n,\n27\n]\n. These methods have shown that pretraining a diverse set of behaviors can substantially improve exploration, state coverage, and downstream task learning efficiency across challenging continuous-control benchmarks.\nDespite this progress, existing approaches often struggle to pretrain\nuseful\nskills efficiently. Standard distance-maximizing objectives treat the state space as largely unstructured, and must discover all behaviors directly in a high-dimensional latent space. Recent works attempt to impose additional priors to mitigate this difficultyâ€”for example, LGSD\n[\n31\n]\nleverages language guidance to bias the skill space toward semantically meaningful behaviors, while â€œDoâ€™s and Donâ€™tsâ€\n[\n17\n]\nleverage desired behavioral preference priors. However, these methods still overlook a fundamental property of many robotic environments: the presence of strong geometric symmetries (e.g., rotations of a locomotion agent) that make many behaviors equivalent up to a group transformation. When such a structure is ignored, skill discovery tends to learn redundant variants of the same behavior, wasting samples and weakening generalization.\nTo address this limitation, we introduce\nGroup-Invariant Skill Discovery (GISD)\n, a framework that injects group symmetry directly into the skill discovery objective and representation.\nOur approach builds upon a key theoretical insight: in a group-invariant environment, the Wasserstein dependency measure\n[\n24\n]\nadmits a globally optimal solution comprised of an equivariant policy and a group-invariant scoring function\nf\nf\n. This existence guarantee implies that we can safely restrict the search space to a class of group-invariant scoring functions without any loss of optimality.\nBased on this principle, we formulate the Group-Invariant Wasserstein dependency measure (GIWDM), which directly optimizes the objective within this reduced subspace.\nGIWDM thus eliminates the redundancy of exploring non-symmetric solutions and ensures that the discovered skills inherently respect the environmental symmetry.\nBuilding on this theory, we parameterize the group-invariant scoring function in a group Fourier space, discovering skills whose latent representations explicitly encode the group symmetry. Once such symmetry-aware skills are learned, we can exploit the same structure: the agent can reuse a skill at novel configurations by transforming its latent representation under the group, enabling systematic generalization across group transformations.\nThe contributions of our work are summarized as follows:\n1)We prove that, in group-symmetric MDPs, the Wasserstein Dependency Measure (WDM) admits a globally optimal solution consisting of an equivariant policy and a group-invariant scoring function\nf\nf\n. This result justifies Group-Invariant Skill Discovery (GISD), which restricts\nf\nf\nto symmetry-respecting functions without sacrificing optimality.\n2) We instantiate GISD by parameterizing the group-invariant scoring function\nf\nf\nin the group Fourier domain. The intrinsic reward is defined via the alignment of equivariant Fourier features, producing skill representations that are group-symmetric by construction. We also show that this symmetric representation enables generalizable skill implementation under the group transformation in downstream tasks.\n3) We evaluate GISD on state-based and pixel-based locomotion benchmarks, showing improved sample efficiency and state-space coverage over a strong distance-based baseline.\nII\nRelated Work\nII-A\nUnsupervised Skill Discovery\nUnsupervised skill discovery seeks to learn diverse behaviors in reinforcement learning (RL) without relying on explicit reward signals and reuse them for efficient downstream task training. A common strategy is to maximize the dependency between states and skills, leading to distinct trajectories according to the different latent skill vectors. One of the classes of unsupervised skill discovery contains leveraging the mutual information (MI). MI-based approaches maximize the correlation between skill and state, typically via a Kullback-Liebler (KL)-divergence formulation\n[\n9\n,\n14\n,\n20\n,\n48\n]\n:\nI\nâ€‹\n(\nğ’®\n;\nZ\n)\n\\displaystyle I(\\mathcal{S};Z)\n=\nD\nK\nâ€‹\nL\nâ€‹\n(\np\nâ€‹\n(\ns\n,\nz\n)\nâˆ¥\np\nâ€‹\n(\ns\n)\nâ€‹\np\nâ€‹\n(\nz\n)\n)\n\\displaystyle=D_{KL}\\left(p(s,z)\\|p(s)p(z)\\right)\n=\nâˆ«\nğ’®\nÃ—\nZ\np\nâ€‹\n(\ns\n,\nz\n)\nâ€‹\nlog\nâ¡\np\nâ€‹\n(\ns\n,\nz\n)\np\nâ€‹\n(\ns\n)\nâ€‹\np\nâ€‹\n(\nz\n)\nâ€‹\nd\nâ€‹\ns\nâ€‹\nd\nâ€‹\nz\n.\n\\displaystyle=\\int_{\\mathcal{S}\\times Z}p(s,z)\\log\\frac{p(s,z)}{p(s)p(z)}\\,dsdz.\nWhile they effectively uncover distinct skills, their reliance on KL divergence can limit overall state coverage.\nTo address the limitation of MI-based approach, distance-maximizing approaches, which is the other class in unsupervised skill discovery, replace MI with the\n1\n1\n-Wasserstein distance (or Kantorovich metric) for tractability, promoting both distinctness and a broader exploration of states\n[\n26\n,\n27\n,\n28\n,\n31\n]\n:\nI\nğ’²\nâ€‹\n(\nğ’®\n;\nZ\n)\n=\nğ’²\nâ€‹\n(\np\nâ€‹\n(\ns\n,\nz\n)\n,\np\nâ€‹\n(\ns\n)\nâ€‹\np\nâ€‹\n(\nz\n)\n)\nI_{\\mathcal{W}}(\\mathcal{S};Z)=\\mathcal{W}\\big(p(s,z),p(s)p(z)\\big)\nThese approaches map states to a compact latent space that preserves a chosen distance metric (e.g., temporal distance\n[\n28\n]\n, controllability distance\n[\n27\n]\n, or language distance\n[\n31\n]\n), thereby promoting both broad exploration and the discovery of skills that are well-separated under the metric.\nBased on distance-maximizing unsupervised skill discovery, recent studies have proposed methods to improve the quality of skills through the addition of prior knowledge. For example, one of the prior works, LGSD\n[\n31\n]\n, utilizes language prior to improve semantic diversity between skills. In another prior work, Doâ€™s and Donâ€™ts\n[\n17\n]\n, they utilize the prior knowledge of desired state transition for feasible skill discovery.\nIn this work, we also build upon distance-maximizing approaches by integrating a geometric prior, but our method differs in that it discovers skills directly from the inherent group symmetric structure of the space, and thereby, the skills are enabled to be discovered with the underlying geometric symmetry.\nII-B\nGroup Equivariance in Reinforcement Learning\nGroup equivariance is a mathematical property that characterizes how a functionâ€™s output transforms in response to a specified group action on its input. Incorporating this property into neural networks ensures that transformations of the input data induce predictable and consistent transformations of the output\n[\n12\n,\n39\n,\n13\n,\n47\n,\n21\n,\n2\n]\n. Recent works have explored group equivariance in robotic settings\n[\n49\n,\n16\n,\n15\n,\n33\n,\n32\n,\n18\n,\n36\n,\n34\n,\n25\n]\n: for example, some prior works\n[\n49\n,\n16\n,\n15\n]\napply group-equivariant convolutions to pick-and-place tasks, and other prior works\n[\n33\n,\n32\n,\n18\n,\n36\n]\nleverage roto-translation symmetry in three-dimensional environments, notably improving data efficiency and generalization. Such benefits are particularly relevant for RL, where sample efficiency remains a central challenge. Several studies have demonstrated that integrating group equivariance into RL algorithms yields enhanced performance and faster learning compared to standard methods\n[\n45\n,\n46\n,\n44\n,\n22\n,\n38\n,\n41\n,\n10\n,\n19\n,\n43\n,\n6\n]\n. Notably, some works\n[\n45\n,\n46\n]\nintroduce the concept of group-invariant Markov decision process (MDPs), offering a formal basis for these improvements. Building upon these successes, our work aims to incorporate group equivariance into unsupervised skill discovery, thereby addressing limitations in existing approaches and further advancing the potential of symmetry-based methods.\nIII\nPreliminaries\nIII-A\nDistance-Maximizing Skill Discovery\nDistance-maximizing skill discovery approaches\n[\n26\n,\n27\n,\n28\n,\n31\n,\n1\n]\nemploy the Wasserstein dependency measure (WDM)\n[\n24\n]\n, an equivalent formulation of the 1-Wasserstein distance due to the Kantorovich-Rubinstein duality\n[\n42\n]\n. Concretely, the objective is given by:\nI\nğ’²\nâ€‹\n(\nğ’®\n;\nZ\n)\n\\displaystyle I_{\\mathcal{W}}(\\mathcal{S};Z)\n=\nW\n1\nâ€‹\n(\np\nâ€‹\n(\ns\n,\nz\n)\n,\np\nâ€‹\n(\ns\n)\nâ€‹\np\nâ€‹\n(\nz\n)\n)\n\\displaystyle=W_{1}(p(s,z),p(s)p(z))\n=\nsup\nâ€–\nf\nâ€–\nL\nâ‰¤\n1\n(\nğ”¼\np\nâ€‹\n(\ns\n,\nz\n)\nâ€‹\n[\nf\nâ€‹\n(\ns\n,\nz\n)\n]\nâˆ’\nğ”¼\np\nâ€‹\n(\ns\n)\nâ€‹\np\nâ€‹\n(\nz\n)\nâ€‹\n[\nf\nâ€‹\n(\ns\n,\nz\n)\n]\n)\n\\displaystyle=\\sup_{\\|f\\|_{L}\\leq 1}\\left(\\mathbb{E}_{p(s,z)}[f(s,z)]-\\mathbb{E}_{p(s)p(z)}[f(s,z)]\\right)\nwhere\nW\n1\nW_{1}\nrepresents\n1\n1\n-Wasserstein distance and\nâˆ¥\nâ‹…\nâˆ¥\nL\n\\|\\cdot\\|_{L}\nindicates the 1-Lipschitz constraint. The function\nf\nf\nis parameterized as\nf\nâ€‹\n(\ns\n,\nz\n)\n=\nÏ•\nâ€‹\n(\ns\n)\nâŠ¤\nâ€‹\nÏˆ\nâ€‹\n(\nz\n)\nf(s,z)=\\phi(s)^{\\top}\\psi(z)\n, mapping the state space\nğ’®\n\\mathcal{S}\nto a latent space via\nÏ•\n:\nğ’®\nâ†’\nâ„\nD\n\\phi:\\mathcal{S}\\rightarrow\\mathbb{R}^{D}\n. In addition, by imposing additional conditions, replacing\nğ’®\n\\mathcal{S}\nwith the terminal state\nS\nT\nS_{T}\n, setting\nÏˆ\nâ€‹\n(\nz\n)\n=\nz\n\\psi(z)=z\n, and sampling\nz\nz\nfrom a zero-mean prior\np\nâ€‹\n(\nz\n)\np(z)\n, the objective can be approximated through a telescoping sum:\nI\nğ’²\nâ€‹\n(\nğ’®\nT\n;\nZ\n)\nâ‰ˆ\nsup\nâ€–\nÏ•\nâ€–\nL\nâ‰¤\n1\nğ”¼\np\nâ€‹\n(\nÏ„\n,\nz\n)\nâ€‹\nâˆ‘\nt\n=\n0\nT\nâˆ’\n1\n(\nÏ•\nâ€‹\n(\ns\nt\n+\n1\n)\nâˆ’\nÏ•\nâ€‹\n(\ns\nt\n)\n)\nâŠ¤\nâ€‹\nz\nI_{\\mathcal{W}}(\\mathcal{S}_{T};Z)\\approx\\sup_{\\|\\phi\\|_{L}\\leq 1}\\mathbb{E}_{p(\\tau,z)}\\sum^{T-1}_{t=0}(\\phi(s_{t+1})-\\phi(s_{t}))^{\\top}z\n(1)\nConsequently, a corresponding reward function is defined as\nr\nt\nâ€‹\n(\ns\nt\n,\nz\n,\ns\nt\n+\n1\n)\n=\n(\nÏ•\nâ€‹\n(\ns\nt\n+\n1\n)\nâˆ’\nÏ•\nâ€‹\n(\ns\nt\n)\n)\nâŠ¤\nâ€‹\nz\nr_{t}(s_{t},z,s_{t+1})=(\\phi(s_{t+1})-\\phi(s_{t}))^{\\top}z\n. The 1-Lipschitz constraint\nâ€–\nÏ•\nâ€‹\n(\ns\nt\n+\n1\n)\nâˆ’\nÏ•\nâ€‹\n(\ns\nt\n)\nâ€–\nâ‰¤\nd\nâ€‹\n(\ns\nt\n+\n1\n,\ns\nt\n)\n\\|\\phi(s_{t+1})-\\phi(s_{t})\\|\\leq d(s_{t+1},s_{t})\npreserves the distance metric in the latent space. A skill conditioned policy\nÏ€\nâ€‹\n(\ns\n,\nz\n)\n\\pi(s,z)\nis trained via RL to maximize the WDM objective, thereby promoting trajectories that accumulate larger defined distance in the direction of\nz\nz\n.\nIII-B\nGroup Equivariance and Representation Theory\nIf a transformation leaves a property of an object or system unchanged, that transformation is called a\nsymmetry\n[\n4\n]\n. Symmetries satisfy the axioms of associativity, identity, inverse, and closure, and the collection of all such transformations forms a\ngroup\n. In our setting, the relevant symmetry is planar rotation, represented by the continuous group\nS\nâ€‹\nO\nâ€‹\n(\n2\n)\nSO(2)\n. For practical implementation, we approximate this continuous symmetry using a discrete cyclic subgroup\nC\nN\nC_{N}\n, where rotations are quantized in increments of\n2\nâ€‹\nÏ€\n/\nN\n2\\pi/N\n.\nA\ngroup representation\nÏ\n:\nG\nâ†’\nG\nâ€‹\nL\nâ€‹\n(\nn\n)\n\\rho:G\\to GL(n)\nmaps each group element\ng\nâˆˆ\nG\ng\\in G\nto an invertible\nn\nÃ—\nn\nn\\times n\nmatrix that describes how\nG\nG\nacts on a vector space. Examples include the\ntrivial representation\nÏ\n0\nâ€‹\n(\ng\n)\nâ€‹\nx\n=\nx\n\\rho_{0}(g)x=x\n, which leaves the space unchanged, and the\nregular representation\non\nâ„\n|\nG\n|\n\\mathbb{R}^{|G|}\n, which can be decomposed into\nirreducible representations\nÏ\nk\n\\rho_{k}\nthat cannot be further reduced. For\nS\nâ€‹\nO\nâ€‹\n(\n2\n)\nSO(2)\n, the complex irreducible representations take the form\nÏ\nk\nâ€‹\n(\nÎ¸\n)\n=\ne\ni\nâ€‹\nk\nâ€‹\nÎ¸\n\\rho_{k}(\\theta)=e^{ik\\theta}\n. In practice, we use a real-valued form by separating real and imaginary parts into a two-dimensional feature vector. Any finite-dimensional representation\nÏ\n\\rho\nof a compact group can be written, up to a change of basis, as a direct sum of irreducible representations:\nÏ\nâ€‹\n(\ng\n)\n=\nQ\nâ€‹\n(\nâ¨\nk\n=\n1\nK\nÏ\nk\nâ€‹\n(\ng\n)\n)\nâ€‹\nQ\nâˆ’\n1\n,\n\\rho(g)=Q\\left(\\bigoplus_{k=1}^{K}\\rho_{k}(g)\\right)Q^{-1},\nfor some invertible matrix\nQ\nQ\n.\nA function\nf\n:\nX\nâ†’\nY\nf:X\\to Y\nis\nequivariant\nwith respect to a group action if applying the group before or after\nf\nf\nis equivalent, i.e.,\nÏ\nY\nâ€‹\n(\ng\n)\nâ€‹\nf\nâ€‹\n(\nx\n)\n=\nf\nâ€‹\n(\nÏ\nX\nâ€‹\n(\ng\n)\nâ€‹\nx\n)\n,\nâˆ€\ng\nâˆˆ\nG\n,\nx\nâˆˆ\nX\n.\n\\rho_{Y}(g)f(x)=f(\\rho_{X}(g)x),\\quad\\forall g\\in G,x\\in X.\nIf the output does not change under the group action on the input,\nf\nâ€‹\n(\nx\n)\n=\nf\nâ€‹\n(\nÏ\nX\nâ€‹\n(\ng\n)\nâ€‹\nx\n)\nf(x)=f(\\rho_{X}(g)x)\n, then\nf\nf\nis\ninvariant\n. Throughout the paper we use the shorthand\ng\nâ€‹\nx\ngx\nto denote the group action\nÏ\nâ€‹\n(\ng\n)\nâ€‹\nx\n\\rho(g)x\nfor notational simplicity.\nIII-C\nGroup-invariant MDPs\nA group-invariant MDP\n[\n45\n,\n46\n]\nbuilds on the notion of MDP homomorphism\n[\n29\n,\n30\n]\nand provides an abstract representation of an underlying MDP that respects symmetry. Denoted as\nâ„³\nG\nâ€‹\n(\nğ’®\n,\nğ’œ\n,\nP\n,\nR\n,\nG\n)\n\\mathcal{M}_{G}(\\mathcal{S},\\mathcal{A},P,R,G)\n, this formulation encodes how a symmetry group\nG\nG\nacts on states and actions. When the reward and transition dynamics satisfy the group-invariance conditions\nR\nâ€‹\n(\ns\n,\na\n)\n=\nR\nâ€‹\n(\ng\nâ€‹\ns\n,\ng\nâ€‹\na\n)\n,\nP\nâ€‹\n(\ns\nâ€²\n|\ns\n,\na\n)\n=\nP\nâ€‹\n(\ng\nâ€‹\ns\nâ€²\n|\ng\nâ€‹\ns\n,\ng\nâ€‹\na\n)\n,\nR(s,a)=R(gs,ga),\\quad P(s^{\\prime}|s,a)=P(gs^{\\prime}|gs,ga),\nThe optimal policy and optimal value functions of the original MDP can be derived directly from the symmetry-reduced MDP. This reduction provides both computational efficiency and structural guarantees tied to the underlying group.\nIV\nProblem Statement\nIn line with previous unsupervised skill discovery approaches, the problem is formalized within the framework of a reward-free MDP, denoted as\nâ„³\n=\n(\nğ’®\n,\nğ’œ\n,\nP\n)\n\\mathcal{M}=(\\mathcal{S},\\mathcal{A},P)\n.\nğ’®\n\\mathcal{S}\n,\nğ’œ\n\\mathcal{A}\n, and\nP\nP\nrepresent the state space, action space, and transition probabilities\nP\n:\nğ’®\nÃ—\nğ’œ\nâ†’\nğ’®\nP:\\mathcal{S}\\times\\mathcal{A}\\rightarrow\\mathcal{S}\n, respectively. The latent skill vector\nz\nâˆˆ\nZ\nz\\in Z\nis sampled from the prior distribution,\nz\nâˆ¼\np\nâ€‹\n(\nz\n)\nz\\sim p(z)\n. The policy is conditioned by the skill vector,\nÏ€\nâ€‹\n(\na\n|\ns\n,\nz\n)\n\\pi(a|s,z)\n, the skill vector informing the policy to select the corresponding action sequence. During the training, the skill vector doesnâ€™t change during the episode, and the policy is trained without any reward supervision, only with the intrinsic reward.\nIn this framework, we leverage the group symmetric prior, prior knowledge of rotation symmetry, to enhance the sample efficiency and generalizability. We convert the original MDPs to group-invariant MDPs by assuming the group-invariance of the intrinsic reward function and transition probability.\nFigure 1:\nOverview of Group-Invariant Skill Discovery (GISD).\nOur method learns an equivariant mapping\nÏ•\nF\n\\phi_{F}\nfrom the state space\nğ’®\n\\mathcal{S}\nto the\nGroup Fourier space\nZ\nZ\n. By aligning state transitions with latent skill vectors\nz\nz\nin the group Fourier domain, the discovered skills inherently respect the underlying geometric symmetry. This structure enables generalization: a policy trained for a specific trajectory\nÏ„\n\\tau\nautomatically generalizes to any group-transformed trajectory\ng\nâ€‹\nÏ„\ng\\tau\nby simply shifting the skill vector along its group orbit to\ng\nâ€‹\nz\ngz\n.\nV\nMethods\nIn this section, we present Group-Invariant Skill Discovery (GISD), a method that leverages the symmetry of the underlying dynamics to accelerate unsupervised skill discovery. We begin by showing that, in a group-invariant environment, the standard Wasserstein dependency measure (WDM) objective already admits symmetry-respecting optimal solutions. Motivated by this result, we then introduce a Group-Invariant WDM formulation and a practical Fourier-space parameterization and intrinsic reward.\nV-A\nTheoretical Analysis: Symmetry of Optimal Solutions\nBefore introducing GISD, we analyze the structure of optimal solutions to the standard WDM-based skill discovery problem. We show that, under group-invariant dynamics, restricting the search to symmetry-aware policies does not compromise optimality.\nTheorem 1\n(Existence of Equivariant Optima)\n.\nIn an MDP where the dynamics, initial state distribution, skill prior, and ground metric are all group-invariant, the Wasserstein dependency measure admits a globally optimal solution\n(\nÏ€\nÂ¯\n,\nf\nÂ¯\n)\n(\\bar{\\pi},\\bar{f})\nsuch that\nÏ€\nÂ¯\nâ€‹\n(\ng\nâ€‹\na\nâˆ£\ng\nâ€‹\ns\n,\ng\nâ€‹\nz\n)\n=\nÏ€\nÂ¯\nâ€‹\n(\na\nâˆ£\ns\n,\nz\n)\n,\nf\nÂ¯\nâ€‹\n(\ng\nâ€‹\ns\n,\ng\nâ€‹\nz\n)\n=\nf\nÂ¯\nâ€‹\n(\ns\n,\nz\n)\n,\nâˆ€\ng\nâˆˆ\nG\n.\n\\bar{\\pi}(ga\\mid gs,gz)=\\bar{\\pi}(a\\mid s,z),\\quad\\bar{f}(gs,gz)=\\bar{f}(s,z),\\quad\\forall g\\in G.\nIn other words, among all WDM global maximizers, there exists at least one policy-function pair with an equivariant policy and a group-invariant\n1\n1\n-Lipschitz function.\nFor proof, see Appendix\nVII-A\n.\nThis theoretical guarantee implies that the exploration of non-equivariant policiesâ€”which correspond to redundant or suboptimal solutions in a symmetric environmentâ€”is unnecessary. This justifies restricting the search to the symmetry-aware function class without sacrificing global optimality.\nV-B\nGroup-Invariant Wasserstein Dependency Measure\nTheorem\n1\nshows that in a group-invariant environment, the standard Wasserstein dependency measure (WDM) admits at least one global optimum where the policy is equivariant and the scoring function\nf\nf\nis group-invariant. This motivates explicitly restricting the scoring function class to symmetry-respecting functions: instead of hoping that symmetry emerges implicitly, we bake it into the objective.\nLet\nG\nG\nact on the state space\nğ’®\n\\mathcal{S}\nand skill space\nZ\nZ\n, and let\nd\nd\nbe a distance metric on\nğ’®\nÃ—\nZ\n\\mathcal{S}\\times Z\nthat is group-invariant under the joint action:\nd\nâ€‹\n(\n(\ng\nâ€‹\ns\n,\ng\nâ€‹\nz\n)\n,\n(\ng\nâ€‹\ns\nâ€²\n,\ng\nâ€‹\nz\nâ€²\n)\n)\n=\nd\nâ€‹\n(\n(\ns\n,\nz\n)\n,\n(\ns\nâ€²\n,\nz\nâ€²\n)\n)\n,\nâˆ€\ng\nâˆˆ\nG\n.\nd((gs,gz),(gs^{\\prime},gz^{\\prime}))=d((s,z),(s^{\\prime},z^{\\prime})),\\quad\\forall g\\in G.\nWe define the group-invariant scoring function class\nâ„±\nG\n\\mathcal{F}_{G}\nas the set of 1-Lipschitz functions\nf\n:\nğ’®\nÃ—\nZ\nâ†’\nâ„\nf:\\mathcal{S}\\times Z\\to\\mathbb{R}\nthat are\ninvariant under the joint action of\nG\nG\n:\nâ„±\nG\n:=\n{\nf\n|\nâ€–\nf\nâ€–\nL\nâ‰¤\n1\n,\nf\nâ€‹\n(\ng\nâ€‹\ns\n,\ng\nâ€‹\nz\n)\n=\nf\nâ€‹\n(\ns\n,\nz\n)\n,\nâˆ€\ng\nâˆˆ\nG\n}\n.\n\\mathcal{F}_{G}\\\\\n:=\\bigl\\{f\\;\\big|\\;\\|f\\|_{L}\\leq 1,\\;f(gs,gz)=f(s,z),\\;\\forall g\\in G\\bigr\\}.\nDefinition 1\n(Group-Invariant WDM)\n.\nGiven a group-invariant metric\nd\nd\non\nS\nÃ—\nZ\nS\\times Z\n, the\ngroup-invariant\nWasserstein dependency measure is defined as\nI\nğ’²\nG\n(\nğ’®\n;\nZ\n)\n:=\nsup\nf\nâˆˆ\nâ„±\nG\nğ”¼\np\nâ€‹\n(\ns\n,\nz\n)\n[\nf\n(\ns\n,\nz\n)\n]\nâˆ’\nğ”¼\np\nâ€‹\n(\ns\n)\nâ€‹\np\nâ€‹\n(\nz\n)\n[\nf\n(\ns\n,\nz\n)\n]\n)\n.\nI_{\\mathcal{W}}^{G}(\\mathcal{S};Z):=\\sup_{f\\in\\mathcal{F}_{G}}\\mathbb{E}_{p(s,z)}[f(s,z)]-\\mathbb{E}_{p(s)p(z)}[f(s,z)]).\nThis constrained objective guarantees invariance under the group action,\na property not generally enjoyed by the standard WDM.\nProposition 1\n.\nIf the distance metric\nd\nd\nis group-invariant, then the\ngroup-invariant WDM satisfies\nI\nğ’²\nG\nâ€‹\n(\ng\nâ€‹\nğ’®\n;\ng\nâ€‹\nZ\n)\n=\nI\nğ’²\nG\nâ€‹\n(\nğ’®\n;\nZ\n)\nI_{\\mathcal{W}}^{G}(g\\mathcal{S};gZ)=I_{\\mathcal{W}}^{G}(\\mathcal{S};Z)\nfor all\ng\nâˆˆ\nG\ng\\in G\n.\nProof is provided in Appendix\nVII-B\n.\nReduction of the search space.\nCompared to the standard WDM, which optimizes over all 1-Lipschitz functions,\nI\nğ’²\nG\nI^{G}_{\\mathcal{W}}\nrestricts the scoring function class to the group-invariant subset\nâ„±\nG\n\\mathcal{F}_{G}\n. Based on\nTheorem\n1\n, this restriction does not eliminate any globally optimal symmetric solution, but acts as a geometric inductive bias: it rules out functions that encode spurious dependencies and focuses optimization on symmetry-consistent structure. In the following subsections, we show how to construct such group-invariant scoring functions via group averaging and how to parameterize them efficiently in Fourier space.\nV-C\nGroup-Averaged Scoring Functions\nThe group-invariant WDM in Definition\n1\nrestricts the\nadmissible scoring functions (the 1-Lipschitz functions in the dual formulation)\nto the invariant class\nâ„±\nG\n\\mathcal{F}_{G}\n. We now construct such\ngroup-invariant scoring functions from arbitrary admissible\n1\n1\n-Lipschitz\nfunctions via a standard group averaging operation.\nDefinition 2\n(Group-averaged Scoring Function)\n.\nFor any\n1\n1\n-Lipschitz function\nf\n:\nğ’®\nÃ—\nZ\nâ†’\nâ„\nf:\\mathcal{S}\\times Z\\to\\mathbb{R}\n(with respect to the metric\nd\nd\n), we define its group average as\nf\n~\nâ€‹\n(\ns\n,\nz\n)\n:=\nâˆ«\nG\nf\nâ€‹\n(\ng\nâ€‹\ns\n,\ng\nâ€‹\nz\n)\nâ€‹\nğ‘‘\nÎ¼\nâ€‹\n(\ng\n)\n,\n\\tilde{f}(s,z):=\\int_{G}f(gs,gz)\\,d\\mu(g),\nwhere\nÎ¼\n\\mu\nis the normalized Haar measure on\nG\nG\n(Appendix\nVII-H\n).\nThis operator maps a general admissible scoring function\nf\nf\nto a group-invariant\nfunction while preserving the\n1\n1\n-Lipschitz constant:\nProposition 2\n(Properties of the group-averaged scoring function)\n.\nLet\nf\n:\nğ’®\nÃ—\nZ\nâ†’\nâ„\nf:\\mathcal{S}\\times Z\\to\\mathbb{R}\nbe\n1\n1\n-Lipschitz with respect to\na group-invariant metric\nd\nd\non\nğ’®\nÃ—\nZ\n\\mathcal{S}\\times Z\n. Then its group\naverage\nf\n~\n\\tilde{f}\nis group-invariant and\n1\n1\n-Lipschitz with respect to\nd\nd\n. In particular,\nf\n~\nâˆˆ\nâ„±\nG\n\\tilde{f}\\in\\mathcal{F}_{G}\n.\nWe provide the proof in Appendix\nVII-C\n.\nThe group averaging operator provides the precise link between the standard and group-invariant WDM: given any optimal scoring function\nf\nâˆ—\nf^{*}\nin the unconstrained class, its group average\nf\n~\nâˆ—\n\\tilde{f}^{*}\nis feasible in\nâ„±\nG\n\\mathcal{F}_{G}\n(Proposition\n2\n) and, assuming an equivariant optimal policy, achieves the same objective value. Thus, for symmetric optima, the restricted and unconstrained WDMs coincide.\nV-D\nSkill Discovery in the Group Fourier Space\nIn contrast to the decompositions of\nf\nâ€‹\n(\ns\n,\nz\n)\nf(s,z)\nused in prior works\n[\n26\n,\n27\n,\n28\n]\n, we\nderive our parameterization from a group representation-theoretic\nviewpoint. Assume a compact group\nG\nG\nacts on the state space\nğ’®\n\\mathcal{S}\nand latent skill space\nZ\nZ\n. We consider the induced action\nof the product group\nG\nÃ—\nG\nG\\times G\non\nğ’®\nÃ—\nZ\n\\mathcal{S}\\times Z\n, given by\n(\ng\n1\n,\ng\n2\n)\nâ‹…\n(\ns\n,\nz\n)\n=\n(\ng\n1\nâ€‹\ns\n,\ng\n2\nâ€‹\nz\n)\n(g_{1},g_{2})\\cdot(s,z)=(g_{1}s,g_{2}z)\n, and define\nf\ng\n1\n,\ng\n2\nâ€‹\n(\ns\n,\nz\n)\n:=\nf\nâ€‹\n(\ng\n1\nâ€‹\ns\n,\ng\n2\nâ€‹\nz\n)\n.\nf_{g_{1},g_{2}}(s,z):=f(g_{1}s,g_{2}z).\nFor each fixed\n(\ns\n,\nz\n)\n(s,z)\n, the map\n(\ng\n1\n,\ng\n2\n)\nâ†¦\nf\ng\n1\n,\ng\n2\nâ€‹\n(\ns\n,\nz\n)\n(g_{1},g_{2})\\mapsto f_{g_{1},g_{2}}(s,z)\nis square-integrable on\nG\nÃ—\nG\nG\\times G\n, i.e.,\nf\n(\nâ‹…\n,\nâ‹…\n)\nâˆˆ\nL\n2\nâ€‹\n(\nG\nÃ—\nG\n)\nf_{(\\cdot,\\cdot)}\\in L^{2}(G\\times G)\n. By the Peterâ€“Weyl theorem\n[\n5\n]\n, this function admits an expansion in\nterms of the irreducible representations of\nG\nÃ—\nG\nG\\times G\n(see Appendix\nVII-I\nfor details):\nf\ng\n1\n,\ng\n2\nâ€‹\n(\ns\n,\nz\n)\n=\nâˆ‘\nÏ\n,\nÏƒ\nâˆˆ\nG\n^\nd\nÏ\nâ€‹\nd\nÏƒ\nâ€‹\nTr\nâ€‹\n(\nA\nÏ\n,\nÏƒ\nâ€‹\n(\ns\n,\nz\n)\nâ€‹\n(\nÏ\nâ€‹\n(\ng\n1\n)\nâŠ—\nÏƒ\nâ€‹\n(\ng\n2\n)\n)\n)\n,\nf_{g_{1},g_{2}}(s,z)=\\sum_{\\rho,\\sigma\\in\\hat{G}}d_{\\rho}d_{\\sigma}\\,\\mathrm{Tr}\\!\\big(A_{\\rho,\\sigma}(s,z)\\,(\\rho(g_{1})\\otimes\\sigma(g_{2}))\\big),\n(2)\nwhere\nG\n^\n\\hat{G}\ndenotes the set of irreducible representations of\nG\nG\n,\nd\nÏ\nd_{\\rho}\nand\nd\nÏƒ\nd_{\\sigma}\nare their dimensions, and\nA\nÏ\n,\nÏƒ\nâ€‹\n(\ns\n,\nz\n)\nA_{\\rho,\\sigma}(s,z)\nare\ncoefficient matrices depending on\n(\ns\n,\nz\n)\n(s,z)\n.\nTo enforce the group-invariance required in\nDefinition\n1\n, we apply the group average over the diagonal\naction\ng\nâ†¦\n(\ng\n,\ng\n)\ng\\mapsto(g,g)\n:\nf\n~\nâ€‹\n(\ns\n,\nz\n)\n=\nâˆ«\nG\nf\ng\n,\ng\nâ€‹\n(\ns\n,\nz\n)\nâ€‹\nğ‘‘\nÎ¼\nâ€‹\n(\ng\n)\n=\nâˆ«\nG\nf\nâ€‹\n(\ng\nâ€‹\ns\n,\ng\nâ€‹\nz\n)\nâ€‹\nğ‘‘\nÎ¼\nâ€‹\n(\ng\n)\n.\n\\tilde{f}(s,z)=\\int_{G}f_{g,g}(s,z)\\,d\\mu(g)=\\int_{G}f(gs,gz)\\,d\\mu(g).\nSubstituting Eq.Â (\n2\n), we utilize Schurâ€™s Lemma\n[\n7\n]\nand the orthogonality relations of irreducible representations:\nâˆ«\nG\nÏ\nâ€‹\n(\ng\n)\nâŠ—\nÏƒ\nâ€‹\n(\ng\n)\nâ€‹\nğ‘‘\nÎ¼\nâ€‹\n(\ng\n)\nâ‰ \n0\nâ‡”\nÏƒ\nâ‰…\nÏ\nâˆ—\n.\n\\int_{G}\\rho(g)\\otimes\\sigma(g)\\ d\\mu(g)\\neq 0\\Leftrightarrow\\sigma\\cong\\rho^{*}.\nThis averaging operation annihilates all non-matching components (\nÏ\nâ‰ \nÏƒ\nâˆ—\n\\rho\\neq\\sigma^{*}\n) and projects the remaining terms onto the group-invariant scalar subspace. Consequently, the double sum collapses into a single sum over the spectrum:\nf\n~\nâ€‹\n(\ns\n,\nz\n)\n=\nâˆ‘\nÏ\nâˆˆ\nG\n^\nÎ»\nÏ\nâ€‹\n(\ns\n,\nz\n)\n,\n\\tilde{f}(s,z)=\\sum_{\\rho\\in\\hat{G}}\\lambda_{\\rho}(s,z),\nwhere each\nÎ»\nÏ\nâ€‹\n(\ns\n,\nz\n)\n\\lambda_{\\rho}(s,z)\nrepresents the scalar contraction of the matching representation blocks.\nWe now parameterize these scalar coefficients in terms of\nFourier-space features\nof\ns\ns\nand\nz\nz\n.\nFor each surviving irrep\nÏ\n\\rho\n, we introduce feature vectors\nÏ•\nÏ\nâ€‹\n(\ns\n)\n\\phi_{\\rho}(s)\nand\nÏˆ\nÏ\nâ€‹\n(\nz\n)\n\\psi_{\\rho}(z)\nin the corresponding representation\nspaces and parameterize\nÎ»\nÏ\nâ€‹\n(\ns\n,\nz\n)\nâ‰ˆ\nâŸ¨\nÏ•\nÏ\nâ€‹\n(\ns\n)\n,\nÏˆ\nÏ\nâ€‹\n(\nz\n)\nâŸ©\n.\n\\lambda_{\\rho}(s,z)\\approx\\big\\langle\\phi_{\\rho}(s),\\,\\psi_{\\rho}(z)\\big\\rangle.\nStacking all irrep components into a single global feature vector, we obtain\nthe maps\nÏ•\nF\n:\nğ’®\nâ†’\nâ„\nd\n,\nÏˆ\nF\n:\nZ\nâ†’\nâ„\nd\n,\n\\phi_{F}:\\mathcal{S}\\to\\mathbb{R}^{d},\\quad\\psi_{F}:Z\\to\\mathbb{R}^{d},\nand the group-averaged scoring function takes the inner-product form:\nf\n~\nâ€‹\n(\ns\n,\nz\n)\nâ‰ˆ\nâŸ¨\nÏ•\nF\nâ€‹\n(\ns\n)\n,\nÏˆ\nF\nâ€‹\n(\nz\n)\nâŸ©\n.\n\\tilde{f}(s,z)\\approx\\big\\langle\\phi_{F}(s),\\psi_{F}(z)\\big\\rangle.\nBy construction,\nÏ•\nF\n\\phi_{F}\nmaps states into the spectral domain and satisfies the\nequivariance\nproperty:\nÏ•\nF\nâ€‹\n(\ng\nâ€‹\ns\n)\n=\nÏ\nF\nâ€‹\n(\ng\n)\nâ€‹\nÏ•\nF\nâ€‹\n(\ns\n)\n,\n\\phi_{F}(gs)=\\rho_{F}(g)\\phi_{F}(s),\n(3)\nwhere\nÏ\nF\nâ€‹\n(\ng\n)\n\\rho_{F}(g)\ndenotes the block-diagonal direct sum of unitary irreducible representations acting on the feature vector. Following METRA\n[\n28\n]\n, we\nset\nÏˆ\nF\nâ€‹\n(\nz\n)\n=\nz\n\\psi_{F}(z)=z\n, treating the latent skill\nz\nz\nas a\nunit-norm vector in Fourier space. This choice, together with a 1-Lipschitz parameterization of\nÏ•\nF\n\\phi_{F}\n,\nis compatible with the\n1\n1\n-Lipschitz constraint required by the WDM\nobjective.\nFrequency Filtering and Interpretability.\nA key advantage of working in Fourier space is the explicit separation\nof geometric frequencies. The feature vector\nÏ•\nF\nâ€‹\n(\ns\n)\n\\phi_{F}(s)\nis a\nconcatenation of coefficients corresponding to different irreducible representations (frequencies). Unlike unstructured latent spaces, this allows us to manually emphasize or suppress specific symmetries by applying a frequency mask\nM\nM\n:\nf\n~\nâ€‹\n(\ns\n,\nz\n)\n=\nâŸ¨\nM\nâ‹…\nÏ•\nF\nâ€‹\n(\ns\n)\n,\nz\nâŸ©\n.\n\\tilde{f}(s,z)=\\big\\langle M\\cdot\\phi_{F}(s),\\,z\\big\\rangle.\nFor example, by selecting only the trivial representation (\nÏ\n0\n\\rho_{0}\n), we\ncan discover purely group-invariant skills. By selecting higher-order frequencies, we encourage skills that are sensitive to the group action. This provides a degree of interpretability and controllability unavailable in standard unsupervised skill discovery.\nV-E\nGroup-Invariant MDP for Skill Discovery\nUsing the group-invariant scoring function parameterization from\nSection\nV-D\n, we now derive the intrinsic reward used for\nskill discovery and show that it is itself group-invariant.\nRecall that METRA\n[\n28\n]\noptimizes a WDM-style objective\nover trajectories (Eq.Â (\n1\n)).\nIn our framework, we restrict to group-invariant scoring functions and\nparameterize the group-averaged scoring function as an inner product in Fourier\nspace,\nf\n~\nâ€‹\n(\ns\n,\nz\n)\nâ‰ˆ\nâŸ¨\nÏ•\nF\nâ€‹\n(\ns\n)\n,\nz\nâŸ©\n,\n\\tilde{f}(s,z)\\approx\\big\\langle\\phi_{F}(s),z\\big\\rangle,\nwhere\nÏ•\nF\n\\phi_{F}\nis equivariant with respect to the group action\n(Section\nV-D\n). Substituting this parameterization into\nEq.Â (\n1\n) leads to\nI\nğ’²\nâ€‹\n(\nğ’®\nT\n;\nZ\n)\n\\displaystyle I_{\\mathcal{W}}(\\mathcal{S}_{T};Z)\nâ‰ˆ\nsup\nâ€–\nÏ•\nF\nâ€–\nL\nâ‰¤\n1\nâˆ‘\nt\n=\n0\nT\nâˆ’\n1\n(\nğ”¼\nÏ„\n,\nz\n[\nâŸ¨\nÏ•\nF\n(\ns\nt\n+\n1\n)\nâˆ’\nÏ•\nF\n(\ns\nt\n)\n,\nz\nâŸ©\n]\n\\displaystyle\\approx\\sup_{\\|\\phi_{F}\\|_{L}\\leq 1}\\sum_{t=0}^{T-1}\\Big(\\mathbb{E}_{\\tau,z}\\big[\\langle\\phi_{F}(s_{t+1})-\\phi_{F}(s_{t}),z\\rangle\\big]\n(4)\nâˆ’\nğ”¼\nÏ„\n[\nâŸ¨\nÏ•\nF\n(\ns\nt\n+\n1\n)\nâˆ’\nÏ•\nF\n(\ns\nt\n)\n,\nğ”¼\nz\n[\nz\n]\nâŸ©\n]\n)\n.\n\\displaystyle\\quad-\\mathbb{E}_{\\tau}\\big[\\langle\\phi_{F}(s_{t+1})-\\phi_{F}(s_{t}),\\mathbb{E}_{z}[z]\\rangle\\big]\\Big).\nAs in METRA, we choose\np\nâ€‹\n(\nz\n)\np(z)\nto have zero mean\nğ”¼\np\nâ€‹\n(\nz\n)\nâ€‹\n[\nz\n]\n=\n0\n\\mathbb{E}_{p(z)}[z]=0\n, in which case the second term vanishes and\n(\n4\n) reduces to\nI\nğ’²\nâ€‹\n(\nğ’®\nT\n;\nZ\n)\nâ‰ˆ\nsup\nâ€–\nÏ•\nF\nâ€–\nL\nâ‰¤\n1\nğ”¼\nÏ„\n,\nz\nâ€‹\n[\nâˆ‘\nt\n=\n0\nT\nâˆ’\n1\nâŸ¨\nÏ•\nF\nâ€‹\n(\ns\nt\n+\n1\n)\nâˆ’\nÏ•\nF\nâ€‹\n(\ns\nt\n)\n,\nz\nâŸ©\n]\n.\nI_{\\mathcal{W}}(\\mathcal{S}_{T};Z)\\approx\\sup_{\\|\\phi_{F}\\|_{L}\\leq 1}\\mathbb{E}_{\\tau,z}\\Bigg[\\sum_{t=0}^{T-1}\\langle\\phi_{F}(s_{t+1})-\\phi_{F}(s_{t}),z\\rangle\\Bigg].\n(5)\nBecause the sum in (\n5\n) is telescoping, it is\nnatural to interpret the incremental term as an intrinsic reward:\nr\nâ€‹\n(\ns\nt\n,\nz\n,\ns\nt\n+\n1\n)\n:=\nâŸ¨\nÏ•\nF\nâ€‹\n(\ns\nt\n+\n1\n)\nâˆ’\nÏ•\nF\nâ€‹\n(\ns\nt\n)\n,\nz\nâŸ©\n.\nr(s_{t},z,s_{t+1}):=\\big\\langle\\phi_{F}(s_{t+1})-\\phi_{F}(s_{t}),\\,z\\big\\rangle.\n(6)\nWe now show that this reward is group-invariant. Let\nh\nâˆˆ\nG\nh\\in G\nact on\nstates and skills as\ns\nâ€²\n=\nh\nâ€‹\ns\ns^{\\prime}=hs\nand\nz\nâ€²\n=\nh\nâ€‹\nz\nz^{\\prime}=hz\n. Using the equivariance of\nÏ•\nF\n\\phi_{F}\n(Eq.Â (\n3\n)) and the fact that the representation\nÏ\nâ€‹\n(\nh\n)\n\\rho(h)\nis unitary, we obtain\nr\nâ€‹\n(\nh\nâ€‹\ns\nt\n,\nh\nâ€‹\nz\n,\nh\nâ€‹\ns\nt\n+\n1\n)\n\\displaystyle r(hs_{t},hz,hs_{t+1})\n=\nâŸ¨\nÏ•\nF\nâ€‹\n(\nh\nâ€‹\ns\nt\n+\n1\n)\nâˆ’\nÏ•\nF\nâ€‹\n(\nh\nâ€‹\ns\nt\n)\n,\nh\nâ€‹\nz\nâŸ©\n\\displaystyle=\\big\\langle\\phi_{F}(hs_{t+1})-\\phi_{F}(hs_{t}),\\,hz\\big\\rangle\n=\nâŸ¨\nÏ\nâ€‹\n(\nh\n)\nâ€‹\n(\nÏ•\nF\nâ€‹\n(\ns\nt\n+\n1\n)\nâˆ’\nÏ•\nF\nâ€‹\n(\ns\nt\n)\n)\n,\nÏ\nâ€‹\n(\nh\n)\nâ€‹\nz\nâŸ©\n\\displaystyle=\\big\\langle\\rho(h)\\big(\\phi_{F}(s_{t+1})-\\phi_{F}(s_{t})\\big),\\rho(h)z\\big\\rangle\n=\nâŸ¨\nÏ•\nF\nâ€‹\n(\ns\nt\n+\n1\n)\nâˆ’\nÏ•\nF\nâ€‹\n(\ns\nt\n)\n,\nz\nâŸ©\n\\displaystyle=\\big\\langle\\phi_{F}(s_{t+1})-\\phi_{F}(s_{t}),\\,z\\big\\rangle\n=\nr\nâ€‹\n(\ns\nt\n,\nz\n,\ns\nt\n+\n1\n)\n,\n\\displaystyle=r(s_{t},z,s_{t+1}),\nwhere the third equality uses unitarity of\nÏ\nâ€‹\n(\nh\n)\n\\rho(h)\n:\nâŸ¨\nÏ\nâ€‹\n(\nh\n)\nâ€‹\nx\n,\nÏ\nâ€‹\n(\nh\n)\nâ€‹\ny\nâŸ©\n=\nâŸ¨\nx\n,\ny\nâŸ©\n\\langle\\rho(h)x,\\rho(h)y\\rangle=\\langle x,y\\rangle\n.\nThus, the intrinsic reward (\n6\n) is invariant under the joint group action on states and skills.\nThis invariance leads to a significant theoretical result for our learning process. Because the environment dynamics are group-invariant (by assumption) and the derived intrinsic reward\nr\nr\nis group-invariant (as shown above), the skill discovery problem constitutes a group-invariant MDP\n[\n46\n]\n. This structural property guarantees the existence of an optimal equivariant policy\nÏ€\nâˆ—\n\\pi^{*}\n.\nWe now connect this architectural choice back to the theoretical guarantees of our objective:\nRemark 1\n(Exactness for Equivariant Policies)\n.\nWhile Theorem\n1\nguarantees the existence of a symmetric global optimum, our method parameterizes the policy\nÏ€\n\\pi\nto be equivariant based on the group-invariant MDP.\nIn a group-invariant MDP, an equivariant policy induces a group-invariant joint distribution\np\nâ€‹\n(\ns\n,\nz\n)\np(s,z)\n(Lemma\n1\n).\nUnder such a symmetric distribution, the optimal scoring function\nf\nâˆ—\nf^{*}\nfor the unconstrained WDM is inherently group-invariant (as non-symmetric components of the scoring function average to zero or contribute nothing to the objective).\nTherefore, for our equivariant policy class, optimizing the restricted objective\nI\nğ’²\nG\nI^{G}_{\\mathcal{W}}\nis mathematically equivalent to optimizing the standard WDM, ensuring no loss of expressivity.\nAlgorithm 1\nGroup-Invariant Unsupervised Skill Discovery\n1:\nInitialize:\nEquivariant policy\nÏ€\nâ€‹\n(\na\n|\ns\n,\nz\n)\n\\pi(a|s,z)\n, Fourier mapping\nÏ•\nF\nâ€‹\n(\ns\n)\n\\phi_{F}(s)\n, dual variable\nÎ»\n\\lambda\n, replay buffer\nğ’Ÿ\n\\mathcal{D}\n2:\nfor\nepoch\n=\n1\n,\nâ€¦\n,\nN\n\\text{epoch}=1,\\dots,N\ndo\n3:\nfor\nepisode\n=\n1\n,\nâ€¦\n,\nM\n\\text{episode}=1,\\dots,M\ndo\n4:\nSample skill\nz\nâˆ¼\np\nâ€‹\n(\nz\n)\nz\\sim p(z)\n5:\nCollect trajectory\nÏ„\n\\tau\nusing\nÏ€\nâ€‹\n(\na\n|\ns\n,\nz\n)\n\\pi(a|s,z)\n6:\nStore transitions\n(\ns\n,\na\n,\ns\nâ€²\n,\nz\n)\n(s,a,s^{\\prime},z)\nin\nğ’Ÿ\n\\mathcal{D}\n7:\nend\nfor\n8:\n1. Update Discriminator\nÏ•\nF\n\\phi_{F}\n:\n9:\nOptimize\nğ’¥\nÏ•\n\\mathcal{J}_{\\phi}\n(Eq.Â (\nV-G\n))\n10:\n2. Update Dual Variable\nÎ»\n\\lambda\n:\n11:\nOptimize\nğ’¥\nÎ»\n\\mathcal{J}_{\\lambda}\n(Eq.Â (\n9\n))\n12:\n3. Update Policy\nÏ€\n\\pi\n:\n13:\nCompute rewards\nr\n=\nâŸ¨\nÏ•\nF\nâ€‹\n(\ns\nâ€²\n)\nâˆ’\nÏ•\nF\nâ€‹\n(\ns\n)\n,\nz\nâŸ©\nr=\\langle\\phi_{F}(s^{\\prime})-\\phi_{F}(s),z\\rangle\n14:\nUpdate\nÏ€\n\\pi\nusing symmetry-aware SAC\n[\n46\n,\n6\n]\n15:\nend\nfor\nV-F\nGroup Symmetry in Downstream Tasks\nAfter skill discovery, prior works\n[\n26\n,\n27\n,\n28\n]\nreuse the discovered skills for downstream tasks via a hierarchical architecture. A high-level policy\nÏ€\nh\nâ€‹\n(\nz\nâˆ£\ns\n,\ngoal\n)\n\\pi^{h}(z\\mid s,\\text{goal})\nselects a latent skill conditioned on the current state and goal, while a low-level policy\nÏ€\nl\nâ€‹\n(\na\nâˆ£\ns\n,\nz\n)\n\\pi^{l}(a\\mid s,z)\nexecutes primitive actions using the pretrained skill-conditioned policy (with parameters frozen).\nThis interaction induces a\nFixed-interval Semi-MDP\n[\n37\n]\n, where the high-level transition dynamics depend on the cumulative effect of the low-level policy over\nk\nk\nsteps. We formally define this transition probability\nP\nk\nP_{k}\n:\nDefinition 3\n(Fixed-interval High-level Transition)\n.\nGiven a fixed interval\nk\nk\n, the high-level transition kernel induced by the low-level policy\nÏ€\nl\n\\pi^{l}\nis defined as the\nk\nk\n-step roll-out:\nP\nk\n(\ns\nt\n+\nk\nâˆ£\ns\nt\n,\nz\n)\n:=\nâˆ«\nâ€¦\nâˆ«\nâˆ\ni\n=\n0\nk\nâˆ’\n1\n[\n\\displaystyle P_{k}(s_{t+k}\\mid s_{t},z)=\\int\\dots\\int\\prod_{i=0}^{k-1}\\bigg[\n(7)\nÏ€\nl\n(\na\nt\n+\ni\nâˆ£\ns\nt\n+\ni\n,\nz\n)\nâ‹…\nP\nl\n(\ns\nt\n+\ni\n+\n1\nâˆ£\ns\nt\n+\ni\n,\na\nt\n+\ni\n)\n]\nd\nÏ„\ni\nâ€‹\nn\nâ€‹\nt\n\\displaystyle\\quad\\pi^{l}(a_{t+i}\\mid s_{t+i},z)\\cdot P^{l}(s_{t+i+1}\\mid s_{t+i},a_{t+i})\\bigg]\\,d\\tau_{int}\nwhere\nP\nl\nP^{l}\ndenotes the one-step transition kernel of the underlying MDP, and the integration is over all intermediate states and actions\nÏ„\ni\nâ€‹\nn\nâ€‹\nt\n=\n{\na\nt\n:\nt\n+\nk\nâˆ’\n1\n,\ns\nt\n+\n1\n:\nt\n+\nk\nâˆ’\n1\n}\n\\tau_{int}=\\{a_{t:t+k-1},s_{t+1:t+k-1}\\}\n.\nFor downstream tasks, the extrinsic reward can typically be chosen to be group-invariant (e.g., sparse goal-reached reward). We now show that if the environment dynamics and low-level skill policy are symmetric, then the induced high-level semi-MDP is itself group-invariant.\nTheorem 2\n(Group-invariant Fixed-interval Semi-MDP)\n.\nAssume the environment dynamics are group-invariant and the pretrained skill policy is equivariant:\nP\nl\nâ€‹\n(\ng\nâ€‹\ns\nâ€²\nâˆ£\ng\nâ€‹\ns\n,\ng\nâ€‹\na\n)\n\\displaystyle P^{l}(gs^{\\prime}\\mid gs,ga)\n=\nP\nl\nâ€‹\n(\ns\nâ€²\nâˆ£\ns\n,\na\n)\n\\displaystyle=P^{l}(s^{\\prime}\\mid s,a)\nÏ€\nl\nâ€‹\n(\ng\nâ€‹\na\nâˆ£\ng\nâ€‹\ns\n,\ng\nâ€‹\nz\n)\n\\displaystyle\\pi^{l}(ga\\mid gs,gz)\n=\nÏ€\nl\nâ€‹\n(\na\nâˆ£\ns\n,\nz\n)\nâˆ€\ng\nâˆˆ\nG\n.\n\\displaystyle=\\pi^{l}(a\\mid s,z)\\quad\\forall g\\in G.\nThen, the induced high-level transition kernel (Eq.Â (\n7\n)) satisfies group invariance:\nP\nk\nâ€‹\n(\ng\nâ€‹\ns\nt\n+\nk\nâˆ£\ng\nâ€‹\ns\nt\n,\ng\nâ€‹\nz\n)\n=\nP\nk\nâ€‹\n(\ns\nt\n+\nk\nâˆ£\ns\nt\n,\nz\n)\n,\nâˆ€\ng\nâˆˆ\nG\n.\nP_{k}(gs_{t+k}\\mid gs_{t},gz)=P_{k}(s_{t+k}\\mid s_{t},z),\\qquad\\forall g\\in G.\nConsequently, the fixed-interval semi-MDP is group-invariant whenever the high-level reward is group-invariant.\nThe proof is provided in Appendix\nVII-F\n.\nGeneralizable Skills.\nTheorem\n2\nestablishes that our pretrained skills induce a group-invariant fixed-interval semi-MDP. Since the skills are represented in the Fourier space and encode symmetric features by construction, an equivariant high-level policy\nÏ€\nh\nâ€‹\n(\nz\nâˆ£\ns\n,\ng\n)\n\\pi^{h}(z\\mid s,g)\ncan systematically exploit this structure.\nBecause the transition dynamics are group-invariant, a high-level policy trained in one group element can generalize to any other group elements by simply transforming the skill vector\nz\nz\naccording to the group action (Fig.\n1\n). This allows for highly sample efficient downstream task training.\nV-G\nPractical Implementation\nTo finalize the training objective, we must specify the distance metric\nd\nd\nfor the Lipschitz constraint.\nWe adopt the temporal distance\nd\nT\nâ€‹\n(\ns\n,\ns\nâ€²\n)\nd_{T}(s,s^{\\prime})\n[\n28\n]\n, which measures the expected number of steps between states. Since the underlying MDP dynamics are group-invariant,\nd\nT\nd_{T}\nis inherently group-invariant (see Appendix\nVII-E\nfor proof), satisfying the metric requirement of Definition\n1\n.\nOur training procedure follows the dual gradient descent method of METRA, but substitutes the standard discriminator with our equivariant Fourier mapping\nÏ•\nF\n\\phi_{F}\n. The discriminator parameters are updated to minimize the following loss, which balances skill alignment against the Lipschitz constraint via a Lagrange multiplier\nÎ»\n\\lambda\n:\nğ’¥\nÏ•\n\\displaystyle\\mathcal{J}_{\\phi}\n=\nğ”¼\nğ’Ÿ\n[\nâŸ¨\nÏ•\nF\n(\ns\nâ€²\n)\nâˆ’\nÏ•\nF\n(\ns\n)\n,\nz\nâŸ©\n\\displaystyle=\\mathbb{E}_{\\mathcal{D}}\\Big[\\langle\\phi_{F}(s^{\\prime})-\\phi_{F}(s),z\\rangle\n+\nÎ»\nâ‹…\nmin\n(\nÏµ\n,\n1\nâˆ’\nâˆ¥\nÏ•\nF\n(\ns\nâ€²\n)\nâˆ’\nÏ•\nF\n(\ns\n)\nâˆ¥\n2\n2\n)\n]\n,\n\\displaystyle\\quad+\\lambda\\cdot\\min\\bigl(\\epsilon,1-\\|\\phi_{F}(s^{\\prime})-\\phi_{F}(s)\\|_{2}^{2}\\bigr)\\Big],\n(8)\nğ’¥\nÎ»\n\\displaystyle\\mathcal{J}_{\\lambda}\n=\nğ”¼\nğ’Ÿ\nâ€‹\n[\nÎ»\nâ‹…\nmin\nâ¡\n(\nÏµ\n,\n1\nâˆ’\nâ€–\nÏ•\nF\nâ€‹\n(\ns\nâ€²\n)\nâˆ’\nÏ•\nF\nâ€‹\n(\ns\n)\nâ€–\n2\n2\n)\n]\n,\n\\displaystyle=\\mathbb{E}_{\\mathcal{D}}\\Big[\\lambda\\cdot\\min\\bigl(\\epsilon,1-\\|\\phi_{F}(s^{\\prime})-\\phi_{F}(s)\\|_{2}^{2}\\bigr)\\Big],\n(9)\nwhere\nğ’Ÿ\n\\mathcal{D}\nis the replay buffer.\nThe policy\nÏ€\nâ€‹\n(\na\nâˆ£\ns\n,\nz\n)\n\\pi(a\\mid s,z)\nis updated using group equivariant SAC\n[\n46\n]\nor PE-SAC\n[\n6\n]\nto maximize the intrinsic reward\nr\n=\nâŸ¨\nÏ•\nF\nâ€‹\n(\ns\nâ€²\n)\nâˆ’\nÏ•\nF\nâ€‹\n(\ns\n)\n,\nz\nâŸ©\nr=\\langle\\phi_{F}(s^{\\prime})-\\phi_{F}(s),z\\rangle\n.\nVI\nExperiments\nWe evaluate GISD against the state-of-the-art unsupervised skill discovery method, METRA\n[\n28\n]\n.\nOur goal is to understand how explicitly exploiting symmetry during skill discovery and downstream task training affects (i) sample efficiency, (ii) state-space coverage, and (iii) downstream task performance.\nWe follow the overall experimental setup of METRA and consider both state-based and pixel-based locomotion with continuous latent skills.\nVI-A\nBenchmark environments and Symmetry Structure\nWe use two benchmark locomotion tasks with known geometric symmetries.\nState-based Ant (\nC\n4\nC_{4}\nsymmetry).\nFor state-based skill discovery, we use the MuJoCo Ant environment\n[\n3\n]\nwith a planar\n(\n90\nâˆ˜\n)\n(90^{\\circ})\nrotational symmetry, modeled as the cyclic group\nC\n4\nC_{4}\n.\nTo faithfully preserve this symmetry, we\ndo not\napply observation normalization (e.g., running mean/variance) to the state input. Such preprocessing typically warps coordinates and breaks equivariance.\nIn this setting, we restrict the Fourier representation to the frequency-\n1\n1\nC\n4\nC_{4}\nirrep and discover 2D latent skills in this subspace, matching the skill dimensionality used in METRA (as introduced in Section\nV-D\n). Intuitively, this emphasizes directional, rotation equivariant behaviors (e.g., â€move in a given headingâ€), which are most relevant in Ant locomotion.\nWe empirically observed that incorporating invariant components had little benefit and could introduce noise in discovery, so we focus on the equivariant features in this work.\nPixel-based Quadruped (\nD\n1\nâ‰…\nC\n2\nD_{1}\\cong C_{2}\n/ flip symmetry\n).\nFor pixel-based skill discovery, we adopt the vision-based quadruped environment from the DeepMind Control Suite (DMC)\n[\n40\n]\n), following the METRA\n[\n28\n]\nsetup.\nMETRA encodes position information by making the floor color vary smoothly as a function of the agentâ€™s\n(\nx\n,\ny\n)\n(x,y)\ncoordinates.\nTo fully expose the horizontal flip symmetry to the agent, we instead redesign the floor so that its color varies\nradially\nfrom the origin.\nThis maintains a consistent appearance under left-right flips while still revealing global position, and matches the\nC\n2\nC_{2}\n(horizontal flip) symmetry.\nThe group\nC\n2\nC_{2}\nhas a 2D real representation consisting of an invariant channel and a sign-flip channel. To keep the comparison with METRA fair, we use a 4D latent skill space by concatenating two such Fourier-feature vectors.\nThis can be viewed as learning two independent Fourier components. In practice, this provided a good balance between expressivity and parity with the baseline.\nSymmetry-aware Policy.\nOn the control side, we use Partially Equivariant SAC\n[\n6\n]\nfor the state-based Ant, which is robust to local symmetry-breaking effects (e.g., contact asymmetries).\nFor the pixel-based quadruped, we use Equivariant SAC\n[\n46\n]\n.\nIn both environments, a high-level policy\nÏ€\nh\nâ€‹\n(\nz\nâˆ£\ns\n,\ng\n)\n\\pi^{h}(z\\mid s,g)\nselects a skill vector\nz\nz\nevery\nK\nK\nsteps to pursue a goal\ng\ng\n, while a low-level policy\nÏ€\nl\nâ€‹\n(\na\nâˆ£\ns\n,\nz\n)\n\\pi^{l}(a\\mid s,z)\nexecutes the learned skill.\nThe skill policy is pretrained and then forzen for downstream training, as in METRA.\nFigure 2:\nBenchmark Environments.\nWe evaluate GISD in state-based Ant and pixel-based Quadruped locomotion.\nIn the pixel-based setting, we redesign the floor so that color varies radially from the origin,\nmaking the observations consistent with the horizontal flip symmetry.\nVI-B\nEvalutation Metric\nWe evaluate both skill discovery and downstream task performance.\nStaet-space coverage.\nFollowing METRA\n[\n28\n]\n, we measure how well skills explore the environment by computing the coverage of the agentâ€™s\n(\nx\n,\ny\n)\n(x,y)\npositions.\nAt evaluation, we sample 48 latent skill vectors uniformly from the skill prior, roll each for a fixed horizon, and aggregate the resulting trajectories.\nWe then quantify coverage using the fraction of grid cells visited in the task-relevant region of the plane.\nFor the state-based Ant, we restrict the coverage region to\n[\nâˆ’\n30\n,\n30\n]\n2\n[-30,30]^{2}\n, which corresponds to the maximum distance the agent can reach under the goal-sampling scheme in the downstream tasks. This avoids counting irrelevant areas.\nDownstream task.\nWe next assess how useful the discovered skills are for solving goal-conditioned tasks.\nWe train a high-level policy (\nÏ€\nh\nâ€‹\n(\nz\nâˆ£\ns\n,\ng\n)\n\\pi^{h}(z\\mid s,g)\non top of the frozen skill policy\n(\nÏ€\n(\na\nâˆ£\ns\n,\nz\n)\n(\\pi(a\\mid s,z)\n.\nIn the state-based Ant environment, each episode is a multi-goal task:\nWhenever the current goal is reached-or after\nK\nK\nsteps-a new goal is sampled uniformly around the current position (we follow METRA and use a sampling range of\n[\nâˆ’\n7.5\n,\n7.5\n]\n2\n[-7.5,7.5]^{2}\n.\nWe report the average return as a function of training iterations during downstream task training, averaged over multiple random seeds.\nFigure 3:\nState-space coverage during skill discovery.\n(a)\nState-based Ant (4 seeds).\n(b)\nPixel-based Quadruped (5 seeds).\nShaded regions show standard error.\nGISD achieves higher coverage and better sample efficiency than METRA in both environments.\nVI-C\nResults and Analysis\nSkill discovery and state coverage.\nFigure\n3\nshows the evolution of\n(\nx\n,\ny\n)\n(x,y)\n-coverage during skill pretraining.\nAcross both state-based Ant and pixel-based quadruped, GISD achieves broader state-space coverage with higher sample efficiency than METRA.\nThe shaded regions indicate standard error across seeds.\nIn the Ant environment, the variance is larger due to the lack of observation normalization, which makes the learning dynamics more sensitive to initialization.\nTo qualitatively understand the learned behaviors, Figure\n4\nvisualizes trajectories induced by 48 randomly sampled skills.\nFor GISD, skills tile the plane in a symmetry-consistent way:\nIn Ant, each direction has rotationally related counterparts (approximately obeying the\nC\n4\nC_{4}\nsymmetry).\nIn Quadruped, up-down reflected skills exhibit mirrored trajectories under the flip symmetry.\nIn contrast, METRA often learns clusters of redundant skills that differ only slightly in direction or fail to cover all symmetric modes, which matches the quantitative coverage gap.\nFigure 4:\nVisualization of discovered skills.\nWe plot trajectories for 48 randomly sampled skills. Colors indicate different latent skills.\nGISD discovers symmetry-consistent skills (Ant:\nC\n4\nC_{4}\nrotations; Quadruped: horizontal flips),\nleading to substantially broader and more uniform state-space coverage than METRA.\nDownstream performance.\nFigure\n5\ncompares downstream goal-reaching performance.\nIn both the state-based Ant and pixel-based DMC Quadruped tasks, GISD attains higher returns than METRA and reaches strong performance with fewer environment steps.\nFigure\n6\nvisualizes the Fourier skill vectors selected by the high-level policy\nÏ€\nh\nâ€‹\n(\nz\nâˆ£\ns\n,\ng\n)\n\\pi^{h}(z\\mid s,g)\nin the DMC Quadruped environment. Starting from a shared initial state with horizontally mirrored goals, the policy chooses skills whose invariant components are nearly identical, while the equivariant components exhibit approximate sign flips. This behavior reflects the underlying flip symmetry and indicates that the Fourier-space skills learned by GISD are both diverse and systematically reusable across transformed tasks.\nFigure 5:\nDownstream task performance.\n(a)\nAverage return in the state-based Ant environment (4 seeds).\n(b)\nAverage return in the pixel-based Quadruped environment (3 seeds).\nShaded regions show standard error.\nGISD consistently achieves higher performance and better sample efficiency than METRA.\nOverall, these results support our main claim:\nBy constraining the scoring function to a group-invariant function class and parameterizing it in Fourier space, GISD discovers symmetry-aligned skills that explore more effectively and transfer more efficiently to downstream control.\nFigure 6:\nVisualization of downstream task in DMC Quadruped.\nStarting from identical initial states with horizontally flipped goal positions, we visualize the Fourier skill vectors predicted by the high-level policy over time. Blue bars denote the invariant components, while orange bars denote the equivariant components, which should flip sign under the flip transformation. At early time steps (\nt\n=\n0\n,\n1\nt=0,1\n), the invariant features closely match, and the equivariant features appear with approximately opposite signs and similar magnitudes. By\nt\n=\n2\nt=2\n, the components begin to diverge, reflecting accumulated symmetry-breaking during execution (e.g., the quadrupedâ€™s rolling behavior under each skill).\nVII\nConclusions and Limitations\nIn this work, we introduced\nGroup-Invariant Skill Discovery\n, a framework that exploits group equivariance in skill discovery to improve sample efficiency and generalization. By enforcing group invariance in the Wasserstein dependency measure, we recast the objective as a symmetry-aware MDP and obtain latent skills that are consistent with the underlying group structure, which can then be effectively reused in downstream tasks.\nOur experiments validate the approach on both state-based and vision-based locomotion benchmarks, but a natural next step is to test it on more challenging domains such as Humanoid control. The method also inherits common limitations of equivariant networks, including increased computational cost and the need to specify the relevant symmetry group a priori.\nLooking forward, we plan to extend this framework to manipulation tasks, where skill discovery is notoriously difficult but rich symmetries are often present. Another promising direction is to study how the symmetric structure of the discovered skills can be more directly exploited in downstream planning and policy learning.\nAppendix A. Theoretical Details\nVII-A\nProof of Theorem\n1\nTheorem\n1\n(Existence of Equivariant Optima)\n.\nIn an MDP where the dynamics, initial state distribution, skill prior, and ground metric are all group-invariant, the Wasserstein dependency measure admits a globally optimal solution\n(\nÏ€\nÂ¯\n,\nf\nÂ¯\n)\n(\\bar{\\pi},\\bar{f})\nsuch that\nÏ€\nÂ¯\nâ€‹\n(\ng\nâ€‹\na\nâˆ£\ng\nâ€‹\ns\n,\ng\nâ€‹\nz\n)\n=\nÏ€\nÂ¯\nâ€‹\n(\na\nâˆ£\ns\n,\nz\n)\n,\nf\nÂ¯\nâ€‹\n(\ng\nâ€‹\ns\n,\ng\nâ€‹\nz\n)\n=\nf\nÂ¯\nâ€‹\n(\ns\n,\nz\n)\n,\nâˆ€\ng\nâˆˆ\nG\n.\n\\bar{\\pi}(ga\\mid gs,gz)=\\bar{\\pi}(a\\mid s,z),\\quad\\bar{f}(gs,gz)=\\bar{f}(s,z),\\quad\\forall g\\in G.\nIn other words, among all WDM global maximizers, there exists at least one policy-function pair with an equivariant policy and a group-invariant\n1\n1\n-Lipschitz function.\nProof.\nWe define the Kantorovich dual objective\nJ\nâ€‹\n(\nÏ€\n,\nf\n)\nJ(\\pi,f)\nfor a policy\nÏ€\n\\pi\nand a\n1\n1\n-Lipschitz function\nf\n:\nğ’®\nÃ—\nğ’µ\nâ†’\nâ„\nf:\\mathcal{S}\\times\\mathcal{Z}\\to\\mathbb{R}\nas:\nJ\nâ€‹\n(\nÏ€\n,\nf\n)\n:=\nğ”¼\nz\nâˆ¼\np\nâ€‹\n(\nz\n)\nâ€‹\ns\nâˆ¼\np\nÏ€\nâ€‹\n(\ns\nâˆ£\nz\n)\nâ€‹\n[\nf\nâ€‹\n(\ns\n,\nz\n)\n]\nâˆ’\nğ”¼\nz\nâˆ¼\np\nâ€‹\n(\nz\n)\nâ€‹\ns\nâˆ¼\np\nÏ€\nâ€‹\n(\ns\n)\nâ€‹\n[\nf\nâ€‹\n(\ns\n,\nz\n)\n]\n.\n\\displaystyle J(\\pi,f):=\\mathbb{E}_{\\begin{subarray}{c}z\\sim p(z)\\ s\\sim p_{\\pi}(s\\mid z)\\end{subarray}}[f(s,z)]-\\mathbb{E}_{\\begin{subarray}{c}z\\sim p(z)\\ s\\sim p_{\\pi}(s)\\end{subarray}}[f(s,z)].\nwhere\np\nÏ€\nâ€‹\n(\ns\nâˆ£\nz\n)\np_{\\pi}(s\\mid z)\nis the conditional state occupancy measure induced by\nÏ€\n\\pi\n, and\np\nÏ€\nâ€‹\n(\ns\n)\np_{\\pi}(s)\nis the corresponding marginal. The Wasserstein Dependency Measure (WDM) is defined as\nWDM\nâ€‹\n(\nÏ€\n)\n=\nsup\nâˆ¥\nf\nâˆ¥\nL\nâ‰¤\n1\nJ\nâ€‹\n(\nÏ€\n,\nf\n)\n.\n\\mathrm{WDM}(\\pi)=\\sup_{\\lVert f\\rVert_{L}\\leq 1}J(\\pi,f).\nLet\n(\nÏ€\nâˆ—\n,\nf\nâˆ—\n)\n(\\pi^{*},f^{*})\nbe a global maximizer of the problem\nmax\nÏ€\nâ¡\nWDM\nâ€‹\n(\nÏ€\n)\n\\max_{\\pi}\\mathrm{WDM}(\\pi)\n.\nBy the assumptions of Theorem\n1\n, the tuple\n(\nğ’®\n,\nğ’œ\n,\nğ’µ\n)\n(\\mathcal{S},\\mathcal{A},\\mathcal{Z})\nis equipped with a measure-preserving group action, the environment dynamics are equivariant, and the ground metric is invariant.\nConsequently, the skill discovery optimization problem can be formulated as finding the pair\n(\nÏ€\n,\nf\n)\n(\\pi,f)\nthat maximizes this objective:\nmax\nÏ€\nâ€‹\nsup\nâˆ¥\nf\nâˆ¥\nL\nâ‰¤\n1\nJ\nâ€‹\n(\nÏ€\n,\nf\n)\n.\n\\displaystyle\\max_{\\pi}\\sup_{\\lVert f\\rVert_{L}\\leq 1}J(\\pi,f).\nLet\n(\nÏ€\nâˆ—\n,\nf\nâˆ—\n)\n(\\pi^{*},f^{*})\nbe any global maximizer of this problem. By the assumptions of Theorem\n1\n, the tuple\n(\nğ’®\n,\nğ’œ\n,\nğ’µ\n)\n(\\mathcal{S},\\mathcal{A},\\mathcal{Z})\nis equipped with a measure-preserving group action, and the environment dynamics satisfy equivariance.\nWe proceed by showing that the orbit of this optimal solution under the group action implies the existence of a symmetric optimizer.\n1. Rotating an Optimal Pair.\nFor any\ng\nâˆˆ\nG\ng\\in G\n, define the rotated policy\nÏ€\ng\nâˆ—\n\\pi_{g}^{*}\nand rotated function\nf\ng\nâˆ—\nf_{g}^{*}\nby:\nÏ€\ng\nâˆ—\nâ€‹\n(\na\nâˆ£\ns\n,\nz\n)\n\\displaystyle\\pi_{g}^{*}(a\\mid s,z)\n:=\nÏ€\nâˆ—\nâ€‹\n(\ng\nâˆ’\n1\nâ€‹\na\nâˆ£\ng\nâˆ’\n1\nâ€‹\ns\n,\ng\nâˆ’\n1\nâ€‹\nz\n)\n,\n\\displaystyle:=\\pi^{*}(g^{-1}a\\mid g^{-1}s,g^{-1}z),\nf\ng\nâˆ—\nâ€‹\n(\ns\n,\nz\n)\n\\displaystyle f_{g}^{*}(s,z)\n:=\nf\nâˆ—\nâ€‹\n(\ng\nâˆ’\n1\nâ€‹\ns\n,\ng\nâˆ’\n1\nâ€‹\nz\n)\n.\n\\displaystyle:=f^{*}(g^{-1}s,g^{-1}z).\nBecause the metric\nd\nd\nis group-invariant,\nâˆ¥\nf\ng\nâˆ—\nâˆ¥\nL\n=\nâˆ¥\nf\nâˆ—\nâˆ¥\nL\nâ‰¤\n1\n\\lVert f_{g}^{*}\\rVert_{L}=\\lVert f^{*}\\rVert_{L}\\leq 1\n, so\nf\ng\nâˆ—\nf_{g}^{*}\nremains feasible.\nThe joint distribution induced by the rotated policy rotates covariantly:\np\nÏ€\ng\nâˆ—\nâ€‹\n(\ns\n,\nz\n)\n=\np\nÏ€\nâˆ—\nâ€‹\n(\ng\nâˆ’\n1\nâ€‹\ns\n,\ng\nâˆ’\n1\nâ€‹\nz\n)\np_{\\pi^{*}_{g}}(s,z)=p_{\\pi^{*}}(g^{-1}s,g^{-1}z)\n(rotated by left regular representation, Appendix\nVII-G\n).\nUsing the measure-preserving property of the group action, we compute the objective value:\nJ\nâ€‹\n(\nÏ€\ng\nâˆ—\n,\nf\ng\nâˆ—\n)\n\\displaystyle J(\\pi_{g}^{*},f_{g}^{*})\n=\nğ”¼\nz\nâˆ¼\np\nâ€‹\n(\nz\n)\ns\nâˆ¼\np\nÏ€\ng\nâˆ—\nâ€‹\n(\ns\nâˆ£\nz\n)\nâ€‹\n[\nf\ng\nâˆ—\nâ€‹\n(\ns\n,\nz\n)\n]\nâˆ’\nğ”¼\nz\nâˆ¼\np\nâ€‹\n(\nz\n)\ns\nâˆ¼\np\nÏ€\ng\nâˆ—\nâ€‹\n(\ns\n)\nâ€‹\n[\nf\ng\nâˆ—\nâ€‹\n(\ns\n,\nz\n)\n]\n\\displaystyle=\\mathbb{E}_{\\begin{subarray}{c}z\\sim p(z)\\\\\ns\\sim p_{\\pi_{g}^{*}}(s\\mid z)\\end{subarray}}[f_{g}^{*}(s,z)]-\\mathbb{E}_{\\begin{subarray}{c}z\\sim p(z)\\\\\ns\\sim p_{\\pi_{g}^{*}}(s)\\end{subarray}}[f_{g}^{*}(s,z)]\n=\nğ”¼\n(\ns\n,\nz\n)\nâˆ¼\np\nÏ€\ng\nâˆ—\nâ€‹\n[\nf\nâˆ—\nâ€‹\n(\ng\nâˆ’\n1\nâ€‹\ns\n,\ng\nâˆ’\n1\nâ€‹\nz\n)\n]\n\\displaystyle=\\mathbb{E}_{(s,z)\\sim p_{\\pi_{g}^{*}}}[f^{*}(g^{-1}s,g^{-1}z)]\nâˆ’\nğ”¼\n(\ns\n,\nz\n)\nâˆ¼\np\nÏ€\ng\nâˆ—\nâ€‹\n(\ns\n)\nâ€‹\np\nâ€‹\n(\nz\n)\nâ€‹\n[\nf\nâˆ—\nâ€‹\n(\ng\nâˆ’\n1\nâ€‹\ns\n,\ng\nâˆ’\n1\nâ€‹\nz\n)\n]\n\\displaystyle\\qquad\\qquad\\qquad\\qquad\\qquad-\\mathbb{E}_{(s,z)\\sim p_{\\pi_{g}^{*}}(s)p(z)}[f^{*}(g^{-1}s,g^{-1}z)]\n=\nğ”¼\n(\ns\nâ€²\n,\nz\nâ€²\n)\nâˆ¼\np\nÏ€\nâˆ—\nâ€‹\n[\nf\nâˆ—\nâ€‹\n(\ns\nâ€²\n,\nz\nâ€²\n)\n]\nâˆ’\nğ”¼\n(\ns\nâ€²\n,\nz\nâ€²\n)\nâˆ¼\np\nÏ€\nâˆ—\nâ€‹\n(\ns\nâ€²\n)\nâ€‹\np\nâ€‹\n(\nz\nâ€²\n)\nâ€‹\n[\nf\nâˆ—\nâ€‹\n(\ns\nâ€²\n,\nz\nâ€²\n)\n]\n\\displaystyle=\\mathbb{E}_{(s^{\\prime},z^{\\prime})\\sim p_{\\pi^{*}}}[f^{*}(s^{\\prime},z^{\\prime})]-\\mathbb{E}_{(s^{\\prime},z^{\\prime})\\sim p_{\\pi^{*}}(s^{\\prime})p(z^{\\prime})}[f^{*}(s^{\\prime},z^{\\prime})]\n=\nJ\nâ€‹\n(\nÏ€\nâˆ—\n,\nf\nâˆ—\n)\n.\n\\displaystyle=J(\\pi^{*},f^{*}).\nwhere\ns\nâ€²\n=\ng\nâˆ’\n1\nâ€‹\ns\n,\nz\nâ€²\n=\ng\nâˆ’\n1\nâ€‹\nz\ns^{\\prime}=g^{-1}s,z^{\\prime}=g^{-1}z\nare change of variables.\nThus, for every\ng\nâˆˆ\nG\ng\\in G\n, the pair\n(\nÏ€\ng\nâˆ—\n,\nf\ng\nâˆ—\n)\n(\\pi_{g}^{*},f_{g}^{*})\nis also a global maximizer.\n2. Symmetrizing the Policy.\nSince averaging policies directly is non-trivial, we work in the space of occupancy measures. Let\nÏ\nÏ€\n\\rho^{\\pi}\ndenote the state-action-skill occupancy measure induced by\nÏ€\n\\pi\n. The set of valid occupancy measures is convex, and the WDM objective is linear with respect to\nÏ\nÏ€\n\\rho^{\\pi}\n(for a fixed optimal\nf\nf\n, the maximum value is linear in\nÏ\n\\rho\n).\nWe define the symmetrized occupancy measure\nÏ\nÂ¯\nâˆ—\n\\bar{\\rho}^{*}\nby averaging over the Haar measure of the compact group\nG\nG\n:\nÏ\nÂ¯\nâˆ—\nâ€‹\n(\ns\n,\na\n,\nz\n)\n:=\nâˆ«\nG\nÏ\nÏ€\ng\nâˆ—\nâ€‹\n(\ns\n,\na\n,\nz\n)\n,\nd\nâ€‹\nÎ¼\nâ€‹\n(\ng\n)\n.\n\\bar{\\rho}^{*}(s,a,z):=\\int_{G}\\rho^{\\pi_{g}^{*}}(s,a,z),d\\mu(g).\nSince every\nÏ\nÏ€\ng\nâˆ—\n\\rho^{\\pi_{g}^{*}}\nis optimal, by convexity,\nÏ\nÂ¯\nâˆ—\n\\bar{\\rho}^{*}\nis also optimal. We verify that\nÏ\nÂ¯\nâˆ—\n\\bar{\\rho}^{*}\nis group-invariant.\nUsing\nÏ\nÏ€\ng\nâˆ—\nâ€‹\n(\ns\n,\na\n,\nz\n)\n=\nÏ\nÏ€\nâˆ—\nâ€‹\n(\ng\nâˆ’\n1\nâ€‹\ns\n,\ng\nâˆ’\n1\nâ€‹\na\n,\ng\nâˆ’\n1\nâ€‹\nz\n)\n\\rho^{\\pi_{g}^{*}}(s,a,z)=\\rho^{\\pi^{*}}(g^{-1}s,g^{-1}a,g^{-1}z)\n:\nÏ\nÂ¯\nâˆ—\nâ€‹\n(\ng\nâ€‹\ns\n,\ng\nâ€‹\na\n,\ng\nâ€‹\nz\n)\n\\displaystyle\\bar{\\rho}^{*}(gs,ga,gz)\n=\nâˆ«\nG\nÏ\nÏ€\nâˆ—\nâ€‹\n(\nh\nâˆ’\n1\nâ€‹\ng\nâ€‹\ns\n,\nh\nâˆ’\n1\nâ€‹\ng\nâ€‹\na\n,\nh\nâˆ’\n1\nâ€‹\ng\nâ€‹\nz\n)\n,\nd\nâ€‹\nÎ¼\nâ€‹\n(\nh\n)\n\\displaystyle=\\int_{G}\\rho^{\\pi^{*}}(h^{-1}gs,h^{-1}ga,h^{-1}gz),d\\mu(h)\n=\nâˆ«\nG\nÏ\nÏ€\nâˆ—\nâ€‹\n(\nk\nâˆ’\n1\nâ€‹\ns\n,\nk\nâˆ’\n1\nâ€‹\na\n,\nk\nâˆ’\n1\nâ€‹\nz\n)\n,\nd\nâ€‹\nÎ¼\nâ€‹\n(\nk\n)\n\\displaystyle=\\int_{G}\\rho^{\\pi^{*}}(k^{-1}s,k^{-1}a,k^{-1}z),d\\mu(k)\\quad\n(\nsubst.\nâ€‹\nk\n=\nh\nâˆ’\n1\nâ€‹\ng\n)\n\\displaystyle\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad(\\text{subst.}~k=h^{-1}g)\n=\nÏ\nÂ¯\nâˆ—\nâ€‹\n(\ns\n,\na\n,\nz\n)\n.\n\\displaystyle=\\bar{\\rho}^{*}(s,a,z).\nWe define the equivariant policy\nÏ€\nÂ¯\nâˆ—\n\\bar{\\pi}^{*}\ninduced by\nÏ\nÂ¯\nâˆ—\n\\bar{\\rho}^{*}\nas\nÏ€\nÂ¯\nâˆ—\nâ€‹\n(\na\nâˆ£\ns\n,\nz\n)\nâˆ\nÏ\nÂ¯\nâˆ—\nâ€‹\n(\ns\n,\na\n,\nz\n)\n\\bar{\\pi}^{*}(a\\mid s,z)\\propto\\bar{\\rho}^{*}(s,a,z)\n. Since\nÏ\nÂ¯\nâˆ—\n\\bar{\\rho}^{*}\nis optimal,\nÏ€\nÂ¯\nâˆ—\n\\bar{\\pi}^{*}\nis an optimal equivariant policy.\n3. Symmetrizing the Scoring Function.\nSince\nÏ€\nÂ¯\nâˆ—\n\\bar{\\pi}^{*}\nis optimal, it maximizes the WDM objective. Let\nf\n~\n\\tilde{f}\nbe any optimal scoring function for\nÏ€\nÂ¯\nâˆ—\n\\bar{\\pi}^{*}\n, i.e.,\nJ\nâ€‹\n(\nÏ€\nÂ¯\nâˆ—\n,\nf\n~\n)\n=\nWDM\nâ€‹\n(\nÏ€\nÂ¯\nâˆ—\n)\nJ(\\bar{\\pi}^{*},\\tilde{f})=\\mathrm{WDM}(\\bar{\\pi}^{*})\n. Since\nÏ€\nÂ¯\nâˆ—\n\\bar{\\pi}^{*}\nis equivariant, the objective\nJ\nâ€‹\n(\nÏ€\nÂ¯\nâˆ—\n,\nâ‹…\n)\nJ(\\bar{\\pi}^{*},\\cdot)\nis invariant under the rotation of\nf\nf\n. Thus,\nJ\nâ€‹\n(\nÏ€\nÂ¯\nâˆ—\n,\nf\n~\ng\n)\n=\nJ\nâ€‹\n(\nÏ€\nÂ¯\nâˆ—\n,\nf\n~\n)\nJ(\\bar{\\pi}^{*},\\tilde{f}_{g})=J(\\bar{\\pi}^{*},\\tilde{f})\nfor all\ng\ng\n. We define the group-averaged scoring function:\nf\nÂ¯\nâˆ—\nâ€‹\n(\ns\n,\nz\n)\n:=\nâˆ«\nG\nf\n~\ng\nâ€‹\n(\ns\n,\nz\n)\n,\nd\nâ€‹\nÎ¼\nâ€‹\n(\ng\n)\n.\n\\bar{f}^{*}(s,z):=\\int_{G}\\tilde{f}_{g}(s,z),d\\mu(g).\nBy construction,\nf\nÂ¯\nâˆ—\n\\bar{f}^{*}\nis group-invariant and\n1\n1\n-Lipschitz (by convexity of the Lipschitz ball). By the linearity of\nJ\nJ\nwith respect to\nf\nf\n:\nJ\nâ€‹\n(\nÏ€\nÂ¯\nâˆ—\n,\nf\nÂ¯\nâˆ—\n)\n=\nâˆ«\nG\nJ\nâ€‹\n(\nÏ€\nÂ¯\nâˆ—\n,\nf\n~\ng\n)\n,\nd\nâ€‹\nÎ¼\nâ€‹\n(\ng\n)\n=\nWDM\nâ€‹\n(\nÏ€\nÂ¯\nâˆ—\n)\n.\n\\displaystyle J(\\bar{\\pi}^{*},\\bar{f}^{*})=\\int_{G}J(\\bar{\\pi}^{*},\\tilde{f}_{g}),d\\mu(g)=\\mathrm{WDM}(\\bar{\\pi}^{*}).\nConclusion.\nThe pair\n(\nÏ€\nÂ¯\nâˆ—\n,\nf\nÂ¯\nâˆ—\n)\n(\\bar{\\pi}^{*},\\bar{f}^{*})\nconstructed above satisfies:\n1.\nGlobal Optimality:\nJ\nâ€‹\n(\nÏ€\nÂ¯\nâˆ—\n,\nf\nÂ¯\nâˆ—\n)\n=\nJ\nâ€‹\n(\nÏ€\nâˆ—\n,\nf\nâˆ—\n)\nJ(\\bar{\\pi}^{*},\\bar{f}^{*})=J(\\pi^{*},f^{*})\n.\n2.\nSymmetry:\nÏ€\nÂ¯\nâˆ—\n\\bar{\\pi}^{*}\nis equivariant and\nf\nÂ¯\nâˆ—\n\\bar{f}^{*}\nis group-invariant.\nâˆ\nVII-B\nProof of Proposition\n1\nProposition 1\n.\nIf the distance metric\nd\nd\nis group-invariant, then the\ngroup-invariant WDM satisfies\nI\nğ’²\nG\nâ€‹\n(\ng\nâ€‹\nğ’®\n;\ng\nâ€‹\nZ\n)\n=\nI\nğ’²\nG\nâ€‹\n(\nğ’®\n;\nZ\n)\nI_{\\mathcal{W}}^{G}(g\\mathcal{S};gZ)=I_{\\mathcal{W}}^{G}(\\mathcal{S};Z)\nfor all\ng\nâˆˆ\nG\ng\\in G\n.\nProof.\nWe analyze the objective\nI\nğ’²\nG\nâ€‹\n(\nğ’®\n;\nZ\n)\nI_{\\mathcal{W}}^{G}(\\mathcal{S};Z)\ndefined as the supremum over the function class\nâ„±\nG\n\\mathcal{F}_{G}\n(Definition\n1\n).\nConsider the objective evaluated on the jointly transformed variables\n(\ng\nâ€‹\nğ’®\n,\ng\nâ€‹\nZ\n)\n(g\\mathcal{S},gZ)\n:\nI\nğ’²\nG\nâ€‹\n(\ng\nâ€‹\nğ’®\n;\ng\nâ€‹\nZ\n)\n\\displaystyle I_{\\mathcal{W}}^{G}(g\\mathcal{S};gZ)\n=\nsup\nf\nâˆˆ\nâ„±\nG\n(\nğ”¼\np\nâ€‹\n(\ng\nâˆ’\n1\nâ€‹\ns\n,\ng\nâˆ’\n1\nâ€‹\nz\n)\nâ€‹\n[\nf\nâ€‹\n(\ns\n,\nz\n)\n]\nâˆ’\nğ”¼\np\nâ€‹\n(\ng\nâˆ’\n1\nâ€‹\ns\n)\nâ€‹\np\nâ€‹\n(\ng\nâˆ’\n1\nâ€‹\nz\n)\nâ€‹\n[\nf\nâ€‹\n(\ns\n,\nz\n)\n]\n)\n\\displaystyle=\\sup_{f\\in\\mathcal{F}_{G}}\\left(\\mathbb{E}_{p(g^{-1}s,g^{-1}z)}[f(s,z)]-\\mathbb{E}_{p(g^{-1}s)p(g^{-1}z)}[f(s,z)]\\right)\nwhere the expectation is taken with respect to the density\nL\ng\nâ€‹\np\nL_{g}p\n, i.e.,\n(\nL\ng\nâ€‹\np\n)\nâ€‹\n(\ns\n,\nz\n)\n:=\np\nâ€‹\n(\ng\nâˆ’\n1\nâ€‹\ns\n,\ng\nâˆ’\n1\nâ€‹\nz\n)\n(L_{g}p)(s,z):=p(g^{-1}s,g^{-1}z)\nis the left regular representation of\nG\nG\non densities (see Appendix.\nVII-G\n).\nFor the first expectation, we write:\nğ”¼\np\nâ€‹\n(\ng\nâˆ’\n1\nâ€‹\ns\n,\ng\nâˆ’\n1\nâ€‹\nz\n)\nâ€‹\n[\nf\nâ€‹\n(\ns\n,\nz\n)\n]\n=\nâˆ«\nğ’®\nÃ—\nZ\nf\nâ€‹\n(\ns\n,\nz\n)\nâ€‹\np\nâ€‹\n(\ng\nâˆ’\n1\nâ€‹\ns\n,\ng\nâˆ’\n1\nâ€‹\nz\n)\nâ€‹\nğ‘‘\ns\nâ€‹\nğ‘‘\nz\n.\n\\mathbb{E}_{p(g^{-1}s,g^{-1}z)}[f(s,z)]=\\int_{\\mathcal{S}\\times Z}f(s,z)\\,p(g^{-1}s,g^{-1}z)\\,ds\\,dz.\nWe perform the change of variables\nu\n=\ng\nâˆ’\n1\nâ€‹\ns\nu=g^{-1}s\n,\nv\n=\ng\nâˆ’\n1\nâ€‹\nz\nv=g^{-1}z\n(so\ns\n=\ng\nâ€‹\nu\ns=gu\n,\nz\n=\ng\nâ€‹\nv\nz=gv\n). Since the action is volume-preserving (\nd\nâ€‹\ns\nâ€‹\nd\nâ€‹\nz\n=\nd\nâ€‹\nu\nâ€‹\nd\nâ€‹\nv\nds\\,dz=du\\,dv\n):\nâˆ«\nğ’®\nÃ—\nZ\nf\nâ€‹\n(\ns\n,\nz\n)\n\\displaystyle\\int_{\\mathcal{S}\\times Z}f(s,z)\\,\np\nâ€‹\n(\ng\nâˆ’\n1\nâ€‹\ns\n,\ng\nâˆ’\n1\nâ€‹\nz\n)\nâ€‹\nd\nâ€‹\ns\nâ€‹\nd\nâ€‹\nz\n\\displaystyle p(g^{-1}s,g^{-1}z)\\,ds\\,dz\n=\nâˆ«\nğ’®\nÃ—\nZ\nf\nâ€‹\n(\ng\nâ€‹\nu\n,\ng\nâ€‹\nv\n)\nâ€‹\np\nâ€‹\n(\nu\n,\nv\n)\nâ€‹\nğ‘‘\nu\nâ€‹\nğ‘‘\nv\n.\n\\displaystyle=\\int_{\\mathcal{S}\\times Z}f(gu,gv)\\,p(u,v)\\,du\\,dv.\nCrucially, since\nf\nâˆˆ\nâ„±\nG\nf\\in\\mathcal{F}_{G}\n, we have\nf\nâ€‹\n(\ng\nâ€‹\nu\n,\ng\nâ€‹\nv\n)\n=\nf\nâ€‹\n(\nu\n,\nv\n)\nf(gu,gv)=f(u,v)\nby definition. Thus:\n=\nâˆ«\nğ’®\nÃ—\nZ\nf\nâ€‹\n(\nu\n,\nv\n)\nâ€‹\np\nâ€‹\n(\nu\n,\nv\n)\nâ€‹\nğ‘‘\nu\nâ€‹\nğ‘‘\nv\n\\displaystyle=\\int_{\\mathcal{S}\\times Z}f(u,v)\\,p(u,v)\\,du\\,dv\n=\nğ”¼\np\nâ€‹\n(\nu\n,\nv\n)\nâ€‹\n[\nf\nâ€‹\n(\nu\n,\nv\n)\n]\n.\n\\displaystyle=\\mathbb{E}_{p(u,v)}[f(u,v)].\nAn analogous calculation for the product of marginals:\nğ”¼\np\nâ€‹\n(\ng\nâˆ’\n1\nâ€‹\ns\n)\nâ€‹\np\nâ€‹\n(\ng\nâˆ’\n1\nâ€‹\nz\n)\nâ€‹\n[\nf\nâ€‹\n(\ns\n,\nz\n)\n]\n\\displaystyle\\mathbb{E}_{p(g^{-1}s)p(g^{-1}z)}[f(s,z)]\n=\nâˆ«\nf\nâ€‹\n(\ns\n,\nz\n)\nâ€‹\np\nâ€‹\n(\ng\nâˆ’\n1\nâ€‹\ns\n)\nâ€‹\np\nâ€‹\n(\ng\nâˆ’\n1\nâ€‹\nz\n)\nâ€‹\nğ‘‘\ns\nâ€‹\nğ‘‘\nz\n\\displaystyle=\\int f(s,z)\\,p(g^{-1}s)\\,p(g^{-1}z)\\,ds\\,dz\n=\nâˆ«\nf\nâ€‹\n(\ng\nâ€‹\nu\n,\ng\nâ€‹\nv\n)\nâ€‹\np\nâ€‹\n(\nu\n)\nâ€‹\np\nâ€‹\n(\nv\n)\nâ€‹\nğ‘‘\nu\nâ€‹\nğ‘‘\nv\n\\displaystyle=\\int f(gu,gv)\\,p(u)\\,p(v)\\,du\\,dv\n=\nğ”¼\np\nâ€‹\n(\nu\n)\nâ€‹\np\nâ€‹\n(\nv\n)\nâ€‹\n[\nf\nâ€‹\n(\ng\nâ€‹\nu\n,\ng\nâ€‹\nv\n)\n]\n.\n\\displaystyle=\\mathbb{E}_{p(u)p(v)}[f(gu,gv)].\nSubstituting these back into the supremum:\nI\nğ’²\nG\n\\displaystyle I_{\\mathcal{W}}^{G}\n(\ng\nâ€‹\nğ’®\n;\ng\nâ€‹\nZ\n)\n\\displaystyle(g\\mathcal{S};gZ)\n=\nsup\nf\nâˆˆ\nâ„±\nG\n(\nğ”¼\np\nâ€‹\n(\ns\n,\nz\n)\nâ€‹\n[\nf\nâ€‹\n(\ns\n,\nz\n)\n]\nâˆ’\nğ”¼\np\nâ€‹\n(\ns\n)\nâ€‹\np\nâ€‹\n(\nz\n)\nâ€‹\n[\nf\nâ€‹\n(\ns\n,\nz\n)\n]\n)\n\\displaystyle=\\sup_{f\\in\\mathcal{F}_{G}}\\Big(\\mathbb{E}_{p(s,z)}[f(s,z)]-\\mathbb{E}_{p(s)p(z)}[f(s,z)]\\Big)\n=\nI\nğ’²\nG\nâ€‹\n(\nğ’®\n;\nZ\n)\n.\n\\displaystyle=I_{\\mathcal{W}}^{G}(\\mathcal{S};Z).\nâˆ\nVII-C\nProof of Proposition\n2\nProposition\n2\n(Properties of the group-averaged scoring function)\n.\nLet\nf\n:\nğ’®\nÃ—\nZ\nâ†’\nâ„\nf:\\mathcal{S}\\times Z\\to\\mathbb{R}\nbe\n1\n1\n-Lipschitz with respect to\na group-invariant metric\nd\nd\non\nğ’®\nÃ—\nZ\n\\mathcal{S}\\times Z\n. Then its group\naverage\nf\n~\n\\tilde{f}\nis group-invariant and\n1\n1\n-Lipschitz with respect to\nd\nd\n. In particular,\nf\n~\nâˆˆ\nâ„±\nG\n\\tilde{f}\\in\\mathcal{F}_{G}\n.\nProof.\nGroup-invariance of\nf\n~\n\\tilde{f}\n.\nDefine the group-averaged function as\nf\n~\nâ€‹\n(\ns\n,\nz\n)\n=\nâˆ«\nG\nf\nâ€‹\n(\ng\nâ€‹\ns\n,\ng\nâ€‹\nz\n)\nâ€‹\nğ‘‘\nÎ¼\nâ€‹\n(\ng\n)\n\\tilde{f}(s,z)=\\int_{G}f(gs,gz)d\\mu(g)\n, where\nÎ¼\n\\mu\nis the Haar measure on the compact group\nG\nG\n. For any\nh\nâˆˆ\nG\nh\\in G\n,\nf\n~\nâ€‹\n(\nh\nâ€‹\ns\n,\nh\nâ€‹\nz\n)\n\\displaystyle\\tilde{f}(hs,hz)\n=\nâˆ«\nG\nf\nâ€‹\n(\nh\nâ€‹\ng\nâ€‹\ns\n,\nh\nâ€‹\ng\nâ€‹\nz\n)\nâ€‹\nğ‘‘\nÎ¼\nâ€‹\n(\ng\n)\n\\displaystyle=\\int_{G}f(hgs,hgz)d\\mu(g)\n=\nâˆ«\nG\nf\nâ€‹\n(\ng\nâ€²\nâ€‹\ns\n,\ng\nâ€²\nâ€‹\nz\n)\nâ€‹\nğ‘‘\nÎ¼\nâ€‹\n(\ng\nâ€²\n)\nâ€‹\n(\ng\nâ€²\n=\ng\nâ€‹\nh\n)\n\\displaystyle=\\int_{G}f(g^{\\prime}s,g^{\\prime}z)d\\mu(g^{\\prime})~~(g^{\\prime}=gh)\n=\nf\n~\nâ€‹\n(\ns\n,\nz\n)\n.\n\\displaystyle=\\tilde{f}(s,z).\nThus,\nf\n~\n\\tilde{f}\nis group-invariant.\nPreservation of the 1-Lipschitz condition.\nAssume that\nf\nf\nis 1-Lipschitz with respect to a group-invariant metric\nd\nd\n, so that\nd\nâ€‹\n(\n(\ng\nâ€‹\ns\n1\n,\ng\nâ€‹\nz\n1\n)\n,\n(\ng\nâ€‹\ns\n2\n,\ng\nâ€‹\nz\n2\n)\n)\n=\nd\nâ€‹\n(\n(\ns\n1\n,\nz\n1\n)\n,\n(\ns\n2\n,\nz\n2\n)\n)\nd((gs_{1},gz_{1}),(gs_{2},gz_{2}))=d((s_{1},z_{1}),(s_{2},z_{2}))\n. Then for any\n(\ns\n1\n,\nz\n1\n)\n(s_{1},z_{1})\nand\n(\ns\n2\n,\nz\n2\n)\n(s_{2},z_{2})\n,\nâ€–\nf\n~\nâ€‹\n(\ns\n1\n,\nz\n1\n)\nâˆ’\nf\n~\nâ€‹\n(\ns\n2\n,\nz\n2\n)\nâ€–\n\\displaystyle\\|\\tilde{f}(s_{1},z_{1})-\\tilde{f}(s_{2},z_{2})\\|\n=\nâ€–\nâˆ«\nG\nf\nâ€‹\n(\ng\nâ€‹\ns\n1\n,\ng\nâ€‹\nz\n1\n)\nâˆ’\nf\nâ€‹\n(\ng\nâ€‹\ns\n2\n,\ng\nâ€‹\nz\n2\n)\nâ€‹\nd\nâ€‹\nÎ¼\nâ€‹\n(\ng\n)\nâ€–\n\\displaystyle=\\left\\|\\int_{G}f(gs_{1},gz_{1})-f(gs_{2},gz_{2})d\\mu(g)\\right\\|\nâ‰¤\nâˆ«\nG\nâ€–\nf\nâ€‹\n(\ng\nâ€‹\ns\n1\n,\ng\nâ€‹\nz\n1\n)\nâˆ’\nf\nâ€‹\n(\ng\nâ€‹\ns\n2\n,\ng\nâ€‹\nz\n2\n)\nâ€–\nâ€‹\nğ‘‘\nÎ¼\nâ€‹\n(\ng\n)\n\\displaystyle\\leq\\int_{G}\\|f(gs_{1},gz_{1})-f(gs_{2},gz_{2})\\|d\\mu(g)\n(\nJensenâ€™s inequality\n)\n\\displaystyle\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad(\\text{Jensen's inequality})\nâ‰¤\nâˆ«\nG\nd\nâ€‹\n(\n(\ng\nâ€‹\ns\n1\n,\ng\nâ€‹\nz\n1\n)\n,\n(\ng\nâ€‹\ns\n2\n,\ng\nâ€‹\nz\n2\n)\n)\nâ€‹\nğ‘‘\nÎ¼\nâ€‹\n(\ng\n)\n\\displaystyle\\leq\\int_{G}d((gs_{1},gz_{1}),(gs_{2},gz_{2}))d\\mu(g)\n(\n1-Lipschitz property of\nâ€‹\nf\n)\n\\displaystyle\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad(\\text{1-Lipschitz property of }f)\n=\nâˆ«\nG\nd\nâ€‹\n(\n(\ns\n1\n,\nz\n1\n)\n,\n(\ns\n2\n,\nz\n2\n)\n)\nâ€‹\nğ‘‘\nÎ¼\nâ€‹\n(\ng\n)\n\\displaystyle=\\int_{G}d((s_{1},z_{1}),(s_{2},z_{2}))~d\\mu(g)\n(\nd\nâ€‹\nis group-invariant\n)\n\\displaystyle\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad(d\\text{ is group-invariant})\n=\nd\nâ€‹\n(\n(\ns\n1\n,\nz\n1\n)\n,\n(\ns\n2\n,\nz\n2\n)\n)\n\\displaystyle=d((s_{1},z_{1}),(s_{2},z_{2}))\nSince\nÎ¼\n\\mu\nis a probability measure,\nf\n~\n\\tilde{f}\nis 1-Lipschitz.\nâˆ\nVII-D\nInvariance of the State-Skill Occupancy Measure\nLemma 1\n(Invariance of the State-Skill Distribution)\n.\nAssume the environment dynamics are group-invariant such that\nP\nâ€‹\n(\ng\nâ€‹\ns\nâ€²\n|\ng\nâ€‹\ns\n,\ng\nâ€‹\na\n)\n=\nP\nâ€‹\n(\ns\nâ€²\n|\ns\n,\na\n)\nP(gs^{\\prime}|gs,ga)=P(s^{\\prime}|s,a)\n. Furthermore, assume the initial state distribution\np\n0\nâ€‹\n(\ns\n)\np_{0}(s)\nand skill prior\np\nâ€‹\n(\nz\n)\np(z)\nare group-invariant. If the skill-conditioned policy is equivariant, i.e.,\nÏ€\nâ€‹\n(\ng\nâ€‹\na\n|\ng\nâ€‹\ns\n,\ng\nâ€‹\nz\n)\n=\nÏ€\nâ€‹\n(\na\n|\ns\n,\nz\n)\n\\pi(ga|gs,gz)=\\pi(a|s,z)\n, then the induced joint distribution at any timestep\nt\nt\nis group-invariant:\np\nt\nâ€‹\n(\ng\nâ€‹\ns\n,\ng\nâ€‹\nz\n)\n=\np\nt\nâ€‹\n(\ns\n,\nz\n)\n,\nâˆ€\ng\nâˆˆ\nG\n.\np_{t}(gs,gz)=p_{t}(s,z),\\quad\\forall g\\in G.\nConsequently, the state-skill occupancy measure\nÏ\nÏ€\nâ€‹\n(\ns\n,\nz\n)\n=\n1\nT\nâ€‹\nâˆ‘\nt\n=\n0\nT\nâˆ’\n1\np\nt\nâ€‹\n(\ns\n,\nz\n)\n\\rho^{\\pi}(s,z)=\\frac{1}{T}\\sum_{t=0}^{T-1}p_{t}(s,z)\nis also group-invariant.\nProof.\nWe prove the lemma through mathematical induction.\nBase Case (\nt\n=\n0\nt=0\n):\nThe joint distribution at\nt\n=\n0\nt=0\ncan be determined by the independent priors:\np\n0\nâ€‹\n(\ns\n,\nz\n)\n=\np\n0\nâ€‹\n(\ns\n)\nâ€‹\np\nâ€‹\n(\nz\n)\n.\np_{0}(s,z)=p_{0}(s)p(z).\nWhen applied by the group transformation\ng\nâˆˆ\nG\ng\\in G\n,\np\n0\nâ€‹\n(\ng\nâ€‹\ns\n,\ng\nâ€‹\nz\n)\n=\np\n0\nâ€‹\n(\ng\nâ€‹\ns\n)\nâ€‹\np\nâ€‹\n(\ng\nâ€‹\nz\n)\n=\np\n0\nâ€‹\n(\ns\n)\nâ€‹\np\nâ€‹\n(\nz\n)\n=\np\n0\nâ€‹\n(\ns\n,\nz\n)\n.\np_{0}(gs,gz)=p_{0}(gs)p(gz)=p_{0}(s)p(z)=p_{0}(s,z).\nInductive step:\nAssume the hypothesis holds for time\nt\nt\n, i.e.,\np\nt\nâ€‹\n(\ng\nâ€‹\ns\n,\ng\nâ€‹\nz\n)\n=\np\nt\nâ€‹\n(\ns\n,\nz\n)\np_{t}(gs,gz)=p_{t}(s,z)\n.\nThe marginal transition probability from\n(\ns\n,\nz\n)\n(s,z)\nto\ns\nâ€²\ns^{\\prime}\nunder policy\nÏ€\n\\pi\nis:\nğ’¯\nâ€‹\n(\ns\nâ€²\nâˆ£\ns\n,\nz\n)\n=\nâˆ«\nğ’œ\nP\nâ€‹\n(\ns\nâ€²\nâˆ£\ns\n,\na\n)\nâ€‹\nÏ€\nâ€‹\n(\na\nâˆ£\ns\n,\nz\n)\nâ€‹\nğ‘‘\na\n.\n\\mathcal{T}(s^{\\prime}\\mid s,z)=\\int_{\\mathcal{A}}P(s^{\\prime}\\mid s,a)\\pi(a\\mid s,z)\\,da.\nFirst, we show that this probability is group-invariant. Consider the transition from rotated inputs\ng\nâ€‹\ns\n,\ng\nâ€‹\nz\ngs,gz\nto\ng\nâ€‹\ns\nâ€²\ngs^{\\prime}\n:\nğ’¯\nâ€‹\n(\ng\nâ€‹\ns\nâ€²\nâˆ£\ng\nâ€‹\ns\n,\ng\nâ€‹\nz\n)\n\\displaystyle\\mathcal{T}(gs^{\\prime}\\mid gs,gz)\n=\nâˆ«\nğ’œ\nP\nâ€‹\n(\ng\nâ€‹\ns\nâ€²\nâˆ£\ng\nâ€‹\ns\n,\na\n)\nâ€‹\nÏ€\nâ€‹\n(\na\nâˆ£\ng\nâ€‹\ns\n,\ng\nâ€‹\nz\n)\nâ€‹\nğ‘‘\na\n.\n\\displaystyle=\\int_{\\mathcal{A}}P(gs^{\\prime}\\mid gs,a)\\pi(a\\mid gs,gz)\\,da.\n=\nâˆ«\nğ’œ\nP\nâ€‹\n(\ng\nâ€‹\ns\nâ€²\nâˆ£\ng\nâ€‹\ns\n,\ng\nâ€‹\na\nÂ¯\n)\nâ€‹\nÏ€\nâ€‹\n(\ng\nâ€‹\na\nÂ¯\nâˆ£\ng\nâ€‹\ns\n,\ng\nâ€‹\nz\n)\nâ€‹\nğ‘‘\na\nÂ¯\n\\displaystyle=\\int_{\\mathcal{A}}P(gs^{\\prime}\\mid gs,g\\bar{a})\\pi(g\\bar{a}\\mid gs,gz)\\,d\\bar{a}\n(\nchange of variable\nâ€‹\na\n=\ng\nâ€‹\na\nÂ¯\n)\n\\displaystyle\\quad\\quad\\quad\\quad\\quad\\quad\\quad(\\text{change of variable}~~a=g\\bar{a})\n=\nâˆ«\nğ’œ\nP\nâ€‹\n(\ns\nâ€²\nâˆ£\ns\n,\na\nÂ¯\n)\nâ€‹\nÏ€\nâ€‹\n(\na\nÂ¯\nâˆ£\ns\n,\nz\n)\nâ€‹\nğ‘‘\na\nÂ¯\n\\displaystyle=\\int_{\\mathcal{A}}P(s^{\\prime}\\mid s,\\bar{a})\\pi(\\bar{a}\\mid s,z)\\,d\\bar{a}\n=\nğ’¯\nâ€‹\n(\ns\nâ€²\nâˆ£\ns\n,\nz\n)\n.\n\\displaystyle=\\mathcal{T}(s^{\\prime}\\mid s,z).\nwhere we use the change of variable\na\n=\ng\nâ€‹\na\nÂ¯\na=g\\bar{a}\n, and\ng\nâˆˆ\nG\ng\\in G\nis a volume-preserving group transform,\nd\nâ€‹\na\n=\nd\nâ€‹\na\nÂ¯\nda=d\\bar{a}\nNow, we express\np\nt\n+\n1\nâ€‹\n(\ns\nâ€²\n,\nz\n)\np_{t+1}(s^{\\prime},z)\nby marginalizing over the previous state\ns\ns\n:\np\nt\n+\n1\nâ€‹\n(\ns\nâ€²\n,\nz\n)\n=\nâˆ«\nğ’®\nğ’¯\nâ€‹\n(\ns\nâ€²\nâˆ£\ns\n,\nz\n)\nâ€‹\np\nt\nâ€‹\n(\ns\n,\nz\n)\nâ€‹\nğ‘‘\ns\n.\np_{t+1}(s^{\\prime},z)=\\int_{\\mathcal{S}}\\mathcal{T}(s^{\\prime}\\mid s,z)p_{t}(s,z)\\,ds.\nAt transformed pair\n(\ng\nâ€‹\ns\nâ€²\n,\ng\nâ€‹\nz\n)\n(gs^{\\prime},gz)\n:\np\nt\n+\n1\nâ€‹\n(\ng\nâ€‹\ns\nâ€²\n,\ng\nâ€‹\nz\n)\n=\nâˆ«\nğ’®\nğ’¯\nâ€‹\n(\ng\nâ€‹\ns\nâ€²\nâˆ£\ns\n,\ng\nâ€‹\nz\n)\nâ€‹\np\nt\nâ€‹\n(\ns\n,\ng\nâ€‹\nz\n)\nâ€‹\nğ‘‘\ns\n.\np_{t+1}(gs^{\\prime},gz)=\\int_{\\mathcal{S}}\\mathcal{T}(gs^{\\prime}\\mid s,gz)p_{t}(s,gz)\\,ds.\nWe again use the change of variable:\ns\n=\ng\nâ€‹\ns\nÂ¯\ns=g\\bar{s}\n,\nd\nâ€‹\ns\n=\nd\nâ€‹\ns\nÂ¯\nds=d\\bar{s}\n:\np\nt\n+\n1\nâ€‹\n(\ng\nâ€‹\ns\nâ€²\n,\ng\nâ€‹\nz\n)\n\\displaystyle p_{t+1}(gs^{\\prime},gz)\n=\nâˆ«\nğ’®\nğ’¯\nâ€‹\n(\ng\nâ€‹\ns\nâ€²\nâˆ£\ng\nâ€‹\ns\nÂ¯\n,\ng\nâ€‹\nz\n)\nâ€‹\np\nt\nâ€‹\n(\ng\nâ€‹\ns\nÂ¯\n,\ng\nâ€‹\nz\n)\nâ€‹\nğ‘‘\ns\nÂ¯\n\\displaystyle=\\int_{\\mathcal{S}}\\mathcal{T}(gs^{\\prime}\\mid g\\bar{s},gz)p_{t}(g\\bar{s},gz)\\,d\\bar{s}\n=\nâˆ«\nğ’®\nğ’¯\nâ€‹\n(\ns\nâ€²\nâˆ£\ns\nÂ¯\n,\nz\n)\nâ€‹\np\nt\nâ€‹\n(\ns\nÂ¯\n,\nz\n)\nâ€‹\nğ‘‘\ns\nÂ¯\n\\displaystyle=\\int_{\\mathcal{S}}\\mathcal{T}(s^{\\prime}\\mid\\bar{s},z)p_{t}(\\bar{s},z)\\,d\\bar{s}\n=\np\nt\n+\n1\nâ€‹\n(\ns\nâ€²\n,\nz\n)\n.\n\\displaystyle=p_{t+1}(s^{\\prime},z).\nBy induction,\np\nt\nâ€‹\n(\ng\nâ€‹\ns\n,\ng\nâ€‹\nz\n)\n=\np\nt\nâ€‹\n(\ns\n,\nz\n)\np_{t}(gs,gz)=p_{t}(s,z)\nfor all\nt\nt\n.\nTherefore,\nÏ\nÏ€\nâ€‹\n(\ns\n,\nz\n)\n\\rho^{\\pi}(s,z)\nis also group-invariant.\nâˆ\nVII-E\nGroup-invariant Temporal Distance under Group-Invariant MDPs\nThe temporal distance\nd\nT\nâ€‹\n(\ns\n1\n,\ns\n2\n)\nd_{T}(s_{1},s_{2})\nbetween two states\ns\n1\ns_{1}\nand\ns\n2\ns_{2}\nis defined as the expected number of transitions needed to reach state\ns\n2\ns_{2}\nfrom state\ns\n1\ns_{1}\nunder policy\nÏ€\n\\pi\n[\n8\n]\n. It satisfies the following recursive relationship:\nd\nT\nâ€‹\n(\ns\n1\n,\ns\n2\n)\n=\n{\n0\nif\nâ€‹\ns\n1\n=\ns\n2\n,\n1\n+\nğ”¼\na\n,\ns\nâ€²\nâˆ£\ns\n1\nâ€‹\n[\nd\nT\nâ€‹\n(\ns\nâ€²\n,\ns\n2\n)\n]\nif\nâ€‹\ns\n1\nâ‰ \ns\n2\n.\nd_{T}(s_{1},s_{2})=\\begin{cases}0&\\text{if }s_{1}=s_{2},\\\\[4.0pt]\n1+\\mathbb{E}_{a,s^{\\prime}\\mid s_{1}}\\big[d_{T}(s^{\\prime},s_{2})\\big]&\\text{if }s_{1}\\neq s_{2}.\\end{cases}\nFor the base case, if\ns\n1\n=\ns\n2\ns_{1}=s_{2}\n, it leads to\nd\nT\nâ€‹\n(\ng\nâ€‹\ns\n1\n,\ng\nâ€‹\ns\n2\n)\n=\n0\nd_{T}(gs_{1},gs_{2})=0\n, since the group action is assumed to be bijective,\ng\nâ€‹\ns\n1\n=\ng\nâ€‹\ns\n2\ngs_{1}=gs_{2}\n. So, the group-invariance is satisfied in the base case:\nd\nT\nâ€‹\n(\ng\nâ€‹\ns\n1\n,\ng\nâ€‹\ns\n2\n)\n=\nd\nT\nâ€‹\n(\ns\n1\n,\ns\n2\n)\n=\n0\nd_{T}(gs_{1},gs_{2})=d_{T}(s_{1},s_{2})=0\nFor the inductive step, assume that the group-invariance holds for states closer to\ns\n2\ns_{2}\n,\nd\nT\nâ€‹\n(\ng\nâ€‹\ns\nâ€²\n,\ng\nâ€‹\ns\n2\n)\n=\nd\nT\nâ€‹\n(\ns\nâ€²\n,\ns\n2\n)\nd_{T}(gs^{\\prime},gs_{2})=d_{T}(s^{\\prime},s_{2})\n. Then from the recursive term,\nd\nT\nâ€‹\n(\ng\nâ€‹\ns\n1\n,\ng\nâ€‹\ns\n2\n)\n=\n1\n+\nğ”¼\na\nâˆ¼\nÏ€\n(\nâ‹…\n|\ng\ns\n1\n)\nâ€‹\nğ”¼\ns\nâ€²\nâˆ¼\nP\n(\nâ‹…\n|\ng\ns\n1\n,\na\n)\nâ€‹\n[\nd\nT\nâ€‹\n(\ns\nâ€²\n,\ng\nâ€‹\ns\n2\n)\n]\nd_{T}(gs_{1},gs_{2})=1+\\mathbb{E}_{a\\sim\\pi(\\cdot|gs_{1})}\\mathbb{E}_{s^{\\prime}\\sim P(\\cdot|gs_{1},a)}[d_{T}(s^{\\prime},gs_{2})]\nBy the Lemma from\n[\n46\n]\nthat\ng\nâ€‹\nS\n=\nS\ngS=S\nand\ng\nâ€‹\nA\n=\nA\ngA=A\n, we can set\na\n=\ng\nâ€‹\na\n~\na=g\\tilde{a}\nand\ns\nâ€²\n=\ng\nâ€‹\ns\nâ€²â€²\ns^{\\prime}=gs^{\\prime\\prime}\n. Then, in the group-invariant MDPs,\nÏ€\nâ€‹\n(\ng\nâ€‹\na\n~\n|\ng\nâ€‹\ns\n1\n)\n=\nÏ€\nâ€‹\n(\na\n~\n|\ns\n1\n)\n\\pi(g\\tilde{a}|gs_{1})=\\pi(\\tilde{a}|s_{1})\nand\nP\nâ€‹\n(\ng\nâ€‹\ns\nâ€²â€²\n|\ng\nâ€‹\ns\n1\n,\ng\nâ€‹\na\n~\n)\n=\nP\nâ€‹\n(\ns\nâ€²â€²\n|\ns\n1\n,\na\n~\n)\nP(gs^{\\prime\\prime}|gs_{1},g\\tilde{a})=P(s^{\\prime\\prime}|s_{1},\\tilde{a})\n. Substituting these into the equation,\nd\nT\nâ€‹\n(\ng\nâ€‹\ns\n1\n,\ng\nâ€‹\ns\n2\n)\n=\n1\n+\nğ”¼\na\n~\nâˆ¼\nÏ€\n(\nâ‹…\n|\ns\n1\n)\nâ€‹\nğ”¼\ns\nâ€²â€²\nâˆ¼\nP\n(\nâ‹…\n|\ns\n1\n,\na\n~\n)\nâ€‹\n[\nd\nT\nâ€‹\n(\ng\nâ€‹\ns\nâ€²â€²\n,\ng\nâ€‹\ns\n2\n)\n]\nd_{T}(gs_{1},gs_{2})=1+\\mathbb{E}_{\\tilde{a}\\sim\\pi(\\cdot|s_{1})}\\mathbb{E}_{s^{\\prime\\prime}\\sim P(\\cdot|s_{1},\\tilde{a})}[d_{T}(gs^{\\prime\\prime},gs_{2})]\nBy the inductive hypothesis,\nd\nT\nâ€‹\n(\ng\nâ€‹\ns\nâ€²â€²\n,\ng\nâ€‹\ns\n2\n)\n=\nd\nT\nâ€‹\n(\ns\nâ€²â€²\n,\ns\n2\n)\nd_{T}(gs^{\\prime\\prime},gs_{2})=d_{T}(s^{\\prime\\prime},s_{2})\n. Therefore,\nd\nT\nâ€‹\n(\ng\nâ€‹\ns\n1\n,\ng\nâ€‹\ns\n2\n)\n\\displaystyle d_{T}(gs_{1},gs_{2})\n=\n1\n+\nğ”¼\na\n~\nâˆ¼\nÏ€\n(\nâ‹…\n|\ns\n1\n)\nâ€‹\nğ”¼\ns\nâ€²â€²\nâˆ¼\nP\n(\nâ‹…\n|\ns\n1\n,\na\n~\n)\nâ€‹\n[\nd\nT\nâ€‹\n(\ns\nâ€²â€²\n,\ns\n2\n)\n]\n\\displaystyle=1+\\mathbb{E}_{\\tilde{a}\\sim\\pi(\\cdot|s_{1})}\\mathbb{E}_{s^{\\prime\\prime}\\sim P(\\cdot|s_{1},\\tilde{a})}[d_{T}(s^{\\prime\\prime},s_{2})]\n=\n1\n+\nğ”¼\na\nâˆ¼\nÏ€\n(\nâ‹…\n|\ns\n1\n)\nâ€‹\nğ”¼\ns\nâ€²\nâˆ¼\nP\n(\nâ‹…\n|\ns\n1\n,\na\n)\nâ€‹\n[\nd\nT\nâ€‹\n(\ns\nâ€²\n,\ns\n2\n)\n]\n\\displaystyle=1+\\mathbb{E}_{a\\sim\\pi(\\cdot|s_{1})}\\mathbb{E}_{s^{\\prime}\\sim P(\\cdot|s_{1},a)}[d_{T}(s^{\\prime},s_{2})]\nwhere its equation is equivalent to the recursive definition of\nd\nT\nâ€‹\n(\ns\n1\n,\ns\n2\n)\nd_{T}(s_{1},s_{2})\n. Thus, by the mathematical induction, temporal distance is group-invariant under the group-invariant MDPs,\nd\nT\nâ€‹\n(\ng\nâ€‹\ns\n1\n,\ng\nâ€‹\ns\n2\n)\n=\nd\nT\nâ€‹\n(\ns\n1\n,\ns\n2\n)\nd_{T}(gs_{1},gs_{2})=d_{T}(s_{1},s_{2})\n.\nVII-F\nProof of Theorem\n2\nIn this section, we prove that if the underlying MDP is group-invariant and the low-level skill policy is equivariant, the induced state transition probability in the high-level Semi-MDP (defined over a fixed interval\nk\nk\n) retains group invariance.\nLet\nG\nG\nbe a compact group acting on the state space\nğ’®\n\\mathcal{S}\nand action space\nğ’œ\n\\mathcal{A}\n. We denote the transition probability of the underlying MDP as\nP\nl\nâ€‹\n(\ns\nâ€²\nâˆ£\ns\n,\na\n)\nP^{l}(s^{\\prime}\\mid s,a)\n. Group-invariance of the dynamics implies that\nP\nl\nâ€‹\n(\ng\nâ€‹\ns\nâ€²\nâˆ£\ng\nâ€‹\ns\n,\ng\nâ€‹\na\n)\n=\nP\nl\nâ€‹\n(\ns\nâ€²\nâˆ£\ns\n,\na\n)\nP^{l}(gs^{\\prime}\\mid gs,ga)=P^{l}(s^{\\prime}\\mid s,a)\nfor all\ng\nâˆˆ\nG\ng\\in G\n. Furthermore, let\nÏ€\nâ€‹\n(\na\nâˆ£\ns\n,\nz\n)\n\\pi(a\\mid s,z)\nbe the low-level skill policy. Equivariance of the policy implies\nÏ€\nâ€‹\n(\ng\nâ€‹\na\nâˆ£\ng\nâ€‹\ns\n,\ng\nâ€‹\nz\n)\n=\nÏ€\nâ€‹\n(\na\nâˆ£\ns\n,\nz\n)\n\\pi(ga\\mid gs,gz)=\\pi(a\\mid s,z)\n. We define\nP\nk\nâ€‹\n(\ns\nt\n+\nk\nâˆ£\ns\nt\n,\nz\n)\nP_{k}(s_{t+k}\\mid s_{t},z)\nas the transition probability of the Semi-MDP, representing the likelihood of reaching state\ns\nt\n+\nk\ns_{t+k}\nfrom\ns\nt\ns_{t}\nafter executing skill\nz\nz\nfor\nk\nk\nsteps.\nTheorem\n2\n(Group-invariant Fixed-interval Semi-MDP)\n.\nAssume the environment dynamics are group-invariant and the pretrained skill policy is equivariant:\nP\nl\nâ€‹\n(\ng\nâ€‹\ns\nâ€²\nâˆ£\ng\nâ€‹\ns\n,\ng\nâ€‹\na\n)\n\\displaystyle P^{l}(gs^{\\prime}\\mid gs,ga)\n=\nP\nl\nâ€‹\n(\ns\nâ€²\nâˆ£\ns\n,\na\n)\n\\displaystyle=P^{l}(s^{\\prime}\\mid s,a)\nÏ€\nl\nâ€‹\n(\ng\nâ€‹\na\nâˆ£\ng\nâ€‹\ns\n,\ng\nâ€‹\nz\n)\n\\displaystyle\\pi^{l}(ga\\mid gs,gz)\n=\nÏ€\nl\nâ€‹\n(\na\nâˆ£\ns\n,\nz\n)\nâˆ€\ng\nâˆˆ\nG\n.\n\\displaystyle=\\pi^{l}(a\\mid s,z)\\quad\\forall g\\in G.\nThen, the induced high-level transition kernel (Eq.Â (\n7\n)) satisfies group invariance:\nP\nk\nâ€‹\n(\ng\nâ€‹\ns\nt\n+\nk\nâˆ£\ng\nâ€‹\ns\nt\n,\ng\nâ€‹\nz\n)\n=\nP\nk\nâ€‹\n(\ns\nt\n+\nk\nâˆ£\ns\nt\n,\nz\n)\n,\nâˆ€\ng\nâˆˆ\nG\n.\nP_{k}(gs_{t+k}\\mid gs_{t},gz)=P_{k}(s_{t+k}\\mid s_{t},z),\\qquad\\forall g\\in G.\nConsequently, the fixed-interval semi-MDP is group-invariant whenever the high-level reward is group-invariant.\nProof.\nThe probability of reaching state\ns\nt\n+\nk\ns_{t+k}\nfrom\ns\nt\ns_{t}\nunder skill\nz\nz\nis obtained by marginalizing over all possible intermediate trajectories of actions\na\nt\n:\nt\n+\nk\nâˆ’\n1\na_{t:t+k-1}\nand states\ns\nt\n+\n1\n:\nt\n+\nk\nâˆ’\n1\ns_{t+1:t+k-1}\n. Let\nÏ„\ni\nâ€‹\nn\nâ€‹\nt\n\\tau_{int}\ndenote the set of these intermediate variables. We write the transition density as:\nP\nk\nâ€‹\n(\ns\nt\n+\nk\nâˆ£\ns\nt\n,\nz\n)\n\\displaystyle P_{k}(s_{t+k}\\mid s_{t},z)\n=\nâˆ«\nâ€¦\nâˆ«\nâˆ\ni\n=\n0\nk\nâˆ’\n1\n[\nÏ€\n(\na\nt\n+\ni\nâˆ£\ns\nt\n+\ni\n,\nz\n)\nâ‹…\n\\displaystyle=\\int\\dots\\int\\prod_{i=0}^{k-1}\\bigg[\\pi(a_{t+i}\\mid s_{t+i},z)\\cdot\nP\nl\n(\ns\nt\n+\ni\n+\n1\nâˆ£\ns\nt\n+\ni\n,\na\nt\n+\ni\n)\n]\nd\nÏ„\ni\nâ€‹\nn\nâ€‹\nt\n.\n\\displaystyle\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad P^{l}(s_{t+i+1}\\mid s_{t+i},a_{t+i})\\bigg]\\,d\\tau_{int}.\nNow, consider the transition probability under the transformed inputs\ng\nâ€‹\ns\nt\ngs_{t}\nand\ng\nâ€‹\nz\ngz\n. Let the integration variables representing the intermediate trajectory be denoted by the primed variables\ns\nt\n+\ni\nâ€²\ns^{\\prime}_{t+i}\nand\na\nt\n+\ni\nâ€²\na^{\\prime}_{t+i}\n:\nP\nk\nâ€‹\n(\ng\nâ€‹\ns\nt\n+\nk\nâˆ£\ng\nâ€‹\ns\nt\n,\ng\nâ€‹\nz\n)\n\\displaystyle P_{k}(gs_{t+k}\\mid gs_{t},gz)\n=\nâˆ«\nâ€¦\nâˆ«\nâˆ\ni\n=\n0\nk\nâˆ’\n1\n[\nÏ€\n(\na\nt\n+\ni\nâ€²\nâˆ£\ns\nt\n+\ni\nâ€²\n,\ng\nz\n)\nâ‹…\n\\displaystyle=\\int\\dots\\int\\prod_{i=0}^{k-1}\\bigg[\\pi(a^{\\prime}_{t+i}\\mid s^{\\prime}_{t+i},gz)\\cdot\nP\nl\n(\ns\nt\n+\ni\n+\n1\nâ€²\nâˆ£\ns\nt\n+\ni\nâ€²\n,\na\nt\n+\ni\nâ€²\n)\n]\nd\nÏ„\nâ€²\ni\nâ€‹\nn\nâ€‹\nt\n.\n\\displaystyle\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad P^{l}(s^{\\prime}_{t+i+1}\\mid s^{\\prime}_{t+i},a^{\\prime}_{t+i})\\bigg]\\,d\\tau^{\\prime}_{int}.\nWe perform a change of variables for the entire trajectory. Let\ns\nt\n+\ni\nâ€²\n=\ng\nâ€‹\ns\n^\nt\n+\ni\ns^{\\prime}_{t+i}=g\\hat{s}_{t+i}\nand\na\nt\n+\ni\nâ€²\n=\ng\nâ€‹\na\n^\nt\n+\ni\na^{\\prime}_{t+i}=g\\hat{a}_{t+i}\n. Since the group action is volume-preserving (unit Jacobian determinant for compact groups), the differential element remains unchanged,\nd\nâ€‹\nÏ„\ni\nâ€‹\nn\nâ€‹\nt\nâ€²\n=\nd\nâ€‹\nÏ„\n^\ni\nâ€‹\nn\nâ€‹\nt\nd\\tau^{\\prime}_{int}=d\\hat{\\tau}_{int}\n. Substituting these variables and applying the group-invariance of\nP\nl\nP^{l}\nand the equivariance of\nÏ€\n\\pi\n:\nP\nk\nâ€‹\n(\ng\nâ€‹\ns\nt\n+\nk\nâˆ£\ng\nâ€‹\ns\nt\n,\ng\nâ€‹\nz\n)\n\\displaystyle P_{k}(gs_{t+k}\\mid gs_{t},gz)\n=\nâˆ«\nâ€¦\nâˆ«\nâˆ\ni\n=\n0\nk\nâˆ’\n1\n[\nP\nl\n(\ng\ns\n^\nt\n+\ni\n+\n1\nâˆ£\ng\ns\n^\nt\n+\ni\n,\ng\na\n^\nt\n+\ni\n)\n\\displaystyle=\\int\\dots\\int\\prod_{i=0}^{k-1}\\bigg[P^{l}(g\\hat{s}_{t+i+1}\\mid g\\hat{s}_{t+i},g\\hat{a}_{t+i})\nâ‹…\nÏ€\n(\ng\na\n^\nt\n+\ni\nâˆ£\ng\ns\n^\nt\n+\ni\n,\ng\nz\n)\n]\nd\nÏ„\n^\ni\nâ€‹\nn\nâ€‹\nt\n\\displaystyle\\quad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\cdot\\pi(g\\hat{a}_{t+i}\\mid g\\hat{s}_{t+i},gz)\\bigg]\\,d\\hat{\\tau}_{int}\n=\nâˆ«\nâ€¦\nâˆ«\nâˆ\ni\n=\n0\nk\nâˆ’\n1\n[\nP\nl\n(\ns\n^\nt\n+\ni\n+\n1\nâˆ£\ns\n^\nt\n+\ni\n,\na\n^\nt\n+\ni\n)\n\\displaystyle=\\int\\dots\\int\\prod_{i=0}^{k-1}\\bigg[P^{l}(\\hat{s}_{t+i+1}\\mid\\hat{s}_{t+i},\\hat{a}_{t+i})\nâ‹…\nÏ€\n(\na\n^\nt\n+\ni\nâˆ£\ns\n^\nt\n+\ni\n,\nz\n)\n]\nd\nÏ„\n^\ni\nâ€‹\nn\nâ€‹\nt\n\\displaystyle\\quad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\cdot\\pi(\\hat{a}_{t+i}\\mid\\hat{s}_{t+i},z)\\bigg]\\,d\\hat{\\tau}_{int}\n=\nP\nk\nâ€‹\n(\ns\nt\n+\nk\nâˆ£\ns\nt\n,\nz\n)\n.\n\\displaystyle=P_{k}(s_{t+k}\\mid s_{t},z).\nThus, the Semi-MDP transition dynamics are group-invariant.\nâˆ\nAppendix B. Representation Theory Background\nVII-G\nLeft Regular Representation\nLet\nG\nG\nbe a compact group acting on a space\nğ’³\n\\mathcal{X}\n(e.g.,\nğ’³\n=\nğ’®\nÃ—\nZ\n\\mathcal{X}=\\mathcal{S}\\times Z\n). The\nleft regular representation\non functions\nf\n:\nğ’³\nâ†’\nâ„\nf:\\mathcal{X}\\to\\mathbb{R}\nis defined as:\n(\nL\ng\nâ€‹\nf\n)\nâ€‹\n(\nx\n)\n:=\nf\nâ€‹\n(\ng\nâˆ’\n1\nâ€‹\nx\n)\n,\ng\nâˆˆ\nG\n(L_{g}f)(x):=f(g^{-1}x),\\quad g\\in G\nIf\np\nâ€‹\n(\nx\n)\np(x)\nis a probability density on\nğ’³\n\\mathcal{X}\nwith respect to group-invariant measure, the corresponding pushforward density transforms identically to the function\n[\n11\n]\n:\n(\nL\ng\nâ€‹\np\n)\nâ€‹\n(\nx\n)\n:=\np\nâ€‹\n(\ng\nâˆ’\n1\nâ€‹\nx\n)\n.\n(L_{g}p)(x):=p(g^{-1}x).\nWe use this convention throughout the main text (e.g.,\nL\ng\nâ€‹\np\nâ€‹\n(\ns\n,\nz\n)\n=\np\nâ€‹\n(\ng\nâˆ’\n1\nâ€‹\ns\n,\ng\nâˆ’\n1\nâ€‹\nz\n)\nL_{g}p(s,z)=p(g^{-1}s,g^{-1}z)\nVII-H\nCompact Groups and Haar Measure\nThroughout this work, we consider a compact Hausdorff topological group\nG\nG\n, i.e.,\na group equipped with a Hausdorff topology such that the multiplication\ng\n.\nh\nâ†¦\ng\nâ€‹\nh\ng.h\\mapsto gh\nand inversion\ng\nâ†¦\ng\nâˆ’\n1\ng\\mapsto g^{-1}\nare continuous and the underlying topological space is compact\n[\n11\n]\n.\nOn any locally compact group, there exists a left-invariant measure\nÎ¼\n\\mu\n, called a (left) Haar measure, satisfying\nÎ¼\nâ€‹\n(\ng\nâ€‹\nS\n)\n=\nÎ¼\nâ€‹\n(\nS\n)\n,\nâˆ€\ng\nâˆˆ\nG\n,\nS\nâŠ†\nG\n.\n\\mu(gS)=\\mu(S),\\quad\\forall g\\in G,S\\subseteq G.\nSuch a left Haar measure is unique up to multiplication by a positive constant.\nSince\nG\nG\nis compact, we can normalize\nÎ¼\nâ€‹\n(\nG\n)\n=\n1\n\\mu(G)=1\n, so that\nâˆ«\nG\nh\nâ€‹\n(\ng\n)\nâ€‹\nğ‘‘\nÎ¼\nâ€‹\n(\ng\n)\n\\int_{G}h(g)~d\\mu(g)\nis the average of a function\nh\nh\nover the group.\nIn particular, the expressions of\nâˆ«\nG\nf\nâ€‹\n(\ng\nâ€‹\ns\n,\ng\nâ€‹\nz\n)\nâ€‹\nğ‘‘\nÎ¼\nâ€‹\n(\ng\n)\n\\int_{G}f(gs,gz)\\ d\\mu(g)\nin the main text are precisely such group averages.\nVII-I\nGroup Fourier Transform for\nS\nâ€‹\nO\nâ€‹\n(\n2\n)\nSO(2)\nIn our experiments we work with a finite cyclic subgroup\nG\n=\nC\nN\nâŠ‚\nS\nâ€‹\nO\nâ€‹\n(\n2\n)\nG=C_{N}\\subset SO(2)\n, so we use the discrete form of the group\nFourier transform. For a finite compact group\nG\nG\n, the Peterâ€“Weyl\ntheorem\n[\n5\n]\nstates that the matrix entries of\nall irreducible representations\nÏ\nj\nâˆˆ\nG\n^\n\\rho_{j}\\in\\hat{G}\nform a complete\northonormal basis of\nL\n2\nâ€‹\n(\nG\n)\nL^{2}(G)\n(with respect to the normalized counting\nmeasure). Consequently, any\nf\nâˆˆ\nL\n2\nâ€‹\n(\nG\n)\nf\\in L^{2}(G)\nadmits an expansion of the\nform\nf\nâ€‹\n(\ng\n)\n\\displaystyle f(g)\n=\nâˆ‘\nÏ\nj\nâˆˆ\nG\n^\nâˆ‘\nm\n,\nn\n<\nd\nj\nw\nj\n,\nm\n,\nn\nâ€‹\nd\nj\nâ€‹\n[\nÏ\nj\nâ€‹\n(\ng\n)\n]\nm\nâ€‹\nn\n\\displaystyle=\\sum_{\\rho_{j}\\in\\hat{G}}\\sum_{m,n<d_{j}}w_{j,m,n}\\,\\sqrt{d_{j}}\\,[\\rho_{j}(g)]_{mn}\n=\nâˆ‘\nÏ\nj\nâˆˆ\nG\n^\nd\nj\nâ€‹\nTr\nâ€‹\n(\nÏ\nj\nâ€‹\n(\ng\n)\nâŠ¤\nâ€‹\nf\n^\nâ€‹\n(\nÏ\nj\n)\n)\n,\n\\displaystyle=\\sum_{\\rho_{j}\\in\\hat{G}}\\sqrt{d_{j}}\\,\\mathrm{Tr}\\!\\big(\\rho_{j}(g)^{\\top}\\hat{f}(\\rho_{j})\\big),\nwhere\nd\nj\nd_{j}\nis the dimension of\nÏ\nj\n\\rho_{j}\n, indices\nm\n,\nn\nm,n\nrange over the\nmatrix entries, and\nf\n^\nâ€‹\n(\nÏ\nj\n)\nâˆˆ\nâ„\nd\nj\nÃ—\nd\nj\n\\hat{f}(\\rho_{j})\\in\\mathbb{R}^{d_{j}\\times d_{j}}\nis the\nmatrix collecting the coefficients\nw\nj\n,\nm\n,\nn\nâˆˆ\nâ„\nw_{j,m,n}\\in\\mathbb{R}\n.\nFor each basis element\n[\nÏ\nj\nâ€‹\n(\ng\n)\n]\nm\nâ€‹\nn\n[\\rho_{j}(g)]_{mn}\n, the associated coefficient is\nobtained by projecting\nf\nf\nonto that basis function:\nw\nj\n,\nm\n,\nn\n=\n1\n|\nG\n|\nâ€‹\nâˆ‘\ng\nâˆˆ\nG\nf\nâ€‹\n(\ng\n)\nâ€‹\nd\nj\nâ€‹\n[\nÏ\nj\nâ€‹\n(\ng\n)\n]\nm\nâ€‹\nn\n,\nw_{j,m,n}=\\frac{1}{|G|}\\sum_{g\\in G}f(g)\\,\\sqrt{d_{j}}\\,[\\rho_{j}(g)]_{mn},\nwhere\n|\nG\n|\n|G|\ndenotes the order of the finite group\nG\nG\n. Stacking these\ncoefficients into a matrix yields\nf\n^\nâ€‹\n(\nÏ\nj\n)\n=\n1\n|\nG\n|\nâ€‹\nâˆ‘\ng\nâˆˆ\nG\nf\nâ€‹\n(\ng\n)\nâ€‹\nd\nj\nâ€‹\nÏ\nj\nâ€‹\n(\ng\n)\n,\n\\hat{f}(\\rho_{j})=\\frac{1}{|G|}\\sum_{g\\in G}f(g)\\,\\sqrt{d_{j}}\\,\\rho_{j}(g),\nwhich we refer to as the (group) Fourier transform of\nf\nf\nat\nrepresentation\nÏ\nj\n\\rho_{j}\n.\nIn the main text, the â€œspectralâ€ or â€œFourierâ€ feature maps\nÏ•\nF\nâ€‹\n(\ns\n)\n\\phi_{F}(s)\nand\nÏˆ\nF\nâ€‹\n(\nz\n)\n\\psi_{F}(z)\nare precisely parametrizations of such\ncoefficient vectors across the irreducible representations of\nG\nG\n.\nReferences\n[1]\nV. Atanassov, W. Yu, A. L. Mitchell, M. N. Finean, and I. Havoutis\n(2024)\nConstrained skill discovery: quadruped locomotion with unsupervised reinforcement learning\n.\narXiv preprint arXiv:2410.07877\n.\nCited by:\nÂ§\nIII-A\n.\n[2]\nG. Bai, W. Xi, X. Hong, X. Liu, Y. Yue, and S. Zhao\n(2025)\nRobust and rotation-equivariant contrastive learning\n.\nIEEE Transactions on Neural Networks and Learning Systems\n36\n(\n11\n),\npp.Â 19501â€“19514\n.\nExternal Links:\nDocument\nCited by:\nÂ§\nII-B\n.\n[3]\nG. Brockman, V. Cheung, L. Pettersson, J. Schneider, J. Schulman, J. Tang, and W. Zaremba\n(2016)\nOpenai gym\n.\narXiv preprint arXiv:1606.01540\n.\nCited by:\nÂ§\nVI-A\n.\n[4]\nM. M. Bronstein, J. Bruna, T. Cohen, and P. VeliÄkoviÄ‡\n(2021)\nGeometric deep learning: grids, groups, graphs, geodesics, and gauges\n.\narXiv preprint arXiv:2104.13478\n.\nCited by:\nÂ§\nIII-B\n.\n[5]\nT. Ceccherini Silberstein, F. Scarabotti, F. Tolli,\net al.\n(2008)\nHarmonic analysis on finite groups\n.\nVol.\n108\n,\nCambridge University Press\n.\nCited by:\nÂ§\nV-D\n,\nÂ§\nVII-I\n.\n[6]\nJ. Chang, M. Park, J. Seo, R. Horowitz, J. Lee, and J. Choi\n(2025)\nPartially equivariant reinforcement learning in symmetry-breaking environments\n.\nExternal Links:\n2512.00915\n,\nLink\nCited by:\nÂ§\nII-B\n,\nÂ§\nV-G\n,\nÂ§\nVI-A\n,\n14\n.\n[7]\nD. S. Dummit and R. M. Foote\n(2004)\nAbstract algebra\n.\n3 edition\n,\nJohn Wiley & Sons\n.\nCited by:\nÂ§\nV-D\n.\n[8]\nI. Durugkar, M. Tec, S. Niekum, and P. Stone\n(2021)\nAdversarial intrinsic motivation for reinforcement learning\n.\nAdvances in Neural Information Processing Systems\n34\n,\npp.Â 8622â€“8636\n.\nCited by:\nÂ§\nVII-E\n.\n[9]\nB. Eysenbach, A. Gupta, J. Ibarz, and S. Levine\n(2018)\nDiversity is all you need: learning skills without a reward function\n.\narXiv preprint arXiv:1802.06070\n.\nCited by:\nÂ§I\n,\nÂ§\nII-A\n.\n[10]\nM. Finzi, G. Benton, and A. G. Wilson\n(2021)\nResidual pathway priors for soft equivariance constraints\n.\nAdvances in Neural Information Processing Systems\n34\n,\npp.Â 30037â€“30049\n.\nCited by:\nÂ§\nII-B\n.\n[11]\nG. B. Folland\n(2016)\nA course in abstract harmonic analysis\n.\nCRC press\n.\nCited by:\nÂ§\nVII-G\n,\nÂ§\nVII-H\n.\n[12]\nF. Fuchs, D. Worrall, V. Fischer, and M. Welling\n(2020)\nSe (3)-transformers: 3d roto-translation equivariant attention networks\n.\nAdvances in neural information processing systems\n33\n,\npp.Â 1970â€“1981\n.\nCited by:\nÂ§\nII-B\n.\n[13]\nM. Geiger and T. Smidt\n(2022)\nE3nn: euclidean neural networks\n.\narXiv preprint arXiv:2207.09453\n.\nCited by:\nÂ§\nII-B\n.\n[14]\nK. Gregor, D. J. Rezende, and D. Wierstra\n(2016)\nVariational intrinsic control\n.\narXiv preprint arXiv:1611.07507\n.\nCited by:\nÂ§\nII-A\n.\n[15]\nH. Huang, O. Howell, D. Wang, X. Zhu, R. Walters, and R. Platt\n(2024)\nFourier transporter: bi-equivariant robotic manipulation in 3d\n.\narXiv preprint arXiv:2401.12046\n.\nCited by:\nÂ§\nII-B\n.\n[16]\nH. Huang, D. Wang, R. Walters, and R. Platt\n(2022)\nEquivariant transporter network\n.\narXiv preprint arXiv:2202.09400\n.\nCited by:\nÂ§\nII-B\n.\n[17]\nH. Kim, B. K. LEE, H. Lee, D. Hwang, D. Kim, and J. Choo\n(2024)\nDoâ€™s and donâ€™ts: learning desirable skills with instruction videos\n.\nAdvances in Neural Information Processing Systems\n37\n,\npp.Â 47741â€“47766\n.\nCited by:\nÂ§I\n,\nÂ§\nII-A\n.\n[18]\nJ. Kim, H. Ryu, J. Choi, J. Seo, N. P. S. Prakash, R. Li, and R. Horowitz\n(2023)\nRobotic manipulation learning with equivariant descriptor fields: generative modeling, bi-equivariance, steerability, and locality\n.\nIn\nRSS 2023 Workshop on Symmetries in Robot Learning\n,\nCited by:\nÂ§\nII-B\n.\n[19]\nC. Kohler, A. S. Srikanth, E. Arora, and R. Platt\n(2024)\nSymmetric models for visual force policy learning\n.\nIn\n2024 IEEE International Conference on Robotics and Automation (ICRA)\n,\npp.Â 3101â€“3107\n.\nCited by:\nÂ§\nII-B\n.\n[20]\nM. Laskin, H. Liu, X. B. Peng, D. Yarats, A. Rajeswaran, and P. Abbeel\n(2022)\nCic: contrastive intrinsic control for unsupervised skill discovery\n.\narXiv preprint arXiv:2202.00161\n.\nCited by:\nÂ§I\n,\nÂ§\nII-A\n.\n[21]\nJ. Li, R. Zheng, H. Feng, M. Li, and X. Zhuang\n(2024)\nPermutation equivariant graph framelets for heterophilous graph learning\n.\nIEEE Transactions on Neural Networks and Learning Systems\n35\n(\n9\n),\npp.Â 11634â€“11648\n.\nExternal Links:\nDocument\nCited by:\nÂ§\nII-B\n.\n[22]\nH. Nguyen, A. Baisero, D. Wang, C. Amato, and R. Platt\n(2022)\nLeveraging fully observable policies for learning under partial observability\n.\narXiv preprint arXiv:2211.01991\n.\nCited by:\nÂ§\nII-B\n.\n[23]\nOpenAI\n(2025)\nChatGPT\n.\nNote:\nhttps://chat.openai.com\nLarge language model\nCited by:\nGroup-Invariant Unsupervised Skill Discovery: Symmetry-aware Skill Representations for Generalizable Behavior\n.\n[24]\nS. Ozair, C. Lynch, Y. Bengio, A. Van den Oord, S. Levine, and P. Sermanet\n(2019)\nWasserstein dependency measure for representation learning\n.\nAdvances in Neural Information Processing Systems\n32\n.\nCited by:\nÂ§I\n,\nÂ§\nIII-A\n.\n[25]\nM. Park, J. Chang, J. Choi, and R. Horowitz\n(2025)\nSymmetry-aware steering of equivariant diffusion policies: benefits and limits\n.\nExternal Links:\n2512.11345\n,\nLink\nCited by:\nÂ§\nII-B\n.\n[26]\nS. Park, J. Choi, J. Kim, H. Lee, and G. Kim\n(2022)\nLipschitz-constrained unsupervised skill discovery\n.\nIn\nInternational Conference on Learning Representations\n,\nCited by:\nÂ§I\n,\nÂ§\nII-A\n,\nÂ§\nIII-A\n,\nÂ§\nV-D\n,\nÂ§\nV-F\n.\n[27]\nS. Park, K. Lee, Y. Lee, and P. Abbeel\n(2023)\nControllability-aware unsupervised skill discovery\n.\narXiv preprint arXiv:2302.05103\n.\nCited by:\nÂ§I\n,\nÂ§\nII-A\n,\nÂ§\nII-A\n,\nÂ§\nIII-A\n,\nÂ§\nV-D\n,\nÂ§\nV-F\n.\n[28]\nS. Park, O. Rybkin, and S. Levine\n(2023)\nMetra: scalable unsupervised rl with metric-aware abstraction\n.\narXiv preprint arXiv:2310.08887\n.\nCited by:\nÂ§I\n,\nÂ§\nII-A\n,\nÂ§\nII-A\n,\nÂ§\nIII-A\n,\nÂ§\nV-D\n,\nÂ§\nV-D\n,\nÂ§\nV-E\n,\nÂ§\nV-F\n,\nÂ§\nV-G\n,\nÂ§\nVI-A\n,\nÂ§\nVI-B\n,\nÂ§VI\n.\n[29]\nB. Ravindran and A. G. Barto\n(2001)\nSymmetries and model minimization in markov decision processes\n.\nUniversity of Massachusetts\n.\nCited by:\nÂ§\nIII-C\n.\n[30]\nRavindran, Balaraman and Barto, Andrew G\n(2004)\nApproximate homomorphisms: a framework for non-exact minimization in markov decision processes\n.\nCited by:\nÂ§\nIII-C\n.\n[31]\nS. Rho, L. Smith, T. Li, S. Levine, X. B. Peng, and S. Ha\n(2024)\nLanguage guided skill discovery\n.\narXiv preprint arXiv:2406.06615\n.\nCited by:\nÂ§I\n,\nÂ§\nII-A\n,\nÂ§\nII-A\n,\nÂ§\nII-A\n,\nÂ§\nIII-A\n.\n[32]\nH. Ryu, J. Kim, H. An, J. Chang, J. Seo, T. Kim, Y. Kim, C. Hwang, J. Choi, and R. Horowitz\n(2024)\nDiffusion-edfs: bi-equivariant denoising generative modeling on se (3) for visual robotic manipulation\n.\nIn\nProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition\n,\npp.Â 18007â€“18018\n.\nCited by:\nÂ§\nII-B\n.\n[33]\nH. Ryu, H. Lee, J. Lee, and J. Choi\n(2022)\nEquivariant descriptor fields: se (3)-equivariant energy-based models for end-to-end visual robotic manipulation learning\n.\narXiv preprint arXiv:2206.08321\n.\nCited by:\nÂ§\nII-B\n.\n[34]\nJ. Seo, S. Yoo, J. Chang, H. An, H. Ryu, S. Lee, A. Kruthiventy, J. Choi, and R. Horowitz\n(2025)\nSE (3)-equivariant robot learning and control: a tutorial survey\n.\nInternational Journal of Control, Automation and Systems\n23\n(\n5\n),\npp.Â 1271â€“1306\n.\nCited by:\nÂ§\nII-B\n.\n[35]\nA. Sharma, S. Gu, S. Levine, V. Kumar, and K. Hausman\n(2019)\nDynamics-aware unsupervised discovery of skills\n.\narXiv preprint arXiv:1907.01657\n.\nCited by:\nÂ§I\n.\n[36]\nA. Simeonov, Y. Du, A. Tagliasacchi, J. B. Tenenbaum, A. Rodriguez, P. Agrawal, and V. Sitzmann\n(2022)\nNeural descriptor fields: se (3)-equivariant object representations for manipulation\n.\nIn\n2022 International Conference on Robotics and Automation (ICRA)\n,\npp.Â 6394â€“6400\n.\nCited by:\nÂ§\nII-B\n.\n[37]\nR. S. Sutton, D. Precup, and S. Singh\n(1999)\nBetween mdps and semi-mdps: a framework for temporal abstraction in reinforcement learning\n.\nArtificial intelligence\n112\n(\n1-2\n),\npp.Â 181â€“211\n.\nCited by:\nÂ§\nV-F\n.\n[38]\nA. Tangri, O. Biza, D. Wang, D. Klee, O. Howell, and R. Platt\n(2024)\nEquivariant offline reinforcement learning\n.\narXiv preprint arXiv:2406.13961\n.\nCited by:\nÂ§\nII-B\n.\n[39]\nN. Thomas, T. Smidt, S. Kearnes, L. Yang, L. Li, K. Kohlhoff, and P. Riley\n(2018)\nTensor field networks: rotation-and translation-equivariant neural networks for 3d point clouds\n.\narXiv preprint arXiv:1802.08219\n.\nCited by:\nÂ§\nII-B\n.\n[40]\nS. Tunyasuvunakool, A. Muldal, Y. Doron, S. Liu, S. Bohez, J. Merel, T. Erez, T. Lillicrap, N. Heess, and Y. Tassa\n(2020)\ndm_control\n: Software and tasks for continuous control\n.\nSoftware Impacts\n6\n,\npp.Â 100022\n.\nExternal Links:\nISSN 2665-9638\n,\nDocument\n,\nLink\nCited by:\nÂ§\nVI-A\n.\n[41]\nE. Van der Pol, D. Worrall, H. van Hoof, F. Oliehoek, and M. Welling\n(2020)\nMdp homomorphic networks: group symmetries in reinforcement learning\n.\nAdvances in Neural Information Processing Systems\n33\n,\npp.Â 4199â€“4210\n.\nCited by:\nÂ§\nII-B\n.\n[42]\nC. Villani\net al.\n(2009)\nOptimal transport: old and new\n.\nVol.\n338\n,\nSpringer\n.\nCited by:\nÂ§\nIII-A\n.\n[43]\nD. Wang, M. Jia, X. Zhu, R. Walters, and R. Platt\n(2022)\nOn-robot learning with equivariant models\n.\narXiv preprint arXiv:2203.04923\n.\nCited by:\nÂ§\nII-B\n.\n[44]\nD. Wang, J. Y. Park, N. Sortur, L. L. Wong, R. Walters, and R. Platt\n(2022)\nThe surprising effectiveness of equivariant models in domains with latent symmetry\n.\narXiv preprint arXiv:2211.09231\n.\nCited by:\nÂ§\nII-B\n.\n[45]\nD. Wang, R. Walters, and R. Platt\n(2022)\nSO(2)-equivariant reinforcement learning\n.\narXiv preprint arXiv:2203.04439\n.\nCited by:\nÂ§\nII-B\n,\nÂ§\nIII-C\n.\n[46]\nD. Wang, R. Walters, X. Zhu, and R. Platt\n(2022)\nEquivariant\nq\nq\nlearning in spatial action spaces\n.\nIn\nConference on Robot Learning\n,\npp.Â 1713â€“1723\n.\nCited by:\nÂ§\nII-B\n,\nÂ§\nIII-C\n,\nÂ§\nV-E\n,\nÂ§\nV-G\n,\nÂ§\nVI-A\n,\nÂ§\nVII-E\n,\n14\n.\n[47]\nM. Weiler and G. Cesa\n(2019)\nGeneral e (2)-equivariant steerable cnns\n.\nAdvances in neural information processing systems\n32\n.\nCited by:\nÂ§\nII-B\n.\n[48]\nR. Yang, C. Bai, H. Guo, S. Li, B. Zhao, Z. Wang, P. Liu, and X. Li\n(2023)\nBehavior contrastive learning for unsupervised skill discovery\n.\nIn\nInternational Conference on Machine Learning\n,\npp.Â 39183â€“39204\n.\nCited by:\nÂ§\nII-A\n.\n[49]\nA. Zeng, P. Florence, J. Tompson, S. Welker, J. Chien, M. Attarian, T. Armstrong, I. Krasin, D. Duong, V. Sindhwani,\net al.\n(2021)\nTransporter networks: rearranging the visual world for robotic manipulation\n.\nIn\nConference on Robot Learning\n,\npp.Â 726â€“747\n.\nCited by:\nÂ§\nII-B\n.",
    "preview_text": "Unsupervised skill discovery aims to acquire behavior primitives that improve exploration and accelerate downstream task learning. However, existing approaches often ignore the geometric symmetries of physical environments, leading to redundant behaviors and sample inefficiency. To address this, we introduce Group-Invariant Skill Discovery (GISD), a framework that explicitly embeds group structure into the skill discovery objective. Our approach is grounded in a theoretical guarantee: we prove that in group-symmetric environments, the standard Wasserstein dependency measure admits a globally optimal solution comprised of an equivariant policy and a group-invariant scoring function. Motivated by this, we formulate the Group-Invariant Wasserstein dependency measure, which restricts the optimization to this symmetry-aware subspace without loss of optimality. Practically, we parameterize the scoring function using a group Fourier representation and define the intrinsic reward via the alignment of equivariant latent features, ensuring that the discovered skills generalize systematically under group transformations. Experiments on state-based and pixel-based locomotion benchmarks demonstrate that GISD achieves broader state-space coverage and improved efficiency in downstream task learning compared to a strong baseline.\n\nGroup-Invariant Unsupervised Skill Discovery: Symmetry-aware Skill Representations for Generalizable Behavior\nJunwooÂ Chang\n,\nJosephÂ Park\n,\nRobertoÂ Horowitz\n,\nJongminÂ Lee\n,\nandÂ JongeunÂ Choi\n(Corresponding authors: Jongeun Choi and Jongmin Lee.)Junwoo Chang, Joseph Park, and Jongeun Choi are with the School of Mechanical Engineering,\nYonsei University, Seoul, South Korea (\ne-mails: junwoochang@yonsei.ac.kr;\niamjoseph1129@yonsei.ac.kr; jongeunchoi@yonsei.ac.kr\n).\nJongmin Lee and Jongeun Choi are with the Department of Artificial Intelligence,\nYonsei University, Seoul, South Korea (\ne-mails: jongminlee@yonsei.ac.kr;\njongeunchoi@yonsei.ac.kr\n).\nJongeun Choi an",
    "is_relevant": true,
    "relevance_score": 6.0,
    "extracted_keywords": [
        "Reinforcement Learning",
        "locomotion"
    ],
    "one_line_summary": "è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºç¾¤ä¸å˜æ€§çš„æ— ç›‘ç£æŠ€èƒ½å‘ç°æ¡†æ¶ï¼Œé€šè¿‡åµŒå…¥å‡ ä½•å¯¹ç§°æ€§æ¥æå‡å¼ºåŒ–å­¦ä¹ ä¸­è¿åŠ¨æ§åˆ¶ä»»åŠ¡çš„æ¢ç´¢æ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚",
    "detailed_summary": "## è®ºæ–‡æ‘˜è¦ï¼šåŸºäºç¾¤ä¸å˜æ€§çš„æ— ç›‘ç£æŠ€èƒ½å‘ç°\n\n**1. ç ”ç©¶èƒŒæ™¯å’ŒåŠ¨æœº**\næ— ç›‘ç£æŠ€èƒ½å‘ç°æ—¨åœ¨å­¦ä¹ å¯é‡ç”¨çš„è¡Œä¸ºåŸºå…ƒï¼Œä»¥åŠ é€Ÿä¸‹æ¸¸ä»»åŠ¡å­¦ä¹ ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•é€šå¸¸å¿½ç•¥ç‰©ç†ç¯å¢ƒä¸­å›ºæœ‰çš„å‡ ä½•å¯¹ç§°æ€§ï¼ˆå¦‚æœºå™¨äººçš„æ—‹è½¬å¯¹ç§°ï¼‰ï¼Œå¯¼è‡´å­¦ä¹ åˆ°å¤§é‡å†—ä½™è¡Œä¸ºï¼Œæ ·æœ¬æ•ˆç‡ä½ä¸‹ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§**æ˜¾å¼å°†ç¾¤å¯¹ç§°ç»“æ„åµŒå…¥æŠ€èƒ½å‘ç°ç›®æ ‡**çš„æ–°æ¡†æ¶ã€‚\n\n**2. æ ¸å¿ƒæ–¹æ³•å’ŒæŠ€æœ¯åˆ›æ–°**\næœ¬æ–‡æå‡ºäº†**ç¾¤ä¸å˜æŠ€èƒ½å‘ç°ï¼ˆGISDï¼‰**æ¡†æ¶ã€‚å…¶æ ¸å¿ƒæŠ€æœ¯åˆ›æ–°åŒ…æ‹¬ï¼š\n- **ç†è®ºä¿è¯**ï¼šè¯æ˜äº†åœ¨å…·æœ‰ç¾¤å¯¹ç§°æ€§çš„é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ä¸­ï¼Œæ ‡å‡†çš„Wassersteinä¾èµ–åº¦é‡å­˜åœ¨ä¸€ä¸ªç”±**ç­‰å˜ç­–ç•¥**å’Œ**ç¾¤ä¸å˜è¯„åˆ†å‡½æ•°**æ„æˆçš„å…¨å±€æœ€ä¼˜è§£ã€‚\n- **ç›®æ ‡å‡½æ•°è®¾è®¡**ï¼šåŸºäºä¸Šè¿°ç†è®ºï¼Œå®šä¹‰äº†**ç¾¤ä¸å˜Wassersteinä¾èµ–åº¦é‡ï¼ˆGIWDMï¼‰**ï¼Œå°†ä¼˜åŒ–é™åˆ¶åœ¨å¯¹ç§°æ„ŸçŸ¥çš„å­ç©ºé—´ä¸­ï¼Œä»è€Œæ¶ˆé™¤äº†æ¢ç´¢éå¯¹ç§°å†—ä½™è§£çš„éœ€è¦ã€‚\n- **å¯¹ç§°è¡¨å¾**ï¼šåˆ©ç”¨**ç¾¤å‚…é‡Œå¶è¡¨ç¤º**æ¥å‚æ•°åŒ–è¯„åˆ†å‡½æ•°ï¼Œç¡®ä¿å‘ç°çš„æŠ€èƒ½å…¶æ½œåœ¨è¡¨å¾æ˜¾å¼ç¼–ç äº†ç¾¤å¯¹ç§°æ€§ã€‚ç”±æ­¤äº§ç”Ÿçš„å†…åœ¨å¥–åŠ±é€šè¿‡ç­‰å˜æ½œåœ¨ç‰¹å¾çš„å¯¹é½æ¥å®šä¹‰ã€‚\n- **æ³›åŒ–æœºåˆ¶**ï¼šå­¦åˆ°çš„å¯¹ç§°æ„ŸçŸ¥æŠ€èƒ½è¡¨å¾ä½¿å¾—æ™ºèƒ½ä½“èƒ½å¤Ÿé€šè¿‡ç¾¤å˜æ¢å…¶æ½œåœ¨è¡¨å¾ï¼Œåœ¨å…¨æ–°çš„é…ç½®ä¸‹ç³»ç»Ÿåœ°é‡ç”¨æŠ€èƒ½ï¼Œå®ç°æ³›åŒ–ã€‚\n\n**3. ä¸»è¦å®éªŒç»“æœ**\nåœ¨åŸºäºçŠ¶æ€ï¼ˆAntï¼‰å’ŒåŸºäºåƒç´ ï¼ˆQuadrupedï¼‰çš„ locomotion åŸºå‡†æµ‹è¯•ä¸­ï¼Œä¸å¼ºåŸºçº¿æ–¹æ³•METRAç›¸æ¯”ï¼ŒGISDå±•ç°å‡ºï¼š\n- **æ›´å¹¿çš„çŠ¶æ€ç©ºé—´è¦†ç›–**ï¼šå‘ç°çš„æŠ€èƒ½èƒ½æ›´å‡åŒ€ã€æ›´å¹¿æ³›åœ°æ¢ç´¢ç¯å¢ƒã€‚\n- **æ›´é«˜çš„æ ·æœ¬æ•ˆç‡**ï¼šåœ¨æŠ€èƒ½é¢„è®­ç»ƒé˜¶æ®µèƒ½æ›´å¿«è¾¾åˆ°é«˜è¦†ç›–ç‡ã€‚\n- **æ›´ä¼˜çš„ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½**ï¼šåœ¨ç›®æ ‡åˆ°è¾¾ä»»åŠ¡ä¸­ï¼Œä½¿ç”¨GISDé¢„è®­ç»ƒæŠ€èƒ½çš„é«˜å±‚ç­–ç•¥èƒ½è·å¾—æ›´é«˜çš„å›æŠ¥å’Œæ›´å¿«çš„æ”¶æ•›é€Ÿåº¦ã€‚\n- **å¯è§†åŒ–éªŒè¯**ï¼šå­¦åˆ°çš„æŠ€èƒ½è½¨è¿¹å‘ˆç°å‡ºä¸å¯¹ç§°æ€§ï¼ˆå¦‚C4æ—‹è½¬ã€æ°´å¹³ç¿»è½¬ï¼‰ä¸€è‡´çš„æ¨¡å¼ã€‚\n\n**4. ç ”ç©¶æ„ä¹‰å’Œä»·å€¼**\næœ¬å·¥ä½œçš„ä»·å€¼åœ¨äºï¼š\n- **ç†è®ºè´¡çŒ®**ï¼šä¸ºåœ¨å¯¹ç§°ç¯å¢ƒä¸­è¿›è¡Œæ— ç›‘ç£å­¦ä¹ æä¾›äº†ä¸¥è°¨çš„ç†è®ºåŸºç¡€ï¼Œè¯æ˜äº†é™åˆ¶æœç´¢ç©ºé—´çš„æœ€ä¼˜æ€§ã€‚\n- **æ–¹æ³•åˆ›æ–°**ï¼šé¦–æ¬¡å°†ç¾¤ç­‰å˜æ€§ç³»ç»Ÿåœ°èå…¥æ— ç›‘ç£æŠ€èƒ½å‘ç°ï¼Œæä¾›äº†ä¸€ç§åˆ©ç”¨ç¯å¢ƒå…ˆéªŒç»“æ„æå‡å­¦ä¹ æ•ˆç‡çš„æ–°èŒƒå¼ã€‚\n- **å®é™…åº”ç”¨**ï¼šæ‰€å‘ç°çš„å¯¹ç§°æ„ŸçŸ¥æŠ€èƒ½å…·æœ‰æ›´å¥½çš„å¯è§£é‡Šæ€§å’Œç³»ç»Ÿæ€§æ³›åŒ–èƒ½åŠ›ï¼Œä¸ºæœºå™¨äººæ§åˆ¶ç­‰é¢†åŸŸçš„æ ·æœ¬é«˜æ•ˆå¼ºåŒ–å­¦ä¹ æä¾›äº†æœ‰åŠ›å·¥å…·ã€‚è¯¥æ¡†æ¶ä¸ºå°†å‡ ä½•å…ˆéªŒåº”ç”¨äºæ›´å¤æ‚çš„æŠ€èƒ½å‘ç°ä¸æ“çºµä»»åŠ¡å¼€è¾Ÿäº†é“è·¯ã€‚",
    "qa_pairs": [
        {
            "question": "è¿™ç¯‡è®ºæ–‡çš„æ ¸å¿ƒåˆ›æ–°ç‚¹æ˜¯ä»€ä¹ˆï¼Œä»–æƒ³è§£å†³ä»€ä¹ˆé—®é¢˜ï¼Œæ€ä¹ˆè§£å†³çš„ï¼Ÿ",
            "answer": "## è®ºæ–‡æ ¸å¿ƒåˆ†æ\n\n### **è®ºæ–‡æ ‡é¢˜**\nGroup-Invariant Unsupervised Skill Discovery: Symmetry-aware Skill Representations for Generalizable Behavior\n\n### **æ ¸å¿ƒé—®é¢˜**\nç°æœ‰çš„æ— ç›‘ç£æŠ€èƒ½å‘ç°æ–¹æ³•é€šå¸¸å¿½ç•¥ç‰©ç†ç¯å¢ƒä¸­å›ºæœ‰çš„**å‡ ä½•å¯¹ç§°æ€§**ï¼ˆä¾‹å¦‚ï¼Œæœºå™¨äººæ—‹è½¬åè¡Œä¸ºæœ¬è´¨ç›¸åŒï¼‰ã€‚è¿™å¯¼è‡´ä¸¤ä¸ªä¸»è¦é—®é¢˜ï¼š\n1.  **æ ·æœ¬æ•ˆç‡ä½ä¸‹**ï¼šç®—æ³•ä¼šå­¦ä¹ å¤§é‡ä»…åœ¨å¯¹ç§°å˜æ¢ä¸‹æœ‰å·®å¼‚çš„â€œå†—ä½™â€è¡Œä¸ºï¼Œæµªè´¹æ¢ç´¢æ ·æœ¬ã€‚\n2.  **æ³›åŒ–èƒ½åŠ›å¼±**ï¼šå­¦åˆ°çš„æŠ€èƒ½ç¼ºä¹å¯¹å¯¹ç§°ç»“æ„çš„æ˜¾å¼ç¼–ç ï¼Œéš¾ä»¥ç³»ç»Ÿæ€§åœ°æ³›åŒ–åˆ°ç»è¿‡ç¾¤å˜æ¢ï¼ˆå¦‚æ—‹è½¬ã€ç¿»è½¬ï¼‰çš„æ–°ä»»åŠ¡é…ç½®ä¸Šã€‚\n\n### **æ ¸å¿ƒåˆ›æ–°ç‚¹**\nè®ºæ–‡æå‡ºäº† **â€œç¾¤ä¸å˜æ— ç›‘ç£æŠ€èƒ½å‘ç°â€** æ¡†æ¶ï¼Œå…¶åˆ›æ–°æ€§ä½“ç°åœ¨**ç†è®ºã€æ–¹æ³•å’Œåº”ç”¨**ä¸‰ä¸ªå±‚é¢ï¼š\n\n1.  **ç†è®ºåˆ›æ–°ï¼šè¯æ˜äº†å¯¹ç§°æœ€ä¼˜è§£çš„å­˜åœ¨æ€§**\n    *   **å®šç†**ï¼šåœ¨å…·æœ‰ç¾¤å¯¹ç§°æ€§çš„é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ä¸­ï¼Œæ ‡å‡†çš„Wassersteinä¾èµ–åº¦é‡çš„**å…¨å±€æœ€ä¼˜è§£**å¿…ç„¶åŒ…å«ä¸€ä¸ª**ç­‰å˜ç­–ç•¥**å’Œä¸€ä¸ª**ç¾¤ä¸å˜è¯„åˆ†å‡½æ•°**ã€‚\n    *   **ä»·å€¼**ï¼šè¿™ä¸€ç†è®ºä¿è¯ä¸ºæ–¹æ³•æä¾›äº†ä¸¥æ ¼ä¾æ®ã€‚å®ƒè¡¨æ˜ï¼Œå°†æœç´¢ç©ºé—´é™åˆ¶åœ¨å¯¹ç§°æ„ŸçŸ¥çš„å‡½æ•°ç±»ä¸­ï¼Œ**ä¸ä¼šæŸå¤±æœ€ä¼˜æ€§**ï¼Œä»è€Œå¯ä»¥å®‰å…¨åœ°å¼•å…¥å¯¹ç§°æ€§ä½œä¸ºå½’çº³åç½®ï¼Œé¿å…æ¢ç´¢å†—ä½™çš„éå¯¹ç§°è§£ã€‚\n\n2.  **æ–¹æ³•åˆ›æ–°ï¼šæ„å»ºäº†ç¾¤ä¸å˜çš„Wassersteinä¾èµ–åº¦é‡**\n    *   **GIWDM**ï¼šåŸºäºä¸Šè¿°ç†è®ºï¼Œè®ºæ–‡å®šä¹‰äº†**ç¾¤ä¸å˜Wassersteinä¾èµ–åº¦é‡**ã€‚å®ƒé€šè¿‡å°†è¯„åˆ†å‡½æ•° `f` é™åˆ¶åœ¨ç¾¤ä¸å˜å‡½æ•°ç±» `â„±_G` ä¸­ï¼Œæ˜¾å¼åœ°å°†å¯¹ç§°æ€§åµŒå…¥ç›®æ ‡å‡½æ•°ã€‚\n    *   **å‚…é‡Œå¶ç©ºé—´å‚æ•°åŒ–**ï¼šä¸ºå®ç°ç¾¤ä¸å˜è¯„åˆ†å‡½æ•°ï¼Œè®ºæ–‡åˆ›æ–°æ€§åœ°åœ¨**ç¾¤å‚…é‡Œå¶ç©ºé—´**ä¸­å¯¹ `f` è¿›è¡Œå‚æ•°åŒ–ã€‚å…·ä½“åœ°ï¼Œå­¦ä¹ ä¸€ä¸ªç­‰å˜çš„ç‰¹å¾æ˜ å°„ `Ï†_F`ï¼Œå°†çŠ¶æ€æ˜ å°„åˆ°ç”±ç¾¤ä¸å¯çº¦è¡¨ç¤ºï¼ˆå¯¹åº”ä¸åŒâ€œé¢‘ç‡â€ï¼‰ç³»æ•°æ„æˆçš„å‚…é‡Œå¶ç‰¹å¾ç©ºé—´ã€‚å†…åœ¨å¥–åŠ±å®šä¹‰ä¸ºçŠ¶æ€å‚…é‡Œå¶ç‰¹å¾å˜åŒ–ä¸æŠ€èƒ½å‘é‡çš„å¯¹é½ç¨‹åº¦ã€‚\n        ```python\n        # æ ¸å¿ƒå¥–åŠ±å‡½æ•°\n        r(s_t, z, s_{t+1}) = âŸ¨Ï†_F(s_{t+1}) - Ï†_F(s_t), zâŸ©\n        # å…¶ä¸­ Ï†_F æ˜¯ç­‰å˜æ˜ å°„ï¼Œz æ˜¯å‚…é‡Œå¶ç©ºé—´ä¸­çš„æŠ€èƒ½å‘é‡\n        ```\n    *   **å¯¹ç§°æ€§ä¸‹æ¸¸åˆ©ç”¨**ï¼šå­¦åˆ°çš„æŠ€èƒ½åœ¨å‚…é‡Œå¶ç©ºé—´ä¸­è¡¨ç¤ºã€‚åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­ï¼Œé«˜å±‚ç­–ç•¥å¯ä»¥é€šè¿‡å¯¹æŠ€èƒ½å‘é‡ `z` æ–½åŠ ç¾¤å˜æ¢ï¼ˆå¦‚æ—‹è½¬å¯¹åº”çš„å‚…é‡Œå¶ç³»æ•°ï¼‰ï¼Œç›´æ¥ç”Ÿæˆé€‚ç”¨äºå˜æ¢åç¯å¢ƒï¼ˆå¦‚æ–°æœå‘ï¼‰çš„è¡Œä¸ºï¼Œå®ç°**ç³»ç»Ÿæ€§æ³›åŒ–**ã€‚\n\n3.  **åº”ç”¨åˆ›æ–°ï¼šå®ç°äº†å¯¹ç§°æ€§ä»å‘ç°åˆ°åˆ©ç”¨çš„é—­ç¯**\n    *   æ•´ä¸ªæ¡†æ¶ç¡®ä¿äº†ä»æŠ€èƒ½å‘ç°ï¼ˆå¯¹ç§°çš„ `Ï†_F` å’Œç­–ç•¥ `Ï€`ï¼‰åˆ°ä¸‹æ¸¸åˆ†å±‚æ§åˆ¶ï¼ˆå¯¹ç§°çš„é«˜å±‚åŠMDPï¼‰çš„æ•´ä¸ªè¿‡ç¨‹éƒ½ä¿æŒå¯¹ç§°æ€§ï¼Œå½¢æˆäº†**å¯æ³›åŒ–è¡Œä¸ºå­¦ä¹ **çš„å®Œæ•´é“¾è·¯ã€‚\n\n### **è§£å†³æ–¹æ¡ˆæ€»ç»“**\nè®ºæ–‡é€šè¿‡ **â€œç†è®ºä¿è¯ -> ç›®æ ‡çº¦æŸ -> å…·ä½“å®ç°â€** çš„è·¯å¾„è§£å†³é—®é¢˜ï¼š\n\n1.  **ç†è®ºå¥ åŸº**ï¼šé¦–å…ˆè¯æ˜åœ¨å¯¹ç§°ç¯å¢ƒä¸­ï¼Œæœ€ä¼˜æŠ€èƒ½æœ¬èº«å°±åº”è¯¥æ˜¯å¯¹ç§°çš„ã€‚\n2.  **ç›®æ ‡æ”¹é€ **ï¼šæ®æ­¤ï¼Œå°†æ ‡å‡†çš„æ— ç›‘ç£æŠ€èƒ½å‘ç°ç›®æ ‡ï¼ˆæœ€å¤§åŒ–Wassersteinä¾èµ–ï¼‰æ”¹é€ ä¸º**ç¾¤ä¸å˜ç‰ˆæœ¬**ï¼Œå¼ºåˆ¶ç®—æ³•åœ¨å¯¹ç§°å­ç©ºé—´å†…æœç´¢ã€‚\n3.  **ç®—æ³•å®ç°**ï¼šåˆ©ç”¨**ç¾¤è¡¨ç¤ºè®º**å’Œ**å‚…é‡Œå¶åˆ†æ**ï¼Œè®¾è®¡å‡ºå¤©ç„¶æ»¡è¶³ç¾¤ä¸å˜æ€§è¦æ±‚çš„ç½‘ç»œæ¶æ„ï¼ˆ`Ï†_F`ï¼‰å’Œå¥–åŠ±å‡½æ•°ã€‚\n4.  **æ³›åŒ–æœºåˆ¶**ï¼šåˆ©ç”¨å­¦åˆ°çš„**ç­‰å˜æŠ€èƒ½è¡¨ç¤º**ï¼Œåœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­é€šè¿‡å˜æ¢æŠ€èƒ½å‘é‡ç›´æ¥ç”Ÿæˆæ–°è¡Œä¸ºï¼Œæ— éœ€é‡æ–°å­¦ä¹ ã€‚\n\n### **å®é™…ä»·å€¼**\n*   **æå‡æ ·æœ¬æ•ˆç‡**ï¼šå®éªŒè¡¨æ˜ï¼Œåœ¨Antå’ŒQuadrupedç­‰å…·æœ‰æ—‹è½¬/ç¿»è½¬å¯¹ç§°æ€§çš„è¿åŠ¨ç¯å¢ƒä¸­ï¼ŒGISDæ¯”åŸºçº¿æ–¹æ³•ï¼ˆMETRAï¼‰ä»¥æ›´å°‘çš„æ ·æœ¬å®ç°äº†**æ›´å¹¿çš„çŠ¶æ€ç©ºé—´è¦†ç›–**ã€‚\n*   **å¢å¼ºæ³›åŒ–èƒ½åŠ›**ï¼šå­¦åˆ°çš„æŠ€èƒ½å…·æœ‰æ¸…æ™°çš„å¯¹ç§°ç»“æ„ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿé€šè¿‡ç®€å•çš„æŠ€èƒ½å‘é‡å˜æ¢ï¼Œé€‚åº”ç»è¿‡ç¾¤å˜æ¢çš„ä»»åŠ¡ï¼Œæé«˜äº†**ä¸‹æ¸¸ä»»åŠ¡çš„å­¦ä¹ é€Ÿåº¦**å’Œæœ€ç»ˆæ€§èƒ½ã€‚\n*   **æä¾›å¯è§£é‡Šæ€§**ï¼šå‚…é‡Œå¶ç©ºé—´è¡¨ç¤ºå°†æŠ€èƒ½åˆ†è§£åˆ°ä¸åŒçš„å¯¹ç§°â€œé¢‘ç‡â€åˆ†é‡ï¼Œå…è®¸ç ”ç©¶è€…é€šè¿‡è¿‡æ»¤ç‰¹å®šé¢‘ç‡æ¥åå‘å‘ç°æŸç§ç±»å‹çš„æŠ€èƒ½ï¼ˆå¦‚å®Œå…¨ä¸å˜çš„æˆ–å¯¹æ—‹è½¬æ•æ„Ÿçš„ï¼‰ï¼Œè¿™ä¸ºæŠ€èƒ½å‘ç°æä¾›äº†**æ–°çš„å¯æ§æ€§å’Œè§£é‡Šç»´åº¦**ã€‚\n\n**æ€»è€Œè¨€ä¹‹ï¼Œè¿™ç¯‡è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®æ˜¯å°†ç¾¤å¯¹ç§°æ€§è¿™ä¸€å…ˆéªŒçŸ¥è¯†ï¼Œä»¥ä¸€ç§æœ‰ç†è®ºä¿éšœã€å¯å®ç°ã€ä¸”èƒ½ç›´æ¥ä¿ƒè¿›æ³›åŒ–çš„æ–¹å¼ï¼Œç³»ç»Ÿåœ°æ³¨å…¥åˆ°äº†æ— ç›‘ç£æŠ€èƒ½å‘ç°çš„å…¨æµç¨‹ä¸­ï¼Œä»è€Œæ˜¾è‘—æå‡äº†æ–¹æ³•çš„æ•ˆç‡å’Œæ‰€å­¦æŠ€èƒ½çš„å¯å¤ç”¨æ€§ã€‚**",
            "timestamp": "2026-01-27T15:54:37.155007",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "åŸºäºä»–çš„å‰ä½œï¼Œæ¢³ç†è¿™ä¸ªæ–¹å‘çš„æ•´ä¸ªå‘å±•è„‰ç»œï¼Œæ¯ä¸€æ­¥ç›¸æ¯”äºä¹‹å‰çš„å·¥ä½œéƒ½æ”¹è¿›äº†ä»€ä¹ˆï¼Œç€é‡äºå‡ ä¸ªä¸åŒçš„å‘å±•æ–¹å‘ã€‚",
            "answer": "## è®ºæ–‡å‘å±•è„‰ç»œæ¢³ç†ï¼šä»æ— ç›‘ç£æŠ€èƒ½å‘ç°åˆ°ç¾¤ä¸å˜æŠ€èƒ½å‘ç°\n\næœ¬æ–‡ã€ŠGroup-Invariant Unsupervised Skill Discoveryã€‹æ˜¯æ— ç›‘ç£æŠ€èƒ½å‘ç°é¢†åŸŸçš„ä¸€ä¸ªæœ€æ–°è¿›å±•ï¼Œå®ƒé€šè¿‡**æ˜¾å¼åœ°èå…¥å‡ ä½•å¯¹ç§°æ€§å…ˆéªŒ**æ¥è§£å†³ç°æœ‰æ–¹æ³•åœ¨å¯¹ç§°ç¯å¢ƒä¸­å­¦ä¹ å†—ä½™æŠ€èƒ½ã€æ ·æœ¬æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚è¦ç†è§£å…¶è´¡çŒ®ï¼Œéœ€è¦æ¢³ç†è¯¥é¢†åŸŸä»åŸºç¡€æ–¹æ³•åˆ°å¼•å…¥å„ç§å…ˆéªŒçŸ¥è¯†ï¼Œå†åˆ°æœ¬æ–‡å¼•å…¥å¯¹ç§°æ€§å…ˆéªŒçš„æ•´ä¸ªå‘å±•è„‰ç»œã€‚ä»¥ä¸‹æ˜¯å‡ ä¸ªå…³é”®å‘å±•æ–¹å‘åŠå…¶æ¼”è¿›ï¼š\n\n### å‘å±•æ–¹å‘ä¸€ï¼šä¾èµ–åº¦é‡ä¸ä¼˜åŒ–ç›®æ ‡çš„æ¼”è¿›\n\nè¿™ä¸ªæ–¹å‘çš„æ ¸å¿ƒæ˜¯**å¦‚ä½•å®šä¹‰å’Œæœ€å¤§åŒ–â€œæŠ€èƒ½â€ä¸â€œçŠ¶æ€/è½¨è¿¹â€ä¹‹é—´çš„å…³è”æ€§**ï¼Œä»¥é©±åŠ¨ç­–ç•¥å­¦ä¹ åˆ°å¤šæ ·åŒ–çš„è¡Œä¸ºã€‚\n\n- **1. äº’ä¿¡æ¯æœ€å¤§åŒ– (Mutual Information, MI)**\n    - **ä»£è¡¨å·¥ä½œ**ï¼šDIAYN [9], VIC [14], CIC [20]ã€‚\n    - **æ ¸å¿ƒæ€æƒ³**ï¼šæœ€å¤§åŒ–æŠ€èƒ½ `z` ä¸çŠ¶æ€ `s` ä¹‹é—´çš„äº’ä¿¡æ¯ `I(S; Z)`ã€‚ç›´è§‚ä¸Šï¼Œä¸åŒæŠ€èƒ½åº”å¯¼è‡´ä¸åŒçš„çŠ¶æ€åˆ†å¸ƒã€‚\n    - **æ”¹è¿›ä¸å±€é™**ï¼š\n        - **æ”¹è¿›**ï¼šé¦–æ¬¡ç³»ç»Ÿæ€§åœ°å°†æ— ç›‘ç£æŠ€èƒ½å‘ç°å½¢å¼åŒ–ä¸ºäº’ä¿¡æ¯æœ€å¤§åŒ–é—®é¢˜ï¼Œè¯æ˜äº†å­¦ä¹ å¤šæ ·åŒ–ã€å¯åŒºåˆ†è¡Œä¸ºçš„å¯è¡Œæ€§ã€‚\n        - **å±€é™**ï¼šåŸºäºKLæ•£åº¦çš„ç›®æ ‡å¯èƒ½é¼“åŠ±ç­–ç•¥è®¿é—®æ˜“äºåŒºåˆ†çš„çŠ¶æ€å­é›†ï¼Œè€Œéå¹¿æ³›æ¢ç´¢æ•´ä¸ªçŠ¶æ€ç©ºé—´ï¼Œå¯¼è‡´**çŠ¶æ€è¦†ç›–ç‡æœ‰é™**ã€‚\n\n- **2. è·ç¦»æœ€å¤§åŒ– (Distance Maximization) / ç“¦ç‘Ÿæ–¯å¦ä¾èµ–åº¦é‡ (Wasserstein Dependency Measure, WDM)**\n    - **ä»£è¡¨å·¥ä½œ**ï¼šLSD [26], CSD [27], METRA [28]ã€‚\n    - **æ ¸å¿ƒæ€æƒ³**ï¼šç”¨1-ç“¦ç‘Ÿæ–¯å¦è·ç¦»ï¼ˆå¯¹å¶å½¢å¼ï¼‰æ›¿ä»£äº’ä¿¡æ¯ä¸­çš„KLæ•£åº¦ã€‚å…¶ç›®æ ‡ `I_W(S; Z)` å¯»æ±‚ä¸€ä¸ª1-Lipschitzè¯„åˆ†å‡½æ•° `f(s,z)`ï¼Œä»¥åŒºåˆ†è”åˆåˆ†å¸ƒ `p(s,z)` å’Œè¾¹é™…åˆ†å¸ƒä¹‹ç§¯ `p(s)p(z)`ã€‚\n    - **æ”¹è¿›**ï¼š\n        - **ç†è®ºä¼˜åŠ¿**ï¼šWDMä¸åœ¨æ½œåœ¨ç©ºé—´ä¸­ä¿ç•™ç‰¹å®š**è·ç¦»åº¦é‡**ï¼ˆå¦‚æ—¶åºè·ç¦»ã€å¯æ§æ€§è·ç¦»ï¼‰ç›´æ¥ç›¸å…³ï¼Œèƒ½æ›´è‡ªç„¶åœ°é¼“åŠ±**å¹¿æ³›çš„çŠ¶æ€æ¢ç´¢**ã€‚\n        - **å®è·µä¼˜åŠ¿**ï¼šé€šè¿‡å‚æ•°åŒ– `f(s,z) = Ï†(s)^T Ïˆ(z)` å¹¶åˆ©ç”¨å¯¹å¶ç†è®ºï¼Œå¯ä»¥æ¨å¯¼å‡ºæ˜“äºè®¡ç®—çš„å†…åœ¨å¥–åŠ±ï¼ˆå¦‚ `r_t = (Ï†(s_{t+1}) - Ï†(s_t))^T z`ï¼‰ï¼Œä½¿è®­ç»ƒæ›´ç¨³å®šé«˜æ•ˆã€‚\n    - **æœ¬æ–‡çš„å®šä½**ï¼šGISD **ç›´æ¥å»ºç«‹åœ¨WDMæ¡†æ¶ä¹‹ä¸Š**ï¼ˆç‰¹åˆ«æ˜¯METRAï¼‰ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°ä¸æ˜¯æ”¹å˜ä¾èµ–åº¦é‡æœ¬èº«ï¼Œè€Œæ˜¯**ä¸ºè¯„åˆ†å‡½æ•° `f` å’Œç­–ç•¥ `Ï€` æ–½åŠ äº†å¯¹ç§°æ€§çº¦æŸ**ã€‚\n\n### å‘å±•æ–¹å‘äºŒï¼šèå…¥å…ˆéªŒçŸ¥è¯†ä»¥å¼•å¯¼æŠ€èƒ½å‘ç°\n\nç”±äºçº¯æ— ç›‘ç£å­¦ä¹ å¯èƒ½äº§ç”Ÿæ— æ„ä¹‰æˆ–éš¾ä»¥åˆ©ç”¨çš„æŠ€èƒ½ï¼Œåç»­å·¥ä½œå°è¯•èå…¥å„ç§å…ˆéªŒæ¥å¼•å¯¼æŠ€èƒ½æœå‘æ›´æœ‰ç”¨çš„æ–¹å‘å‘å±•ã€‚\n\n- **1. è¯­è¨€å…ˆéªŒ**\n    - **ä»£è¡¨å·¥ä½œ**ï¼šLGSD [31]ã€‚\n    - **æ ¸å¿ƒæ€æƒ³**ï¼šåˆ©ç”¨è‡ªç„¶è¯­è¨€æè¿°ï¼ˆå¦‚â€œå‘å‰è·‘â€ã€â€œå‘å·¦è½¬â€ï¼‰æ¥å®šä¹‰æŠ€èƒ½ç©ºé—´ä¸­çš„è¯­ä¹‰è·ç¦»ã€‚æŠ€èƒ½å‘ç°çš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–ä¸åŒæŠ€èƒ½äº§ç”Ÿçš„è½¨è¿¹åœ¨è¯­è¨€åµŒå…¥ç©ºé—´ä¸­çš„è·ç¦»ã€‚\n    - **æ”¹è¿›**ï¼šå°†äººç±»å…ˆéªŒçŸ¥è¯†é€šè¿‡è¯­è¨€å¼•å…¥ï¼Œä½¿å‘ç°çš„æŠ€èƒ½å…·æœ‰**è¯­ä¹‰å¯è§£é‡Šæ€§**ï¼Œå¹¶ä¸é«˜å±‚ä»»åŠ¡æŒ‡ä»¤æ›´æ˜“å¯¹é½ã€‚\n\n- **2. è¡Œä¸ºåå¥½å…ˆéªŒ**\n    - **ä»£è¡¨å·¥ä½œ**ï¼šDoâ€™s and Donâ€™ts [17]ã€‚\n    - **æ ¸å¿ƒæ€æƒ³**ï¼šåˆ©ç”¨ç¤ºèŒƒè§†é¢‘ï¼ˆâ€œè¯¥åšä»€ä¹ˆâ€ï¼‰å’Œåä¾‹è§†é¢‘ï¼ˆâ€œä¸è¯¥åšä»€ä¹ˆâ€ï¼‰æ¥å­¦ä¹ ä¸€ä¸ªåå¥½æ¨¡å‹ï¼Œå¹¶ä»¥æ­¤ä½œä¸ºå†…åœ¨å¥–åŠ±æ¥å¼•å¯¼æŠ€èƒ½å‘ç°ã€‚\n    - **æ”¹è¿›**ï¼šä½¿æŠ€èƒ½å‘ç°è¿‡ç¨‹åå‘äºå­¦ä¹ **å¯è¡Œã€å®‰å…¨ä¸”ç¬¦åˆäººç±»æœŸæœ›**çš„è¡Œä¸ºæ¨¡å¼ï¼Œé¿å…äº†å±é™©æˆ–æ— æ•ˆçš„æŠ€èƒ½ã€‚\n\n- **3. å‡ ä½•å¯¹ç§°æ€§å…ˆéªŒï¼ˆæœ¬æ–‡çš„æ ¸å¿ƒè´¡çŒ®ï¼‰**\n    - **ä»£è¡¨å·¥ä½œ**ï¼š**Group-Invariant Skill Discovery (GISD)**ã€‚\n    - **æ ¸å¿ƒæ€æƒ³**ï¼šè¯†åˆ«å¹¶åˆ©ç”¨ç‰©ç†ç¯å¢ƒï¼ˆå¦‚æœºå™¨äºº locomotionï¼‰ä¸­å›ºæœ‰çš„**å‡ ä½•å¯¹ç§°æ€§**ï¼ˆå¦‚æ—‹è½¬ã€ç¿»è½¬ï¼‰ã€‚æœ¬æ–‡è¯æ˜ï¼Œåœ¨ç¾¤ä¸å˜MDPä¸­ï¼Œæ ‡å‡†çš„WDMæœ€ä¼˜è§£å¤©ç„¶åŒ…å«ä¸€ä¸ª**ç­‰å˜ç­–ç•¥**å’Œä¸€ä¸ª**ç¾¤ä¸å˜è¯„åˆ†å‡½æ•°**ã€‚\n    - **æ”¹è¿›**ï¼š\n        1.  **ç†è®ºåˆ›æ–°**ï¼šæä¾›äº†åœ¨å¯¹ç§°ç¯å¢ƒä¸‹ï¼Œé™åˆ¶æœç´¢ç©ºé—´åˆ°ç­‰å˜ç­–ç•¥å’Œä¸å˜è¯„åˆ†å‡½æ•°**ä¸ä¼šæŸå¤±æœ€ä¼˜æ€§**çš„ä¸¥æ ¼è¯æ˜ï¼ˆ**Theorem 1**ï¼‰ã€‚è¿™ä¸ºæ–¹æ³•æä¾›äº†åšå®çš„ç†è®ºåŸºç¡€ã€‚\n        2.  **æ–¹æ³•åˆ›æ–°**ï¼šæå‡ºäº†**ç¾¤ä¸å˜ç“¦ç‘Ÿæ–¯å¦ä¾èµ–åº¦é‡**ï¼Œé€šè¿‡**ç¾¤å¹³å‡**æ“ä½œæ˜¾å¼æ„é€ ç¾¤ä¸å˜è¯„åˆ†å‡½æ•°ï¼Œå¹¶åˆ©ç”¨**ç¾¤å‚…é‡Œå¶è¡¨ç¤º**è¿›è¡Œå‚æ•°åŒ–ã€‚è¿™ç¡®ä¿äº†å­¦åˆ°çš„æŠ€èƒ½è¡¨å¾æœ¬èº«ç¼–ç äº†å¯¹ç§°æ€§ã€‚\n        3.  **æ•ˆæœæå‡**ï¼š\n            - **æ¶ˆé™¤å†—ä½™**ï¼šé¿å…å­¦ä¹ ä»…åœ¨ç¾¤å˜æ¢ä¸‹ç­‰ä»·çš„é‡å¤æŠ€èƒ½ï¼Œå¤§å¹…æå‡**æ ·æœ¬æ•ˆç‡**ã€‚\n            - **æå‡è¦†ç›–ç‡**ï¼šå¯¹ç§°æ€§çº¦æŸå¼•å¯¼æŠ€èƒ½æ›´ç³»ç»Ÿåœ°è¦†ç›–çŠ¶æ€ç©ºé—´çš„ä¸åŒå¯¹ç§°æ¨¡å¼ï¼ˆå¦‚å›¾4æ‰€ç¤ºï¼‰ã€‚\n            - **ä¿ƒè¿›æ³›åŒ–**ï¼šå­¦åˆ°çš„å‚…é‡Œå¶ç©ºé—´æŠ€èƒ½è¡¨å¾å…è®¸é€šè¿‡ç®€å•çš„ç¾¤å˜æ¢ï¼ˆå¦‚æ—‹è½¬æŠ€èƒ½å‘é‡ `z`ï¼‰å°†æŠ€èƒ½**ç³»ç»Ÿæ€§åœ°æ³›åŒ–**åˆ°æ–°çš„ä½å§¿ï¼Œæå¤§æå‡äº†ä¸‹æ¸¸ä»»åŠ¡çš„é€‚åº”æ•ˆç‡ï¼ˆ**Theorem 2**ï¼‰ã€‚\n\n### å‘å±•æ–¹å‘ä¸‰ï¼šå¯¹ç§°æ€§åœ¨å¼ºåŒ–å­¦ä¹ ä¸­çš„åº”ç”¨\n\næœ¬æ–‡ä¹Ÿéš¶å±äºå°†ç¾¤ç­‰å˜æ€§å¼•å…¥å¼ºåŒ–å­¦ä¹ ä»¥æå‡æ•ˆç‡ä¸æ³›åŒ–èƒ½åŠ›çš„ç ”ç©¶è„‰ç»œã€‚\n\n- **æ—©æœŸåº”ç”¨**ï¼šå°†ç­‰å˜ç½‘ç»œï¼ˆå¦‚ç­‰å˜CNNã€SE(3)-Transformerï¼‰åº”ç”¨äºæœºå™¨äººè§†è§‰å’Œæ“æ§ä»»åŠ¡ [12, 13, 16, 49]ï¼Œä¸»è¦æ”¹å–„**æ„ŸçŸ¥æ¨¡å—**çš„æ ·æœ¬æ•ˆç‡å’Œæ³›åŒ–æ€§ã€‚\n- **æ·±åŒ–åˆ°å†³ç­–ä¸æ§åˆ¶**ï¼šæå‡º**ç¾¤ä¸å˜MDP** [45, 46] å’Œ**éƒ¨åˆ†ç­‰å˜**ç­–ç•¥ [6] ç­‰æ¡†æ¶ï¼Œå°†å¯¹ç§°æ€§ä»æ„ŸçŸ¥æ‰©å±•åˆ°**ä»·å€¼å‡½æ•°ã€ç­–ç•¥å’ŒåŠ¨æ€æ¨¡å‹**çš„å±‚é¢ã€‚\n- **æœ¬æ–‡çš„æ¨è¿›**ï¼šé¦–æ¬¡å°†ç¾¤ç­‰å˜æ€§ç³»ç»Ÿåœ°æ•´åˆåˆ°**æ— ç›‘ç£æŠ€èƒ½å‘ç°**è¿™ä¸€**è¡¨å¾å­¦ä¹ **é˜¶æ®µã€‚å®ƒä¸ä»…ä½¿ç”¨äº†ç­‰å˜ç­–ç•¥ç½‘ç»œï¼Œæ›´é‡è¦çš„æ˜¯ï¼Œå®ƒè®¾è®¡äº†ä¸€ä¸ª**ç­‰å˜çš„æŠ€èƒ½è¡¨å¾ç©ºé—´**ï¼ˆå‚…é‡Œå¶ç©ºé—´ï¼‰ï¼Œä½¿å¾—æŠ€èƒ½å‘ç°è¿‡ç¨‹å’Œå­¦åˆ°çš„æŠ€èƒ½åº“æœ¬èº«éƒ½å…·æœ‰å¯¹ç§°æ€§ã€‚è¿™è¿æ¥äº†è¡¨å¾å­¦ä¹ ä¸å†³ç­–æ§åˆ¶ï¼Œå®ç°äº†ç«¯åˆ°ç«¯çš„å¯¹ç§°æ€§åˆ©ç”¨ã€‚\n\n### æ€»ç»“è„‰ç»œå›¾\n\n```mermaid\ngraph TD\n    A[åŸºç¡€: äº’ä¿¡æ¯æœ€å¤§åŒ–<br>DIAYN, VIC] --> B[æ ¸å¿ƒæ¡†æ¶æ¼”è¿›: è·ç¦»æœ€å¤§åŒ–/WDM<br>LSD, CSD, METRA]ï¼›\n\n    B --> C1[å‘å±•æ–¹å‘1: èå…¥è¯­è¨€å…ˆéªŒ<br>LGSD]ï¼›\n    B --> C2[å‘å±•æ–¹å‘2: èå…¥è¡Œä¸ºåå¥½å…ˆéªŒ<br>Doâ€˜s and Donâ€™ts]ï¼›\n    B --> C3[å‘å±•æ–¹å‘3: èå…¥å‡ ä½•å¯¹ç§°æ€§å…ˆéªŒ<br>**GISD (æœ¬æ–‡)**]ï¼›\n\n    D[ç›¸å…³é¢†åŸŸ: å¼ºåŒ–å­¦ä¹ ä¸­çš„ç­‰å˜æ€§<br>ç¾¤ä¸å˜MDP, ç­‰å˜SAC] --> C3ï¼›\n\n    C3 -- ç›¸æ¯”äºä¹‹å‰æ‰€æœ‰å·¥ä½œ --> E[**æ ¸å¿ƒæ”¹è¿›**ï¼š<br>1. **ç†è®ºä¿è¯**æœ€ä¼˜å¯¹ç§°è§£å­˜åœ¨<br>2. **æ–¹æ³•ä¸Šæ˜¾å¼ç¼–ç å¯¹ç§°æ€§**è‡³æŠ€èƒ½è¡¨å¾<br>3. **æ•ˆæœä¸Š**å…¼é¡¾å¤šæ ·æ€§ã€æ•ˆç‡ä¸ç³»ç»Ÿæ€§æ³›åŒ–]ï¼›\n```\n\n**ç»“è®º**ï¼šæœ¬æ–‡ä»£è¡¨äº†æ— ç›‘ç£æŠ€èƒ½å‘ç°é¢†åŸŸä¸€ä¸ªé‡è¦çš„èŒƒå¼è½¬å˜â€”â€”ä»å°†çŠ¶æ€ç©ºé—´è§†ä¸ºéç»“æ„åŒ–çš„ã€æˆ–ä¾èµ–å¤–éƒ¨è¯­ä¹‰å…ˆéªŒï¼Œè½¬å‘**æŒ–æ˜å’Œåˆ©ç”¨ç¯å¢ƒå†…åœ¨çš„ç‰©ç†ç»“æ„å…ˆéªŒï¼ˆå¯¹ç§°æ€§ï¼‰**ã€‚å®ƒé€šè¿‡ä¸¥è°¨çš„ç¾¤è®ºæ¡†æ¶ï¼Œå°†å¯¹ç§°æ€§ä»ç­–ç•¥ç½‘ç»œè®¾è®¡æå‡åˆ°äº†æŠ€èƒ½è¡¨å¾å­¦ä¹ çš„ç›®æ ‡å‡½æ•°å±‚é¢ï¼Œä»è€Œåœ¨æ ·æœ¬æ•ˆç‡ã€çŠ¶æ€è¦†ç›–å’Œæ³›åŒ–èƒ½åŠ›ä¸Šå®ç°äº†æ˜¾è‘—æå‡ï¼Œä¸ºåœ¨æ›´å¤æ‚çš„å¯¹ç§°ç¯å¢ƒï¼ˆå¦‚äººå½¢æœºå™¨äººã€æœºæ¢°è‡‚æ“ä½œï¼‰ä¸­å­¦ä¹ å¯é‡ç”¨æŠ€èƒ½åº“å¼€è¾Ÿäº†æ–°è·¯å¾„ã€‚",
            "timestamp": "2026-01-27T15:55:42.603210",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "ä»–çš„å‰ä½œæœ‰å“ªäº›ï¼Ÿä½¿ç”¨è¡¨æ ¼ä»”ç»†è®²è®²ä»–çš„æ¯ç¯‡å‰ä½œï¼Œä»–å’Œå‰ä½œçš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Œä¸»è¦æ”¹å–„æ˜¯ä»€ä¹ˆï¼Ÿç€é‡äºå…·ä½“ç›¸æ¯”äºä¹‹å‰æ–‡ç« çš„æ”¹åŠ¨",
            "answer": "## å‰ä½œæ¢³ç†ä¸å¯¹æ¯”åˆ†æ\n\næ ¹æ®è®ºæ–‡å†…å®¹ï¼Œä½œè€…å›¢é˜Ÿï¼ˆç‰¹åˆ«æ˜¯é€šè®¯ä½œè€…Jongeun Choiå’ŒJongmin Leeï¼‰åœ¨**ç¾¤ç­‰å˜æ€§å¼ºåŒ–å­¦ä¹ **å’Œ**æ— ç›‘ç£æŠ€èƒ½å‘ç°**é¢†åŸŸæœ‰ä¸€ç³»åˆ—å‰æœŸå·¥ä½œã€‚ä»¥ä¸‹æ˜¯åŸºäºè®ºæ–‡å¼•ç”¨æ¢³ç†å‡ºçš„ä¸»è¦å‰ä½œï¼Œå¹¶ä»¥è¡¨æ ¼å½¢å¼è¿›è¡Œè¯¦ç»†å¯¹æ¯”ï¼Œé‡ç‚¹åˆ†ææœ¬æ–‡ï¼ˆGISDï¼‰ç›¸å¯¹äºæ¯ç¯‡å‰ä½œçš„**å…·ä½“æ”¹åŠ¨ä¸æ ¸å¿ƒæ”¹å–„**ã€‚\n\n| å‰ä½œæ ‡é¢˜ | å‘è¡¨å¹´ä»½/å‡ºå¤„ | æ ¸å¿ƒè´¡çŒ® | ä¸æœ¬æ–‡ï¼ˆGISDï¼‰çš„åŒºåˆ«ä¸ä¸»è¦æ”¹å–„ |\n| :--- | :--- | :--- | :--- |\n| **Equivariant $Q$ Learning in Spatial Action Spaces** [46] | 2022, CoRL | é¦–æ¬¡å°†**ç¾¤ç­‰å˜æ€§**ç³»ç»Ÿæ€§åœ°å¼•å…¥æ·±åº¦Qå­¦ä¹ ï¼Œæå‡ºäº†**ç­‰å˜æ€§SAC**æ¡†æ¶ã€‚å®šä¹‰äº†**ç¾¤ä¸å˜MDP**ï¼Œè¯æ˜äº†åœ¨å¯¹ç§°ç¯å¢ƒä¸‹æœ€ä¼˜ç­–ç•¥å¯ä»¥æ˜¯ç­‰å˜çš„ã€‚ | **åŒºåˆ«**ï¼šå‰ä½œä¸“æ³¨äº**æœ‰ç›‘ç£çš„ã€åŸºäºå€¼å‡½æ•°çš„RL**ï¼ˆè§£å†³ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡ï¼‰ã€‚æœ¬æ–‡ä¸“æ³¨äº**æ— ç›‘ç£çš„ã€åŸºäºæŠ€èƒ½å‘ç°çš„é¢„è®­ç»ƒ**ã€‚<br>**æ”¹å–„**ï¼šæœ¬æ–‡**å°†ç¾¤ç­‰å˜æ€§åŸç†ä»ä¸‹æ¸¸ç­–ç•¥å­¦ä¹ ï¼Œå‰ç½®å¹¶æ•´åˆåˆ°äº†æ— ç›‘ç£æŠ€èƒ½å‘ç°é˜¶æ®µ**ã€‚åˆ©ç”¨[46]ä¸­å®šä¹‰çš„ç¾¤ä¸å˜MDPæ¡†æ¶ï¼Œä¸ºæŠ€èƒ½å‘ç°è¿‡ç¨‹æä¾›äº†ç†è®ºä¿è¯ï¼ˆTheorem 1ï¼‰ï¼Œå¹¶æœ€ç»ˆä½¿ç”¨ç­‰å˜æ€§SACè®­ç»ƒæŠ€èƒ½ç­–ç•¥ã€‚æœ¬æ–‡æ˜¯**å°†å¯¹ç§°æ€§å…ˆéªŒä»â€œç­–ç•¥å­¦ä¹ â€æ‰©å±•åˆ°â€œè¡¨ç¤ºå­¦ä¹ /æŠ€èƒ½å‘ç°â€**ã€‚ |\n| **SO(2)-Equivariant Reinforcement Learning** [45] | 2022, arXiv | æ›´æ—©åœ°å½¢å¼åŒ–äº†**SO(2)ç­‰å˜æ€§RL**é—®é¢˜ï¼Œä¸º[46]æä¾›äº†ç†è®ºåŸºç¡€ã€‚ä¾§é‡äºç†è®ºæ¡†æ¶æ„å»ºã€‚ | **åŒºåˆ«**ï¼šå‰ä½œæ˜¯æ›´åç†è®ºçš„å½¢å¼åŒ–å·¥ä½œã€‚æœ¬æ–‡æ˜¯å®Œæ•´çš„**æ–¹æ³•+å®éªŒ**æ¡†æ¶ã€‚<br>**æ”¹å–„**ï¼šæœ¬æ–‡**å…·ä½“åŒ–äº†ç†è®ºçš„åº”ç”¨åœºæ™¯**â€”â€”æ— ç›‘ç£æŠ€èƒ½å‘ç°ã€‚æå‡ºäº†**ç¾¤ä¸å˜Wassersteinä¾èµ–åº¦é‡ï¼ˆGIWDMï¼‰**è¿™ä¸€æ–°ç›®æ ‡å‡½æ•°ï¼Œå¹¶å°†ç†è®ºï¼ˆæœ€ä¼˜è§£å…·æœ‰ç­‰å˜ç­–ç•¥å’Œä¸å˜è¯„åˆ†å‡½æ•°ï¼‰è½¬åŒ–ä¸ºå¯ä¼˜åŒ–çš„å®è·µï¼ˆåœ¨ç¾¤å‚…é‡Œå¶ç©ºé—´å‚æ•°åŒ–è¯„åˆ†å‡½æ•°ï¼‰ã€‚ |\n| **Partially Equivariant Reinforcement Learning in Symmetry-Breaking Environments** [6] | 2025, arXiv | é’ˆå¯¹ç°å®ç¯å¢ƒä¸­å¯¹ç§°æ€§è¢«éƒ¨åˆ†ç ´åçš„é—®é¢˜ï¼ˆå¦‚æ¥è§¦åŠ›å­¦ä¸å¯¹ç§°ï¼‰ï¼Œæå‡ºäº†**éƒ¨åˆ†ç­‰å˜æ€§SACï¼ˆPE-SACï¼‰**ï¼Œé€šè¿‡å¯å­¦ä¹ çš„ç¾¤è¡¨ç¤ºæ¥å¹³è¡¡ç­‰å˜æ€§ä¸çµæ´»æ€§ã€‚ | **åŒºåˆ«**ï¼šå‰ä½œå…³æ³¨**å¯¹ç§°æ€§ä¸å®Œç¾**çš„ç¯å¢ƒï¼Œæ—¨åœ¨æå‡é²æ£’æ€§ã€‚æœ¬æ–‡åœ¨å®éªŒä¸­å‡è®¾ç¯å¢ƒå…·æœ‰å®Œç¾å¯¹ç§°æ€§ï¼ˆæˆ–é€šè¿‡è®¾è®¡ä½¿å…¶å¯¹ç§°ï¼‰ã€‚<br>**æ”¹å–„ä¸è”ç³»**ï¼šæœ¬æ–‡åœ¨**çŠ¶æ€Antå®éªŒ**ä¸­ç›´æ¥ä½¿ç”¨äº†[6]çš„PE-SACä½œä¸ºç­–ç•¥ä¼˜åŒ–å™¨ï¼Œä»¥å¤„ç†MuJoCoç¯å¢ƒä¸­å¯èƒ½å­˜åœ¨çš„å¾®å°ä¸å¯¹ç§°æ€§ã€‚è¿™è¡¨æ˜æœ¬æ–‡æ–¹æ³•**èƒ½å…¼å®¹æœ€æ–°çš„éƒ¨åˆ†ç­‰å˜æ¶æ„**ï¼Œæå‡äº†å®é™…åº”ç”¨çš„ç¨³å¥æ€§ã€‚æœ¬æ–‡çš„æ ¸å¿ƒåˆ›æ–°åœ¨æŠ€èƒ½å‘ç°ç›®æ ‡ï¼Œè€Œç­–ç•¥è®­ç»ƒå™¨å¯ä»¥æ¨¡å—åŒ–åœ°é€‰ç”¨[46]æˆ–[6]ã€‚ |\n| **METRA: Scalable Unsupervised RL with Metric-Aware Abstraction** [28] | 2023, arXiv | æå‡ºäº†**è·ç¦»æœ€å¤§åŒ–æ— ç›‘ç£æŠ€èƒ½å‘ç°**çš„SOTAåŸºçº¿ã€‚ä½¿ç”¨Wassersteinä¾èµ–åº¦é‡ï¼ˆWDMï¼‰ï¼Œé€šè¿‡åº¦é‡æ„ŸçŸ¥çš„æŠ½è±¡æ¥å‘ç°æŠ€èƒ½ï¼Œåœ¨è¦†ç›–èŒƒå›´å’Œä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚ | **åŒºåˆ«**ï¼šå‰ä½œæ˜¯**éç­‰å˜çš„ã€é€šç”¨çš„**æŠ€èƒ½å‘ç°æ–¹æ³•ï¼Œå°†çŠ¶æ€ç©ºé—´è§†ä¸ºéç»“æ„åŒ–çš„ã€‚<br>**æ”¹å–„**ï¼šæœ¬æ–‡æ˜¯**å¯¹METRAæ¡†æ¶çš„å¯¹ç§°æ€§ç‰¹åŒ–æ”¹è¿›**ï¼š<br>1. **ç†è®ºå±‚é¢**ï¼šè¯æ˜äº†åœ¨å¯¹ç§°ç¯å¢ƒä¸‹ï¼ŒWDMçš„æœ€ä¼˜è§£æœ¬èº«å…·æœ‰ç­‰å˜æ€§ï¼ˆTheorem 1ï¼‰ï¼Œä»è€Œä¸ºå¼•å…¥å¯¹ç§°æ€§çº¦æŸæä¾›äº†ä¾æ®ã€‚<br>2. **ç›®æ ‡å‡½æ•°**ï¼šå°†METRAçš„WDMçº¦æŸä¸º**ç¾¤ä¸å˜WDMï¼ˆGIWDMï¼‰**ï¼Œæ˜¾å¼åœ°å°†å¯¹ç§°æ€§ä½œä¸ºå½’çº³åç½®æ³¨å…¥ä¼˜åŒ–è¿‡ç¨‹ï¼Œé¿å…äº†å­¦ä¹ å†—ä½™çš„ã€ä»…åœ¨ç¾¤å˜æ¢ä¸‹ä¸åŒçš„æŠ€èƒ½ã€‚<br>3. **è¡¨ç¤ºå±‚é¢**ï¼šç”¨**ç¾¤å‚…é‡Œå¶ç©ºé—´ç‰¹å¾** `Ï•_F(s)` æ›¿ä»£METRAä¸­é€šç”¨çš„æ½œåœ¨æ˜ å°„`Ï•(s)`ï¼Œä½¿æŠ€èƒ½è¡¨ç¤ºå¤©ç”Ÿå…·æœ‰å¯¹ç§°ç»“æ„ã€‚<br>4. **æ³›åŒ–æ€§**ï¼šå­¦åˆ°çš„å‚…é‡Œå¶ç©ºé—´æŠ€èƒ½`z`å¯ä»¥é€šè¿‡ç¾¤ä½œç”¨`gÂ·z`è¿›è¡Œå˜æ¢ï¼Œä»è€Œ**ç³»ç»Ÿæ€§åœ°æ³›åŒ–åˆ°æ–°çš„å¯¹ç§°é…ç½®**ï¼Œè¿™æ˜¯METRAä¸å…·å¤‡çš„ç‰¹æ€§ã€‚ |\n| **Lipschitz-Constrained Unsupervised Skill Discovery** [26] / **Controllability-Aware Unsupervised Skill Discovery** [27] | 2022, ICLR / 2023, arXiv | è¿™ä¸¤ç¯‡æ˜¯è·ç¦»æœ€å¤§åŒ–æŠ€èƒ½å‘ç°çš„æ—©æœŸå·¥ä½œï¼Œ[26]å¼•å…¥Lipschitzçº¦æŸï¼Œ[27]å¼•å…¥å¯æ§æ€§è·ç¦»å…ˆéªŒã€‚å®ƒä»¬éƒ½æ˜¯METRA[28]çš„å‰èº«ã€‚ | **åŒºåˆ«**ï¼šå‰ä½œæ˜¯æ›´æ—©çš„æŠ€èƒ½å‘ç°æ–¹æ³•ï¼Œå°šæœªè¾¾åˆ°METRAçš„æˆç†Ÿåº¦ã€‚<br>**æ”¹å–„**ï¼šæœ¬æ–‡çš„å¯¹æ¯”åŸºå‡†å’Œç®—æ³•æ¡†æ¶ä¸»è¦åŸºäºæ›´å…ˆè¿›çš„METRA[28]ã€‚ç›¸å¯¹äº[26,27]ï¼Œæœ¬æ–‡çš„æ”¹å–„ä¸ä¸Šè¿°ç›¸å¯¹äºMETRAçš„æ”¹å–„ä¸€è‡´ï¼Œå³**å¼•å…¥äº†ç¾¤å¯¹ç§°æ€§è¿™ä¸€æ›´æ ¹æœ¬çš„å‡ ä½•å…ˆéªŒ**ï¼Œæ›¿ä»£æˆ–å¢å¼ºäº†å®ƒä»¬ä½¿ç”¨çš„Lipschitzæˆ–å¯æ§æ€§ç­‰å…ˆéªŒï¼Œåœ¨å…·æœ‰å¯¹ç§°æ€§çš„ç¯å¢ƒä¸­æ•ˆç‡æ›´é«˜ã€‚ |\n\n## æ€»ç»“ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ¼”è¿›è·¯å¾„\n\næœ¬æ–‡çš„å·¥ä½œå»ºç«‹åœ¨ä½œè€…å›¢é˜Ÿä¸¤æ¡ç ”ç©¶ä¸»çº¿çš„**äº¤å‰ç‚¹ä¸Š**ï¼š\n\n1.  **ä¸»çº¿ä¸€ï¼ˆå¯¹ç§°æ€§RLï¼‰**ï¼š`[45] -> [46] -> [6]`ã€‚è¿™æ¡çº¿ä»ç†è®ºå½¢å¼åŒ–[45]ï¼Œåˆ°æå‡ºå®ç”¨çš„ç­‰å˜æ€§SACç®—æ³•[46]ï¼Œå†åˆ°å¢å¼ºé²æ£’æ€§å¤„ç†éƒ¨åˆ†å¯¹ç§°[6]ã€‚\n2.  **ä¸»çº¿äºŒï¼ˆæ— ç›‘ç£æŠ€èƒ½å‘ç°ï¼‰**ï¼š`[26] -> [27] -> [28] (METRA)`ã€‚è¿™æ¡çº¿ä»æ—©æœŸè·ç¦»æœ€å¤§åŒ–æ–¹æ³•[26,27]ï¼Œå‘å±•åˆ°SOTAçš„METRAæ¡†æ¶[28]ã€‚\n\n**æœ¬æ–‡ï¼ˆGISDï¼‰çš„ç‹¬åˆ›æ€§åœ¨äº**ï¼š\n-   **ç†è®ºäº¤å‰**ï¼šå°†**ä¸»çº¿ä¸€**çš„**ç¾¤ä¸å˜MDPç†è®º**åº”ç”¨äº**ä¸»çº¿äºŒ**çš„**æ— ç›‘ç£æŠ€èƒ½å‘ç°é—®é¢˜**ï¼Œè¯æ˜äº†æœ€ä¼˜æŠ€èƒ½å‘ç°è§£å…·æœ‰å¯¹ç§°æ€§ï¼ˆTheorem 1ï¼‰ã€‚\n-   **æ–¹æ³•åˆ›æ–°**ï¼šåŸºäºè¯¥ç†è®ºï¼Œè®¾è®¡äº†**ç¾¤ä¸å˜WDMï¼ˆGIWDMï¼‰ç›®æ ‡**å’Œ**ç¾¤å‚…é‡Œå¶ç©ºé—´å‚æ•°åŒ–**ï¼Œåœ¨METRAçš„æ¡†æ¶å†…åµŒå…¥äº†å¯¹ç§°æ€§çº¦æŸã€‚\n-   **ä»·å€¼æå‡**ï¼šç”±æ­¤äº§ç”Ÿçš„æŠ€èƒ½**éå†—ä½™ã€è¦†ç›–æ›´å¹¿ã€ä¸”å…·æœ‰ç³»ç»Ÿæ€§æ³›åŒ–èƒ½åŠ›**ï¼ˆé€šè¿‡å˜æ¢æŠ€èƒ½å‘é‡`z`å³å¯é€‚åº”æ–°çš„å¯¹ç§°çŠ¶æ€ï¼‰ã€‚è¿™è§£å†³äº†ç°æœ‰æŠ€èƒ½å‘ç°æ–¹æ³•åœ¨å¯¹ç§°ç¯å¢ƒä¸­â€œé‡å¤é€ è½®å­â€çš„æ ·æœ¬æ•ˆç‡ä½ä¸‹é—®é¢˜ã€‚\n\nç®€è¨€ä¹‹ï¼Œæœ¬æ–‡ä¸æ˜¯ç®€å•åœ°åº”ç”¨ç­‰å˜ç½‘ç»œï¼Œè€Œæ˜¯**ä»ä¼˜åŒ–ç›®æ ‡çš„ç†è®ºæ ¹æºä¸Šé‡æ–°å½¢å¼åŒ–äº†å¯¹ç§°ç¯å¢ƒä¸‹çš„æŠ€èƒ½å‘ç°é—®é¢˜**ï¼Œå¹¶ç»™å‡ºäº†ä¸€ä¸ªä¼˜é›…çš„ã€åŸºäºç¾¤è¡¨ç¤ºçš„å®ç°æ–¹æ¡ˆï¼Œä»è€Œåœ¨æ ·æœ¬æ•ˆç‡ã€è¦†ç›–ç‡å’Œæ³›åŒ–æ€§ä¸Šå®ç°äº†æ˜¾è‘—æå‡ã€‚",
            "timestamp": "2026-01-27T15:56:39.856979",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "è®ºæ–‡æå‡ºäº†å“ªäº›å…³é”®æŠ€æœ¯æ–¹æ³•ï¼Œè¯·åˆ—è¡¨æ ¼å…·ä½“è¯¦ç»†è¯´æ˜æŠ€æœ¯ç»†èŠ‚ï¼Œéœ€è¦åŒ…å«å…·ä½“çš„æ•°å­¦åŸç†æ¨å¯¼ï¼Œä»¥åŠå…·ä½“å‚æ•°ã€‚",
            "answer": "## è®ºæ–‡å…³é”®æŠ€æœ¯æ–¹æ³•åˆ†æ\n\næœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º**ç¾¤ä¸å˜æ— ç›‘ç£æŠ€èƒ½å‘ç°ï¼ˆGroup-Invariant Skill Discovery, GISDï¼‰** çš„æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ˜¯é€šè¿‡å°†ç¯å¢ƒçš„å‡ ä½•å¯¹ç§°æ€§ï¼ˆç¾¤ç»“æ„ï¼‰æ˜¾å¼åœ°åµŒå…¥åˆ°æŠ€èƒ½å‘ç°çš„ç›®æ ‡å‡½æ•°å’Œè¡¨ç¤ºä¸­ï¼Œä»¥æé«˜æ ·æœ¬æ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚ä»¥ä¸‹æ˜¯å…¶å…³é”®æŠ€æœ¯æ–¹æ³•çš„è¯¦ç»†è¯´æ˜ã€‚\n\n### å…³é”®æŠ€æœ¯æ–¹æ³•åˆ—è¡¨\n\n| æ–¹æ³•åç§° | æ ¸å¿ƒæ€æƒ³ | æŠ€æœ¯ç»†èŠ‚ä¸æ•°å­¦åŸç† | å…·ä½“å‚æ•°ä¸å®ç° |\n| :--- | :--- | :--- | :--- |\n| **1. ç¾¤ä¸å˜Wassersteinä¾èµ–åº¦é‡** | å°†æ ‡å‡†Wassersteinä¾èµ–åº¦é‡ï¼ˆWDMï¼‰çš„ä¼˜åŒ–ç©ºé—´é™åˆ¶åœ¨**ç¾¤ä¸å˜è¯„åˆ†å‡½æ•°**çš„å­ç©ºé—´ä¸Šï¼Œä»¥æ¶ˆé™¤å¯¹ç§°ç¯å¢ƒä¸­çš„å†—ä½™è§£ã€‚ | **æ•°å­¦åŸç†**ï¼š<br>1. **æ ‡å‡†WDM**ï¼š<br>   `I_ğ’²(ğ’®; Z) = sup_{â€–fâ€–_L â‰¤ 1} (ğ”¼_{p(s,z)}[f(s,z)] - ğ”¼_{p(s)p(z)}[f(s,z)])`<br>   å…¶ä¸­ `f(s,z)` æ˜¯1-Lipschitzè¯„åˆ†å‡½æ•°ã€‚<br>2. **ç¾¤ä¸å˜çº¦æŸ**ï¼šå®šä¹‰ç¾¤ä¸å˜è¯„åˆ†å‡½æ•°ç±» `â„±_G`ï¼š<br>   `â„±_G := {f | â€–fâ€–_L â‰¤ 1, f(gs, gz) = f(s, z), âˆ€g âˆˆ G}`<br>3. **ç¾¤ä¸å˜WDM (GIWDM)**ï¼š<br>   `I_ğ’²^G(ğ’®; Z) := sup_{f âˆˆ â„±_G} (ğ”¼_{p(s,z)}[f(s,z)] - ğ”¼_{p(s)p(z)}[f(s,z)])`<br>**ç†è®ºä¿è¯ï¼ˆå®šç†1ï¼‰**ï¼šåœ¨ç¾¤ä¸å˜MDPä¸­ï¼Œæ ‡å‡†WDMçš„å…¨å±€æœ€ä¼˜è§£åŒ…å«ä¸€ä¸ª**ç­‰å˜ç­–ç•¥**å’Œä¸€ä¸ª**ç¾¤ä¸å˜è¯„åˆ†å‡½æ•°**ã€‚å› æ­¤ï¼Œå°†æœç´¢é™åˆ¶åœ¨ `â„±_G` å†…ä¸ä¼šæŸå¤±æœ€ä¼˜æ€§ã€‚ | **å…³é”®å‚æ•°**ï¼š<br>- **å¯¹ç§°ç¾¤ G**ï¼šåœ¨å®éªŒä¸­ä¸»è¦ä½¿ç”¨ç¦»æ•£å¾ªç¯ç¾¤ `C_4`ï¼ˆ90Â°æ—‹è½¬ï¼‰å’Œ `C_2`ï¼ˆæ°´å¹³ç¿»è½¬ï¼‰ã€‚<br>- **è·ç¦»åº¦é‡ d**ï¼šé‡‡ç”¨**æ—¶é—´è·ç¦»** `d_T`ï¼Œè¯¥åº¦é‡åœ¨ç¾¤ä¸å˜MDPä¸‹è¢«è¯æ˜æ˜¯ç¾¤ä¸å˜çš„ï¼ˆé™„å½•VII-Eï¼‰ã€‚<br>- **Lipschitzçº¦æŸ**ï¼šé€šè¿‡æ‹‰æ ¼æœ—æ—¥ä¹˜å­æ³•åœ¨æŸå¤±å‡½æ•°ä¸­å®æ–½ï¼ˆè§å…¬å¼8,9ï¼‰ã€‚ |\n| **2. ç¾¤å‚…é‡Œå¶ç©ºé—´å‚æ•°åŒ–** | åˆ©ç”¨**ç¾¤è¡¨ç¤ºè®º**å’Œ**å‚…é‡Œå¶åˆ†æ**ï¼Œå°†ç¾¤ä¸å˜è¯„åˆ†å‡½æ•° `f(s,z)` å‚æ•°åŒ–ä¸ºç¾¤å‚…é‡Œå¶ç©ºé—´ä¸­çš„å†…ç§¯å½¢å¼ï¼Œä»è€Œæ˜¾å¼åœ°ç¼–ç å¯¹ç§°æ€§ã€‚ | **æ•°å­¦åŸç†**ï¼š<br>1. **ç¾¤å¹³å‡**ï¼šä¸ºè·å¾—ç¾¤ä¸å˜å‡½æ•°ï¼Œå¯¹ä»»æ„è¯„åˆ†å‡½æ•°è¿›è¡Œç¾¤å¹³å‡ï¼š<br>   `fÌƒ(s,z) = âˆ«_G f(gs, gz) dÎ¼(g)`<br>   å…¶ä¸­ `Î¼` æ˜¯ç¾¤ `G` ä¸Šçš„å“ˆå°”æµ‹åº¦ã€‚<br>2. **å½¼å¾—-å¤–å°”å®šç†ä¸å‚…é‡Œå¶å±•å¼€**ï¼šå‡½æ•° `f_{g1,g2}(s,z) = f(g1 s, g2 z)` åœ¨ `L^2(GÃ—G)` ä¸­å¯å±•å¼€ä¸ºä¸å¯çº¦è¡¨ç¤ºçš„æ±‚å’Œï¼ˆå…¬å¼2ï¼‰ã€‚<br>3. **æ–½åŠ ä¸å˜æ€§**ï¼šé€šè¿‡å¯¹è§’ç¾¤ä½œç”¨ `g â†¦ (g, g)` è¿›è¡Œå¹³å‡ï¼Œå¹¶åˆ©ç”¨**èˆ’å°”å¼•ç†**ï¼ŒéåŒ¹é…çš„è¡¨ç¤ºåˆ†é‡è¢«æ¶ˆå»ï¼Œæœ€ç»ˆå¾—åˆ°ï¼š<br>   `fÌƒ(s,z) = Î£_{Ï âˆˆ Äœ} Î»_Ï(s,z)`<br>   å…¶ä¸­ `Î»_Ï(s,z)` æ˜¯å¯¹åº”äºä¸å¯çº¦è¡¨ç¤º `Ï` çš„æ ‡é‡ç³»æ•°ã€‚<br>4. **å†…ç§¯å‚æ•°åŒ–**ï¼šå°†æ¯ä¸ªç³»æ•°å‚æ•°åŒ–ä¸ºç‰¹å¾å‘é‡çš„å†…ç§¯ï¼š<br>   `Î»_Ï(s,z) â‰ˆ âŸ¨Ï†_Ï(s), Ïˆ_Ï(z)âŸ©`<br>   å°†æ‰€æœ‰è¡¨ç¤ºçš„ç‰¹å¾å †å ï¼Œå¾—åˆ°å…¨å±€æ˜ å°„ï¼š<br>   `Ï†_F: ğ’® â†’ â„^d`, `Ïˆ_F: Z â†’ â„^d`<br>   æœ€ç»ˆè¯„åˆ†å‡½æ•°è¿‘ä¼¼ä¸ºï¼š<br>   `fÌƒ(s,z) â‰ˆ âŸ¨Ï†_F(s), Ïˆ_F(z)âŸ©`<br>5. **ç­‰å˜æ€§**ï¼šé€šè¿‡æ„é€ ï¼Œ`Ï†_F` æ˜¯**ç­‰å˜**çš„ï¼š`Ï†_F(gs) = Ï_F(g) Ï†_F(s)`ï¼Œå…¶ä¸­ `Ï_F(g)` æ˜¯å—å¯¹è§’åŒ–çš„ä¸å¯çº¦è¡¨ç¤ºçŸ©é˜µã€‚ | **å…·ä½“å®ç°**ï¼š<br>- **æŠ€èƒ½å…ˆéªŒ p(z)**ï¼šè®¾ `z` ä¸ºé›¶å‡å€¼çš„å•ä½èŒƒæ•°å‘é‡ï¼Œé‡‡æ ·è‡ª `p(z)`ï¼Œä½¿å¾— `ğ”¼[z] = 0`ã€‚<br>- **æ˜ å°„è®¾ç½®**ï¼šéµå¾ªMETRAï¼Œè®¾ `Ïˆ_F(z) = z`ï¼Œå› æ­¤ `fÌƒ(s,z) = âŸ¨Ï†_F(s), zâŸ©`ã€‚<br>- **é¢‘ç‡æ»¤æ³¢**ï¼šç‰¹å¾å‘é‡ `Ï†_F(s)` æ˜¯ä¸åŒä¸å¯çº¦è¡¨ç¤ºï¼ˆé¢‘ç‡ï¼‰ç³»æ•°çš„æ‹¼æ¥ã€‚å¯é€šè¿‡æ©ç  `M` é€‰æ‹©ç‰¹å®šé¢‘ç‡ä»¥å¼ºè°ƒæˆ–æŠ‘åˆ¶æŸäº›å¯¹ç§°æ€§ï¼š`fÌƒ(s,z) = âŸ¨M Â· Ï†_F(s), zâŸ©`ã€‚<br>- **å®éªŒå‚æ•°**ï¼š<br>  - **Ant (C4)**ï¼šä½¿ç”¨é¢‘ç‡-1çš„ `C4` ä¸å¯çº¦è¡¨ç¤ºï¼ŒæŠ€èƒ½ç©ºé—´ä¸º2ç»´ã€‚<br>  - **Quadruped (C2)**ï¼š`C2` çš„å®è¡¨ç¤ºåŒ…å«ä¸€ä¸ªä¸å˜é€šé“å’Œä¸€ä¸ªç¬¦å·ç¿»è½¬é€šé“ã€‚ä½¿ç”¨ä¸¤ä¸ªè¿™æ ·çš„å‚…é‡Œå¶ç‰¹å¾å‘é‡æ‹¼æ¥æˆ4ç»´æŠ€èƒ½ç©ºé—´ã€‚ |\n| **3. å¯¹ç§°æ€§æ„ŸçŸ¥çš„å†…åœ¨å¥–åŠ±ä¸ç­–ç•¥å­¦ä¹ ** | åŸºäºç¾¤å‚…é‡Œå¶å‚æ•°åŒ–ï¼Œæ¨å¯¼å‡ºå…·æœ‰ç¾¤ä¸å˜æ€§çš„å†…åœ¨å¥–åŠ±å‡½æ•°ï¼Œå¹¶åˆ©ç”¨ç­‰å˜å¼ºåŒ–å­¦ä¹ ç®—æ³•è®­ç»ƒç­‰å˜ç­–ç•¥ã€‚ | **æ•°å­¦åŸç†**ï¼š<br>1. **å†…åœ¨å¥–åŠ±æ¨å¯¼**ï¼šå°†å‚æ•°åŒ–å½¢å¼ `fÌƒ(s,z) = âŸ¨Ï†_F(s), zâŸ©` ä»£å…¥WDMçš„è½¨è¿¹è¿‘ä¼¼ç›®æ ‡ï¼ˆå…¬å¼1, 5ï¼‰ï¼Œå¾—åˆ°æ¯ä¸€æ­¥çš„å¢é‡å¥–åŠ±ï¼š<br>   `r(s_t, z, s_{t+1}) := âŸ¨Ï†_F(s_{t+1}) - Ï†_F(s_t), zâŸ©`<br>2. **å¥–åŠ±çš„ä¸å˜æ€§è¯æ˜**ï¼šåˆ©ç”¨ `Ï†_F` çš„ç­‰å˜æ€§å’Œè¡¨ç¤º `Ï(h)` çš„é…‰æ€§ï¼Œå¯è¯æ˜ `r(h s_t, h z, h s_{t+1}) = r(s_t, z, s_{t+1})`ï¼Œå³è¯¥å¥–åŠ±åœ¨ç¾¤çš„è”åˆä½œç”¨ä¸‹ä¸å˜ã€‚<br>3. **ç­–ç•¥å­¦ä¹ **ï¼šåœ¨**ç¾¤ä¸å˜MDP**ä¸­ï¼Œæœ€ä¼˜ç­–ç•¥å¯ä»¥æ˜¯ç­‰å˜çš„ã€‚å› æ­¤ï¼Œä½¿ç”¨ç­‰å˜ç­–ç•¥ç½‘ç»œè¿›è¡Œå­¦ä¹ ã€‚ | **è®­ç»ƒç»†èŠ‚**ï¼š<br>- **ä¼˜åŒ–ç›®æ ‡**ï¼šé‡‡ç”¨å¯¹å¶æ¢¯åº¦ä¸‹é™æ³•ï¼Œä¼˜åŒ–ä»¥ä¸‹æŸå¤±å‡½æ•°ï¼š<br>  **åˆ¤åˆ«å™¨æŸå¤± `ğ’¥_Ï†` (å…¬å¼8)**ï¼š<br>  `ğ’¥_Ï† = ğ”¼_ğ’Ÿ[ âŸ¨Ï†_F(s') - Ï†_F(s), zâŸ© + Î» Â· min(Ïµ, 1 - â€–Ï†_F(s') - Ï†_F(s)â€–_2^2) ]`<br>  ç¬¬ä¸€é¡¹æœ€å¤§åŒ–æŠ€èƒ½å¯¹é½ï¼Œç¬¬äºŒé¡¹é€šè¿‡æ‹‰æ ¼æœ—æ—¥ä¹˜å­ `Î»` å¼ºåˆ¶ Lipschitz çº¦æŸï¼ˆ`Ïµ` ä¸ºæ¾å¼›å‚æ•°ï¼‰ã€‚<br>  **å¯¹å¶å˜é‡æŸå¤± `ğ’¥_Î»` (å…¬å¼9)**ï¼š<br>  `ğ’¥_Î» = ğ”¼_ğ’Ÿ[ Î» Â· min(Ïµ, 1 - â€–Ï†_F(s') - Ï†_F(s)â€–_2^2) ]`<br>- **ç­–ç•¥æ›´æ–°**ï¼šä½¿ç”¨**ç­‰å˜SAC**æˆ–**éƒ¨åˆ†ç­‰å˜SAC**æ¥æœ€å¤§åŒ–ç´¯ç§¯å†…åœ¨å¥–åŠ± `Î£_t r(s_t, z, s_{t+1})`ã€‚<br>- **å…·ä½“ç®—æ³•**ï¼šè§**ç®—æ³•1**ï¼Œäº¤æ›¿æ›´æ–°åˆ¤åˆ«å™¨ `Ï†_F`ã€å¯¹å¶å˜é‡ `Î»` å’Œç­–ç•¥ `Ï€`ã€‚ |\n| **4. ä¸‹æ¸¸ä»»åŠ¡ä¸­çš„ç³»ç»Ÿæ€§æ³›åŒ–** | åˆ©ç”¨é¢„è®­ç»ƒæŠ€èƒ½çš„å¯¹ç§°æ€§ç»“æ„ï¼Œè¯æ˜å…¶è¯±å¯¼çš„é«˜å±‚åŠMDPä¹Ÿæ˜¯ç¾¤ä¸å˜çš„ï¼Œä»è€Œæ”¯æŒé€šè¿‡ç®€å•çš„æŠ€èƒ½å‘é‡å˜æ¢å®ç°è·¨ç»„æ€çš„ç³»ç»Ÿæ€§æ³›åŒ–ã€‚ | **æ•°å­¦åŸç†**ï¼š<br>1. **å›ºå®šé—´éš”åŠMDP**ï¼šä¸‹æ¸¸ä»»åŠ¡é‡‡ç”¨åˆ†å±‚æ¶æ„ã€‚é«˜å±‚ç­–ç•¥ `Ï€^h(z|s, goal)` æ¯ `k` æ­¥é€‰æ‹©ä¸€ä¸ªæŠ€èƒ½ `z`ï¼Œåº•å±‚å†»ç»“æŠ€èƒ½ç­–ç•¥ `Ï€^l(a|s,z)` æ‰§è¡Œ `k` æ­¥ã€‚è¿™å®šä¹‰äº†ä¸€ä¸ªé«˜å±‚è½¬ç§»æ ¸ `P_k`ï¼ˆå…¬å¼7ï¼‰ã€‚<br>2. **é«˜å±‚MDPçš„ä¸å˜æ€§ï¼ˆå®šç†2ï¼‰**ï¼š<br>   è‹¥åº•å±‚åŠ¨åŠ›å­¦ `P^l` æ˜¯ç¾¤ä¸å˜çš„ï¼Œä¸”æŠ€èƒ½ç­–ç•¥ `Ï€^l` æ˜¯ç­‰å˜çš„ï¼Œåˆ™è¯±å¯¼çš„é«˜å±‚è½¬ç§»æ ¸ `P_k` ä¹Ÿæ˜¯ç¾¤ä¸å˜çš„ï¼š<br>   `P_k(g",
            "timestamp": "2026-01-27T15:57:49.314250",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "ä»–ä½¿ç”¨äº†å“ªäº›è¯„ä»·æŒ‡æ ‡ä¸æ•°æ®é›†ï¼Œåˆ—è¡¨æ ¼å…·ä½“è®²è®²ä»–çš„è¯„ä»·æŒ‡æ ‡çš„ç»†èŠ‚ä¸æ•°æ®é›†çš„ç»†èŠ‚",
            "answer": "## è®ºæ–‡è¯„ä»·æŒ‡æ ‡ä¸æ•°æ®é›†åˆ†æ\n\n### ä¸€ã€ è¯„ä»·æŒ‡æ ‡\n\nè®ºæ–‡ä½¿ç”¨äº†ä¸¤ä¸ªæ ¸å¿ƒè¯„ä»·æŒ‡æ ‡æ¥è¯„ä¼°**æŠ€èƒ½å‘ç°**å’Œ**ä¸‹æ¸¸ä»»åŠ¡**çš„æ€§èƒ½ã€‚\n\n| æŒ‡æ ‡ç±»åˆ« | å…·ä½“æŒ‡æ ‡ | è®¡ç®—æ–¹å¼ä¸ç»†èŠ‚ | ç›®çš„ |\n| :--- | :--- | :--- | :--- |\n| **æŠ€èƒ½å‘ç° (é¢„è®­ç»ƒé˜¶æ®µ)** | **çŠ¶æ€ç©ºé—´è¦†ç›–ç‡** | 1. **ç¯å¢ƒ**ï¼šåœ¨çŠ¶æ€ç©ºé—´ï¼ˆAntï¼‰æˆ–åƒç´ ç©ºé—´ï¼ˆQuadrupedï¼‰ä¸­ï¼Œå…³æ³¨æ™ºèƒ½ä½“çš„ `(x, y)` ä½ç½®åæ ‡ã€‚<br>2. **è¯„ä¼°è¿‡ç¨‹**ï¼šä»æŠ€èƒ½å…ˆéªŒåˆ†å¸ƒä¸­å‡åŒ€é‡‡æ · **48ä¸ª** æ½œåœ¨æŠ€èƒ½å‘é‡ `z`ï¼Œæ¯ä¸ªæŠ€èƒ½æ‰§è¡Œå›ºå®šæ­¥é•¿çš„è½¨è¿¹ã€‚<br>3. **é‡åŒ–æ–¹æ³•**ï¼šå°†ä»»åŠ¡ç›¸å…³åŒºåŸŸï¼ˆå¦‚ Ant çš„ `[-30, 30]Â²`ï¼‰åˆ’åˆ†ä¸ºç½‘æ ¼ï¼Œè®¡ç®—è¢«è®¿é—®è¿‡çš„ç½‘æ ¼å•å…ƒæ‰€å çš„**æ¯”ä¾‹**ã€‚<br>4. **å…³é”®ç»†èŠ‚**ï¼šä¸ºé¿å…è®¡ç®—æ— å…³åŒºåŸŸï¼Œå¯¹ Ant ç¯å¢ƒé™åˆ¶äº†è¯„ä¼°èŒƒå›´ï¼Œè¿™ä¸ä¸‹æ¸¸ä»»åŠ¡çš„ç›®æ ‡é‡‡æ ·èŒƒå›´ä¸€è‡´ã€‚ | è¡¡é‡æ— ç›‘ç£å‘ç°çš„æŠ€èƒ½**æ¢ç´¢ç¯å¢ƒçš„èƒ½åŠ›å’Œå¤šæ ·æ€§**ã€‚æ›´é«˜çš„è¦†ç›–ç‡æ„å‘³ç€æŠ€èƒ½èƒ½å¼•å¯¼æ™ºèƒ½ä½“åˆ°è¾¾æ›´å¹¿æ³›çš„çŠ¶æ€ç©ºé—´ã€‚ |\n| **ä¸‹æ¸¸ä»»åŠ¡ (å¾®è°ƒé˜¶æ®µ)** | **å¹³å‡å›æŠ¥** | 1. **ä»»åŠ¡è®¾ç½®**ï¼šåŸºäºé¢„è®­ç»ƒå¹¶å†»ç»“çš„ä½å±‚æŠ€èƒ½ç­–ç•¥ï¼Œè®­ç»ƒä¸€ä¸ªé«˜å±‚ç­–ç•¥ `Ï€Ê°(z|s, g)` æ¥å®Œæˆç›®æ ‡å¯¼å‘ä»»åŠ¡ã€‚<br>2. **ä»»åŠ¡ç»†èŠ‚ (Ant)**ï¼š**å¤šç›®æ ‡ä»»åŠ¡**ã€‚æ¯å½“å½“å‰ç›®æ ‡è¾¾æˆæˆ–ç»è¿‡ `K` æ­¥åï¼Œåœ¨å½“å‰ä½ç½®å‘¨å›´ `[-7.5, 7.5]Â²` èŒƒå›´å†…å‡åŒ€é‡‡æ ·ä¸€ä¸ªæ–°ç›®æ ‡ã€‚<br>3. **æŠ¥å‘Šæ–¹å¼**ï¼šç»˜åˆ¶ä¸‹æ¸¸ä»»åŠ¡è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œ**å¹³å‡å›æŠ¥éšè®­ç»ƒè¿­ä»£æ¬¡æ•°å˜åŒ–**çš„æ›²çº¿ï¼Œå¹¶è®¡ç®—å¤šä¸ªéšæœºç§å­çš„å¹³å‡å€¼å’Œæ ‡å‡†è¯¯ã€‚ | è¯„ä¼°æ‰€å‘ç°æŠ€èƒ½çš„**å®ç”¨æ€§å’Œå¯è¿ç§»æ€§**ã€‚æ›´é«˜çš„å›æŠ¥å’Œæ›´å¿«çš„æ”¶æ•›é€Ÿåº¦è¡¨æ˜æŠ€èƒ½èƒ½æœ‰æ•ˆåŠ é€Ÿä¸‹æ¸¸ä»»åŠ¡çš„å­¦ä¹ ã€‚ |\n\n**å…¶ä»–éšå«çš„å®šæ€§åˆ†ææŒ‡æ ‡**ï¼š\n- **æŠ€èƒ½å¯è§†åŒ–**ï¼šç»˜åˆ¶48ä¸ªéšæœºæŠ€èƒ½ç”Ÿæˆçš„è½¨è¿¹ï¼Œå®šæ€§åˆ†ææŠ€èƒ½çš„å¯¹ç§°ä¸€è‡´æ€§ï¼ˆå¦‚ `Câ‚„` æ—‹è½¬å¯¹ç§°ã€æ°´å¹³ç¿»è½¬å¯¹ç§°ï¼‰å’Œå†—ä½™åº¦ã€‚\n- **å‚…é‡Œå¶æŠ€èƒ½å‘é‡åˆ†æ**ï¼šåœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­ï¼Œå¯è§†åŒ–é«˜å±‚ç­–ç•¥é€‰æ‹©çš„æŠ€èƒ½å‘é‡çš„ä¸å˜åˆ†é‡å’Œç­‰å˜åˆ†é‡ï¼Œä»¥éªŒè¯å…¶æ˜¯å¦éµå¾ªé¢„æœŸçš„å¯¹ç§°å˜æ¢ï¼ˆå¦‚å›¾6æ‰€ç¤ºï¼‰ã€‚\n\n### äºŒã€ æ•°æ®é›†ï¼ˆåŸºå‡†ç¯å¢ƒï¼‰\n\nè®ºæ–‡åœ¨ä¸¤ä¸ªå…·æœ‰å·²çŸ¥å‡ ä½•å¯¹ç§°æ€§çš„è¿ç»­æ§åˆ¶ locomotion åŸºå‡†ç¯å¢ƒä¸­è¿›è¡Œå®éªŒã€‚\n\n| ç¯å¢ƒåç§° | æ¨¡æ€ | å¯¹ç§°æ€§ç»“æ„ | ç¯å¢ƒä¿®æ”¹ä¸å…³é”®ç»†èŠ‚ |\n| :--- | :--- | :--- | :--- |\n| **State-based Ant** | çŠ¶æ€è§‚æµ‹ (MuJoCo) | **`Câ‚„` å¯¹ç§°æ€§** (90Â° å¹³é¢æ—‹è½¬) | 1. **å¯¹ç§°æ€§ä¿æŒ**ï¼š**åˆ»æ„ä¸ä½¿ç”¨**è§‚æµ‹å½’ä¸€åŒ–ï¼ˆå¦‚ running mean/varianceï¼‰ï¼Œå› ä¸ºè¿™ç§é¢„å¤„ç†ä¼šæ‰­æ›²åæ ‡ï¼Œç ´åç­‰å˜æ€§ã€‚<br>2. **æŠ€èƒ½è¡¨ç¤º**ï¼šå°†å‚…é‡Œå¶è¡¨ç¤ºé™åˆ¶åœ¨ `Câ‚„` ç¾¤çš„ **é¢‘ç‡-1 ä¸å¯çº¦è¡¨ç¤º** ä¸Šï¼Œå¹¶åœ¨æ­¤å­ç©ºé—´ä¸­å­¦ä¹  **2D** æ½œåœ¨æŠ€èƒ½ï¼Œä»¥å¼ºè°ƒæ–¹å‘æ€§ã€æ—‹è½¬ç­‰å˜çš„è¡Œä¸ºï¼ˆå¦‚â€œå‘ç‰¹å®šæ–¹å‘ç§»åŠ¨â€ï¼‰ã€‚<br>3. **ç­–ç•¥**ï¼šä½¿ç”¨ **éƒ¨åˆ†ç­‰å˜SAC** ä»¥åº”å¯¹å±€éƒ¨å¯¹ç§°æ€§ç ´ç¼ºï¼ˆå¦‚æ¥è§¦ä¸å¯¹ç§°ï¼‰ã€‚ |\n| **Pixel-based Quadruped** | åƒç´ è§‚æµ‹ (DeepMind Control Suite) | **`Dâ‚ â‰… Câ‚‚` å¯¹ç§°æ€§** (æ°´å¹³ç¿»è½¬) | 1. **ç¯å¢ƒæ”¹é€ **ï¼šå¯¹ METRA åŸºå‡†è¿›è¡Œäº†å…³é”®ä¿®æ”¹ã€‚å°†åœ°æ¿é¢œè‰²ä»éš `(x, y)` åæ ‡å¹³æ»‘å˜åŒ–ï¼Œæ”¹ä¸º**ä»åŸç‚¹å¾„å‘å˜åŒ–**ã€‚è¿™ç¡®ä¿äº†åœ¨æ°´å¹³ç¿»è½¬ä¸‹è§‚å¯Ÿå¤–è§‚çš„ä¸€è‡´æ€§ï¼ŒåŒæ—¶ä»èƒ½æ­ç¤ºå…¨å±€ä½ç½®ä¿¡æ¯ã€‚<br>2. **æŠ€èƒ½è¡¨ç¤º**ï¼š`Câ‚‚` ç¾¤æœ‰ä¸€ä¸ª2Då®è¡¨ç¤ºï¼ˆåŒ…å«ä¸€ä¸ªä¸å˜é€šé“å’Œä¸€ä¸ªç¬¦å·ç¿»è½¬é€šé“ï¼‰ã€‚ä¸ºä¸åŸºçº¿å…¬å¹³æ¯”è¾ƒï¼Œé€šè¿‡æ‹¼æ¥ä¸¤ä¸ªè¿™æ ·çš„å‚…é‡Œå¶ç‰¹å¾å‘é‡ï¼Œä½¿ç”¨ **4D** æ½œåœ¨æŠ€èƒ½ç©ºé—´ã€‚<br>3. **ç­–ç•¥**ï¼šä½¿ç”¨ **ç­‰å˜SAC**ã€‚ |\n\n**åŸºçº¿æ–¹æ³•**ï¼šè®ºæ–‡å§‹ç»ˆä»¥ **METRA** ä½œä¸ºå¼ºåŸºçº¿è¿›è¡Œå¯¹æ¯”ã€‚METRA æ˜¯å½“å‰æœ€å…ˆè¿›çš„è·ç¦»æœ€å¤§åŒ–æ— ç›‘ç£æŠ€èƒ½å‘ç°æ–¹æ³•ï¼Œä½†æœªæ˜¾å¼åˆ©ç”¨å¯¹ç§°æ€§ã€‚\n\n### æ€»ç»“ä¸ä»·å€¼\n\n- **è¯„ä»·æŒ‡æ ‡çš„é’ˆå¯¹æ€§**ï¼šæ‰€é€‰æŒ‡æ ‡ç›´æ¥å¯¹åº”è®ºæ–‡çš„æ ¸å¿ƒä¸»å¼ â€”â€”**åˆ©ç”¨å¯¹ç§°æ€§èƒ½æé«˜æ¢ç´¢æ•ˆç‡ï¼ˆè¦†ç›–ç‡ï¼‰å’Œä¸‹æ¸¸ä»»åŠ¡å­¦ä¹ æ•ˆç‡ï¼ˆå›æŠ¥ä¸æ ·æœ¬æ•ˆç‡ï¼‰**ã€‚å®éªŒè®¾è®¡ä¸¥è°¨ï¼Œè¦†ç›–äº†ä»æ— ç›‘ç£é¢„è®­ç»ƒåˆ°æœ‰ç›‘ç£å¾®è°ƒçš„å…¨æµç¨‹ã€‚\n- **æ•°æ®é›†çš„ç²¾å¿ƒè®¾è®¡**ï¼šå®éªŒç¯å¢ƒçš„é€‰æ‹©å’Œæ”¹é€ æå…·åŒ å¿ƒã€‚ä¸ä»…é€‰æ‹©äº†å¤©ç„¶å…·æœ‰å¯¹ç§°æ€§çš„ locomotion ä»»åŠ¡ï¼Œè¿˜é€šè¿‡**ç¦ç”¨é¢„å¤„ç†**å’Œ**æ”¹é€ è§†è§‰è¾“å…¥**ç­‰æ‰‹æ®µï¼Œç¡®ä¿å¯¹ç§°æ€§åœ¨è¾“å…¥å±‚é¢å¾—ä»¥ä¿æŒï¼Œä»è€Œèƒ½å¤Ÿçº¯ç²¹åœ°æ£€éªŒæ–¹æ³•åœ¨å¯¹ç§°æ€§åˆ©ç”¨ä¸Šçš„æœ‰æ•ˆæ€§ã€‚\n- **å®é™…ä»·å€¼ä½“ç°**ï¼šé€šè¿‡åœ¨çŠ¶æ€å’Œåƒç´ ä¸¤ç§æ¨¡æ€ã€`Câ‚„` å’Œ `Câ‚‚` ä¸¤ç§å¯¹ç§°ç¾¤ä¸Šçš„æˆåŠŸå®éªŒï¼Œè¯æ˜äº† **GISD æ¡†æ¶çš„é€šç”¨æ€§**ã€‚å…¶æ ¸å¿ƒä»·å€¼åœ¨äºæä¾›äº†ä¸€ç§å°†**å…ˆéªŒçš„å‡ ä½•çŸ¥è¯†**ï¼ˆå¯¹ç§°æ€§ï¼‰ç³»ç»Ÿæ€§åœ°æ³¨å…¥æ— è¡¨ç¤ºå­¦ä¹ æµç¨‹çš„æ–¹æ³•ï¼Œä»è€Œå‡å°‘å†—ä½™æ¢ç´¢ã€æå‡æ ·æœ¬æ•ˆç‡ï¼Œå¹¶èµ‹äºˆæŠ€èƒ½å¯è§£é‡Šçš„å¯¹ç§°ç»“æ„ï¼Œä¾¿äºç³»ç»ŸåŒ–æ³›åŒ–ã€‚è¿™ä¸ºåœ¨æ›´å¤æ‚çš„æœºå™¨äººæ“æ§ç­‰å¯Œå«å¯¹ç§°æ€§çš„é¢†åŸŸä¸­åº”ç”¨æ— ç›‘ç£æŠ€èƒ½å‘ç°å¥ å®šäº†åŸºç¡€ã€‚",
            "timestamp": "2026-01-27T15:58:33.735754",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "è®ºæ–‡åœ¨å“ªäº›æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Ÿä¸»è¦çš„è¯„ä¼°æŒ‡æ ‡å’Œæ€§èƒ½æå‡æ˜¯å¤šå°‘ï¼Ÿ",
            "answer": "## è®ºæ–‡å®éªŒæ•°æ®é›†ã€è¯„ä¼°æŒ‡æ ‡ä¸æ€§èƒ½æå‡åˆ†æ\n\n### ä¸€ã€ å®éªŒæ•°æ®é›†ï¼ˆåŸºå‡†ç¯å¢ƒï¼‰\nè®ºæ–‡åœ¨ä¸¤ä¸ªå…·æœ‰å·²çŸ¥å‡ ä½•å¯¹ç§°æ€§çš„è¿ç»­æ§åˆ¶åŸºå‡†ç¯å¢ƒä¸­è¿›è¡Œäº†å®éªŒï¼š\n\n1.  **çŠ¶æ€è¾“å…¥ç¯å¢ƒ**\n    *   **ä»»åŠ¡**ï¼š MuJoCo Ant å››è¶³æœºå™¨äººå¹³é¢è¿åŠ¨ã€‚\n    *   **å¯¹ç§°æ€§**ï¼š å¹³é¢90Â°æ—‹è½¬å¯¹ç§°ï¼Œå»ºæ¨¡ä¸ºå¾ªç¯ç¾¤ **`Câ‚„`**ã€‚\n    *   **å…³é”®è®¾ç½®**ï¼š ä¸ºäº†ä¿æŒå¯¹ç§°æ€§ï¼Œ**æœªå¯¹çŠ¶æ€è¾“å…¥è¿›è¡Œè§‚æµ‹å½’ä¸€åŒ–**ï¼ˆå¦‚è¿è¡Œå‡å€¼/æ–¹å·®ï¼‰ï¼Œä»¥é¿å…ç ´åç­‰å˜æ€§ã€‚\n\n2.  **åƒç´ è¾“å…¥ç¯å¢ƒ**\n    *   **ä»»åŠ¡**ï¼š DeepMind Control Suite (DMC) ä¸­çš„è§†è§‰å››è¶³æœºå™¨äººè¿åŠ¨ã€‚\n    *   **å¯¹ç§°æ€§**ï¼š æ°´å¹³ç¿»è½¬å¯¹ç§°ï¼Œå»ºæ¨¡ä¸º **`Dâ‚ â‰… Câ‚‚`** ç¾¤ã€‚\n    *   **å…³é”®è®¾ç½®**ï¼š ä¸ºäº†å……åˆ†æš´éœ²å¯¹ç§°æ€§ï¼Œ**é‡æ–°è®¾è®¡äº†åœ°é¢çº¹ç†**ï¼Œä½¿å…¶é¢œè‰²ä»åŸç‚¹å‘ˆ**å¾„å‘å˜åŒ–**ï¼Œä»è€Œåœ¨å·¦å³ç¿»è½¬ä¸‹ä¿æŒå¤–è§‚ä¸€è‡´ï¼ŒåŒæ—¶ä»èƒ½æä¾›å…¨å±€ä½ç½®ä¿¡æ¯ã€‚\n\n### äºŒã€ ä¸»è¦è¯„ä¼°æŒ‡æ ‡\nè®ºæ–‡ä»**æŠ€èƒ½å‘ç°**å’Œ**ä¸‹æ¸¸ä»»åŠ¡**ä¸¤ä¸ªé˜¶æ®µè¿›è¡Œè¯„ä¼°ï¼š\n\n1.  **æŠ€èƒ½å‘ç°é˜¶æ®µï¼šçŠ¶æ€ç©ºé—´è¦†ç›–ç‡**\n    *   **æ–¹æ³•**ï¼š ä»æŠ€èƒ½å…ˆéªŒä¸­å‡åŒ€é‡‡æ ·48ä¸ªæ½œåœ¨æŠ€èƒ½å‘é‡ï¼Œæ¯ä¸ªæ‰§è¡Œå›ºå®šæ­¥é•¿ï¼Œæ”¶é›†è½¨è¿¹ã€‚\n    *   **åº¦é‡**ï¼š è®¡ç®—æ™ºèƒ½ä½“åœ¨ä»»åŠ¡ç›¸å…³å¹³é¢åŒºåŸŸ `(x, y)` åæ ‡ä¸Šçš„**ç½‘æ ¼å•å…ƒè®¿é—®æ¯”ä¾‹**ã€‚\n    *   **ç›®çš„**ï¼š é‡åŒ–æ— ç›‘ç£å‘ç°çš„æŠ€èƒ½å¯¹ç¯å¢ƒçš„æ¢ç´¢å¹¿åº¦ã€‚\n\n2.  **ä¸‹æ¸¸ä»»åŠ¡é˜¶æ®µï¼šç›®æ ‡è¾¾æˆæ€§èƒ½**\n    *   **ä»»åŠ¡è®¾ç½®**ï¼š åœ¨å†»ç»“çš„åº•å±‚æŠ€èƒ½ç­–ç•¥ä¹‹ä¸Šï¼Œè®­ç»ƒä¸€ä¸ªé«˜å±‚ç­–ç•¥ `Ï€Ê°(z|s, g)` æ¥å®Œæˆ**å¤šç›®æ ‡åˆ°è¾¾ä»»åŠ¡**ã€‚\n        *   **Ant**ï¼š æ¯å½“å½“å‰ç›®æ ‡è¾¾æˆæˆ–ç»è¿‡Kæ­¥åï¼Œåœ¨å½“å‰ä½ç½®å‘¨å›´å‡åŒ€é‡‡æ ·æ–°ç›®æ ‡ã€‚\n    *   **åº¦é‡**ï¼š æŠ¥å‘Šä¸‹æ¸¸ä»»åŠ¡è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œ**å¹³å‡å›æŠ¥éšè®­ç»ƒè¿­ä»£æ¬¡æ•°çš„å˜åŒ–**ã€‚\n    *   **ç›®çš„**ï¼š è¯„ä¼°å·²å‘ç°æŠ€èƒ½å¯¹äºè§£å†³å…·ä½“ä»»åŠ¡çš„æœ‰æ•ˆæ€§å’Œå¯é‡ç”¨æ€§ã€‚\n\n### ä¸‰ã€ æ€§èƒ½æå‡ç»“æœ\nè®ºæ–‡å°†æå‡ºçš„ **GISD** æ–¹æ³•ä¸å½“å‰æœ€å…ˆè¿›çš„æ— ç›‘ç£æŠ€èƒ½å‘ç°æ–¹æ³• **METRA** è¿›è¡Œäº†å¯¹æ¯”ã€‚\n\n1.  **çŠ¶æ€ç©ºé—´è¦†ç›–ç‡ï¼ˆæŠ€èƒ½å‘ç°æ•ˆç‡ï¼‰**\n    *   **ç»“æœ**ï¼š å¦‚å›¾3æ‰€ç¤ºï¼Œåœ¨**çŠ¶æ€Ant**å’Œ**åƒç´ Quadruped**ä¸¤ä¸ªç¯å¢ƒä¸­ï¼ŒGISDéƒ½å®ç°äº†**æ¯”METRAæ›´å¹¿çš„çŠ¶æ€ç©ºé—´è¦†ç›–ç‡å’Œæ›´é«˜çš„æ ·æœ¬æ•ˆç‡**ã€‚\n    *   **å®šæ€§åˆ†æ**ï¼š å¯è§†åŒ–æ˜¾ç¤ºï¼ˆå›¾4ï¼‰ï¼ŒGISDå‘ç°çš„æŠ€èƒ½ä»¥å¯¹ç§°ä¸€è‡´çš„æ–¹å¼å¹³é“ºå¹³é¢ï¼ˆAntä¸­å‘ˆç°`Câ‚„`æ—‹è½¬ç›¸å…³ï¼ŒQuadrupedä¸­å‘ˆç°æ°´å¹³ç¿»è½¬é•œåƒï¼‰ï¼Œè€ŒMETRAçš„æŠ€èƒ½åˆ™ç»å¸¸å‡ºç°å†—ä½™èšç±»æˆ–æœªèƒ½è¦†ç›–æ‰€æœ‰å¯¹ç§°æ¨¡å¼ã€‚\n\n2.  **ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ï¼ˆæŠ€èƒ½å®ç”¨æ€§ï¼‰**\n    *   **ç»“æœ**ï¼š å¦‚å›¾5æ‰€ç¤ºï¼Œåœ¨ä¸¤ä¸ªç¯å¢ƒçš„ä¸‹æ¸¸ç›®æ ‡åˆ°è¾¾ä»»åŠ¡ä¸­ï¼ŒGISDéƒ½è·å¾—äº†**æ¯”METRAæ›´é«˜çš„æœ€ç»ˆå›æŠ¥ï¼Œå¹¶ä¸”ä»¥æ›´å°‘çš„ç¯å¢ƒäº¤äº’æ­¥æ•°è¾¾åˆ°å¼ºæ€§èƒ½**ã€‚\n    *   **æ³›åŒ–åˆ†æ**ï¼š å¦‚å›¾6æ‰€ç¤ºï¼Œåœ¨DMC Quadrupedä¸­ï¼Œå¯¹äºæ°´å¹³é•œåƒçš„ç›®æ ‡ï¼Œé«˜å±‚ç­–ç•¥é€‰æ‹©çš„æŠ€èƒ½å‘é‡ä¸­ï¼Œ**ä¸å˜åˆ†é‡å‡ ä¹ç›¸åŒï¼Œè€Œç­‰å˜åˆ†é‡å‘ˆç°è¿‘ä¼¼ç¬¦å·ç¿»è½¬**ã€‚è¿™è¡¨æ˜GISDå­¦ä¹ çš„å‚…é‡Œå¶ç©ºé—´æŠ€èƒ½å…·æœ‰å¤šæ ·æ€§ï¼Œå¹¶èƒ½è¢«ç³»ç»Ÿæ€§åœ°é‡ç”¨äºå˜æ¢åçš„ä»»åŠ¡ã€‚\n\n### å››ã€ æ€»ç»“\n| æ–¹é¢ | è¯„ä¼°æŒ‡æ ‡ | GISD ç›¸æ¯”åŸºçº¿ (METRA) çš„æå‡ |\n| :--- | :--- | :--- |\n| **æŠ€èƒ½å‘ç°** | çŠ¶æ€ç©ºé—´ `(x, y)` è¦†ç›–ç‡ | **æ›´å¹¿çš„è¦†ç›–ï¼Œæ›´é«˜çš„æ ·æœ¬æ•ˆç‡**ã€‚æŠ€èƒ½å‘ˆç°å¯¹ç§°ä¸€è‡´æ€§ï¼Œæ— å†—ä½™ã€‚ |\n| **ä¸‹æ¸¸ä»»åŠ¡** | å¹³å‡å›æŠ¥ (å¤šç›®æ ‡åˆ°è¾¾) | **æ›´é«˜çš„æœ€ç»ˆæ€§èƒ½ï¼Œæ›´å¿«çš„æ”¶æ•›é€Ÿåº¦**ã€‚æŠ€èƒ½æ”¯æŒåŸºäºç¾¤å˜æ¢çš„ç³»ç»Ÿæ€§æ³›åŒ–ã€‚ |\n\n**æ ¸å¿ƒç»“è®º**ï¼šé€šè¿‡å°†ç¾¤ä¸å˜æ€§çº¦æŸæ˜¾å¼åµŒå…¥Wassersteinä¾èµ–åº¦é‡ç›®æ ‡ï¼Œå¹¶åœ¨å‚…é‡Œå¶ç©ºé—´å‚æ•°åŒ–è¯„åˆ†å‡½æ•°ï¼ŒGISDå‘ç°äº†ä¸åº•å±‚å‡ ä½•å¯¹ç§°æ€§å¯¹é½çš„æŠ€èƒ½ã€‚è¿™äº›æŠ€èƒ½ä¸ä»…èƒ½æ›´æœ‰æ•ˆåœ°æ¢ç´¢ç¯å¢ƒï¼Œè€Œä¸”åœ¨è¿ç§»åˆ°ä¸‹æ¸¸æ§åˆ¶ä»»åŠ¡æ—¶ï¼Œè¡¨ç°å‡ºæ›´ä¼˜çš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚",
            "timestamp": "2026-01-27T15:59:08.916066",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "è®ºæ–‡çš„ä¸»è¦å±€é™æ€§æœ‰å“ªäº›ï¼Ÿæœªæ¥å¯èƒ½çš„æ”¹è¿›æ–¹å‘æ˜¯ä»€ä¹ˆï¼Ÿ",
            "answer": "## è®ºæ–‡ä¸»è¦å±€é™æ€§åˆ†æ\n\nåŸºäºå¯¹è®ºæ–‡å†…å®¹çš„åˆ†æï¼Œå…¶å±€é™æ€§ä¸»è¦é›†ä¸­åœ¨ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š\n\n- **è®¡ç®—æˆæœ¬ä¸å®ç°å¤æ‚åº¦**ï¼šè®ºæ–‡æ˜ç¡®æŒ‡å‡ºï¼Œè¯¥æ–¹æ³•ç»§æ‰¿äº†ç­‰å˜ç¥ç»ç½‘ç»œï¼ˆequivariant networksï¼‰çš„å¸¸è§å±€é™ï¼ŒåŒ…æ‹¬**å¢åŠ çš„è®¡ç®—æˆæœ¬**ã€‚æ„å»ºå’Œä¼˜åŒ–åŸºäºç¾¤å‚…é‡Œå¶è¡¨ç¤ºçš„è¯„åˆ†å‡½æ•°å’Œç­–ç•¥ï¼Œç›¸æ¯”éç»“æ„åŒ–æ–¹æ³•ï¼ˆå¦‚åŸºçº¿METRAï¼‰åœ¨å®ç°ä¸Šæ›´ä¸ºå¤æ‚ã€‚\n\n- **éœ€è¦é¢„å…ˆæŒ‡å®šå¯¹ç§°ç¾¤**ï¼šæ–¹æ³•çš„æœ‰æ•ˆæ€§ä¾èµ–äº**å¯¹ç¯å¢ƒä¸­ç›¸å…³å¯¹ç§°ç¾¤ï¼ˆå¦‚SO(2), Câ‚„, Câ‚‚ï¼‰çš„å…ˆéªŒçŸ¥è¯†**ã€‚è®ºæ–‡å‡è®¾ç¯å¢ƒåŠ¨æ€æ˜¯ç¾¤ä¸å˜çš„ï¼Œå¹¶åœ¨å®éªŒä¸­å¯¹Antå’ŒQuadrupedç¯å¢ƒæ‰‹åŠ¨è®¾å®šäº†æ—‹è½¬æˆ–ç¿»è½¬å¯¹ç§°æ€§ã€‚åœ¨å¯¹ç§°æ€§æœªçŸ¥ã€ä¸å®Œæ•´æˆ–åŠ¨æ€å˜åŒ–çš„ç¯å¢ƒä¸­ï¼Œè¯¥æ–¹æ³•å¯èƒ½æ— æ³•ç›´æ¥åº”ç”¨æˆ–æ€§èƒ½ä¸‹é™ã€‚\n\n- **å¯¹å±€éƒ¨å¯¹ç§°æ€§ç ´åçš„æ•æ„Ÿæ€§**ï¼šå°½ç®¡åœ¨çŠ¶æ€Antç¯å¢ƒä¸­ä½¿ç”¨äº†Partially Equivariant SACæ¥å¢å¼ºé²æ£’æ€§ï¼Œä½†æ–¹æ³•æœ¬è´¨ä¸Šä¾èµ–äºç¯å¢ƒåŠ¨æ€çš„ä¸¥æ ¼ç¾¤ä¸å˜æ€§å‡è®¾ã€‚ç°å®æœºå™¨äººç¯å¢ƒå¸¸å­˜åœ¨**å¾®å°çš„ä¸å¯¹ç§°æ€§**ï¼ˆå¦‚æ¥è§¦åŠ›ä¸å¯¹ç§°ã€ä¼ æ„Ÿå™¨åå·®ã€éå‡åŒ€æ‘©æ“¦ï¼‰ï¼Œè¿™äº›å¯èƒ½ç ´åç†æƒ³çš„å¯¹ç§°æ€§ï¼Œå½±å“æŠ€èƒ½å‘ç°å’Œæ³›åŒ–æ•ˆæœã€‚\n\n- **å®éªŒç¯å¢ƒçš„å±€é™æ€§**ï¼šå®éªŒéªŒè¯é›†ä¸­åœ¨å…·æœ‰**æ˜ç¡®ã€å…¨å±€å‡ ä½•å¯¹ç§°æ€§**çš„è¿ç»­æ§åˆ¶ locomotion ä»»åŠ¡ï¼ˆAnt, Quadrupedï¼‰ä¸Šã€‚è®ºæ–‡åœ¨ç»“è®ºä¸­æŒ‡å‡ºï¼Œå°šæœªåœ¨æ›´å…·æŒ‘æˆ˜æ€§çš„é¢†åŸŸï¼ˆå¦‚Humanoidæ§åˆ¶ï¼‰æˆ–å¯¹ç§°æ€§æ›´å¤æ‚ã€æ›´å±€éƒ¨çš„ä»»åŠ¡ï¼ˆå¦‚ç²¾ç»†æ“ä½œï¼‰ä¸Šè¿›è¡Œæµ‹è¯•ï¼Œå…¶æ™®é€‚æ€§æœ‰å¾…è¿›ä¸€æ­¥è¯æ˜ã€‚\n\n- **æŠ€èƒ½è¡¨ç¤ºçš„è®¾è®¡é€‰æ‹©**ï¼šåœ¨å®éªŒä¸­ï¼Œä¸ºäº†ä¸åŸºçº¿å…¬å¹³æ¯”è¾ƒï¼Œå¯¹æŠ€èƒ½ç»´åº¦ï¼ˆå¦‚Quadrupedä¸­æ‹¼æ¥ä¸¤ä¸ªå‚…é‡Œå¶ç‰¹å¾å‘é‡ï¼‰å’Œå¼ºè°ƒçš„è¡¨ç¤ºåˆ†é‡ï¼ˆå¦‚Antä¸­ä»…ä½¿ç”¨é¢‘ç‡-1çš„Câ‚„ä¸å¯çº¦è¡¨ç¤ºï¼‰åšå‡ºäº†ç‰¹å®šè®¾è®¡é€‰æ‹©ã€‚è¿™äº›é€‰æ‹©å¯èƒ½**å¹¶éæœ€ä¼˜**ï¼Œä¸”éœ€è¦é’ˆå¯¹ä¸åŒä»»åŠ¡è¿›è¡Œè°ƒæ•´ã€‚\n\n## æœªæ¥å¯èƒ½çš„æ”¹è¿›æ–¹å‘\n\nè®ºæ–‡åœ¨ç»“è®ºå’Œæœªæ¥å±•æœ›éƒ¨åˆ†æå‡ºäº†ä»¥ä¸‹æ½œåœ¨å‘å±•æ–¹å‘ï¼š\n\n- **æ‰©å±•åˆ°æ›´å¤æ‚å’Œå®é™…çš„ä»»åŠ¡é¢†åŸŸ**ï¼š\n    - **æŒ‘æˆ˜æ€§æ§åˆ¶ä»»åŠ¡**ï¼šå¦‚Humanoidç­‰æ›´å¤æ‚çš„é«˜ç»´åŠ¨åŠ›å­¦ç³»ç»Ÿã€‚\n    - **æœºå™¨äººæ“ä½œä»»åŠ¡**ï¼šè®ºæ–‡æ˜ç¡®æŒ‡å‡ºï¼Œæ“ä½œä»»åŠ¡ä¸­æŠ€èƒ½å‘ç° notoriously difficultï¼Œä½†é€šå¸¸å­˜åœ¨ä¸°å¯Œçš„å¯¹ç§°æ€§ï¼ˆå¦‚æŠ“å–ã€æ”¾ç½®ä¸­çš„æ—‹è½¬ã€å¹³ç§»å¯¹ç§°ï¼‰ï¼Œæ˜¯æœªæ¥åº”ç”¨çš„**é‡è¦æ–¹å‘**ã€‚\n\n- **å¢å¼ºæ–¹æ³•çš„è‡ªé€‚åº”æ€§**ï¼š\n    - **è‡ªåŠ¨å¯¹ç§°æ€§å‘ç°**ï¼šæœªæ¥å·¥ä½œå¯ä»¥æ¢ç´¢å¦‚ä½•**ä»æ•°æ®ä¸­è‡ªåŠ¨æ¨æ–­æˆ–å­¦ä¹ ç¯å¢ƒçš„å¯¹ç§°ç¾¤ç»“æ„**ï¼Œå‡å°‘å¯¹å…ˆéªŒçŸ¥è¯†çš„ä¾èµ–ã€‚\n    - **å¤„ç†éƒ¨åˆ†æˆ–è¿‘ä¼¼å¯¹ç§°æ€§**ï¼šå¼€å‘èƒ½**é²æ£’åœ°å¤„ç†å±€éƒ¨å¯¹ç§°æ€§ç ´å**çš„ç®—æ³•ï¼Œä¾‹å¦‚é€šè¿‡æ›´çµæ´»çš„ partial equivariance æ¡†æ¶æˆ–å­¦ä¹ å¯¹ä¸å¯¹ç§°å› ç´ ä¸å˜çš„è¡¨ç¤ºã€‚\n\n- **æ·±åŒ–å¯¹ç§°æ€§åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­çš„åˆ©ç”¨**ï¼š\n    - **è§„åˆ’ä¸ç­–ç•¥å­¦ä¹ **ï¼šæ›´ç›´æ¥åœ°åˆ©ç”¨å·²å‘ç°æŠ€èƒ½çš„å¯¹ç§°ç»“æ„æ¥**åŠ é€Ÿä¸‹æ¸¸ä»»åŠ¡çš„è§„åˆ’å’Œé«˜å±‚ç­–ç•¥å­¦ä¹ **ã€‚ä¾‹å¦‚ï¼Œåˆ©ç”¨å¯¹ç§°æ€§è¿›è¡Œæ•°æ®å¢å¼ºã€æ„å»ºå¯¹ç§°æ€§æ„ŸçŸ¥çš„è§„åˆ’ç®—æ³•ã€‚\n\n- **ç®—æ³•ä¸ç†è®ºçš„è¿›ä¸€æ­¥æ‹“å±•**ï¼š\n    - **æ¢ç´¢å…¶ä»–å¯¹ç§°ç¾¤**ï¼šå½“å‰å·¥ä½œä¸»è¦å…³æ³¨è¿ç»­/ç¦»æ•£æ—‹è½¬å’Œç¿»è½¬å¯¹ç§°ã€‚å¯æ‰©å±•åˆ°æ›´ä¸€èˆ¬çš„ç¾¤ï¼Œå¦‚**æ¬§å‡ é‡Œå¾—ç¾¤E(n)**ã€ç¼©æ”¾å¯¹ç§°ç¾¤ç­‰ã€‚\n    - **ä¸å…¶ä»–å…ˆéªŒçš„èåˆ**ï¼šå°†å‡ ä½•å¯¹ç§°æ€§å…ˆéªŒä¸**å…¶ä»–å½¢å¼çš„å…ˆéªŒ**ï¼ˆå¦‚è®ºæ–‡æåˆ°çš„è¯­è¨€æŒ‡å¯¼ã€è¡Œä¸ºåå¥½ï¼‰ç›¸ç»“åˆï¼Œä»¥å‘ç°æ›´ä¸°å¯Œã€æ›´å¯æ§çš„æŠ€èƒ½ã€‚\n\n- **é™ä½è®¡ç®—ä¸å®ç°é—¨æ§›**ï¼š\n    - å¼€å‘æ›´é«˜æ•ˆçš„ç¾¤è¡¨ç¤ºå‚æ•°åŒ–æ–¹æ³•æˆ–è¿‘ä¼¼ç®—æ³•ï¼Œä»¥**é™ä½è®¡ç®—å¼€é”€**ï¼Œä¿ƒè¿›åœ¨æ›´å¤§è§„æ¨¡æˆ–å®æ—¶ç³»ç»Ÿä¸­çš„åº”ç”¨ã€‚\n\næ€»è€Œè¨€ä¹‹ï¼Œè¯¥è®ºæ–‡åœ¨**ç†è®ºåˆ›æ–°**ï¼ˆè¯æ˜äº†å¯¹ç§°æœ€ä¼˜è§£çš„å­˜åœ¨æ€§å¹¶æ„å»ºäº†ç¾¤ä¸å˜WDMï¼‰å’Œ**å®é™…ä»·å€¼**ï¼ˆåœ¨locomotionä»»åŠ¡ä¸Šæå‡äº†æ ·æœ¬æ•ˆç‡ä¸æ³›åŒ–èƒ½åŠ›ï¼‰ä¸Šè´¡çŒ®æ˜¾è‘—ï¼Œä½†å…¶åº”ç”¨èŒƒå›´å—é™äºå¯¹ç§°æ€§å‡è®¾å’Œå®ç°å¤æ‚åº¦ã€‚æœªæ¥çš„å·¥ä½œæ ¸å¿ƒåœ¨äº**çªç ´è¿™äº›é™åˆ¶**ï¼Œä½¿å¯¹ç§°æ€§æ„ŸçŸ¥çš„æŠ€èƒ½å‘ç°æ–¹æ³•èƒ½åº”ç”¨äºæ›´å¹¿æ³›ã€æ›´å¤æ‚çš„ç°å®ä¸–ç•Œæœºå™¨äººå­¦ä¹ é—®é¢˜ã€‚",
            "timestamp": "2026-01-27T15:59:43.153822",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        }
    ],
    "is_hidden": false,
    "is_starred": false,
    "flag": true,
    "published_date": "2026-01-20T14:21:18Z",
    "created_at": "2026-01-27T15:53:12.362499",
    "updated_at": "2026-01-27T15:53:12.362506"
}