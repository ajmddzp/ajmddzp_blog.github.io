{
    "id": "2601.09178v2",
    "title": "Vision-Conditioned Variational Bayesian Last Layer Dynamics Models",
    "authors": [
        "Paul Brunzema",
        "Thomas Lew",
        "Ray Zhang",
        "Takeru Shirasawa",
        "John Subosits",
        "Marcus Greiff"
    ],
    "abstract": "æœºå™¨äººç³»ç»Ÿçš„æ•æ·æ§åˆ¶é€šå¸¸éœ€è¦é¢„åˆ¤ç¯å¢ƒå¦‚ä½•å½±å“ç³»ç»Ÿè¡Œä¸ºã€‚ä¾‹å¦‚ï¼Œé©¾é©¶å‘˜å¿…é¡»æ„ŸçŸ¥å‰æ–¹è·¯å†µä»¥é¢„åˆ¤å¯ç”¨æ‘©æ“¦åŠ›ï¼Œå¹¶æ®æ­¤è§„åˆ’è¡ŒåŠ¨ã€‚åœ¨è‡ªä¸»æ¡†æ¶å†…å®ç°è¿™ç§å‰ç»æ€§é€‚åº”ä»å…·æŒ‘æˆ˜æ€§ï¼Œå°¤å…¶åœ¨å¿«é€Ÿå˜åŒ–æ¡ä»¶ä¸‹ã€‚ä¼ ç»Ÿå»ºæ¨¡æ–¹æ³•å¾€å¾€éš¾ä»¥æ•æ‰ç³»ç»Ÿè¡Œä¸ºçš„çªå˜ï¼Œè€Œè‡ªé€‚åº”æ–¹æ³•æœ¬è´¨ä¸Šæ˜¯ååº”å¼çš„ï¼Œå¯èƒ½å› é€‚åº”è¿‡è¿Ÿè€Œæ— æ³•ç¡®ä¿å®‰å…¨ã€‚æˆ‘ä»¬æå‡ºä¸€ç§è§†è§‰æ¡ä»¶åŒ–çš„å˜åˆ†è´å¶æ–¯æœ«å±‚åŠ¨åŠ›å­¦æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åˆ©ç”¨è§†è§‰ä¸Šä¸‹æ–‡é¢„åˆ¤ç¯å¢ƒå˜åŒ–ã€‚è¯¥æ¨¡å‹é¦–å…ˆå­¦ä¹ æ ‡ç§°è½¦è¾†åŠ¨åŠ›å­¦ï¼Œéšåé€šè¿‡æ½œåœ¨ç‰¹å¾çš„é€ç‰¹å¾ä»¿å°„å˜æ¢è¿›è¡Œå¾®è°ƒï¼Œä»è€Œå®ç°æƒ…å¢ƒæ„ŸçŸ¥çš„åŠ¨åŠ›å­¦é¢„æµ‹ã€‚æœ€ç»ˆæ¨¡å‹è¢«é›†æˆè‡³è½¦è¾†ç«é€Ÿçš„æœ€ä¼˜æ§åˆ¶å™¨ä¸­ã€‚æˆ‘ä»¬åœ¨é›·å…‹è¨æ–¯LC500æ¶‰æ°´ç«é€Ÿåœºæ™¯ä¸­éªŒè¯äº†è¯¥æ–¹æ³•ã€‚é€šè¿‡è§†è§‰æ¡ä»¶åŒ–ï¼Œç³»ç»Ÿåœ¨ä¸åŒæ¡ä»¶ä¸‹æˆåŠŸå®Œæˆäº†å…¨éƒ¨12åœˆå°è¯•ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œæ‰€æœ‰æœªä½¿ç”¨è§†è§‰ä¸Šä¸‹æ–‡çš„åŸºçº¿æ¨¡å‹å‡æŒç»­å¤±æ§ï¼Œè¿™è¯æ˜äº†å‰ç»æ€§åŠ¨åŠ›å­¦é€‚åº”åœ¨é«˜æ€§èƒ½åº”ç”¨ä¸­çš„é‡è¦æ€§ã€‚",
    "url": "https://arxiv.org/abs/2601.09178v2",
    "html_url": "https://arxiv.org/html/2601.09178v2",
    "html_content": "Vision-Conditioned Variational Bayesian Last Layer Dynamics Models\nPaul Brunzema\n1\n, Thomas Lew\n2\n, Ray Zhang\n2\n, Takeru Shirasawa\n2\n, John Subosits\n2\n, Marcus Greiff\n2,âˆ—\nâˆ—\nCorresponding author.\n1\nPaul Brunzema is with the department of Mechanical Engineering, Aachen University, Germany. Email:\npaul.brunzema@googlemail.com\n. Paul was with TRI when conducting this research.\n2\nThe remaining authors are with Toyota Research Institute,\n4440 El Camino Real, CA, USA. Email:\nfirst.last@tri.global\n.\nAbstract\nAgile control of robotic systems often requires anticipating how the environment affects system behavior.\nFor example, a driver must perceive the road ahead to anticipate available friction and plan actions accordingly.\nAchieving such proactive adaptation within autonomous frameworks remains a challenge, particularly under rapidly changing conditions.\nTraditional modeling approaches often struggle to capture abrupt variations in system behavior, while adaptive methods are inherently reactive and may adapt too late to ensure safety.\nWe propose a vision-conditioned variational Bayesian last-layer dynamics model that leverages visual context to anticipate changes in the environment.\nThe model first learns nominal vehicle dynamics and is then fine-tuned with feature-wise affine transformations of latent features, enabling context-aware dynamics prediction.\nThe resulting model is integrated into an optimal controller for vehicle racing.\nWe validate our method on a Lexus LC500 racing through water puddles.\nWith vision-conditioning, the system completed all 12 attempted laps under varying conditions.\nIn contrast, all baselines without visual context consistently lost control, demonstrating the importance of proactive dynamics adaptation in high-performance applications.\nVideo:\nhttps://youtu.be/m-gcFK0moI8\n.\nI\nIntroduction\nAccurate dynamics models are key to agile robotic autonomy, such as in scenarios like emergency avoidance or racing, where vehicles operate at the limits of handling\n[\n10\n]\n.\nAt these extremes, even minor modeling errors can cascade into catastrophic failure\n[\n12\n,\n33\n]\n, making precise prediction of vehicle behavior essential for both safety and performance.\nTraditional vehicle dynamics models rely on simplified assumptions about road conditions and tire behavior\n[\n49\n,\n7\n,\n3\n]\n.\nThese assumptions hold in nominal settings but often fail when faced with significant environmental variations, especially when driving at the limit.\nFor example, transitioning between dry and wet pavement significantly alters friction, leading to substantially different vehicle dynamics\n[\n17\n]\n.\nLearning-based approaches seek to compensate for such effects using online adaptation of a learned dynamics model\n[\n15\n,\n12\n,\n48\n,\n30\n,\n27\n]\n. However, adaptation is reactive and often too slow to prevent instability near handling limits\n[\n12\n]\n,\nmotivating a shift toward anticipatory models that utilize exteroceptive sensing to adjust control strategies proactively.\nWithout vision\nWith vision\nCamera FOV\nLateral limits\nWater\nFigure 1:\nA learned vehicle model conditioned on visual context is used for predictive control. With the visual context (orange), the car autonomously races through the water (blue), while models void of context spin out (red).\nWhile recent learned models achieve strong performance using proprioceptive data\n[\n16\n,\n15\n,\n17\n,\n12\n]\n, they are often blind to the environmental context.\nIncorporating exteroceptive cues from vision promises a shift from reactive to anticipatory dynamics modeling.\nTo this end, we introduce\nVcVBLL\n, a vision-conditioned variational Bayesian last-layerÂ (VBLL) dynamics model.\nThis novel model integrates visual context, extracted from forward-facing cameras, directly into the VBLL dynamics representation.\nThe learned conditioning on visual information allows a controller to proactively adjust its actions before encountering challenging conditions.\nWhile this letter emphasizes racing as a challenging problem, the proposed concepts readily generalize to other applications.\nContributions.\nWe propose a vision-conditioned VBLL dynamics (\nVcVBLL\n) model to capture changing vehicle dynamics arising from varying road surface properties (e.g.,Â wet vs. dry conditions) through visual information.\nSpecifically:\nâ€¢\nWith\nVcVBLL\nwe present the first VBLL-based dynamics model conditioned on visual information.\nTo address the scarcity of data with environmental changes (e.g.,Â waterâ€“tire interactions), we introduce a two-stage fine-tuning procedure. This approach modulates the dynamics representation of a base VBLL trained on nominal driving data with a vision-conditioning path learned from limited wet-surface data. The resulting model yields interpretable adjustments in the predictive distribution.\nâ€¢\nWe integrate the\nVcVBLL\ndynamics model within a model predictive control (MPC) framework to achieve proactive, vision-informed autonomous racing on a Lexus LC500 in hardware experiments.\nOur model enables high-speed autonomous racing through changing conditions where all proprioceptive-only baselines spin out.\nOrganization.\nWe review related work in Sec.\nII\nand present preliminaries on vehicle modeling and optimal control in Sec.\nIII\n. The proposed\nVcVBLL\nmodel is developed in Sec.\nIV\nand the main results are presented in Sec.\nV\n.\nII\nRelated Work\nAutonomous Driving at the Limit.\nHigh-performance driving research has focused on vehicle modeling and optimal control for racing\n[\n33\n,\n52\n,\n45\n,\n47\n,\n9\n,\n10\n]\nand drifting\n[\n51\n,\n16\n,\n15\n,\n17\n]\n.\nIn these works, MPC\n[\n22\n]\nis used to track a reference trajectory using a first-principles vehicle model\n[\n42\n,\n19\n,\n49\n,\n51\n]\n, often refined via system identification\n[\n34\n]\nwith a fixed parametric form\n[\n14\n]\n, parameter estimation\n[\n33\n]\n, or online adaptation\n[\n10\n]\n.\nTo capture more complex dynamics, neural network (NN)\n[\n45\n]\nand Gaussian process\n[\n30\n,\n29\n]\nmodels have been explored.\nRecent work also demonstrates that diffusion-generated parameters can enable complex drifting\n[\n17\n]\n, albeit at a higher computational cost.\nOther approaches include Koopman-based models that lift dynamics into a higher-dimensional space of observables\n[\n41\n,\n48\n]\n.\nCrucially,\nthese approaches do not consider proactive adaptation of the dynamics model based on exteroceptive information.\nStill, parametric NNs offer a distinct advantage as a model class: their flexibility enables conditioning on visual cues via mechanisms like FiLM\n[\n40\n]\n.\nSuch conditioning has proven effective in vision-based manipulation\n[\n8\n]\n, motivating learning exteroceptive-informed NN features from data.\nBayesian Last-Layer Models.\nBayesian last-layer (BLL) models extend parametric NNs with Gaussian last-layer weights\n[\n29\n,\n44\n,\n24\n,\n50\n,\n20\n]\nas a light-weight Bayesian NN.\nThey provide Gaussian predictive posteriors and have shown promise in drifting\n[\n11\n]\nand off-road driving\n[\n32\n]\n.\nVariational BLL (VBLL) models\n[\n25\n]\njointly learn last-layer weights and noise via a variational objective, achieving promising results across various applications\n[\n25\n,\n5\n]\n.\nTherefore, we adopt VBLLs as our base architecture, applying this state-of-the-art model class to dynamics learning for the first time.\nVision-Conditioned Control.\nMuch work has been done on end-to-end driving, directly learning a mapping from pixels to control signals\n[\n4\n]\n.\nNumerous reinforcement learning approaches have been proposed for racing\n[\n6\n,\n2\n]\n, focusing on learning an NN policy.\nAlso in MPC, vision-conditioning has been applied to infer cost\n[\n18\n,\n53\n]\nor derive constraints for obstacle avoidance\n[\n18\n]\n, but not to condition a dynamics model.\nAlthough recent methods learn MPC dynamics within an RL framework for aggressive driving, they do not incorporate vision\n[\n1\n]\n.\nIn mobile robotics, visual foundation models have been used to estimate disturbances for a nominal physics-based dynamics model\n[\n36\n]\n, and perceptive dynamics models have been proposed for legged robots using exteroceptive inputs to enable safe planning\n[\n43\n]\nwith MPPI.\nTo our knowledge, our approach is the first to\nexplicitly condition a dynamics model on vision with downstream use in an optimal controller for proactive racing.\nOur results show that this capability can be the difference-maker when racing autonomously in varying friction conditions.\nIII\nPreliminaries\nF\nx\nâ€‹\nr\nF_{xr}\nF\ny\nâ€‹\nr\nF_{yr}\nÏ„\nr\n\\tau_{r}\nÏ„\neng\n\\tau_{\\mathrm{eng}}\nÏ‰\nr\n\\omega_{r}\nF\nx\nâ€‹\nf\nF_{xf}\nF\ny\nâ€‹\nf\nF_{yf}\nÏ„\nf\n\\tau_{f}\nÎ´\n\\delta\nğ’—\n\\boldsymbol{v}\nÎ²\n\\beta\nr\nr\nreference path\ns\ns\ne\ne\npath tangent\nÎ”\nâ€‹\nÏ•\n\\Delta\\phi\nFigure 2:\nVehicle geometry with the bicycle model states\nğ’™\n\\boldsymbol{x}\n(black), control inputs\nğ’–\n\\boldsymbol{u}\n(blue), tire forces (red), and the reference path\nğ’™\nref\nâ€‹\n(\ns\n)\n\\boldsymbol{x}_{\\mathrm{ref}}(s)\n(orange).\nVectors are denoted by\nğ’™\nâˆˆ\nâ„\nn\n\\boldsymbol{x}\\in\\mathbb{R}^{n}\n, with\nx\ni\nx_{i}\nbeing the\ni\ni\nth element of\nğ’™\n\\boldsymbol{x}\n. Matrices are indicated in bold,\nğ‘¿\n\\boldsymbol{X}\n, and the element on row\ni\ni\nand column\nj\nj\nof\nğ‘¿\n\\boldsymbol{X}\nis\n[\nğ‘¿\n]\ni\nâ€‹\nj\n[\\boldsymbol{X}]_{ij}\n. We let\nğ’™\nÂ¯\nâˆ¼\nN\nâ€‹\n(\nğ’™\n|\nğ’\n,\nğ‘·\n)\nâˆ\n|\nğ‘·\n|\nâˆ’\n1\n/\n2\nâ€‹\nexp\nâ¡\n(\nâˆ’\n1\n2\nâ€‹\n(\nğ’™\nâˆ’\nğ’\n)\nâŠ¤\nâ€‹\nğ‘·\nâˆ’\n1\nâ€‹\n(\nğ’™\nâˆ’\nğ’\n)\n)\n\\underaccent{\\bar}{\\xvec}\\sim\\mathrm{N}(\\boldsymbol{x}|\\boldsymbol{m},\\boldsymbol{P})\\propto|\\boldsymbol{P}|^{-1/2}\\exp(-\\tfrac{1}{2}(\\boldsymbol{x}-\\boldsymbol{m})^{\\top}\\boldsymbol{P}^{-1}(\\boldsymbol{x}-\\boldsymbol{m}))\nindicate that the random variable\nğ’™\nÂ¯\n\\underaccent{\\bar}{\\xvec}\nis Gaussian distributed with mean\nğ’\n\\boldsymbol{m}\nand covariance\nğ‘·\n\\boldsymbol{P}\n. Similarly, we let\nx\nÂ¯\nâˆ¼\nIG\nâ€‹\n(\nx\n|\nÎ±\n,\nÎ²\n)\nâˆ\nx\nâˆ’\nÎ±\nâˆ’\n1\nâ€‹\nexp\nâ¡\n(\nâˆ’\nÎ²\nâ€‹\nx\nâˆ’\n1\n)\n,\n\\underaccent{\\bar}{x}\\sim\\mathrm{IG}(x|\\alpha,\\beta)\\propto x^{-\\alpha-1}\\exp(-\\beta x^{-1}),\nindicate that\nx\nÂ¯\n\\underaccent{\\bar}{x}\nis inverse Gamma distributed. We write the expectation of\nğ’™\nÂ¯\nâˆ¼\np\nğ’™\nÂ¯\nâ€‹\n(\nğ’™\n)\n\\underaccent{\\bar}{\\xvec}\\sim p_{\\underaccent{\\bar}{\\xvec}}(\\boldsymbol{x})\nas\nğ”¼\nğ’™\nÂ¯\nâˆ¼\np\nğ’™\nÂ¯\nâ€‹\n(\nğ’™\n)\nâ€‹\n[\nğ’™\nÂ¯\n]\n=\nâˆ«\nğ’™\nâ€‹\np\nğ’™\nÂ¯\nâ€‹\n(\nğ’™\n)\nâ€‹\nd\nğ’™\n\\mathbb{E}_{\\underaccent{\\bar}{\\xvec}\\sim p_{\\underaccent{\\bar}{\\xvec}}(\\boldsymbol{x})}[\\underaccent{\\bar}{\\xvec}]=\\int\\boldsymbol{x}p_{\\underaccent{\\bar}{\\xvec}}(\\boldsymbol{x})\\mathrm{d}\\boldsymbol{x}\ncompactly as\nğ”¼\np\nâ€‹\n[\nğ’™\n]\n\\mathbb{E}_{p}[\\boldsymbol{x}]\n. In this notation, the KL-divergence between the densities\np\np\nand\nq\nq\nis\nKL\nâ€‹\n(\np\nâˆ¥\nq\n)\n=\nğ”¼\np\nâ€‹\n[\nlog\nâ¡\n(\np\nâ€‹\n(\nğ’™\n)\n/\nq\nâ€‹\n(\nğ’™\n)\n)\n]\n\\mathrm{KL}(p\\|q)=\\mathbb{E}_{p}[\\log(p(\\boldsymbol{x})/q(\\boldsymbol{x}))]\n.\nPhysics-based models.\nIn\n[\n45\n,\n11\n,\n33\n]\n, it is shown that a well-calibrated single-track model\n[\n42\n]\nwith Fiala tire-forces\n[\n19\n,\n49\n]\nenables racing at the limits of handling (see Fig.\n2\n).\nThus, we use similar inputs for our learned model, and define the state\nğ’™\n=\n(\nğ’™\n1\n,\nğ’™\n2\n)\n\\boldsymbol{x}=(\\boldsymbol{x}_{1},\\boldsymbol{x}_{2})\nand control input\nğ’–\n\\boldsymbol{u}\nas\nğ’™\n1\n\\displaystyle\\boldsymbol{x}_{1}\n=\n(\nr\n,\nv\n,\nÎ²\n,\nÏ‰\nr\n)\nâŠ¤\nâˆˆ\nâ„\n4\n,\n\\displaystyle=(r,v,\\beta,\\omega_{r})^{\\top}\\in\\mathbb{R}^{4},\n(1a)\nğ’™\n2\n\\displaystyle\\boldsymbol{x}_{2}\n=\n(\ne\n,\nÎ”\nâ€‹\nÏ•\n,\ns\n)\nâŠ¤\nâˆˆ\nâ„\n3\n,\n\\displaystyle=(e,\\Delta\\phi,s)^{\\top}\\in\\mathbb{R}^{3},\n(1b)\nğ’–\n\\displaystyle\\boldsymbol{u}\n=\n(\nÎ´\n,\nÏ„\ncombined\n,\nÏ„\nf\n)\nâŠ¤\nâˆˆ\nâ„\n3\n,\n\\displaystyle=(\\delta,\\tau_{\\text{combined}},\\tau_{f})^{\\top}\\in\\mathbb{R}^{3},\n(1c)\nwhere\nr\nr\n(rad/s) is a yaw rate,\nv\nv\n(m/s) is the longitudinal velocity,\nÎ²\n\\beta\n(rad) is a side-slip angle, and\nÏ‰\nr\n\\omega_{r}\n(rad/s) is an average rear wheel speed,\ne\ne\n(m) is a lateral path distance,\nÎ”\nâ€‹\nÏ•\n\\Delta\\phi\n(rad) is a deviation with respect to a racing line, and\ns\ns\n(m) is a path distance (see Fig.\n2\n). Furthermore,\nÎ´\n\\delta\n(rad) is the steering angle,\nÏ„\ncombined\n\\tau_{\\text{combined}}\n(Nm) is the combined rear torque, and\nÏ„\nf\n\\tau_{f}\n(Nm) are the front brake torques. The dynamics of the vehicle can then be written as a cascaded system\nğ’™\nË™\n1\nâ€‹\n(\nt\n)\n\\displaystyle\\dot{\\boldsymbol{x}}_{1}(t)\n=\nğ’‡\n1\nâ€‹\n(\nğ’™\n1\nâ€‹\n(\nt\n)\n,\nğ’–\nâ€‹\n(\nt\n)\n)\n,\n\\displaystyle=\\boldsymbol{f}_{1}(\\boldsymbol{x}_{1}(t),\\boldsymbol{u}(t)),\n(2a)\nğ’™\nË™\n2\nâ€‹\n(\nt\n)\n\\displaystyle\\dot{\\boldsymbol{x}}_{2}(t)\n=\nğ’‡\n2\nâ€‹\n(\nğ’™\n1\nâ€‹\n(\nt\n)\n,\nğ’™\n2\nâ€‹\n(\nt\n)\n,\nğ’–\nâ€‹\n(\nt\n)\n)\n.\n\\displaystyle=\\boldsymbol{f}_{2}(\\boldsymbol{x}_{1}(t),\\boldsymbol{x}_{2}(t),\\boldsymbol{u}(t)).\n(2b)\nIn this representation,\nğ’‡\n1\n\\boldsymbol{f}_{1}\nencodes assumptions about the tire-force model and is defined by parameters that are estimated or manually tuned (see the appendix), whereas\nğ’‡\n2\n\\boldsymbol{f}_{2}\nis known from the carâ€™s kinematics. Indeed, from Fig.\n2\n, we obtain\ne\nË™\nâ€‹\n(\nt\n)\n\\displaystyle\\dot{e}(t)\n=\nv\nâ€‹\n(\nt\n)\nâ€‹\nsin\nâ¡\n(\nÎ”\nâ€‹\nÏ•\nâ€‹\n(\nt\n)\n)\n,\n\\displaystyle=v(t)\\sin(\\Delta\\phi(t)),\n(3a)\nÎ”\nâ€‹\nÏ•\nË™\n\\displaystyle\\Delta\\dot{\\phi}\n=\nÎ²\nË™\nâ€‹\n(\nt\n)\n+\nr\nâ€‹\n(\nt\n)\nâˆ’\nÎº\nref\nâ€‹\n(\nt\n)\nâ€‹\nv\nâ€‹\n(\nt\n)\nâ€‹\ncos\nâ¡\n(\nÎ”\nâ€‹\nÏ•\nâ€‹\n(\nt\n)\n)\n(\n1\nâˆ’\nÎº\nref\nâ€‹\n(\nt\n)\nâ€‹\ne\nâ€‹\n(\nt\n)\n)\n,\n\\displaystyle=\\dot{\\beta}(t)+r(t)-\\frac{\\kappa_{\\textrm{ref}}(t)v(t)\\cos(\\Delta\\phi(t))}{(1-\\kappa_{\\textrm{ref}}(t)e(t))},\n(3b)\ns\nË™\nâ€‹\n(\nt\n)\n\\displaystyle\\dot{s}(t)\n=\nv\nâ€‹\n(\nt\n)\nâ€‹\ncos\nâ¡\n(\nÎ”\nâ€‹\nÏ•\n)\n(\n1\nâˆ’\nÎº\nref\nâ€‹\n(\nt\n)\nâ€‹\ne\nâ€‹\n(\nt\n)\n)\n,\n\\displaystyle=\\frac{v(t)\\cos(\\Delta\\phi)}{(1-\\kappa_{\\textrm{ref}}(t)e(t))},\n(3c)\nwhere\nÎº\nref\n\\kappa_{\\mathrm{ref}}\nis the signed curvature of the reference path. The term\nğ’‡\n1\n\\boldsymbol{f}_{1}\ncontains all the epistemic uncertainty of the vehicle model, and is the focus of our learning based methods. To embed this model in a predictive control framework, we reparametrize the model in the path variable\ns\ns\n, as\nd\nd\nâ€‹\ns\nâ€‹\nğ’™\nâ€‹\n(\ns\n)\n\\displaystyle\\frac{\\mathrm{d}}{\\mathrm{d}s}\\boldsymbol{x}(s)\n=\n1\ns\nË™\nâ€‹\n[\nğ’‡\n1\nâ€‹\n(\nğ’™\n1\nâ€‹\n(\ns\n)\n,\nğ’–\nâ€‹\n(\ns\n)\n)\ne\nË™\nâ€‹\n(\ns\n)\nÎ”\nâ€‹\nÏ•\nË™\nâ€‹\n(\ns\n)\n1\n]\nâ‰œ\nğ’‡\nâ€‹\n(\nğ’™\nâ€‹\n(\ns\n)\n,\nğ’–\nâ€‹\n(\ns\n)\n)\n.\n\\displaystyle=\\frac{1}{\\dot{s}}\\begin{bmatrix}\\boldsymbol{f}_{1}(\\boldsymbol{x}_{1}(s),\\boldsymbol{u}(s))\\\\\n\\dot{e}(s)\\\\\n\\dot{\\Delta\\phi}(s)\\\\\n1\\end{bmatrix}\\triangleq\\boldsymbol{f}(\\boldsymbol{x}(s),\\boldsymbol{u}(s)).\n(4a)\nWe then discretize the dynamics with a constant path step\nÎ”\nâ€‹\ns\n=\n3\nm\n\\Delta s=$3\\text{\\,}\\mathrm{m}$\nand integrate the ODE with explicit Euler as\nğ’™\nk\n+\n1\n=\nğ’™\nk\n+\nÎ”\nâ€‹\ns\nâ€‹\nğ’‡\nâ€‹\n(\nğ’™\nk\n,\nğ’–\nk\n)\n.\n\\boldsymbol{x}_{k+1}=\\boldsymbol{x}_{k}+\\Delta s\\boldsymbol{f}(\\boldsymbol{x}_{k},\\boldsymbol{u}_{k}).\n(5)\nOptimal Control.\nIn the context of racing, the objective is to minimize lap time. Following\n[\n33\n]\n, we penalize state-control deviations from a pre-computed reference trajectory\n(\nğ’™\nref\nâ€‹\n(\ns\n)\n,\nğ’–\nref\n,\nÎº\nref\nâ€‹\n(\ns\n)\n)\ns\n>\n0\n(\\boldsymbol{x}_{\\text{ref}}(s),\\boldsymbol{u}_{\\text{ref}},\\kappa_{\\text{ref}}(s))_{s>0}\nand rapid changes in control inputs to improve robustness and numerical stability. We define the linear time cost and quadratic stage costs as:\nâ„“\nT\nâ€‹\n(\nğ’™\n)\n\\displaystyle\\ell_{T}(\\boldsymbol{x})\\!\n=\nÎ»\nT\nâ€‹\nt\n,\n\\displaystyle=\\!\\lambda_{T}\\,t,\n(6a)\nâ„“\nâ€‹\n(\nğ’™\n,\nğ’–\n,\nğ’–\nâˆ’\n)\n\\displaystyle\\ell(\\boldsymbol{x},\\!\\boldsymbol{u},\\!\\boldsymbol{u}_{-})\\!\n=\nâ€–\nğ’™\nâˆ’\nğ’™\nref\nâ€–\nğ‘¸\n2\n+\nâ€–\nğ’–\nâˆ’\nğ’–\nref\nâ€–\nğ‘¹\n2\n+\nâ€–\nğ’–\nâˆ’\nğ’–\nâˆ’\nâ€–\nğ‘»\n2\n(\nÎ”\nâ€‹\ns\n)\n2\n,\n\\displaystyle=\\!\\|\\boldsymbol{x}\\!-\\!\\boldsymbol{x}_{\\text{ref}}\\|_{\\boldsymbol{Q}}^{2}\\!+\\!\\|\\boldsymbol{u}\\!-\\!\\boldsymbol{u}_{\\text{ref}}\\|_{\\boldsymbol{R}}^{2}\\!+\\!\\frac{\\|\\boldsymbol{u}\\!-\\!\\boldsymbol{u}_{-}\\|_{\\boldsymbol{T}}^{2}}{(\\Delta s)^{2}},\n(6b)\nwhere\nâ€–\nğ’—\nâ€–\nğ‘·\n2\n=\nğ’—\nâŠ¤\nâ€‹\nğ‘·\nâ€‹\nğ’—\n\\|\\boldsymbol{v}\\|_{\\boldsymbol{P}}^{2}=\\boldsymbol{v}^{\\top}\\boldsymbol{P}\\boldsymbol{v}\n, and\n(\nğ‘¸\n,\nğ‘¹\n,\nğ‘»\n)\n(\\boldsymbol{Q},\\boldsymbol{R},\\boldsymbol{T})\nare diagonal weight matrices with small entries compared to terminal time cost\nâ„“\nT\n\\ell_{T}\n(see the appendix). The term\nâ€–\nğ’–\nâˆ’\nğ’–\nâˆ’\nâ€–\nğ‘»\n2\n/\n(\nÎ”\nâ€‹\ns\n)\n2\n\\|\\boldsymbol{u}-\\boldsymbol{u}_{-}\\|_{\\boldsymbol{T}}^{2}/(\\Delta s)^{2}\npenalizes control rates, where\nğ’–\nâˆ’\n\\boldsymbol{u}_{-}\nis the previous control input. With these costs, we formulate the optimal control problem (OCP):\nmin\nğ’™\n0\n:\nN\nğ’–\n0\n:\nN\nâˆ’\n1\n\\displaystyle\\min_{\\begin{subarray}{c}\\boldsymbol{x}_{0:N}\\\\\n\\boldsymbol{u}_{0:N-1}\\end{subarray}}\\quad\nâ„“\nT\nâ€‹\n(\nğ’™\nN\n)\n+\nâˆ‘\nk\n=\n0\nN\nâˆ’\n1\nâ„“\nâ€‹\n(\nğ’™\nk\n,\nğ’–\nk\n,\nğ’–\nk\nâˆ’\n1\n)\n\\displaystyle\\ell_{T}(\\boldsymbol{x}_{N})+\\textstyle\\sum_{k=0}^{N-1}\\ell(\\boldsymbol{x}_{k},\\boldsymbol{u}_{k},\\boldsymbol{u}_{k-1})\n(7)\ns.t.\nğ‘­\nâ€‹\n(\nğ’™\nk\n,\nğ’–\nk\n,\nğ’™\nk\n+\n1\nâˆ£\nğ’„\nt\n)\n=\nğŸ\n,\nk\nâˆˆ\n[\n0\n,\nN\nâˆ’\n1\n]\n\\displaystyle\\boldsymbol{F}(\\boldsymbol{x}_{k},\\boldsymbol{u}_{k},\\boldsymbol{x}_{k+1}\\mid\\boldsymbol{c}_{t})=\\mathbf{0},\\hskip 35.0ptk\\in[0,N-1]\n(\nğ’™\n0\n,\nğ’–\n0\n)\n=\n(\nğ’™\ninit\n,\nğ’–\ninit\n)\n,\n\\displaystyle(\\boldsymbol{x}_{0},\\boldsymbol{u}_{0})=(\\boldsymbol{x}_{\\text{init}},\\boldsymbol{u}_{\\text{init}}),\nğ’–\nmin\nâ‰¤\nğ’–\nk\nâ‰¤\nğ’–\nmax\n,\nk\nâˆˆ\n[\n0\n,\nN\nâˆ’\n1\n]\n\\displaystyle\\boldsymbol{u}_{\\min}\\leq\\boldsymbol{u}_{k}\\leq\\boldsymbol{u}_{\\max},\\hskip 61.0ptk\\in[0,N-1]\ne\nmin\n,\nk\nâ‰¤\ne\nk\nâ‰¤\ne\nmax\n,\nk\n,\nk\nâˆˆ\n[\n0\n,\nN\n]\n\\displaystyle e_{\\min,k}\\leq e_{k}\\leq e_{\\max,k},\\hskip 54.0ptk\\in[0,N]\nwhere\nğ‘­\n\\boldsymbol{F}\nrepresents the combined dynamics given the current context\nğ’„\nt\n\\boldsymbol{c}_{t}\n, enforcingÂ (\n5\n).\nThis formulation results in a context-dependent optimal control problem that is solved in a receding horizon fashion. The car is actuated with the optimal controls\nğ’–\n0\n:\nN\nâˆ’\n1\nâ‹†\n\\boldsymbol{u}^{\\star}_{0:N-1}\nlinearly interpolated to the current position of the car in\ns\ns\n. Next, we describe how to express\nğ‘­\n\\boldsymbol{F}\nusing VBLLs.\nFigure 3:\nConceptual overview of\nVcVBLL\nand its training.\nWe begin by training a base VBLL dynamics model (green path).\nTo incorporate vision-based conditioning, we first extract semantic classes using a fine-tuned\nSegman-t\nbackbone from the limited available data with water interaction, from which we compute a short\n2\nsec\n2\\text{\\,}\\sec\ntime series of past water scores corresponding to\nğ’„\nt\n\\boldsymbol{c}_{t}\n.\nIn a subsequent fine-tuning phase, this time series is encoded with an LSTM and used in a FiLM conditioning path to obtain our vision-conditioned\nVcVBLL\ndynamics model (orange path).\nIV\nVBLLs with FiLM Conditioning\nWe begin in Sec.\nIV-A\nby describing how to learn a base VBLL dynamics model from state transitions only.\nSec.\nIV-B\nexplains how to extract visual context from limited data, and Sec.\nIV-C\ndetails how to condition the VBLL model on this context in a fine-tuning step with limited data (see Fig.\n3\n).\nIV-A\nLearning a VBLL vehicle model\nFollowing common practice in dynamics learning\n[\n13\n,\n15\n]\n, we train a VBLL model to predict state differences rather than absolute states, which has been shown to improve numerical stability\n[\n15\n]\n.\nWe learn the dynamicsÂ (\n2a\n) in time coordinates and then convert to path coordinates usingÂ (\n4a\n). Specifically, for a time step\nÎ”\nâ€‹\nt\n>\n0\n\\Delta t>0\n, we model\nÎ”\nâ€‹\nğ’™\nt\nâ‰”\nğ’™\n1\n,\nt\n+\nÎ”\nâ€‹\nt\nâˆ’\nğ’™\n1\n,\nt\n=\nğ’‡\nÎ¸\nâ€‹\n(\nğ’›\nt\n)\n,\n\\Delta\\boldsymbol{x}_{t}\\coloneqq\\boldsymbol{x}_{1,t+\\Delta t}-\\boldsymbol{x}_{1,t}=\\boldsymbol{f}_{\\theta}(\\boldsymbol{z}_{t}),\n(8)\nwhere\nğ’‡\nÎ¸\n\\boldsymbol{f}_{\\theta}\ndenotes the learned dynamics function parameterized by\nÎ¸\n\\theta\n, and\nğ’›\nt\n=\n[\nğ’™\n1\n,\nt\n,\nğ’–\nt\n,\nğ’–\nt\n+\nÎ”\nâ€‹\nt\n]\nâˆˆ\nâ„\nn\nz\n\\boldsymbol{z}_{t}=[\\boldsymbol{x}_{1,t},\\boldsymbol{u}_{t},\\boldsymbol{u}_{t+\\Delta t}]\\in\\mathbb{R}^{n_{\\mathrm{z}}}\ncontains the relevant states and controls at time\nt\nt\nalong with the controls at the next time step.\n1\n1\n1\nThe subscript\nt\nt\nis a time (continuous) and\nk\nk\nis a path coordinate (discrete).\nSelecting a\nÎ”\nâ€‹\nt\n\\Delta t\nto approximately match the discrete path step\nÎ”\nâ€‹\ns\n\\Delta s\nat the expected average velocity will later allow us to directly integrate the learned model using the discretization scheme in (\n5\n).\nRemark 1\nAs in\n[\n33\n,\n12\n]\n, we include the control input at the next time step in the dynamics model inputs, consistent with our MPC implementation that interpolates the control sequence in\ns\ns\nat runtime.\nGiven the training target description in (\n8\n), we now define the VBLL model architecture that learns to predict these state differences in a supervised manner.\nWe define a VBLL model with\nd\nd\nindependent heads as\nğ’‡\nÎ¸\nâ€‹\n(\nğ’›\nk\n)\n=\nğ‹\nÎ¸\nâ€‹\n(\nğ’›\nk\n)\nâŠ¤\nâ€‹\nğ‘¾\n=\nğ‹\nÎ¸\nâ€‹\n(\nğ’›\nk\n)\nâŠ¤\nâ€‹\n[\nğ’˜\n1\n,\nâ€¦\n,\nğ’˜\nd\n]\n,\n\\boldsymbol{f}_{\\theta}(\\boldsymbol{z}_{k})=\\boldsymbol{\\varphi}_{\\theta}(\\boldsymbol{z}_{k})^{\\top}\\boldsymbol{W}=\\boldsymbol{\\varphi}_{\\theta}(\\boldsymbol{z}_{k})^{\\top}[\\boldsymbol{w}_{1},\\dots,\\boldsymbol{w}_{d}],\n(9)\nwhere\nğ‹\nÎ¸\n:\nâ„\nn\nz\nâ†¦\nâ„\nn\nw\n\\boldsymbol{\\varphi}_{\\theta}:\\mathbb{R}^{n_{\\mathrm{z}}}\\mapsto\\mathbb{R}^{n_{w}}\nare learned features and\nğ’˜\ni\nâˆˆ\nâ„\nn\nw\n\\boldsymbol{w}_{i}\\in\\mathbb{R}^{n_{w}}\nare Gaussian random variables associated with each VBLL prediction head. Sampling the state differenceÂ (\n8\n) in practice is noisy, and we therefore define a measurement model\nğ’š\nk\n=\nğ’‡\nÎ¸\nâ€‹\n(\nğ’›\nk\n)\n+\nğœº\nk\n,\n\\boldsymbol{y}_{k}=\\boldsymbol{f}_{\\theta}(\\boldsymbol{z}_{k})+\\boldsymbol{\\varepsilon}_{k},\n(10)\nwhere\nğœº\nk\n\\boldsymbol{\\varepsilon}_{k}\nis independent Gaussian zero-mean noise with covariance\nğšº\n=\ndiag\nâ€‹\n(\nÎ£\n1\n,\nâ‹¯\n,\nÎ£\nd\n)\n\\boldsymbol{\\Sigma}=\\mathrm{diag}(\\Sigma_{1},\\cdots,\\Sigma_{d})\n. To infer the backbone parameters, weight distribution, and noise statistics, we follow\n[\n26\n]\nand assume a zero-mean Gaussian prior with covariance\np\nâ€‹\n(\nğ’˜\ni\n)\n=\nN\nâ€‹\n(\nğ’˜\ni\n;\nğŸ\n,\nÎ¾\ni\nâˆ˜\nâ€‹\nğ‘°\n)\np(\\boldsymbol{w}_{i})=\\mathrm{N}(\\boldsymbol{w}_{i};\\boldsymbol{0},\\xi^{\\circ}_{i}\\boldsymbol{I})\nfor the\ni\ni\nth head.\nThe measurements inÂ (\n10\n) are Gaussian givenÂ (\n9\n).\nAs the Gaussian is its own conjugate prior, we\ndefine the posterior\nq\nâ€‹\n(\nğ‘¾\n)\n=\nâˆ\ni\n=\n1\nd\nq\nâ€‹\n(\nğ’˜\ni\n)\n=\nâˆ\ni\n=\n1\nd\nN\nâ€‹\n(\nğ’˜\ni\n;\nğ’\ni\n,\nğ‘º\ni\n)\n,\nq(\\boldsymbol{W})=\\prod_{i=1}^{d}q(\\boldsymbol{w}_{i})=\\prod_{i=1}^{d}\\mathrm{N}(\\boldsymbol{w}_{i};\\boldsymbol{m}_{i},\\boldsymbol{S}_{i}),\n(11)\nand let\nğ‘º\ni\n=\nğ‘³\ni\nâ€‹\nğ‘³\ni\nâŠ¤\n\\boldsymbol{S}_{i}=\\boldsymbol{L}_{i}\\boldsymbol{L}_{i}^{\\top}\nwhere\nğ‘³\ni\n=\nğ‘µ\ni\n+\ndiag\nâ¡\n(\nexp\nâ¡\n(\nğ’…\ni\n)\n)\n\\boldsymbol{L}_{i}=\\boldsymbol{N}_{{i}}+\\operatorname{diag}(\\exp(\\boldsymbol{d}_{i}))\nis lower-triangular and\ndiag\nâ€‹\n(\nğ‘µ\ni\n)\n=\nğŸ\n\\mathrm{diag}(\\boldsymbol{N}_{{i}})=\\boldsymbol{0}\n. This ensures that\nğ‘º\ni\n\\boldsymbol{S}_{i}\nis positive definite without imposing explicit constraints during training. For ease of notation, we define the learnable parameters of the VBLL heads as\nÎ·\n=\n{\nğ’\ni\n,\nğ‘µ\ni\n,\nğ’…\ni\n,\nÎ£\ni\n}\ni\n=\n1\nd\n\\eta=\\{\\boldsymbol{m}_{i},{\\boldsymbol{N}}_{i},\\boldsymbol{d}_{i},\\Sigma_{i}\\}_{i=1}^{d}\n.\nRemark 2\nThis approach differs from the BLL in\n[\n12\n]\nin that\nÎ·\n\\eta\nincludes the unknown noise statistics\n{\nÎ£\ni\n}\ni\n=\n1\nd\n\\{\\Sigma_{i}\\}_{i=1}^{d}\n, giving the model more flexibility. As in\n[\n12\n]\n, our model allows for online adaptation, which is one of our baselines in Sec.\nV\n.\nLosses.\nLet\nğ’Ÿ\n=\n{\n(\nğ’›\nj\n,\nğ’š\nj\n)\n}\nj\n=\n1\n|\nğ’Ÿ\n|\n\\mathcal{D}=\\{(\\boldsymbol{z}_{j},\\boldsymbol{y}_{j})\\}_{j=1}^{|\\mathcal{D}|}\ndenote our training dataset, where each sample consists of inputs\nğ’›\nj\n\\boldsymbol{z}_{j}\nand the corresponding measured state differences\nğ’š\nj\n\\boldsymbol{y}_{j}\n.\nWe standardize all inputs and outputs to have a zero mean and unit variance, thereby improving training stability and convergence.\nWe seek to maximize the evidence lower bound (ELBO) derived in\n[\n26\n, Theorem 1]\n. Given the weights inÂ (\n11\n) the noise inÂ (\n10\n) are both independent across the VBLL heads, we get\nâ„’\nELL\nâ€‹\n(\nÎ·\n,\nÎ¸\n)\n=\n\\displaystyle\\mathcal{L}_{\\text{ELL}}(\\eta,\\theta)=\n1\n|\nğ’Ÿ\n|\nâˆ‘\nj\n=\n1\n|\nğ’Ÿ\n|\nâˆ‘\ni\n=\n1\nd\n[\nlog\nN\n(\ny\nj\nâ€‹\ni\n|\nğ‹\nÎ¸\n(\nğ’›\nj\n)\nâŠ¤\nğ’\ni\n,\nÎ£\ni\n)\n\\displaystyle\\frac{1}{|\\mathcal{D}|}\\sum_{j=1}^{|\\mathcal{D}|}\\sum_{i=1}^{d}\\Big[\\log\\mathrm{N}(y_{ji}|\\boldsymbol{\\varphi}_{\\theta}(\\boldsymbol{z}_{j})^{\\top}\\boldsymbol{m}_{i},\\Sigma_{i})\nâˆ’\n1\n2\nğ‹\nÎ¸\n(\nğ’›\nj\n)\nâŠ¤\nğ‘º\ni\nğ‹\nÎ¸\n(\nğ’›\nj\n)\nÎ£\ni\nâˆ’\n1\n]\n,\n\\displaystyle-\\frac{1}{2}\\boldsymbol{\\varphi}_{\\theta}(\\boldsymbol{z}_{j})^{\\top}\\boldsymbol{S}_{i}\\boldsymbol{\\varphi}_{\\theta}(\\boldsymbol{z}_{j})\\Sigma_{i}^{-1}\\Big],\n(12)\nas a lower bound on the expected log-likelihood (ELL) of\nğ’Ÿ\n\\mathcal{D}\n.\nFollowing\n[\n26\n]\n, we also introduce a regularizer\nâ„›\nâ€‹\n(\nÎ·\n,\nÎ¸\n)\n=\n\\displaystyle\\mathcal{R}(\\eta,\\theta)=\n1\n|\nğ’Ÿ\n|\nâˆ‘\ni\n=\n1\nd\n[\nâˆ’\nKL\n(\nq\n(\nğ’˜\ni\n)\n|\n|\np\n(\nğ’˜\ni\n)\n)\n\\displaystyle\\frac{1}{|\\mathcal{D}|}\\sum_{i=1}^{d}\\Big[-\\text{KL}(q(\\boldsymbol{w}_{i})||p(\\boldsymbol{w}_{i}))\nâˆ’\nlog\nN\n(\nÎ¸\n|\nğŸ\n,\nÎ³\nâˆ˜\nğ‘°\n)\nâˆ’\nlog\nIG\n(\nÎ£\ni\n|\nÎ±\ni\nâˆ˜\n,\nÎ²\ni\nâˆ˜\n)\n]\n.\n\\displaystyle-\\log\\mathrm{N}(\\theta|\\boldsymbol{0},\\gamma^{\\circ}\\boldsymbol{I})-\\log\\mathrm{IG}(\\Sigma_{i}|\\alpha_{i}^{\\circ},\\beta_{i}^{\\circ})\\Big].\n(13)\nweighted by\nÎ»\nreg\n>\n0\n\\lambda_{\\text{reg}}>0\nto stabilize training and regularize the densities toward suitable priors defined by\n{\nÎ±\ni\nâˆ˜\n,\nÎ²\ni\nâˆ˜\n,\nÎ³\nâˆ˜\n,\nÎ¾\ni\nâˆ˜\n}\ni\n=\n1\nd\n\\{\\alpha_{i}^{\\circ},\\beta_{i}^{\\circ},\\gamma^{\\circ},\\xi_{i}^{\\circ}\\}_{i=1}^{d}\n.\nCombining both parts, we formulate and solve the following optimization problem\nÎ¸\nÂ¯\n,\nÎ·\nÂ¯\n=\narg\nâ¡\nmin\nÎ¸\n,\nÎ·\nâ¡\n[\nâˆ’\nâ„’\nELL\nâ€‹\n(\nÎ·\n,\nÎ¸\n)\n+\nÎ»\nreg\nâ€‹\nâ„›\nâ€‹\n(\nÎ·\n,\nÎ¸\n)\n]\nâŸ\nâ‰•\nâ„’\nâ€‹\n(\nÎ·\n,\nÎ¸\n)\n,\n\\bar{\\theta},\\bar{\\eta}=\\arg\\min_{\\theta,\\eta}\\underbrace{\\left[-\\mathcal{L}_{\\text{ELL}}(\\eta,\\theta)+\\lambda_{\\text{reg}}\\mathcal{R}(\\eta,\\theta)\\right]}_{\\eqqcolon\\mathcal{L}(\\eta,\\theta)},\n(14)\nwith additional details on the priors, specifications of the MLP backbone\nğ‹\n\\boldsymbol{\\varphi}\n, and considered regularizers given in the Appendix. With the learned parameters, we obtain a posterior predictive given an input at time\nt\nt\nas\ny\nt\nâ€‹\ni\nâˆ£\nğ’›\nt\nâˆ¼\nN\nâ€‹\n(\nğ‹\nÎ¸\nÂ¯\nâ€‹\n(\nğ’›\nt\n)\nâŠ¤\nâ€‹\nğ’\nÂ¯\ni\n,\nğ‹\nÎ¸\nÂ¯\nâ€‹\n(\nğ’›\nt\n)\nâŠ¤\nâ€‹\nğ‘º\nÂ¯\ni\nâ€‹\nğ‹\nÎ¸\nÂ¯\nâ€‹\n(\nğ’›\nt\n)\n+\nÎ£\nÂ¯\ni\n)\n.\ny_{ti}\\mid\\boldsymbol{z}_{t}\\sim\\mathrm{N}(\\boldsymbol{\\varphi}_{\\bar{\\theta}}(\\boldsymbol{z}_{t})^{\\top}\\bar{\\boldsymbol{m}}_{i},\\boldsymbol{\\varphi}_{\\bar{\\theta}}(\\boldsymbol{z}_{t})^{\\top}\\bar{\\boldsymbol{S}}_{i}\\boldsymbol{\\varphi}_{\\bar{\\theta}}(\\boldsymbol{z}_{t})+\\bar{\\Sigma}_{i}).\n(15)\nTo use this model in the intended racing application, we use the maximum a posteriori (MAP) estimate of the learned state difference in the ODEÂ (\n2a\n) of the states\nğ’™\n1\n\\boldsymbol{x}_{1}\n, and let\nğ’™\nË™\n1\nâ€‹\n(\nt\n)\nâ‰ˆ\nğ‹\nÎ¸\nÂ¯\nâ€‹\n(\nğ’›\nt\n)\nâŠ¤\nâ€‹\n[\nğ’\nÂ¯\n1\n,\nâ‹¯\n,\nğ’\nÂ¯\nd\n]\n/\nÎ”\nâ€‹\nt\n.\n\\dot{\\boldsymbol{x}}_{1}(t)\\approx\\boldsymbol{\\varphi}_{\\bar{\\theta}}(\\boldsymbol{z}_{t})^{\\top}[\\bar{\\boldsymbol{m}}_{1},\\cdots,\\bar{\\boldsymbol{m}}_{d}]/\\Delta t.\n(16)\nThis approach allows us to use the curvilinear coordinates and reparametrize the dynamics in path distanceÂ (\n4a\n), discretize the dynamics in\ns\ns\n(\n5\n), and formulate the OCPÂ (\n7\n) in Sec.\nIII\n.\nIV-B\nExtracting Contextual Visual Information\nBackbones.\nTo extract meaningful visual context for the learned model in Sec.\nIV-A\n, we use\nSegman\n[\n21\n]\nto segment images captured on the car. We also evaluated\nSegNeXt\n[\n23\n]\nand\nSegFormer\n[\n54\n]\n, but found\nSegman\nsuperior in both speed and accuracy for our driving application.\nWe use the tiny model and train it from scratch on the public\nGoose\ndataset\n[\n37\n]\n, which contains 10k images of rural and off-road driving in Germany. This setting better matches racing conditions, which are closer to rural than urban environments, yielding better embeddings.\nTo further improve performance, we fine-tune the model on 500 manually labeled images from the California test location used in our experiments.\nWe retain the 64 closed-set classes of the\nGoose\ndataset, represented by unique integers\nğ’\n=\n{\n1\n,\nâ€¦\n,\n64\n}\n\\mathcal{C}=\\{1,\\ldots,64\\}\n. At inference, this yields a segmented image\nI\n^\nk\nâˆˆ\n[\n|\nğ’\n|\n]\nW\nÃ—\nH\n\\hat{I}_{k}\\in[|\\mathcal{C}|]^{W\\times H}\nof size\n(\nW\n,\nH\n)\n=\n(\n1440\n,\n928\n)\n(W,H)=(1440,928)\n. Example outputs are shown in Fig.\n3\n.\nWeighting.\nTo extract semantically meaningful surface information from this output, we compute a spatially weighted water presence score. This score emphasizes the region of the image most relevant to the vehicleâ€™s trajectory. We define a Gaussian weighting mask over the image domain. At pixel coordinates\n(\nw\n,\nh\n)\nâˆˆ\n[\nW\n]\nÃ—\n[\nH\n]\n(w,h)\\in[W]\\times[H]\n, the weight is given by\nw\nâ€‹\n(\nh\n,\nw\n)\n=\nexp\nâ¡\n(\nâˆ’\n[\n(\nh\nâˆ’\nÎ¼\nh\n)\n2\n2\nâ€‹\nÏƒ\nh\n2\n+\n(\nw\nâˆ’\nÎ¼\nw\n)\n2\n2\nâ€‹\nÏƒ\nw\n2\n]\n)\n,\nw(h,w)=\\exp\\left(-\\left[\\frac{(h-\\mu_{h})^{2}}{2\\sigma_{h}^{2}}+\\frac{(w-\\mu_{w})^{2}}{2\\sigma_{w}^{2}}\\right]\\right),\n(17)\nwhere\nÎ¼\nh\nâˆˆ\n[\nH\n]\n\\mu_{h}\\in[H]\nand\nÎ¼\nw\nâˆˆ\n[\nW\n]\n\\mu_{w}\\in[W]\nand\nÏƒ\nh\n,\nÏƒ\nw\n>\n0\n\\sigma_{h},\\sigma_{w}>0\ncontrol its spread in the vertical and horizontal directions, respectively. This approach focuses attention on a region of interest, such as the road area directly ahead of the vehicle, and down-weights potential outliers on the edge of the image (see Fig.\n3\n).\nContext.\nWithout loss of generality, we consider two classes:\nâ€¢\nc\nw\nâˆˆ\nğ’\nc_{\\texttt{w}}\\in\\mathcal{C}\n: the class label corresponding to water;\nâ€¢\nc\na\nâˆˆ\nğ’\nc_{\\texttt{a}}\\in\\mathcal{C}\n: the class label corresponding to asphalt.\nFurthermore, let\nÎ©\nâŠ‚\n[\nW\n]\nÃ—\n[\nH\n]\n\\Omega\\subset[W]\\times[H]\ndenote the set of pixels that are not occluded (i.e., not part of the vehicle body), for which the weight is non-zero. We then define a â€œwater scoreâ€ as\nÏ\nt\n=\nâˆ‘\n(\nw\n,\nh\n)\nâˆˆ\nÎ©\nw\nâ€‹\n(\nh\n,\nw\n)\nâ‹…\nğŸ\nâ€‹\n{\nI\n^\nk\n=\nc\nw\n}\nâˆ‘\n(\nw\n,\nh\n)\nâˆˆ\nÎ©\nw\nâ€‹\n(\nh\n,\nw\n)\nâ‹…\n[\nğŸ\nâ€‹\n{\nI\n^\nk\n=\nc\nw\n}\n+\nğŸ\nâ€‹\n{\nI\n^\nk\n=\nc\na\n}\n]\n,\n\\rho_{t}=\\frac{\\sum_{(w,h)\\in\\Omega}w(h,w)\\cdot\\mathbf{1}\\{\\hat{I}_{k}=c_{\\texttt{w}}\\}}{\\sum_{(w,h)\\in\\Omega}w(h,w)\\!\\cdot\\!\\left[\\mathbf{1}\\{\\hat{I}_{k}\\!=c_{\\texttt{w}}\\}\\!+\\!\\mathbf{1}\\{\\hat{I}_{k}\\!=c_{\\texttt{a}}\\}\\right]},\n(18)\nwhere\nğŸ\nâ€‹\n{\nâ‹…\n}\n\\mathbf{1}\\{\\cdot\\}\ndenotes the indicator function.\nThis ratio provides a normalized measure of the prevalence of water relative to asphalt in the spatial region emphasized by the Gaussian. In general, if there are more classes of relevance, such as ice or gravel, we can easily extendÂ (\n18\n) to a vector-valued score, with the relative prevalence of each class of interest. In the following, we provide the context\nğ’„\nt\n=\n(\nÏ\nt\nâˆ’\nN\n,\nâ€¦\n,\nÏ\nt\n)\n\\boldsymbol{c}_{t}=(\\rho_{t-N},\\dots,\\rho_{t})\nof the current surface condition to the learned dynamics models.\nIV-C\nVision-based Conditioning using FiLM\nTo incorporate contextual visual information into our learned dynamics model, we employ Feature-wise Linear Modulation (FiLM)\n[\n40\n]\n. This approach allows the visual context to adaptively modulate the backbone networkâ€™s features through learned affine transformations. FiLM relies on a conditioning function\ng\nÏˆ\nâ€‹\n(\nâ‹…\n)\ng_{\\psi}(\\cdot)\nthat maps the contextual input to modulation parameters. We implement this function as a Long Short-Term Memory (LSTM) network\n[\n28\n]\n, with\n(\nğœ¸\nÏˆ\nâ€‹\n(\nğ’„\nt\n)\n,\nğœ·\nÏˆ\nâ€‹\n(\nğ’„\nt\n)\n)\n=\ng\nÏˆ\nâ€‹\n(\nğ’„\nt\n)\n,\n(\\boldsymbol{\\gamma}_{\\psi}(\\boldsymbol{c}_{t}),\\boldsymbol{\\beta}_{\\psi}(\\boldsymbol{c}_{t}))=g_{\\psi}(\\boldsymbol{c}_{t}),\n(19)\nwhere\ng\nÏˆ\ng_{\\psi}\nis parameterized by LSTM weights\nÏˆ\n\\psi\n, and the factors\nğœ¸\nâ€‹\n(\nğ’„\nt\n)\n\\boldsymbol{\\gamma}(\\boldsymbol{c}_{t})\nand shift parameters\nğœ·\nâ€‹\n(\nğ’„\nt\n)\n\\boldsymbol{\\beta}(\\boldsymbol{c}_{t})\nhave the same dimensionality as the backbone features (see Sec.\nIV-B\n). While it is possible to use simple MLPs, the LSTM is chosen to better capture temporal dependencies in the context\nğ’„\nt\n\\boldsymbol{c}_{t}\n.\nModulation.\nThe backbone features of the VBLL are modulated as in\n[\n40\n]\n, with an element-wise affine transformation\nğ‹\n~\nt\nâ‰”\nğ‹\n{\nÎ¸\n,\nÏˆ\n}\nFiLM\nâ€‹\n(\nğ’›\nt\n,\nğ’„\nt\n)\n=\nğ‹\nÎ¸\nâ€‹\n(\nğ’›\nt\n)\nâŠ™\nğœ¸\nÏˆ\nâ€‹\n(\nğ’„\nt\n)\n+\nğœ·\nÏˆ\nâ€‹\n(\nğ’„\nt\n)\n,\n\\tilde{\\boldsymbol{\\varphi}}_{t}\\coloneqq\\boldsymbol{\\varphi}^{\\text{FiLM}}_{\\{\\theta,\\psi\\}}(\\boldsymbol{z}_{t},\\boldsymbol{c}_{t})=\\boldsymbol{\\varphi}_{\\theta}(\\boldsymbol{z}_{t})\\odot\\boldsymbol{\\gamma}_{\\psi}(\\boldsymbol{c}_{t})+\\boldsymbol{\\beta}_{\\psi}(\\boldsymbol{c}_{t}),\n(20)\nwhere\nâŠ™\n\\odot\ndenotes element-wise multiplication. This formulation enables the visual context to selectively amplify or suppress different feature dimensions based on the observed surface conditions, allowing the model to adapt its internal representations to account for varying road surface properties.\nFinally, we formulate the conditional posterior predictive\nÎ”\nâ€‹\nğ’™\nt\n+\n1\n,\ni\nâˆ£\nğ’›\nt\n,\nğ’„\nt\nâˆ¼\nN\nâ€‹\n(\nğ‹\n~\nt\nâŠ¤\nâ€‹\nğ’\ni\n,\nğ‹\n~\nt\nâŠ¤\nâ€‹\nğ‘º\ni\nâ€‹\nğ‹\n~\nt\n+\nÎ£\ni\n)\n.\n\\Delta\\boldsymbol{x}_{t+1,i}\\mid\\boldsymbol{z}_{t},\\boldsymbol{c}_{t}\\sim\\mathrm{N}\\left(\\tilde{\\boldsymbol{\\varphi}}_{t}^{\\top}\\boldsymbol{m}_{i},\\tilde{\\boldsymbol{\\varphi}}_{t}^{\\top}\\boldsymbol{S}_{i}\\tilde{\\boldsymbol{\\varphi}}_{t}+\\Sigma_{i}\\right).\n(21)\nIV-D\nData Collection, Training, and Fine-Tuning\nData Collection.\nAn expert driver operated a Lexus LC500 on a skidpad under controlled conditions to collect training data.\nThe nominal dataset, containing\n|\nğ’Ÿ\n|\n=\n12â€‰229\n|\\mathcal{D}|=$12\\,229$\nsamples for training, was obtained through a series of aggressive maneuvers designed to excite the full range of the nonlinear vehicle dynamics in nominal, i.e.,Â dry, conditions (see Fig.\n3\n).\nFor the fine-tuning dataset, we introduced a water puddle on the skidpad. The driver then repeated similar aggressive maneuvers to capture transient tire-surface interactions under wet conditions (cf.Â Fig.\n3\n, bottom left). High ambient temperatures and sun exposure at the test site caused rapid evaporation, making this data collection process slow and labor-intensive, which highlights the utility of our fine-tuning approach.\nThe fine-tuning dataset comprises\n6349\n6349\nsamples, of which only\n1540\n1540\n(approx. 24%) contain a non-zero context vector\nğ’„\nt\n\\boldsymbol{c}_{t}\n.\nSince\nğ’„\nt\n\\boldsymbol{c}_{t}\nspans a two-second window, the direct exposure to wet conditions is even more limited.\nTraining Procedure.\nWe first train the base VBLL dynamics model on the nominal dataset by minimizing the loss in (\n14\n). To enhance numerical stability, all input and output features are standardized prior to training.\nThe same standardization parameters are applied to the fine-tuning dataset to ensure feature consistency.\nWe then use this trained base VBLL model as the initialization for the subsequent fine-tuning to learn the conditional path (i.e., the orange path in Fig.\n3\n).\nTo prevent catastrophic forgetting, we augment the base loss from (\n14\n) with an L2-SP regularization term\n[\n55\n]\n, and solve the following optimization problem using the fine-tuning dataset\nÎ¸\nÂ¯\n,\nÎ·\nÂ¯\n,\nÏˆ\nÂ¯\n=\narg\nâ¡\nmin\nÎ¸\n,\nÎ·\n,\nÏˆ\nâ¡\n[\nâ„’\nâ€‹\n(\nÎ·\n,\n{\nÎ¸\n,\nÏˆ\n}\n)\n+\nÎ»\nL2-SP\nâ€‹\nâ€–\nÎ¸\nâˆ’\nÎ¸\ninit\nâ€–\n2\n2\n]\n,\n\\hskip-2.0pt\\bar{\\theta},\\bar{\\eta},\\bar{\\psi}=\\arg\\min_{\\theta,\\eta,\\psi}\\left[\\mathcal{L}(\\eta,\\{\\theta,\\psi\\})+\\lambda_{\\text{L2-SP}}\\left\\|\\theta\\!-\\!\\theta_{\\text{init}}\\right\\|_{2}^{2}\\right],\\hskip-2.0pt\n(22)\nwhere\nÎ¸\ninit\n\\theta_{\\text{init}}\nare the parameters of the VBLL model trained with a lossÂ (\n14\n) using only dry data (green path in Fig.\n3\n).\nWe refer to the resulting finetuned model as\nVcVBLL\n.\nFigure 4:\nSlices through the\nVcVBLL\nposterior when driving over a puddle.\nAfter fine-tuning, the\nVcVBLL\nmodel can effectively provide conditional prediction based on the provided visual context, as seen by the difference in posterior predictive distributions for the selected states.\nMoreover, the modelâ€™s behavior is physically plausible: a wet surface results in higher wheel speeds and increased side-slip dynamics, as well as increased uncertainty.\nV\nResults\nWe test the proposed\nVcVBLL\nvehicle model in closed-loop MPC on a Lexus LC500.\nWe discuss the effect of the visual context in Sec.\nV-A\nand then present hardware results with baseline models, with and without the vision context, when racing through puddles in Sec.\nV-B\n. A video of the experiments is available at:\nhttps://youtu.be/m-gcFK0moI8\n.\nV-A\nIntuition on the Effect of Vision Conditioning\nTo illustrate the effect of the vision context on model predictions, we study the fine-tuned\nVcVBLL\ndescribed in Sec.\nIV-C\n, with and without vision context.\nWe use segmentation outputs recorded in the car while racing through a puddle, and show the posterior predictiveÂ (\n21\n) as a function of the steering input\nÎ´\n\\delta\nat different points in time (see Fig.\n4\n).\nThe\nVcVBLL\npredictions diverge upon detecting water (\nt\n=\n15\n{t=15}\n): with the context, the wheels are predicted to slip and spin more, and the car is also predicted to lose traction and gain more sideslip under the same actuation. Notably, the difference induced by the context is maximal after a small delay, corresponding to the time between detecting water and the vehicle entering the puddle (\nt\n=\n20\nt=20\n). These differences in prediction persist for some time due to the tires remaining wet after having passed through the puddle (\nt\n=\n25\nt=25\n). Over time, the impact of water on the dynamics becomes negligible (\nt\n=\n30\nt=30\n). The effect of the vision context on the VBLL predictions thus makes sense physically. The presence of water also inflates the uncertainty\nof the predictive posterior, which is expected as the vehicle dynamics become harder to model accurately under such transient surface conditions.\nV-B\nHardware Experiments\nSetup.\nWe validate the proposed method on the LC500 vehicle depicted in Fig.\n1\n. The segmentation backbone is run on an L4 GPU, and all other computations are done on a 3.30GHz Intel Xeon E-2278GE CPU. This includes evaluating the FiLM modulation and solving the OCP via sequential quadratic programming\n[\n38\n, Chapter 18]\nusing the OSQP solver\n[\n46\n]\n. The vehicle states are estimated using an OxTS system\n[\n39\n]\n, and the images are sampled from a single forward-facing Lucid Ti 3.2MP camera\n[\n31\n]\n(see Fig.\n3\n). With this setup, the segmentation runs at approximately 25-30Hz, and is therefore separated in a different thread to not prevent the execution of the controller. Compared to the offline training data for the FiLM conditioning, which provides segmentation results at 30Hz, some frames are dropped in the experiments. Consequently, we align the vehicle states with the images and populate the missing frames by interpolating the water score. When present, the modulating FiLM signal is computed at 7Hz, while the controller is running at 62.5Hz.\nRacing Baselines.\nTo verify that the learned VBLL serves as a suitable evaluation baseline, we first test it in hardware using the deterministic minimum-time MPC formulation from\n[\n33\n]\n(without puddles), and compare:\nâ€¢\nThe\nphysics-based\nvehicle model used in\n[\n33\n]\n;\nâ€¢\nA baseline\nVBLL\nvehicle model, similar to that of\n[\n12\n]\n;\nâ€¢\nA\nVcVBLL\nmodel derived from the baseline\nVBLL\n.\nWe consider the racing task in\n[\n33\n]\n, and report results in Fig.\n5\n. We observe that the controllers using the OCPs formulated with VBLL models better utilize the available rear tire force by applying more throttle, resulting in more rear wheel speed (see\nÏ‰\nr\n\\omega_{r}\n), sideslip (see\nÎ²\n\\beta\n), and ultimately velocity (see\nv\nv\n) when exiting the corner. Performance is reduced marginally in\nVcVBLL\ncompared to\nVBLL\n, but both methods still beat the\nphysics-based\nmodel in lap times (see Tab.\nI\n). Next, we introduce water on the track and study the effect of vision.\nFigure 5:\nPerformance of VBLL dynamics model on the dry track.\nWith a learned dynamics model (\nVBLL\nand\nVcVBLL\n) the MPC is able to achieve higher velocities resulting in faster lap times (cf.Â Table\nI\n).\nFigure 6:\nHardware experiments comparing various methods in a racing task with water placed on the exit of a turn. All methods spin out after driving through the puddle, except for the\nVcVBLL\nwith vision context, which completes three laps before the experiment is stopped manually.\nTABLE I:\nLap time of baseline methods for Figure\n5\nwithout puddle.\nPhysics-based\nVBLL\nVcVBLL\nLap time\n24.53\nsec\n24.53\\text{\\,}\\sec\n24.06\nsec\n24.06\\text{\\,}\\sec\n24.24\nsec\n24.24\\text{\\,}\\sec\nRacing Through Puddles.\nTo study how the vision context affects closed-loop control, we place a large puddle near the exit of the first turn and replenish it with equal amounts of water between each consecutive experiment. We use the minimum-time MPC with dynamics constraints from:\nâ€¢\nThe baseline\nVBLL\nvehicle model;\nâ€¢\nThe\nVBLL\nmodel with RLS adaptation, as in\n[\n12\n]\n;\nâ€¢\nThe\nVcVBLL\nmodel ignoring vision context;\nâ€¢\nThe\nVcVBLL\nmodel utilizing vision context.\nThe results from one of three sets of experiments are shown in Fig.\n6\n, and indicate that the vision context is crucial for the car to drive safely through the puddle. In particular, as soon as there is a signal from the segmentation that water will be present, the controller preemptively drops the engine torque and engages the brakes, which reduces the side-slip on exit and allows the vehicle to recover and continue racing. The\nVcVBLL\nwithout vision context exhibits similar behavior in engine torque, but does not initiate the brakes and spins out as a result. These experiments were repeated three times, with the\nVcVBLL\nusing vision context completing all 9 laps through the water successfully. We conclude that the vision context, albeit simplistic, allows for preemptive control through the MPC, and is the unambiguous difference maker between staying on track and spinning out.\nRobustness.\nTo test robustness to vehicle parameter changes like road conditions and tire wear, we deployed the method twice with (i) different tires, (ii) 15\nâˆ˜\nC temperature difference, and (iii) different lighting (see Fig.\n7\n).\nWe slightly re-tuned the parameters of the controller for all baselines, using\nÎ»\nT\n=\n500\n\\lambda_{T}=500\non the first occasion and\nÎ»\nT\n=\n200\n\\lambda_{T}=200\non the second occasion.\nAugust\nSeptember\nFigure 7:\nDifference in lighting conditions in the August and September tests.\nTABLE II:\nPercentage of successful attempted turns through a puddle.\nOccasion\nVBLL\nVBLL\n+ RLS\nVcVBLL\n(\nğ’„\nt\n=\n0\n\\boldsymbol{c}_{t}=0\n)\nVcVBLL\nAugust\n0 (0/1)\n0 (0/1)\nâ€“\n100\n(3/3)\nSeptember\n0 (0/3)\n0 (0/1)\n0 (0/1)\n100\n(9/9)\nThe hardware results were repeatable, as shown in Tab.\nII\n, with one set of experiments from the second row illustrated in Fig.\n6\n. In total, across the two test sessions, the baselines spun out every single time (although the baseline\nVcVBLL\nignoring vision was not tested in August).\nIn contrast, the\nVcVBLL\nwith vision context completed 12 out of 12 attempted laps, indicating that it is robust to experimental conditions.\nVI\nConclusion\nThis letter presents a vision-conditioned VBLL vehicle model that enables proactive control in autonomous racing under varying surface conditions.\nBy conditioning the dynamics model on visual context via FiLM, a controller can anticipate changes in road surface properties before encountering them.\nOur approach employs a two-stage training strategy: first learning a nominal VBLL model on dry surface data, then fine-tuning the conditioning path using the limited available data of water interactions.\nHardware experiments on a Lexus LC500 racing through water puddles demonstrate the efficacy of the approach: the vision-conditioned model completed multiple laps across varying conditions, while baseline methods without visual context consistently spun out.\nThese results demonstrate that incorporating exteroceptive information into learned dynamics models is essential for safe and robust autonomous racing in changing conditions. Future work will explore the use of vision-conditioned models for predictive control in other applications, such as autonomous drifting and off-road driving with a richer visual context.\nPhysics-based vehicle model\nThe dynamics in (\n2a\n) are\nr\nË™\n=\n\\displaystyle\\dot{r}=\n(\na\nâ€‹\nF\ny\nâ€‹\nf\nâ€‹\ncos\nâ¡\n(\nÎ´\n)\n+\na\nâ€‹\nF\nx\nâ€‹\nf\nâ€‹\nsin\nâ¡\n(\nÎ´\n)\nâˆ’\nb\nâ€‹\nF\ny\nâ€‹\nr\n)\n/\nI\nz\n,\n\\displaystyle(aF_{yf}\\cos(\\delta)+aF_{xf}\\sin(\\delta)-bF_{yr})/I_{z},\n(23a)\nv\nË™\n=\n\\displaystyle\\dot{v}=\n(\nâˆ’\nF\ny\nâ€‹\nf\nsin\n(\nÎ´\nâˆ’\nÎ²\n)\n+\nF\nx\nâ€‹\nf\ncos\n(\nÎ´\nâˆ’\nÎ²\n)\n\\displaystyle\\big(-F_{yf}\\sin(\\delta-\\beta)+F_{xf}\\cos(\\delta-\\beta)\n+\nF\ny\nâ€‹\nr\nsin\nÎ²\n+\nF\nx\nâ€‹\nr\ncos\nÎ²\n)\n/\nm\n,\n\\displaystyle+F_{yr}\\sin\\beta+F_{xr}\\cos\\beta\\big)/m,\n(23b)\nÎ²\nË™\n=\n\\displaystyle\\dot{\\beta}=\nâˆ’\nr\n+\n(\nF\ny\nâ€‹\nf\ncos\n(\nÎ´\nâˆ’\nÎ²\n)\n+\nF\nx\nâ€‹\nf\nsin\n(\nÎ´\nâˆ’\nÎ²\n)\n\\displaystyle-r+\\big(F_{yf}\\cos(\\delta-\\beta)+F_{xf}\\sin(\\delta-\\beta)\n+\nF\ny\nâ€‹\nr\ncos\nÎ²\nâˆ’\nF\nx\nâ€‹\nr\nsin\nÎ²\n)\n/\n(\nm\nv\n)\n,\n\\displaystyle+F_{yr}\\cos\\beta-F_{xr}\\sin\\beta\\big)/(mv),\n(23c)\nÏ‰\nË™\nr\n=\n\\displaystyle\\dot{\\omega}_{r}=\n(\nÏ„\neng\nâˆ’\nF\nx\nâ€‹\nr\nâ€‹\nr\nw\n)\n/\nI\nw\n,\n\\displaystyle(\\tau_{\\textrm{eng}}-F_{xr}r_{\\textrm{w}})/I_{\\textrm{w}},\n(23d)\nTABLE III:\nModel param.\nParam.\nValue\na\na\n1.3457754\nb\nb\n1.5222246\nI\nz\nI_{z}\n3675\nm\nm\n2048\nr\nw\nr_{\\mathrm{w}}\n0.368\nI\nw\nI_{\\mathrm{w}}\n30\nC\nf\nC_{f}\n156000\nC\nr\nC_{r}\n422000\nÎ¼\nf\n\\mu_{f}\n1.02\nÎ¼\nr\n\\mu_{r}\n1.08\nwith parameters\n(\na\n,\nb\n,\nI\nz\n,\nm\n,\nr\nw\n,\nI\nw\n)\nâˆˆ\nâ„\n>\n0\n6\n(a,b,I_{z},m,r_{\\mathrm{w}},I_{\\mathrm{w}})\\in\\mathbb{R}_{>0}^{6}\n. The tire forces\nF\nx\nâ€‹\nf\n,\nF\ny\nâ€‹\nf\n,\nF\nx\nâ€‹\nr\n,\nF\ny\nâ€‹\nr\nF_{xf},F_{yf},F_{xr},F_{yr}\n(N) are nonlinear functions of the state (see, e.g.\n[\n33\n]\nfor details) parametrized in cornering stiffness\n(\nC\nf\n,\nC\nr\n)\nâˆˆ\nâ„\n>\n0\n2\n(C_{f},C_{r})\\in\\mathbb{R}_{>0}^{2}\nand friction coefficients\n(\nÎ¼\nf\n,\nÎ¼\nr\n)\nâˆˆ\nâ„\n>\n0\n2\n(\\mu_{f},\\mu_{r})\\in\\mathbb{R}_{>0}^{2}\n, with\nf\nf\nand\nr\nr\nreferring to the front and rear wheels, respectively. The parameters are found by physical measurements and gray-box system identification. The parameters used in the experiments are summarized in SI units in Tab.\nIII\n.\nBaseline VBLL Model and Training Details.\nFor the backbone of the VBLL model, we use 4 hidden layers with 64 neurons and ELU activations.\nThe LSTM of the FiLM VBLL has a latent state size of 16 and we use an additional linear layer to decode this latent to the FiLM vectors (cf.Â Fig.\n3\n).\nFor the VBLL heads, we set\nÎ¾\ni\nâˆ˜\n=\n1\n\\xi_{i}^{\\circ}=1\n,\nÎ±\ni\nâˆ˜\n=\n1\n2\n\\alpha_{i}^{\\circ}=\\frac{1}{2}\n, and\nÎ²\ni\nâˆ˜\n=\n0.01\n2\n\\beta_{i}^{\\circ}=\\frac{0.01}{2}\n.\nWe implicitly set\nÎ³\nâˆ˜\n\\gamma^{\\circ}\nby adding weight decay of\n10\nâˆ’\n4\n10^{-4}\non the backbone as in\n[\n25\n]\nand using AdamW\n[\n35\n]\nwith a learning rate of\n5\nâ‹…\n10\nâˆ’\n4\n5\\cdot 10^{-4}\nfor the base model and\n10\nâˆ’\n4\n10^{-4}\nfor fine-tuning.\nWe further use a gradient clipping of 1 for both.\nFor the base model, we train for\n5000\n5000\nepochs and for the fine-tuning for\n1000\n1000\n, but use the best performing model based on a holdout validation set.\nFor both, we use a batch size of\n1028\n1028\n.\nThe regularization parameters are\nÎ»\nreg\n=\n10\n\\lambda_{\\text{reg}}=10\nand\nÎ»\nL2-SP\n=\n10\n\\lambda_{\\text{L2-SP}}=10\n.\nController parameters.\nThe nominal MPC weights are\nÎ»\nT\n=\n500\n\\lambda_{T}=500\n,\nğ‘¸\n=\ndiag\nâ€‹\n(\n10\n,\n0.1\n,\n1\n,\n10\nâˆ’\n8\n,\n0.01\n,\n10\n,\n0.01\n,\n0\n)\n\\boldsymbol{Q}=\\mathrm{diag}(10,0.1,1,10^{-8},0.01,10,0.01,0)\n,\nğ‘¹\n=\ndiag\nâ€‹\n(\n0.1\n,\n10\nâˆ’\n4\n,\n10\nâˆ’\n5\n)\n{\\boldsymbol{R}\\!=\\!\\mathrm{diag}(0.1,10^{-4},10^{-5})}\n,\nğ‘»\n=\ndiag\nâ€‹\n(\n2\nâ‹…\n10\n5\n,\n10\nâˆ’\n5\n,\n10\nâˆ’\n9\n)\n{\\boldsymbol{T}\\!=\\!\\mathrm{diag}(2\\!\\cdot\\!10^{5},10^{-5},10^{-9})}\n.\nACKNOWLEDGMENT\nThe authors acknowledge Steven Goldine for driving in the data collection, Emre Adabag for helpful discussions, and William Kettle, Phung Nguyen, Zachary Conybeare, and Max Freeman for support in the experiments.\nReferences\n[1]\nE. Adabag, M. Greiff, J. Subosits, and T. Lew\n(2025)\nDifferentiable model predictive control on the gpu\n.\narXiv preprint arXiv:2510.06179\n.\nCited by:\nÂ§II\n.\n[2]\nB. Balaji, S. Mallya, S. Genc, S. Gupta, L. Dirac, V. Khare, G. Roy, T. Sun, Y. Tao, B. Townsend,\net al.\n(2019)\nDeepracer: educational autonomous racing platform for experimentation with sim2real reinforcement learning\n.\narXiv:1911.01562\n.\nCited by:\nÂ§II\n.\n[3]\nK. Berntorp\n(2014)\nParticle filtering and optimal control for vehicles and robots\n.\nPh.D. Thesis\n,\nLund University\n.\nCited by:\nÂ§I\n.\n[4]\nM. Bojarski, D. Del Testa, D. Dworakowski, B. Firner, B. Flepp, P. Goyal, L. D. Jackel, M. Monfort, U. Muller, J. Zhang,\net al.\n(2016)\nEnd to end learning for self-driving cars\n.\narXiv:1604.07316\n.\nCited by:\nÂ§II\n.\n[5]\nP. Brunzema, M. Jordahn, J. Willes, S. Trimpe, J. Snoek, and J. Harrison\n(2025)\nBayesian optimization via continual variational last layer training\n.\nIn\nInternational Conference on Learning Representationn\n,\nCited by:\nÂ§II\n.\n[6]\nP. Cai, H. Wang, H. Huang, Y. Liu, and M. Liu\n(2021)\nVision-based autonomous car racing using deep imitative reinforcement learning\n.\nIEEE Robotics and Automation Letters\n.\nCited by:\nÂ§II\n.\n[7]\nC. R. Carlson and J. C. Gerdes\n(2003)\nNonlinear estimation of longitudinal tire slip under several driving conditions\n.\nIn\nAmerican Control Conference\n,\nCited by:\nÂ§I\n.\n[8]\nC. Chi, Z. Xu, S. Feng, E. Cousineau, Y. Du, B. Burchfiel, R. Tedrake, and S. Song\n(2025)\nDiffusion policy: visuomotor policy learning via action diffusion\n.\nInternational Journal of Robotics Research\n.\nCited by:\nÂ§II\n.\n[9]\nJ. Dallas, M. P. Cole, P. Jayakumar, and T. Ersal\n(2021)\nTerrain adaptive trajectory planning and tracking on deformable terrains\n.\nIEEE Trans. on Vehicular Technology\n.\nCited by:\nÂ§II\n.\n[10]\nJ. Dallas, M. Thompson, J. Y. Goh, and A. Balachandran\n(2023)\nAdaptive nonlinear model predictive control: maximizing tire force and obstacle avoidance in autonomous vehicles\n.\nField Robotics\n.\nCited by:\nÂ§I\n,\nÂ§II\n.\n[11]\nA. Davydov, F. Djeumou, M. Greiff, M. Suminaka, M. Thompson, J. Subosits, and T. Lew\n(2025)\nFirst, learn what you donâ€™t know: active information gathering for driving at the limits of handling\n.\nIEEE Robotics and Automation Letters\n.\nCited by:\nÂ§II\n,\nÂ§III\n.\n[12]\nA. Davydov, F. Djeumou, M. Greiff, M. Suminaka, M. Thompson, J. Subosits, and T. Lew\n(2025)\nFirst, learn what you donâ€™t know: active information gathering for driving at the limits of handling\n.\nIEEE Robotics and Automation Letters\n.\nCited by:\nÂ§I\n,\nÂ§I\n,\nÂ§I\n,\n2nd item\n,\n2nd item\n,\nRemark 1\n,\nRemark 2\n.\n[13]\nM. P. Deisenroth and C. E. Rasmussen\n(2011)\nPILCO: a modelâ€‘based and dataâ€‘efficient approach to policy search\n.\nIn\nICML\n,\nCited by:\nÂ§\nIV-A\n.\n[14]\nO. Dikici, E. Ghignone, C. Hu, N. Baumann, L. Xie, A. Carron, M. Magno, and M. Corno\n(2025)\nLearning-based on-track system identification for scaled autonomous racing in under a minute\n.\nIEEE Robotics and Automation Letters\n.\nCited by:\nÂ§II\n.\n[15]\nN. Ding, M. Thompson, J. Dallas, J. Y. Goh, and J. Subosits\n(2024)\nDrifting with unknown tires: learning vehicle models online with neural networks and model predictive control\n.\nIn\nInt. Vehicles Sym.\n,\nCited by:\nÂ§I\n,\nÂ§I\n,\nÂ§II\n,\nÂ§\nIV-A\n.\n[16]\nF. Djeumou, J. Y. Goh, U. Topcu, and A. Balachandran\n(2023)\nAutonomous drifting with 3 minutes of data via learned tire models\n.\nICRA\n.\nCited by:\nÂ§I\n,\nÂ§II\n.\n[17]\nF. Djeumou, T. J. Lew, N. Ding, M. Thompson, M. Suminaka, M. Greiff, and J. Subosits\n(2024)\nOne model to drift them all: physics-informed conditional diffusion model for driving at the limits\n.\nIn\nConference on Robot Learning\n,\nCited by:\nÂ§I\n,\nÂ§I\n,\nÂ§II\n.\n[18]\nP. Drews, G. Williams, B. Goldfain, E. A. Theodorou, and J. M. Rehg\n(2017)\nAggressive deep driving: model predictive control with a cnn cost model\n.\narXiv preprint arXiv:1707.05303\n.\nCited by:\nÂ§II\n.\n[19]\nE. Fiala\n(1954)\nSeitenkraften am rollenden luftreifen\n.\nVDI\n.\nCited by:\nÂ§II\n,\nÂ§III\n.\n[20]\nF. Fiedler and S. Lucia\n(2023)\nImproved uncertainty quantification for neural networks with Bayesian last layer\n.\nIEEE Access\n.\nCited by:\nÂ§II\n.\n[21]\nY. Fu, M. Lou, and Y. Yu\n(2025)\nSegMAN: omni-scale context modeling with state space models and local attention for semantic segmentation\n.\nIn\nComputer Vision and Pattern Recognition Conference\n,\nCited by:\nÂ§\nIV-B\n.\n[22]\nC. E. Garcia, D. M. Prett, and M. Morari\n(1989)\nModel predictive control: theory and practiceâ€”a survey\n.\nAutomatica\n.\nCited by:\nÂ§II\n.\n[23]\nM. Guo, C. Lu, Q. Hou, Z. Liu, M. Cheng, and S. Hu\n(2022)\nSegnext: rethinking convolutional attention design for semantic segmentation\n.\nNeural Information Processing Systems\n35\n.\nCited by:\nÂ§\nIV-B\n.\n[24]\nJ. Harrison, A. Sharma, and M. Pavone\n(2018)\nMeta-learning priors for efficient online bayesian regression\n.\nIn\nInternational Workshop on the Algorithmic Foundations of Robotics\n,\nCited by:\nÂ§II\n.\n[25]\nJ. Harrison, J. Willes, and J. Snoek\n(2024)\nVariational bayesian last layers\n.\nIn\nInternational Conference on Learning Representations\n,\nCited by:\nÂ§II\n,\nÂ§VI\n.\n[26]\nJ. Harrison, J. Willes, and J. Snoek\n(2024)\nVariational bayesian last layers\n.\nIn\nInternational Conference on Learning Representations\n,\nCited by:\nÂ§\nIV-A\n,\nÂ§\nIV-A\n,\nÂ§\nIV-A\n.\n[27]\nL. Hewing, J. Kabzan, and M. N. Zeilinger\n(2019)\nCautious model predictive control using gaussian process regression\n.\nIEEE Trans. on Control Systems Technology\n.\nCited by:\nÂ§I\n.\n[28]\nS. Hochreiter and J. Schmidhuber\n(1997)\nLong short-term memory\n.\nNeural Computation\n.\nCited by:\nÂ§\nIV-C\n.\n[29]\nA. Jain, M. Oâ€™Kelly, P. Chaudhari, and M. Morari\n(2021)\nBayesRace: learning to race autonomously using prior experience\n.\nIn\nConference on Robot Learning\n,\nCited by:\nÂ§II\n,\nÂ§II\n.\n[30]\nJ. Kabzan, L. Hewing, A. Liniger, and M. N. Zeilinger\n(2019)\nLearning-based model predictive control for autonomous racing\n.\nIEEE Robotics and Automation Letters\n.\nCited by:\nÂ§I\n,\nÂ§II\n.\n[31]\nL. V. Labs\n(2025)\nTriton 3.2 mp technical reference manual\n.\nExternal Links:\nLink\nCited by:\nÂ§\nV-B\n.\n[32]\nJ. Levy, J. Gibson, B. Vlahov, E. Tevere, E. Theodorou, D. Fridovich-Keil, and P. Spieler\n(2025)\nMeta-learning online dynamics model adaptation in off-road autonomous driving\n.\narXiv:2504.16923\n.\nCited by:\nÂ§II\n.\n[33]\nT. Lew, M. Greiff, F. Djeumou, M. Suminaka, M. Thompson, and J. Subosits\n(2025)\nRisk-averse model predictive control for racing in adverse conditions\n.\nIn\nInt. Conf. on Robotics and Automation\n,\nCited by:\nÂ§I\n,\nÂ§II\n,\nÂ§III\n,\nÂ§III\n,\n1st item\n,\nÂ§\nV-B\n,\nÂ§\nV-B\n,\nÂ§VI\n,\nRemark 1\n.\n[34]\nL. Ljung\n(1998)\nSystem identification\n.\nCited by:\nÂ§II\n.\n[35]\nI. Loshchilov and F. Hutter\n(2019)\nDecoupled weight decay regularization\n.\nIn\nInternational Conference on Learning Representations\n,\nCited by:\nÂ§VI\n.\n[36]\nE. S. Lupu, F. Xie, J. A. Preiss, J. Alindogan, M. Anderson, and S. Chung\n(2024)\nMAGIC vfm-meta-learning adaptation for ground interaction control with visual foundation models\n.\nIEEE Trans. on Robotics\n.\nCited by:\nÂ§II\n.\n[37]\nP. Mortimer, R. Hagmanns, M. Granero, T. Luettel, J. Petereit, and H. Wuensche\n(2024)\nThe goose dataset for perception in unstructured environments\n.\nIn\nInt. Conference on Robotics and Automation\n,\nCited by:\nÂ§\nIV-B\n.\n[38]\nJ. Nocedal and S. J. Wright\n(2006)\nNumerical optimization\n.\nSpringer\n.\nCited by:\nÂ§\nV-B\n.\n[39]\nOxTS\n(2022)\nUser manual: NCOM data format for the efficient communication of navigation measurements\n.\nCited by:\nÂ§\nV-B\n.\n[40]\nE. Perez, F. Strub, H. De Vries, V. Dumoulin, and A. Courville\n(2018)\nFilm: visual reasoning with a general conditioning layer\n.\nIn\nAAAI\n,\nCited by:\nÂ§II\n,\nÂ§\nIV-C\n,\nÂ§\nIV-C\n.\n[41]\nJ. L. Proctor, S. L. Brunton, and J. N. Kutz\n(2018)\nGeneralizing koopman theory to allow for inputs and control\n.\nJ. on Applied Dyn. Sys.\n.\nCited by:\nÂ§II\n.\n[42]\nP. Riekert and T. Schunck\n(1940)\nZur fahrmechanik des gummibereiften kraftfahrzeugs\n.\nIngenieur-Archiv\n.\nCited by:\nÂ§II\n,\nÂ§III\n.\n[43]\nP. Roth, J. Frey, C. Cadena, and M. Hutter\n(2025)\nLearned perceptive forward dynamics model for safe and platform-aware robotic navigation\n.\narXiv:2504.19322\n.\nCited by:\nÂ§II\n.\n[44]\nJ. Snoek, O. Rippel, K. Swersky, R. Kiros, N. Satish, N. Sundaram, M. Patwary, M. Prabhat, and R. Adams\n(2015)\nScalable bayesian optimization using deep neural networks\n.\nIn\nInt. Conf. on Mach. Learning\n,\nCited by:\nÂ§II\n.\n[45]\nN. A. Spielberg, M. Brown, and J. C. Gerdes\n(2021)\nNeural network model predictive motion control applied to automated driving with unknown friction\n.\nIEEE Trans. on Control Systems Technology\n.\nCited by:\nÂ§II\n,\nÂ§III\n.\n[46]\nB. Stellato, G. Banjac, P. Goulart, A. Bemporad, and S. Boyd\n(2020)\nOSQP: an operator splitting solver for quadratic programs\n.\nMathematical Programming Computation\n.\nCited by:\nÂ§\nV-B\n.\n[47]\nJ. K. Subosits and J. C. Gerdes\n(2021)\nImpacts of model fidelity on trajectory optimization for autonomous vehicles in extreme maneuvers\n.\nIEEE Trans. on Intelligent Vehicles\n.\nCited by:\nÂ§II\n.\n[48]\nM. Suminaka, J. Dallas, M. Thompson, M. Soga, E. Kasai, and J. Subosits\n(2025)\nAdaptable high-speed model predictive control for autonomous drifting\n.\nIn\nACC\n,\nCited by:\nÂ§I\n,\nÂ§II\n.\n[49]\nJ. Svendenius\n(2007)\nTire modeling and friction estimation\n.\nPh.D. Thesis\n,\nLund University\n.\nCited by:\nÂ§I\n,\nÂ§II\n,\nÂ§III\n.\n[50]\nJ. Watson, J. A. Lin, P. Klink, J. Pajarinen, and J. Peters\n(2021)\nLatent derivative Bayesian last layer networks\n.\nIn\nAISTATS\n,\nCited by:\nÂ§II\n.\n[51]\nT. P. Weber and J. C. Gerdes\n(2023)\nModeling and control for dynamic drifting trajectories\n.\nIEEE Trans. on Intelligent Vehicles\n.\nCited by:\nÂ§II\n.\n[52]\nG. Williams, P. Drews, B. Goldfain, J. M. Rehg, and E. A. Theodorou\n(2016)\nAggressive driving with model predictive path integral control\n.\nIn\nIEEE International Conference on Robotics and Automation\n,\nCited by:\nÂ§II\n.\n[53]\nX. Xiao, T. Zhang, K. Choromanski, E. Lee, A. Francis, J. Varley, S. Tu, S. Singh, P. Xu, F. Xia,\net al.\n(2022)\nLearning model predictive controllers with real-time attention for real-world navigation\n.\narXiv preprint arXiv:2209.10780\n.\nCited by:\nÂ§II\n.\n[54]\nE. Xie, W. Wang, Z. Yu, A. Anandkumar, J. M. Alvarez, and P. Luo\n(2021)\nSegFormer: simple and efficient design for semantic segmentation with transformers\n.\nNeural Information Processing Systems\n.\nCited by:\nÂ§\nIV-B\n.\n[55]\nL. Xuhong, Y. Grandvalet, and F. Davoine\n(2018)\nExplicit inductive bias for transfer learning with convolutional networks\n.\nIn\nInternational Conference on Machine Learning\n,\nCited by:\nÂ§\nIV-D\n.",
    "preview_text": "Agile control of robotic systems often requires anticipating how the environment affects system behavior. For example, a driver must perceive the road ahead to anticipate available friction and plan actions accordingly. Achieving such proactive adaptation within autonomous frameworks remains a challenge, particularly under rapidly changing conditions. Traditional modeling approaches often struggle to capture abrupt variations in system behavior, while adaptive methods are inherently reactive and may adapt too late to ensure safety. We propose a vision-conditioned variational Bayesian last-layer dynamics model that leverages visual context to anticipate changes in the environment. The model first learns nominal vehicle dynamics and is then fine-tuned with feature-wise affine transformations of latent features, enabling context-aware dynamics prediction. The resulting model is integrated into an optimal controller for vehicle racing. We validate our method on a Lexus LC500 racing through water puddles. With vision-conditioning, the system completed all 12 attempted laps under varying conditions. In contrast, all baselines without visual context consistently lost control, demonstrating the importance of proactive dynamics adaptation in high-performance applications.\n\nVision-Conditioned Variational Bayesian Last Layer Dynamics Models\nPaul Brunzema\n1\n, Thomas Lew\n2\n, Ray Zhang\n2\n, Takeru Shirasawa\n2\n, John Subosits\n2\n, Marcus Greiff\n2,âˆ—\nâˆ—\nCorresponding author.\n1\nPaul Brunzema is with the department of Mechanical Engineering, Aachen University, Germany. Email:\npaul.brunzema@googlemail.com\n. Paul was with TRI when conducting this research.\n2\nThe remaining authors are with Toyota Research Institute,\n4440 El Camino Real, CA, USA. Email:\nfirst.last@tri.global\n.\nAbstract\nAgile control of robotic systems often requires anticipating how the environment affects system behavior.\nFor example, a driver must perceive the road ahead to anticipate available friction and plan actions ac",
    "is_relevant": true,
    "relevance_score": 7.0,
    "extracted_keywords": [
        "Reinforcement Learning",
        "locomotion",
        "whole body control"
    ],
    "one_line_summary": "è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºè§†è§‰æ¡ä»¶çš„å˜åˆ†è´å¶æ–¯æœ€åä¸€å±‚åŠ¨åŠ›å­¦æ¨¡å‹ï¼Œç”¨äºé¢„æµ‹ç¯å¢ƒå˜åŒ–å¹¶ä¼˜åŒ–è½¦è¾†æ§åˆ¶ï¼Œåœ¨èµ›è½¦åœºæ™¯ä¸­éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚",
    "detailed_summary": "## è®ºæ–‡æ‘˜è¦\n\n**è®ºæ–‡æ ‡é¢˜ï¼š** Vision-Conditioned Variational Bayesian Last Layer Dynamics Models\n\n### 1. ç ”ç©¶èƒŒæ™¯å’ŒåŠ¨æœº\nåœ¨æœºå™¨äººæ•æ·æ§åˆ¶ï¼ˆå¦‚æé™èµ›è½¦ï¼‰ä¸­ï¼Œå‡†ç¡®é¢„æµ‹ç¯å¢ƒå˜åŒ–å¯¹ç³»ç»ŸåŠ¨åŠ›å­¦çš„å½±å“è‡³å…³é‡è¦ã€‚ä¼ ç»Ÿæ¨¡å‹éš¾ä»¥æ•æ‰è·¯é¢æ¡ä»¶ï¼ˆå¦‚å¹²æ¹¿è½¬æ¢ï¼‰çš„çªå˜ï¼Œè€ŒåŸºäºå­¦ä¹ çš„è‡ªé€‚åº”æ–¹æ³•é€šå¸¸æ˜¯**ååº”å¼**çš„ï¼Œåœ¨æé™å·¥å†µä¸‹å¯èƒ½å› é€‚åº”è¿‡æ…¢è€Œå¯¼è‡´å¤±æ§ã€‚å› æ­¤ï¼Œç ”ç©¶éœ€è¦ä»**ååº”å¼**è½¬å‘**å‰ç»å¼**çš„åŠ¨åŠ›å­¦å»ºæ¨¡ï¼Œåˆ©ç”¨å¤–éƒ¨æ„ŸçŸ¥ï¼ˆå¦‚è§†è§‰ï¼‰æå‰é¢„æµ‹ç¯å¢ƒå˜åŒ–ï¼Œä»¥å®ç°å®‰å…¨ã€é«˜æ€§èƒ½çš„è‡ªä¸»æ§åˆ¶ã€‚\n\n### 2. æ ¸å¿ƒæ–¹æ³•å’ŒæŠ€æœ¯åˆ›æ–°\næœ¬æ–‡æå‡ºäº†**è§†è§‰æ¡ä»¶åŒ–å˜åˆ†è´å¶æ–¯æœ€åä¸€å±‚åŠ¨åŠ›å­¦æ¨¡å‹**ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºï¼š\n- **ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥**ï¼šé¦–å…ˆåœ¨**å¹²ç‡¥è·¯é¢**æ•°æ®ä¸Šè®­ç»ƒä¸€ä¸ªåŸºç¡€çš„VBLLåŠ¨åŠ›å­¦æ¨¡å‹ï¼›ç„¶åï¼Œåˆ©ç”¨**æœ‰é™çš„æ¹¿æ»‘è·¯é¢**æ•°æ®ï¼Œé€šè¿‡**ç‰¹å¾çº¿æ€§è°ƒåˆ¶**æŠ€æœ¯å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä½¿è§†è§‰ä¸Šä¸‹æ–‡ä¿¡æ¯èƒ½å¤Ÿè°ƒèŠ‚æ¨¡å‹çš„ç‰¹å¾è¡¨ç¤ºã€‚\n- **è§†è§‰ä¸Šä¸‹æ–‡æå–**ï¼šä½¿ç”¨è¯­ä¹‰åˆ†å‰²ç½‘ç»œå¤„ç†å‰è§†å›¾åƒï¼Œè®¡ç®—å‰æ–¹è·¯é¢çš„â€œæ°´è¦†ç›–ç‡â€ä½œä¸ºä¸Šä¸‹æ–‡å‘é‡ã€‚\n- **æ¨¡å‹é¢„æµ‹æ§åˆ¶é›†æˆ**ï¼šå°†å­¦ä¹ åˆ°çš„æ¡ä»¶åŒ–åŠ¨åŠ›å­¦æ¨¡å‹é›†æˆåˆ°**æ¨¡å‹é¢„æµ‹æ§åˆ¶**æ¡†æ¶ä¸­ï¼Œä½¿æ§åˆ¶å™¨èƒ½åŸºäºè§†è§‰ä¿¡æ¯**å‰ç»æ€§åœ°**è°ƒæ•´æ§åˆ¶ç­–ç•¥ã€‚\n\n### 3. ä¸»è¦å®éªŒç»“æœ\nåœ¨é›·å…‹è¨æ–¯LC500å®è½¦èµ›è½¦å®éªŒä¸­ï¼Œèµ›é“è®¾ç½®äº†æ°´å‘ä»¥æ¨¡æ‹Ÿçªå˜çš„è·¯é¢æ¡ä»¶ï¼š\n- **æˆåŠŸéªŒè¯**ï¼šé‡‡ç”¨è§†è§‰æ¡ä»¶åŒ–çš„ **VcVBLL** æ¨¡å‹æˆåŠŸå®Œæˆäº†å…¨éƒ¨12åœˆæµ‹è¯•ã€‚\n- **åŸºçº¿å¯¹æ¯”**ï¼šæ‰€æœ‰ä¸ä¾èµ–è§†è§‰ä¸Šä¸‹æ–‡çš„åŸºçº¿æ¨¡å‹ï¼ˆåŒ…æ‹¬åŸºç¡€VBLLæ¨¡å‹ã€å¸¦åœ¨çº¿é€‚åº”çš„VBLLæ¨¡å‹ï¼‰åœ¨é€šè¿‡æ°´å‘æ—¶**å…¨éƒ¨å¤±æ§**ã€‚\n- **ç‰©ç†å¯è§£é‡Šæ€§**ï¼šæ¨¡å‹é¢„æµ‹è¡¨æ˜ï¼Œæ£€æµ‹åˆ°æ°´æ—¶ï¼Œé¢„æµ‹çš„åè½®æ»‘ç§»å’Œä¾§åè§’ä¼šå¢å¤§ï¼Œä¸ç¡®å®šæ€§ä¹Ÿéšä¹‹å¢åŠ ï¼Œè¿™ä¸ç‰©ç†ç›´è§‰ä¸€è‡´ã€‚\n\n### 4. ç ”ç©¶æ„ä¹‰å’Œä»·å€¼\næœ¬ç ”ç©¶é¦–æ¬¡å°†è§†è§‰ä¿¡æ¯æ˜ç¡®åœ°æ¡ä»¶åŒ–åˆ°ä¸€ä¸ªè´å¶æ–¯åŠ¨åŠ›å­¦æ¨¡å‹ä¸­ï¼Œå¹¶ç”¨äºæœ€ä¼˜æ§åˆ¶ï¼Œå®ç°äº†ä»**ååº”å¼é€‚åº”**åˆ°**å‰ç»å¼é€‚åº”**çš„å…³é”®è½¬å˜ã€‚å®éªŒè¯æ˜ï¼Œè¿™ç§è§†è§‰å‰ç»èƒ½åŠ›æ˜¯è½¦è¾†åœ¨çªå˜æ¡ä»¶ä¸‹å®ç°**å®‰å…¨ã€é«˜é€Ÿè‡ªä¸»é©¾é©¶**çš„å†³å®šæ€§å› ç´ ã€‚è¯¥æ–¹æ³•ä¸ä»…é€‚ç”¨äºèµ›è½¦åœºæ™¯ï¼Œå…¶æ¡†æ¶å¯æ¨å¹¿è‡³æ¼‚ç§»ã€è¶Šé‡é©¾é©¶ç­‰éœ€è¦åº”å¯¹å¤æ‚ç¯å¢ƒå˜åŒ–çš„å…¶ä»–æœºå™¨äººåº”ç”¨é¢†åŸŸã€‚",
    "qa_pairs": [
        {
            "question": "è¿™ç¯‡è®ºæ–‡çš„æ ¸å¿ƒåˆ›æ–°ç‚¹æ˜¯ä»€ä¹ˆï¼Œä»–æƒ³è§£å†³ä»€ä¹ˆé—®é¢˜ï¼Œæ€ä¹ˆè§£å†³çš„ï¼Ÿ",
            "answer": "## è®ºæ–‡æ ¸å¿ƒåˆ†æ\n\n### **ç ”ç©¶é—®é¢˜**\nè®ºæ–‡æ—¨åœ¨è§£å†³**è‡ªåŠ¨é©¾é©¶åœ¨æé™æ“æ§åœºæ™¯ä¸‹ï¼ˆå¦‚èµ›è½¦ï¼‰æ— æ³•ä¸»åŠ¨é€‚åº”ç¯å¢ƒçªå˜**çš„éš¾é¢˜ã€‚ä¼ ç»ŸåŠ¨åŠ›å­¦æ¨¡å‹åŸºäºç®€åŒ–å‡è®¾ï¼Œåœ¨è·¯é¢æ¡ä»¶å‰§å˜ï¼ˆå¦‚å¹²æ¹¿è½¬æ¢ï¼‰æ—¶å®¹æ˜“å¤±æ•ˆï¼›è€ŒåŸºäºå­¦ä¹ çš„è‡ªé€‚åº”æ–¹æ³•é€šå¸¸æ˜¯â€œè¢«åŠ¨ååº”å¼â€çš„ï¼Œåœ¨è½¦è¾†æ¥è¿‘æ“æ§æé™æ—¶å¾€å¾€å› é€‚åº”è¿‡æ…¢è€Œå¯¼è‡´å¤±æ§ã€‚\n\n**æ ¸å¿ƒæŒ‘æˆ˜**ï¼šå¦‚ä½•è®©è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿåƒäººç±»é©¾é©¶å‘˜ä¸€æ ·ï¼Œ**æå‰æ„ŸçŸ¥ç¯å¢ƒå˜åŒ–ï¼ˆå¦‚å‰æ–¹ç§¯æ°´ï¼‰å¹¶ä¸»åŠ¨è°ƒæ•´æ§åˆ¶ç­–ç•¥**ï¼Œè€Œéç­‰åˆ°é©¶å…¥ç§¯æ°´åæ‰è¢«åŠ¨é€‚åº”ã€‚\n\n### **æ ¸å¿ƒåˆ›æ–°ç‚¹**\nè®ºæ–‡æå‡ºäº† **Vision-Conditioned Variational Bayesian Last Layer (VcVBLL) åŠ¨åŠ›å­¦æ¨¡å‹**ï¼Œè¿™æ˜¯ä¸€ä¸ª**èåˆè§†è§‰ä¸Šä¸‹æ–‡è¿›è¡Œå‰ç»æ€§åŠ¨åŠ›å­¦é¢„æµ‹**çš„æ¡†æ¶ã€‚å…¶ä¸»è¦åˆ›æ–°ä½“ç°åœ¨ï¼š\n\n1.  **é¦–æ¬¡å°†è§†è§‰ä¿¡æ¯ä¸å˜åˆ†è´å¶æ–¯æœ€åä¸€å±‚ï¼ˆVBLLï¼‰åŠ¨åŠ›å­¦æ¨¡å‹ç»“åˆ**\n    *   **VBLLä½œä¸ºåŸºç¡€**ï¼šé‡‡ç”¨VBLLä½œä¸ºè½»é‡çº§è´å¶æ–¯ç¥ç»ç½‘ç»œï¼Œèƒ½æä¾›é«˜æ–¯é¢„æµ‹åéªŒåˆ†å¸ƒï¼ˆå‡å€¼å’Œä¸ç¡®å®šæ€§ï¼‰ï¼Œå…¼å…·è¡¨è¾¾èƒ½åŠ›å’Œè®¡ç®—æ•ˆç‡ã€‚\n    *   **è§†è§‰æ¡ä»¶åŒ–**ï¼šé€šè¿‡**FiLMï¼ˆFeature-wise Linear Modulationï¼‰æœºåˆ¶**ï¼Œå°†ä»å‰å‘æ‘„åƒå¤´æå–çš„è¯­ä¹‰ä¿¡æ¯ï¼ˆå¦‚è·¯é¢å¹²æ¹¿ç¨‹åº¦ï¼‰ç¼–ç ä¸ºä»¿å°„å˜æ¢å‚æ•°ï¼ŒåŠ¨æ€è°ƒåˆ¶VBLLä¸»å¹²ç½‘ç»œçš„ç‰¹å¾ã€‚è¿™ä½¿å¾—åŠ¨åŠ›å­¦é¢„æµ‹èƒ½æ ¹æ®â€œçœ‹åˆ°â€çš„ç¯å¢ƒè¿›è¡Œä¸»åŠ¨è°ƒæ•´ã€‚\n\n2.  **é’ˆå¯¹æ•°æ®ç¨€ç¼ºçš„ä¸¤é˜¶æ®µå¾®è°ƒè®­ç»ƒç­–ç•¥**\n    *   **é˜¶æ®µä¸€ï¼ˆåŸºç¡€æ¨¡å‹ï¼‰**ï¼šåœ¨å¤§é‡**æ­£å¸¸ï¼ˆå¹²ç‡¥ï¼‰è·¯é¢**çš„é©¾é©¶æ•°æ®ä¸Šè®­ç»ƒä¸€ä¸ªåŸºç¡€çš„VBLLåŠ¨åŠ›å­¦æ¨¡å‹ã€‚\n    *   **é˜¶æ®µäºŒï¼ˆæ¡ä»¶åŒ–å¾®è°ƒï¼‰**ï¼šåœ¨**æœ‰é™çš„æ¹¿æ»‘è·¯é¢ï¼ˆç§¯æ°´ï¼‰æ•°æ®**ä¸Šï¼Œ**å†»ç»“åŸºç¡€VBLLçš„ä¸»å¹²ç½‘ç»œ**ï¼Œä»…è®­ç»ƒè§†è§‰ç¼–ç å™¨ï¼ˆLSTMï¼‰å’ŒFiMLè°ƒåˆ¶è·¯å¾„ã€‚è¿™é¿å…äº†åœ¨å°æ ·æœ¬æ•°æ®ä¸Šé‡æ–°è®­ç»ƒæ•´ä¸ªæ¨¡å‹å¯¼è‡´çš„è¿‡æ‹Ÿåˆæˆ–ç¾éš¾æ€§é—å¿˜ï¼Œé€šè¿‡**L2-SPæ­£åˆ™åŒ–**ä¿æŠ¤å·²å­¦åˆ°çš„åä¹‰åŠ¨åŠ›å­¦çŸ¥è¯†ã€‚\n\n3.  **åœ¨æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆMPCï¼‰ä¸­å®ç°å‰ç»æ€§å†³ç­–**\n    *   å°†å­¦ä¹ åˆ°çš„VcVBLLæ¨¡å‹é›†æˆåˆ°MPCæ¡†æ¶ä¸­ï¼Œä½œä¸ºåŠ¨åŠ›å­¦çº¦æŸã€‚\n    *   æ§åˆ¶å™¨åˆ©ç”¨æ¨¡å‹æä¾›çš„ã€**åŸºäºè§†è§‰ä¸Šä¸‹æ–‡çš„æ¡ä»¶é¢„æµ‹**ï¼Œèƒ½å¤Ÿåœ¨è½¦è¾†ç‰©ç†ä¸Šæ¥è§¦åˆ°æ¹¿æ»‘è·¯é¢ä¹‹å‰ï¼Œå°±æå‰è§„åˆ’å‡ºé™ä½æ‰­çŸ©ã€æ–½åŠ åˆ¶åŠ¨ç­‰æ§åˆ¶åŠ¨ä½œï¼Œå®ç°**ä¸»åŠ¨ã€å®‰å…¨çš„é¿éšœå’Œé€Ÿåº¦è°ƒæ•´**ã€‚\n\n### **è§£å†³æ–¹æ¡ˆæ¶æ„**\n1.  **è§†è§‰ä¸Šä¸‹æ–‡æå–**ï¼š\n    *   ä½¿ç”¨è¯­ä¹‰åˆ†å‰²æ¨¡å‹ï¼ˆSegMan-tï¼‰å¤„ç†å‰å‘æ‘„åƒå¤´å›¾åƒï¼Œè¯†åˆ«â€œæ°´é¢â€å’Œâ€œæ²¥é’â€ç­‰ç±»åˆ«ã€‚\n    *   é€šè¿‡é«˜æ–¯ç©ºé—´åŠ æƒï¼Œè®¡ç®—ä¸€ä¸ªåæ˜ å‰æ–¹è·¯é¢æ¹¿æ»‘ç¨‹åº¦çš„â€œæ°´é¢åˆ†æ•°â€æ—¶é—´åºåˆ—ä½œä¸ºä¸Šä¸‹æ–‡ `c_t`ã€‚\n\n2.  **åŠ¨åŠ›å­¦æ¨¡å‹å­¦ä¹ **ï¼š\n    *   **åŸºç¡€VBLL**ï¼šå­¦ä¹ çŠ¶æ€å·®åˆ† `Î”x`ï¼Œè¾“å‡ºä¸ºé«˜æ–¯åˆ†å¸ƒã€‚\n    *   **VcVBLL**ï¼šé€šè¿‡LSTMç¼–ç ä¸Šä¸‹æ–‡ `c_t`ï¼Œç”ŸæˆFiLMçš„ç¼©æ”¾ `Î³` å’Œåç§» `Î²` å‚æ•°ï¼Œå¯¹VBLLä¸»å¹²ç‰¹å¾è¿›è¡Œè°ƒåˆ¶ï¼Œä»è€Œå¾—åˆ°æ¡ä»¶é¢„æµ‹åˆ†å¸ƒã€‚\n\n3.  **æ§åˆ¶ä¸éªŒè¯**ï¼š\n    *   **é›†æˆ**ï¼šå°†VcVBLLçš„MAPä¼°è®¡ä½œä¸ºMPCçš„åŠ¨åŠ›å­¦æ¨¡å‹ã€‚\n    *   **å®éªŒ**ï¼šåœ¨çœŸå®é›·å…‹è¨æ–¯LC500èµ›è½¦ä¸Šè¿›è¡Œç¡¬ä»¶å®éªŒï¼Œè®¾ç½®ç§¯æ°´è·¯æ®µã€‚\n\n### **å®é™…ä»·å€¼ä¸ç»“æœ**\n*   **æ€§èƒ½çªç ´**ï¼šåœ¨é€šè¿‡ç§¯æ°´è·¯æ®µçš„èµ›è½¦ä»»åŠ¡ä¸­ï¼Œ**é…å¤‡è§†è§‰æ¡ä»¶åŒ–çš„VcVBLLæ¨¡å‹æˆåŠŸå®Œæˆäº†å…¨éƒ¨12åœˆæµ‹è¯•**ã€‚\n*   **åŸºçº¿å¯¹æ¯”**ï¼šæ‰€æœ‰ä¸åˆ©ç”¨è§†è§‰ä¸Šä¸‹æ–‡çš„åŸºçº¿æ¨¡å‹ï¼ˆåŒ…æ‹¬åŸºç¡€VBLLã€å¸¦RLSè‡ªé€‚åº”çš„VBLLä»¥åŠå¿½ç•¥è§†è§‰æ¡ä»¶çš„VcVBLLï¼‰**å…¨éƒ¨å¤±æ§**ã€‚\n*   **å…³é”®ç»“è®º**ï¼šè¯æ˜äº†**å°†å¤–æ„Ÿï¼ˆè§†è§‰ï¼‰ä¿¡æ¯èå…¥å­¦ä¹ å‹åŠ¨åŠ›å­¦æ¨¡å‹ï¼Œæ˜¯å®ç°é«˜é€Ÿã€æé™å·¥å†µä¸‹é²æ£’ã€å‰ç»æ€§è‡ªåŠ¨é©¾é©¶çš„å…³é”®**ã€‚è¯¥æ–¹æ³•ä½¿æ§åˆ¶ç³»ç»Ÿä»â€œè¢«åŠ¨ååº”â€è½¬å˜ä¸ºâ€œä¸»åŠ¨é€‚åº”â€ï¼Œæ˜¾è‘—æå‡äº†åœ¨åŠ¨æ€å˜åŒ–ç¯å¢ƒä¸­çš„å®‰å…¨æ€§å’Œæ€§èƒ½æé™ã€‚\n\n**æ€»ç»“**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒåˆ›æ–°åœ¨äº**é€šè¿‡â€œè§†è§‰æ¡ä»¶åŒ–+ä¸¤é˜¶æ®µè´å¶æ–¯å­¦ä¹ â€çš„æ–¹æ³•ï¼Œæ„å»ºäº†ä¸€ä¸ªèƒ½å‰ç»æ€§é¢„æµ‹ç¯å¢ƒå˜åŒ–å¯¹åŠ¨åŠ›å­¦å½±å“çš„æ¨¡å‹ï¼Œå¹¶æˆåŠŸå°†å…¶åº”ç”¨äºå®æ—¶æœ€ä¼˜æ§åˆ¶ï¼Œè§£å†³äº†æé™é©¾é©¶åœºæ™¯ä¸‹å› ç¯å¢ƒçªå˜å¯¼è‡´çš„å¤±æ§é—®é¢˜**ã€‚",
            "timestamp": "2026-01-20T17:57:36.520003",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "åŸºäºä»–çš„å‰ä½œï¼Œæ¢³ç†è¿™ä¸ªæ–¹å‘çš„æ•´ä¸ªå‘å±•è„‰ç»œï¼Œæ¯ä¸€æ­¥ç›¸æ¯”äºä¹‹å‰çš„å·¥ä½œéƒ½æ”¹è¿›äº†ä»€ä¹ˆï¼Œç€é‡äºå‡ ä¸ªä¸åŒçš„å‘å±•æ–¹å‘ã€‚",
            "answer": "## è®ºæ–‡å‘å±•è„‰ç»œæ¢³ç†\n\næœ¬æ–‡ã€ŠVision-Conditioned Variational Bayesian Last Layer Dynamics Modelsã€‹æ˜¯ä¸°ç”°ç ”ç©¶é™¢åœ¨**æé™é©¾é©¶ä¸è‡ªé€‚åº”åŠ¨åŠ›å­¦å»ºæ¨¡**æ–¹å‘ä¸Šçš„æœ€æ–°å·¥ä½œã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äº**é¦–æ¬¡å°†è§†è§‰ä¸Šä¸‹æ–‡ï¼ˆexteroceptive sensingï¼‰ä¸å˜åˆ†è´å¶æ–¯æœ€åä¸€å±‚ï¼ˆVBLLï¼‰åŠ¨åŠ›å­¦æ¨¡å‹ç»“åˆï¼Œå®ç°äº†å¯¹è·¯é¢æ¡ä»¶ï¼ˆå¦‚å¹²/æ¹¿ï¼‰çš„ä¸»åŠ¨ã€å‰ç»æ€§é€‚åº”**ã€‚ä»¥ä¸‹å°†åŸºäºå…¶å¼•ç”¨çš„å‰ä½œï¼Œæ¢³ç†è¯¥æ–¹å‘çš„å‘å±•è„‰ç»œã€å…³é”®æ”¹è¿›ä¸ä¸åŒåˆ†æ”¯ã€‚\n\n### å‘å±•è„‰ç»œæ€»è§ˆ\nè¯¥é¢†åŸŸçš„å‘å±•å¯æ¦‚æ‹¬ä¸ºä¸‰ä¸ªé˜¶æ®µï¼š\n1.  **åŸºäºç‰©ç†æ¨¡å‹ä¸ç³»ç»Ÿè¾¨è¯†çš„ä¼ ç»Ÿæ–¹æ³•**ï¼šä¾èµ–å‚æ•°åŒ–æ¨¡å‹ï¼Œåœ¨å·²çŸ¥/ç¨³å®šæ¡ä»¶ä¸‹æœ‰æ•ˆï¼Œä½†éš¾ä»¥åº”å¯¹å‰§çƒˆå˜åŒ–ã€‚\n2.  **åŸºäºå­¦ä¹ çš„è‡ªé€‚åº”åŠ¨åŠ›å­¦æ¨¡å‹**ï¼šåˆ©ç”¨æ•°æ®é©±åŠ¨æ¨¡å‹ï¼ˆNNã€GPï¼‰åœ¨çº¿é€‚åº”ï¼Œä½†æœ¬è´¨æ˜¯**ååº”å¼ï¼ˆreactiveï¼‰**ï¼Œåœ¨æé™å·¥å†µä¸‹å¯èƒ½â€œä¸ºæ—¶å·²æ™šâ€ã€‚\n3.  **è§†è§‰æ¡ä»¶åŒ–çš„å‰ç»æ€§åŠ¨åŠ›å­¦æ¨¡å‹**ï¼šæœ¬æ–‡å·¥ä½œæ‰€å±çš„æ–°é˜¶æ®µï¼Œåˆ©ç”¨å¤–æ„ŸçŸ¥ï¼ˆè§†è§‰ï¼‰ä¿¡æ¯**æå‰é¢„æµ‹**åŠ¨åŠ›å­¦å˜åŒ–ï¼Œå®ç°ä¸»åŠ¨æ§åˆ¶ã€‚\n\n### å…³é”®å‘å±•é˜¶æ®µä¸æ”¹è¿›\n\n#### æ–¹å‘ä¸€ï¼šä»ç‰©ç†æ¨¡å‹åˆ°æ•°æ®é©±åŠ¨è‡ªé€‚åº”æ¨¡å‹\n*   **å‰ä½œåŸºç¡€**ï¼š\n    *   **ç‰©ç†æ¨¡å‹**ï¼šä½¿ç”¨å•è½¨æ¨¡å‹ï¼ˆsingle-trackï¼‰ä¸Fialaè½®èƒæ¨¡å‹ [`42`, `19`, `49`]ï¼Œå‚æ•°é€šè¿‡ç³»ç»Ÿè¾¨è¯†ç¡®å®š [`34`]ã€‚è¿™ç±»æ¨¡å‹åœ¨æ ‡å®šè‰¯å¥½æ—¶å¯ç”¨äºç«é€Ÿ [`33`, `51`]ã€‚\n    *   **å±€é™æ€§**ï¼šæ¨¡å‹åŸºäºç®€åŒ–å‡è®¾ï¼Œæ— æ³•æ•æ‰å¤æ‚ã€çªå˜çš„è½®èƒ-è·¯é¢äº¤äº’ï¼ˆå¦‚æ‘©æ“¦ç³»æ•°å‰§å˜ï¼‰ã€‚\n*   **æ”¹è¿›1ï¼šå¼•å…¥å­¦ä¹ æ¨¡å‹è¿›è¡Œåœ¨çº¿é€‚åº”**\n    *   **ä»£è¡¨å·¥ä½œ**ï¼š`[12, 15, 30, 48]`ã€‚è¿™äº›å·¥ä½œç”¨ç¥ç»ç½‘ç»œï¼ˆNNï¼‰æˆ–é«˜æ–¯è¿‡ç¨‹ï¼ˆGPï¼‰æ›¿ä»£æˆ–å¢å¼ºç‰©ç†æ¨¡å‹ï¼Œå¹¶**åœ¨çº¿æ›´æ–°æ¨¡å‹å‚æ•°**ä»¥é€‚åº”å˜åŒ–ã€‚\n    *   **å…³é”®æ”¹è¿›**ï¼šæ¨¡å‹çµæ´»æ€§å¤§å¹…æå‡ï¼Œèƒ½æ‹Ÿåˆæ›´å¤æ‚çš„åŠ¨åŠ›å­¦ã€‚\n    *   **é—ç•™é—®é¢˜**ï¼šé€‚åº”æ˜¯**ååº”å¼çš„**â€”â€”æ¨¡å‹åªæœ‰åœ¨è½¦è¾†**å·²ç»**é©¶å…¥ä¸åŒè·¯é¢ã€æ„Ÿå—åˆ°åŠ¨åŠ›å­¦å˜åŒ–åï¼Œæ‰å¼€å§‹è°ƒæ•´ã€‚åœ¨é«˜é€Ÿæé™é©¾é©¶ä¸­ï¼Œè¿™ç§å»¶è¿Ÿè¶³ä»¥å¯¼è‡´å¤±æ§ [`12`]ã€‚\n\n#### æ–¹å‘äºŒï¼šä»ç¡®å®šæ€§æ¨¡å‹åˆ°è´å¶æ–¯ä¸ç¡®å®šæ€§å»ºæ¨¡\n*   **å‰ä½œåŸºç¡€**ï¼šæ—©æœŸå­¦ä¹ æ¨¡å‹å¤šä¸ºç¡®å®šæ€§NN [`45`] æˆ–ç‚¹ä¼°è®¡ï¼Œç¼ºä¹å¯¹é¢„æµ‹ä¸ç¡®å®šæ€§çš„é‡åŒ–ã€‚\n*   **æ”¹è¿›2ï¼šå¼•å…¥è´å¶æ–¯æœ€åä¸€å±‚ï¼ˆBLLï¼‰æ¨¡å‹**\n    *   **ä»£è¡¨å·¥ä½œ**ï¼š`[29, 44, 50]`ã€‚BLLåœ¨ç¥ç»ç½‘ç»œçš„æœ€åä¸€å±‚ä½¿ç”¨é«˜æ–¯æƒé‡ï¼Œæä¾›**é«˜æ–¯é¢„æµ‹åéªŒ**ï¼Œèƒ½åŒæ—¶ç»™å‡ºé¢„æµ‹å‡å€¼ä¸ä¸ç¡®å®šæ€§ã€‚\n    *   **å…³é”®æ”¹è¿›**ï¼šä¸ºæ§åˆ¶å™¨æä¾›äº†å®è´µçš„**ä¸ç¡®å®šæ€§ä¿¡æ¯**ï¼Œå¯ç”¨äºé£é™©æ„ŸçŸ¥è§„åˆ’æˆ–ä¸»åŠ¨æ¢ç´¢ [`11`, `32`]ã€‚\n*   **æ”¹è¿›3ï¼šä»BLLåˆ°å˜åˆ†BLLï¼ˆVBLLï¼‰**\n    *   **ä»£è¡¨å·¥ä½œ**ï¼š`[25]`ã€‚VBLLé€šè¿‡å˜åˆ†ç›®æ ‡**è”åˆå­¦ä¹ æœ€åä¸€å±‚æƒé‡å’Œå™ªå£°å‚æ•°**ï¼Œç›¸æ¯”BLLæ›´çµæ´»ã€æ€§èƒ½æ›´ä¼˜ã€‚\n    *   **å…³é”®æ”¹è¿›**ï¼šæœ¬æ–‡é¦–æ¬¡å°†**VBLLåº”ç”¨äºåŠ¨åŠ›å­¦å­¦ä¹ **ï¼Œä½œä¸ºå…¶åŸºç¡€æ¶æ„ï¼Œè·å¾—äº†æ›´ä¼˜çš„é¢„æµ‹åˆ†å¸ƒå’Œè®­ç»ƒç¨³å®šæ€§ã€‚\n\n#### æ–¹å‘ä¸‰ï¼šä»çº¯æœ¬ä½“æ„ŸçŸ¥åˆ°è§†è§‰æ¡ä»¶åŒ–å‰ç»æ¨¡å‹\n*   **å‰ä½œåŸºç¡€**ï¼š\n    *   **çº¯æœ¬ä½“æ„ŸçŸ¥æ¨¡å‹**ï¼šç»å¤§å¤šæ•°å­¦ä¹ åŠ¨åŠ›å­¦æ¨¡å‹ [`16`, `15`, `12`] ä»…ä½¿ç”¨è½¦è¾†çŠ¶æ€ï¼ˆé€Ÿåº¦ã€åèˆªç‡ç­‰ï¼‰å’Œæ§åˆ¶è¾“å…¥ä½œä¸ºè¾“å…¥ï¼Œå¯¹å³å°†åˆ°æ¥çš„ç¯å¢ƒå˜åŒ–â€œè§†è€Œä¸è§â€ã€‚\n    *   **è§†è§‰åœ¨æ§åˆ¶ä¸­çš„åº”ç”¨**ï¼šè§†è§‰ä¸»è¦ç”¨äºç«¯åˆ°ç«¯é©¾é©¶ [`4`]ã€RLç­–ç•¥ [`6`]ï¼Œæˆ–åœ¨MPCä¸­ç”¨äº**æ¨æ–­ä»£ä»· [`18`] æˆ–éšœç¢ç‰©çº¦æŸ**ï¼Œä½†**ä»æœªç”¨äºç›´æ¥æ¡ä»¶åŒ–åŠ¨åŠ›å­¦æ¨¡å‹** [`1`, `18`, `53`]ã€‚\n*   **æœ¬æ–‡çš„æ ¸å¿ƒæ”¹è¿›ï¼šVision-Conditioned VBLL (VcVBLL)**\n    *   **åˆ›æ–°ç‚¹1ï¼šè§†è§‰ä¸Šä¸‹æ–‡ä¸åŠ¨åŠ›å­¦æ¨¡å‹çš„èåˆ**ã€‚é¦–æ¬¡æå‡ºå°†è§†è§‰ä¿¡æ¯ï¼ˆé€šè¿‡è¯­ä¹‰åˆ†å‰²å¾—åˆ°çš„æ°´/æ²¥é’åŒºåŸŸåˆ†æ•°ï¼‰ä½œä¸ºæ¡ä»¶ï¼Œç›´æ¥è°ƒåˆ¶åŠ¨åŠ›å­¦æ¨¡å‹çš„å†…éƒ¨ç‰¹å¾è¡¨ç¤ºã€‚\n    *   **åˆ›æ–°ç‚¹2ï¼šFiLMè°ƒåˆ¶æœºåˆ¶**ã€‚é‡‡ç”¨Feature-wise Linear Modulation (FiLM) [`40`] æŠ€æœ¯ï¼Œåˆ©ç”¨LSTMç¼–ç çš„è§†è§‰ä¸Šä¸‹æ–‡æ—¶é—´åºåˆ—ï¼Œå¯¹VBLLçš„éª¨å¹²ç½‘ç»œç‰¹å¾è¿›è¡Œä»¿å°„å˜æ¢ï¼ˆ`Î³ * ç‰¹å¾ + Î²`ï¼‰ï¼Œå®ç°**ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„ç‰¹å¾è°ƒæ•´**ã€‚\n    *   **åˆ›æ–°ç‚¹3ï¼šä¸¤é˜¶æ®µé«˜æ•ˆè®­ç»ƒç­–ç•¥**ã€‚\n        1.  **åŸºç¡€é˜¶æ®µ**ï¼šåœ¨å¤§é‡â€œå¹²ç‡¥è·¯é¢â€æ•°æ®ä¸Šè®­ç»ƒä¸€ä¸ªé€šç”¨çš„VBLLæ¨¡å‹ã€‚\n        2.  **å¾®è°ƒé˜¶æ®µ**ï¼šåœ¨æœ‰é™çš„â€œæ¹¿æ»‘è·¯é¢â€æ•°æ®ä¸Šï¼Œ**ä»…è®­ç»ƒFiLM conditioningè·¯å¾„å’ŒLSTM**ï¼ŒåŒæ—¶ç”¨L2-SPæ­£åˆ™åŒ– [`55`] å†»ç»“éª¨å¹²ç½‘ç»œå¤§éƒ¨åˆ†å‚æ•°ï¼Œé˜²æ­¢ç¾éš¾æ€§é—å¿˜ã€‚\n    *   **æ ¹æœ¬æ€§çªç ´**ï¼šå°†åŠ¨åŠ›å­¦æ¨¡å‹ä»**ååº”å¼**è½¬å˜ä¸º**å‰ç»å¼**ã€‚æ§åˆ¶å™¨èƒ½åœ¨è½¦è½®æ¥è§¦æ°´å‘**ä¹‹å‰**ï¼Œå°±æ ¹æ®â€œçœ‹åˆ°â€çš„æ°´é¢è°ƒæ•´é¢„æµ‹æ¨¡å‹ï¼Œä»è€Œæå‰è§„åˆ’å‡é€Ÿã€æ”¶æ²¹ç­‰åŠ¨ä½œï¼ˆå¦‚å›¾6æ‰€ç¤ºï¼‰ã€‚\n\n### ä¸åŒå‘å±•æ–¹å‘æ€»ç»“\n\n1.  **æ¨¡å‹è¡¨è¾¾èƒ½åŠ›çš„æ¼”è¿›**\n    *   **è·¯å¾„**ï¼šå‚æ•°åŒ–ç‰©ç†æ¨¡å‹ â†’ é»‘ç›’ç¥ç»ç½‘ç»œ/é«˜æ–¯è¿‡ç¨‹ â†’ è´å¶æ–¯ç¥ç»ç½‘ç»œï¼ˆBLL/VBLLï¼‰ã€‚\n    *   **é©±åŠ¨ç›®æ ‡**ï¼šä»ä¾èµ–å…ˆéªŒçŸ¥è¯†åˆ°æ•°æ®é©±åŠ¨ï¼Œå†åˆ°**é‡åŒ–é¢„æµ‹ä¸ç¡®å®šæ€§**ä»¥æå‡å®‰å…¨æ€§ã€‚\n\n2.  **é€‚åº”èŒƒå¼çš„æ¼”è¿›**\n    *   **è·¯å¾„**ï¼šå›ºå®šå‚æ•° â†’ åœ¨çº¿å‚æ•°ä¼°è®¡/æ¨¡å‹è‡ªé€‚åº” â†’ **åŸºäºè§†è§‰çš„å‰ç»æ€§æ¡ä»¶åŒ–**ã€‚\n    *   **é©±åŠ¨ç›®æ ‡**ï¼šä»æ— æ³•é€‚åº”ï¼Œåˆ°è¢«åŠ¨é€‚åº”ï¼Œæœ€ç»ˆå®ç°**ä¸»åŠ¨ã€æå‰é€‚åº”**ï¼Œè§£å†³æé™å·¥å†µä¸‹çš„ååº”å»¶è¿Ÿé—®é¢˜ã€‚\n\n3.  **æ„ŸçŸ¥-æ§åˆ¶èåˆæ–¹å¼çš„æ¼”è¿›**\n    *   **è·¯å¾„**ï¼šæ„ŸçŸ¥ä¸åŠ¨åŠ›å­¦æ¨¡å‹è§£è€¦ï¼ˆæ„ŸçŸ¥ç”¨äºè§„åˆ’/é¿éšœï¼‰â†’ **æ„ŸçŸ¥ä¿¡æ¯æ·±åº¦åµŒå…¥åŠ¨åŠ›å­¦æ¨¡å‹å†…éƒ¨**ã€‚\n    *   **é©±åŠ¨ç›®æ ‡**ï¼šä»åˆ†å±‚æ¶æ„åˆ°ç´§å¯†è€¦åˆï¼Œä½¿**åŠ¨åŠ›å­¦é¢„æµ‹æœ¬èº«æˆä¸ºç¯å¢ƒæ„ŸçŸ¥çš„å‡½æ•°**ï¼Œå®ç°æ›´æ ¹æœ¬çš„å…·èº«æ™ºèƒ½ã€‚\n\n### æœ¬æ–‡çš„å®é™…ä»·å€¼ä¸å¯ç¤º\n*   **æŠ€æœ¯ä»·å€¼**ï¼šæˆåŠŸéªŒè¯äº†â€œè§†è§‰æ¡ä»¶åŒ–åŠ¨åŠ›å­¦æ¨¡å‹â€åœ¨çœŸå®ä¸–ç•Œé«˜é€Ÿæé™åœºæ™¯ï¼ˆèµ›è½¦è¿‡æ°´å‘ï¼‰ä¸­çš„å¯è¡Œæ€§ä¸å¿…è¦æ€§ã€‚VcVBLLæ˜¯å”¯ä¸€èƒ½ç¨³å®šå®Œæˆ12åœˆæµ‹è¯•çš„æ–¹æ³•ã€‚\n*   **æ–¹æ³•è®ºä»·å€¼**ï¼šæå‡ºçš„**ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥**ä¸ºè§£å†³â€œé«˜é£é™©åœºæ™¯æ•°æ®ç¨€ç¼ºâ€é—®é¢˜æä¾›äº†èŒƒä¾‹ã€‚å…ˆå­¦é€šç”¨æ¨¡å‹ï¼Œå†ç”¨å°‘é‡ç‰¹å¼‚æ•°æ®å¾®è°ƒè§£ç è·¯å¾„ï¼Œæå…·å®ç”¨ä»·å€¼ã€‚\n*   **é¢†åŸŸå½±å“**ï¼šä¸ºè‡ªåŠ¨é©¾é©¶ï¼ˆå°¤å…¶æ˜¯é«˜æ€§èƒ½é©¾é©¶ã€è¶Šé‡é©¾é©¶ï¼‰å’Œæ›´å¹¿æ³›çš„æœºå™¨äººé¢†åŸŸæŒ‡æ˜äº†ä¸€ä¸ªé‡è¦æ–¹å‘ï¼š**å°†å¤–æ„ŸçŸ¥ä¿¡æ¯æ·±åº¦é›†æˆåˆ°åŠ¨åŠ›å­¦æ¨¡å‹ä¸­ï¼Œæ˜¯å®ç°åœ¨å¤æ‚ã€åŠ¨æ€ç¯å¢ƒä¸­é²æ£’ã€ä¸»åŠ¨æ§åˆ¶çš„å…³é”®**ã€‚è®ºæ–‡ç»“å°¾ä¹ŸæŒ‡å‡ºï¼Œè¯¥æ–¹æ³•å¯æ¨å¹¿è‡³æ¼‚ç§»ã€è¶Šé‡ç­‰æ›´ä¸°å¯Œè§†è§‰åœºæ™¯ä¸­ã€‚",
            "timestamp": "2026-01-20T17:58:28.855457",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "ä»–çš„å‰ä½œæœ‰å“ªäº›ï¼Ÿä½¿ç”¨è¡¨æ ¼ä»”ç»†è®²è®²ä»–çš„æ¯ç¯‡å‰ä½œï¼Œä»–å’Œå‰ä½œçš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Œä¸»è¦æ”¹å–„æ˜¯ä»€ä¹ˆï¼Ÿç€é‡äºå…·ä½“ç›¸æ¯”äºä¹‹å‰æ–‡ç« çš„æ”¹åŠ¨",
            "answer": "## è®ºæ–‡å‰ä½œåˆ†æ\n\næ ¹æ®è®ºæ–‡å†…å®¹ï¼Œä½œè€…å›¢é˜Ÿï¼ˆç‰¹åˆ«æ˜¯Toyota Research Instituteå›¢é˜Ÿï¼‰åœ¨**æé™é©¾é©¶æ¡ä»¶ä¸‹çš„è½¦è¾†åŠ¨åŠ›å­¦å»ºæ¨¡ä¸æ§åˆ¶**é¢†åŸŸæœ‰ä¸€ç³»åˆ—ç´§å¯†ç›¸å…³çš„å‰æœŸå·¥ä½œã€‚ä»¥ä¸‹æ˜¯åŸºäºè®ºæ–‡å¼•ç”¨æ¢³ç†å‡ºçš„ä¸»è¦å‰ä½œã€æ ¸å¿ƒè´¡çŒ®ï¼Œä»¥åŠæœ¬æ–‡ï¼ˆVision-Conditioned Variational Bayesian Last Layer Dynamics Models, **VcVBLL**ï¼‰ä¸å®ƒä»¬çš„åŒºåˆ«å’Œæ”¹è¿›ã€‚\n\n### å‰ä½œæ±‡æ€»ä¸å¯¹æ¯”åˆ†æè¡¨\n\n| å‰ä½œæ–‡çŒ® (æ ¸å¿ƒä½œè€…) | æ ¸å¿ƒæ–¹æ³•/æ¨¡å‹ | è§£å†³çš„é—®é¢˜/åœºæ™¯ | ä¸æœ¬æ–‡ï¼ˆVcVBLLï¼‰çš„ä¸»è¦åŒºåˆ« | æœ¬æ–‡çš„ä¸»è¦æ”¹è¿›/åˆ›æ–°ç‚¹ |\n| :--- | :--- | :--- | :--- | :--- |\n| **[12, 33] Lew et al. (2025)** <br>â€œRisk-averse model predictive control for racing in adverse conditionsâ€ | **è´å¶æ–¯æœ€åä¸€å±‚ï¼ˆBLLï¼‰æ¨¡å‹** + æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆMPCï¼‰ã€‚ä½¿ç”¨**åœ¨çº¿é€’å½’æœ€å°äºŒä¹˜ï¼ˆRLSï¼‰** è¿›è¡Œæ¨¡å‹å‚æ•°è‡ªé€‚åº”ã€‚ | åœ¨ä¸åˆ©æ¡ä»¶ä¸‹ï¼ˆå¦‚æ‘©æ“¦å˜åŒ–ï¼‰è¿›è¡Œå®‰å…¨èµ›è½¦ã€‚æ¨¡å‹èƒ½å¤Ÿé€šè¿‡**æœ¬ä½“æ„ŸçŸ¥æ•°æ®**åœ¨çº¿é€‚åº”å˜åŒ–çš„åŠ¨åŠ›å­¦ã€‚ | 1. **æ„ŸçŸ¥æ–¹å¼**ï¼šå‰ä½œä»…ä¾èµ–**æœ¬ä½“æ„ŸçŸ¥**ï¼ˆè½¦è¾†çŠ¶æ€ï¼‰è¿›è¡Œ**ååº”å¼**è‡ªé€‚åº”ã€‚<br>2. **æ¨¡å‹åŸºç¡€**ï¼šä½¿ç”¨æ ‡å‡†BLLï¼Œå™ªå£°ç»Ÿè®¡æ˜¯å›ºå®šçš„æˆ–éœ€å•ç‹¬ä¼°è®¡ã€‚<br>3. **ä¿¡æ¯åˆ©ç”¨**ï¼šé€‚åº”å‘ç”Ÿåœ¨è½¦è¾†**å·²ç»**ç»å†åŠ¨åŠ›å­¦å˜åŒ–ä¹‹åã€‚ | 1. **å‰ç»æ€§æ„ŸçŸ¥**ï¼šå¼•å…¥**è§†è§‰**ä½œä¸º**å¤–æ„Ÿå—**ä¿¡æ¯æºï¼Œå®ç°**å‰ç»æ€§**åŠ¨åŠ›å­¦é¢„æµ‹ä¸è°ƒæ•´ã€‚<br>2. **æ¨¡å‹å‡çº§**ï¼šé‡‡ç”¨**å˜åˆ†è´å¶æ–¯æœ€åä¸€å±‚ï¼ˆVBLLï¼‰**ï¼Œå¯è”åˆå­¦ä¹ æœ€åä¸€å±‚æƒé‡å’Œå™ªå£°ç»Ÿè®¡ï¼Œçµæ´»æ€§æ›´é«˜ã€‚<br>3. **è®­ç»ƒç­–ç•¥**ï¼šæå‡º**ä¸¤é˜¶æ®µå¾®è°ƒ**æµç¨‹ï¼Œåœ¨åŸºç¡€VBLLä¸Šå¢åŠ **FiLMè§†è§‰è°ƒèŠ‚è·¯å¾„**ï¼Œç”¨å°‘é‡æ¹¿æ»‘è·¯é¢æ•°æ®å®ç°æ¡ä»¶é¢„æµ‹ã€‚ |\n| **[15] Ding et al. (2024)** <br>â€œDrifting with unknown tires: learning vehicle models online with neural networks and model predictive controlâ€ | **ç¥ç»ç½‘ç»œåŠ¨åŠ›å­¦æ¨¡å‹** + åœ¨çº¿è‡ªé€‚åº”MPCã€‚ | åœ¨è½®èƒå‚æ•°æœªçŸ¥çš„æƒ…å†µä¸‹å®ç°æ¼‚ç§»ã€‚ä¸“æ³¨äºé€šè¿‡åœ¨çº¿æ•°æ®å¿«é€Ÿé€‚åº”æ–°çš„è½®èƒç‰¹æ€§ã€‚ | 1. **æ¨¡å‹ç±»å‹**ï¼šä½¿ç”¨ç¡®å®šæ€§ç¥ç»ç½‘ç»œï¼Œç¼ºä¹å¯¹é¢„æµ‹ä¸ç¡®å®šæ€§çš„é‡åŒ–ã€‚<br>2. **é€‚åº”æœºåˆ¶**ï¼šå®Œå…¨æ˜¯**åœ¨çº¿ã€ååº”å¼**çš„ï¼Œä¾èµ–è½¦è¾†åœ¨æ¼‚ç§»è¿‡ç¨‹ä¸­äº§ç”Ÿçš„æ•°æ®ã€‚ | 1. **è´å¶æ–¯æ¡†æ¶**ï¼šæä¾›**é«˜æ–¯é¢„æµ‹åéªŒ**ï¼Œé‡åŒ–ä¸ç¡®å®šæ€§ï¼Œå¯¹å®‰å…¨å…³é”®æ§åˆ¶æ›´é‡è¦ã€‚<br>2. **è§†è§‰æ¡ä»¶åŒ–**ï¼šåœ¨æ§åˆ¶æ‰§è¡Œ**å‰**ï¼Œåˆ©ç”¨è§†è§‰ä¿¡æ¯é¢„å…ˆè°ƒæ•´æ¨¡å‹ï¼Œå˜â€œé€‚åº”â€ä¸ºâ€œé¢„é€‚åº”â€ã€‚ |\n| **[17] Djeumou et al. (2024)** <br>â€œOne model to drift them all: physics-informed conditional diffusion model for driving at the limitsâ€ | **ç‰©ç†ä¿¡æ¯æ¡ä»¶æ‰©æ•£æ¨¡å‹**ã€‚åˆ©ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆé€‚åº”ä¸åŒåœºæ™¯çš„åŠ¨åŠ›å­¦æ¨¡å‹å‚æ•°ã€‚ | å®ç°å¤æ‚çš„æ¼‚ç§»åŠ¨ä½œã€‚æ¨¡å‹èƒ½æ ¹æ®é«˜çº§æŒ‡ä»¤ï¼ˆå¦‚â€œå·¦æ¼‚â€ï¼‰æ¡ä»¶åŒ–åœ°ç”Ÿæˆç›¸åº”åŠ¨åŠ›å­¦ã€‚ | 1. **æ¡ä»¶ä¿¡å·**ï¼šæ¡ä»¶åŒ–åŸºäº**é«˜çº§æŒ‡ä»¤**ï¼ˆå¦‚æ¼‚ç§»æ–¹å‘ï¼‰ï¼Œè€Œé**å®æ—¶ç¯å¢ƒæ„ŸçŸ¥**ã€‚<br>2. **è®¡ç®—æˆæœ¬**ï¼šæ‰©æ•£æ¨¡å‹æ¨ç†æˆæœ¬è¾ƒé«˜ï¼Œä¸åˆ©äºå®æ—¶æ§åˆ¶ã€‚<br>3. **æ•°æ®éœ€æ±‚**ï¼šå¯èƒ½éœ€è¦å¤§é‡å¤šæ ·åŒ–æ•°æ®è®­ç»ƒç”Ÿæˆæ¨¡å‹ã€‚ | 1. **å®æ—¶ç¯å¢ƒæ„ŸçŸ¥**ï¼šæ¡ä»¶åŒ–åŸºäº**å®æ—¶è§†è§‰åœºæ™¯**ï¼ˆæ°´å‘ï¼‰ï¼Œæ›´ç›´æ¥åº”å¯¹ç¯å¢ƒçªå˜ã€‚<br>2. **é«˜æ•ˆæ¨ç†**ï¼šVBLL+FiLMæ¶æ„è®¡ç®—è½»é‡ï¼Œé€‚åˆé›†æˆåˆ°å®æ—¶MPCä¸­ã€‚<br>3. **æ•°æ®æ•ˆç‡**ï¼šä¸¤é˜¶æ®µè®­ç»ƒåˆ©ç”¨ä¸°å¯Œçš„æ ‡ç§°æ•°æ®å’Œå°è§„æ¨¡æ¡ä»¶æ•°æ®ï¼Œæ›´å®ç”¨ã€‚ |\n| **[11, 32] Davydov et al. (2025), Levy et al. (2025)** <br>æ¶‰åŠBLL/VBLLåœ¨æ¼‚ç§»ã€è¶Šé‡ä¸­çš„åº”ç”¨ã€‚ | **BLL/VBLLæ¨¡å‹**ç”¨äºåŠ¨åŠ›å­¦å­¦ä¹ ä¸åœ¨çº¿å…ƒå­¦ä¹ é€‚åº”ã€‚ | åœ¨æ¼‚ç§»æˆ–è¶Šé‡ç­‰ä¸ç¡®å®šæ€§é«˜çš„åœºæ™¯ä¸­å­¦ä¹ å¹¶é€‚åº”åŠ¨åŠ›å­¦ã€‚ | 1. **åº”ç”¨ç„¦ç‚¹**ï¼šä¸“æ³¨äº**æœ¬ä½“æ„ŸçŸ¥**ä¸‹çš„åœ¨çº¿é€‚åº”æˆ–å…ƒå­¦ä¹ ï¼Œæœªé›†æˆå¤–æ„Ÿå—æ„ŸçŸ¥ã€‚<br>2. **æ³›åŒ–æ–¹å¼**ï¼šé€šè¿‡å…ˆéªŒæˆ–å…ƒå­¦ä¹ å¿«é€Ÿé€‚åº”æ–°è½¦è¾†/åœ°å½¢ï¼Œä½†éåŸºäºå®æ—¶è§†è§‰çš„é¢„è°ƒæ•´ã€‚ | 1. **å¤šæ¨¡æ€èåˆ**ï¼šé¦–æ¬¡å°†**è§†è§‰è¯­ä¹‰ä¿¡æ¯**ï¼ˆé€šè¿‡åˆ†å‰²ç½‘ç»œæå–ï¼‰ä¸**è´å¶æ–¯åŠ¨åŠ›å­¦æ¨¡å‹**æ·±åº¦èåˆã€‚<br>2. **æ§åˆ¶èŒƒå¼è½¬å˜**ï¼šä»â€œ**æ„ŸçŸ¥-é€‚åº”-æ§åˆ¶**â€å˜ä¸ºâ€œ**æ„ŸçŸ¥-é¢„æµ‹-é¢„æ§**â€ï¼Œåœ¨é‡åˆ°ä½æ‘©æ“¦åŒºåŸŸå‰å°±æå‰åˆ¹è½¦ã€æ”¶æ²¹ã€‚ |\n| **[25, 26] Harrison et al. (2024)** <br>â€œVariational Bayesian Last Layersâ€ | **å˜åˆ†è´å¶æ–¯æœ€åä¸€å±‚ï¼ˆVBLLï¼‰** ç†è®ºæ¡†æ¶ã€‚ | æå‡ºä¸€ç§è½»é‡çº§çš„è´å¶æ–¯ç¥ç»ç½‘ç»œå˜ä½“ï¼Œèƒ½æä¾›ä¸ç¡®å®šæ€§ä¼°è®¡ä¸”è®­ç»ƒé«˜æ•ˆã€‚ | 1. **é¢†åŸŸ**ï¼šè¿™æ˜¯**åŸºç¡€æ–¹æ³•è®º**è®ºæ–‡ï¼Œæœªåº”ç”¨äºå…·ä½“æœºå™¨äººæˆ–è½¦è¾†æ§åˆ¶é—®é¢˜ã€‚ | 1. **é¢†åŸŸé¦–æ¬¡åº”ç”¨**ï¼šæœ¬æ–‡æ˜¯**é¦–æ¬¡å°†VBLLæ¨¡å‹åº”ç”¨äºåŠ¨åŠ›å­¦å­¦ä¹ **ï¼Œå¹¶ä¸ºå…¶å¢åŠ äº†**è§†è§‰æ¡ä»¶åŒ–**èƒ½åŠ›ï¼Œæ‹“å±•äº†VBLLçš„åº”ç”¨è¾¹ç•Œã€‚ |\n\n### æ€»ç»“ï¼šæœ¬æ–‡ç›¸å¯¹äºå‰ä½œçš„æ ¸å¿ƒæ”¹åŠ¨ä¸æå‡\n\n1.  **ä»ååº”å¼åˆ°å‰ç»å¼çš„æ ¹æœ¬æ€§è½¬å˜**ï¼š\n    *   **å‰ä½œå±€é™**ï¼šæ‰€æœ‰åŸºäºå­¦ä¹ çš„è‡ªé€‚åº”æ–¹æ³•ï¼ˆ[12], [15], [48]ï¼‰æœ¬è´¨éƒ½æ˜¯**ååº”å¼**çš„ã€‚æ¨¡å‹éœ€è¦åœ¨è½¦è¾†**å·²ç»**é©¶å…¥ä½æ‘©æ“¦åŒºåŸŸã€åŠ¨åŠ›å­¦å‘ç”Ÿæ”¹å˜åï¼Œæ‰èƒ½æ”¶é›†æ•°æ®å¹¶æ›´æ–°æ¨¡å‹ï¼Œè¿™åœ¨æé™é©¾é©¶ä¸­å¾€å¾€ä¸ºæ—¶å·²æ™šã€‚\n    *   **æœ¬æ–‡åˆ›æ–°**ï¼šé€šè¿‡**è§†è§‰æ¡ä»¶åŒ–**ï¼Œæ¨¡å‹èƒ½â€œçœ‹åˆ°â€å‰æ–¹çš„æ°´å‘ï¼Œå¹¶**æå‰**è°ƒæ•´å…¶åŠ¨åŠ›å­¦é¢„æµ‹ã€‚è¿™ä½¿å¾—æ§åˆ¶å™¨èƒ½**ä¸»åŠ¨åœ°**åœ¨æ¥è§¦æ°´å‘å‰é‡‡å–ä¿å®ˆåŠ¨ä½œï¼ˆå¦‚æå‰åˆ¶åŠ¨ï¼‰ï¼Œå®ç°äº†**å‰ç»æ€§æ§åˆ¶**ã€‚\n\n2.  **ä»å•ä¸€æ¨¡æ€åˆ°å¤šæ¨¡æ€æ„ŸçŸ¥çš„èåˆ**ï¼š\n    *   **å‰ä½œå±€é™**ï¼šæ¨¡å‹è¾“å…¥ä»…åŒ…å«è½¦è¾†çŠ¶æ€å’Œæ“æ§æŒ‡ä»¤ï¼ˆ**æœ¬ä½“æ„ŸçŸ¥**ï¼‰ï¼Œæ˜¯â€œç›²ç›®çš„â€ã€‚\n    *   **æœ¬æ–‡åˆ›æ–°**ï¼šåˆ›æ–°æ€§åœ°å°†**è§†è§‰è¯­ä¹‰ä¿¡æ¯**ï¼ˆé€šè¿‡SegMANåˆ†å‰²ç½‘ç»œæå–çš„â€œæ°´åˆ†æ•°â€ï¼‰ä½œä¸ºæ¡ä»¶ä¿¡å·ï¼Œé€šè¿‡**FiLMå±‚**è°ƒåˆ¶VBLLæ¨¡å‹çš„ç‰¹å¾ã€‚è¿™æ˜¯å°†é«˜ç»´è§†è§‰ä¿¡æ¯æœ‰æ•ˆæ³¨å…¥ä½ç»´åŠ¨åŠ›å­¦æ¨¡å‹çš„ç²¾å·§è®¾è®¡ã€‚\n\n3.  **æ¨¡å‹æ¶æ„ä¸è®­ç»ƒç­–ç•¥çš„é’ˆå¯¹æ€§æ”¹è¿›**ï¼š\n    *   **æ¨¡å‹åŸºç¡€**ï¼šé‡‡ç”¨æ¯”BLLæ›´çµæ´»çš„**VBLL**ä½œä¸ºåŸºç¡€åŠ¨åŠ›å­¦å­¦ä¹ å™¨ã€‚\n    *   **è®­ç»ƒæµç¨‹**ï¼šè®¾è®¡äº†**ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥**ï¼š1) ç”¨å¤§é‡å¹²åœ°æ•°æ®è®­ç»ƒåŸºç¡€VBLLï¼›2) ç”¨å°‘é‡åŒ…å«æ°´å‘çš„æ•°æ®ï¼Œ**å†»ç»“åŸºç¡€VBLLä¸»å¹²**ï¼Œä»…è®­ç»ƒ**FiLMè°ƒèŠ‚è·¯å¾„**ï¼ˆLSTM+çº¿æ€§å±‚ï¼‰ã€‚è¿™è§£å†³äº†æ¹¿æ»‘è·¯é¢æ•°æ®ç¨€ç¼ºçš„éš¾é¢˜ï¼Œå¹¶é˜²æ­¢äº†ç¾éš¾æ€§é—å¿˜ã€‚\n    *   **é›†æˆæ–¹å¼**ï¼šå°†å­¦ä¹ åˆ°çš„æ¡ä»¶åŠ¨åŠ›å­¦æ¨¡å‹æ— ç¼é›†æˆåˆ°**æ—¶é—´æœ€ä¼˜çš„MPCæ¡†æ¶**ä¸­ï¼Œå®Œæˆäº†ä»æ„ŸçŸ¥åˆ°æœ€ä¼˜æ§åˆ¶çš„å®Œæ•´é—­ç¯ã€‚\n\n4.  **å®è¯æ•ˆæœçš„é£è·ƒ**ï¼š\n    *   **å‰ä½œç»“æœ**ï¼šåœ¨é‡åˆ°æ°´å‘æ—¶ï¼Œå³ä½¿æœ‰åœ¨çº¿è‡ªé€‚åº”çš„æ¨¡å‹ä¹Ÿä¼šå¤±æ§ã€‚\n    *   **æœ¬æ–‡ç»“æœ**ï¼š**VcVBLL**åœ¨çœŸå®è½¦è¾†æµ‹è¯•ä¸­æˆåŠŸå®Œæˆäº†**12/12åœˆ**é€šè¿‡æ°´å‘çš„æµ‹è¯•ï¼Œè€Œæ‰€æœ‰æ— è§†è§‰æ¡ä»¶çš„åŸºçº¿æ¨¡å‹**å…¨éƒ¨å¤±æ§**ã€‚è¿™ä»¥æœ€ç›´è§‚çš„æ–¹å¼è¯æ˜äº†è§†è§‰æ¡ä»¶åŒ–å¯¹äºåœ¨çªå˜ç¯å¢ƒä¸‹å®ç°é²æ£’ã€é«˜æ€§èƒ½è‡ªä¸»é©¾é©¶çš„**å…³é”®æ€§ä½œç”¨**ã€‚\n\n**ç»“è®º**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒè¿›æ­¥åœ¨äºï¼Œé€šè¿‡**è§†è§‰æ¡ä»¶åŒ–çš„VBLLæ¨¡å‹**ï¼Œå°†**ç¯å¢ƒä¸Šä¸‹æ–‡æ„ŸçŸ¥**ä¸**è´å¶æ–¯åŠ¨åŠ›å­¦å­¦ä¹ **ç›¸ç»“åˆï¼Œå®ç°äº†ä»â€œ**äº‹åé€‚åº”**â€åˆ°â€œ**äº‹å‰é¢„æµ‹**â€çš„èŒƒå¼è½¬æ¢ï¼Œè§£å†³äº†åœ¨å¿«é€Ÿå˜åŒ–ç¯å¢ƒä¸‹ä¼ ç»Ÿè‡ªé€‚åº”æ–¹æ³•è¿‡äºè¿Ÿç¼“çš„æ ¹æœ¬é—®é¢˜ã€‚",
            "timestamp": "2026-01-20T17:59:29.385619",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "è®ºæ–‡æå‡ºäº†å“ªäº›å…³é”®æŠ€æœ¯æ–¹æ³•ï¼Œè¯·åˆ—è¡¨æ ¼å…·ä½“è¯¦ç»†è¯´æ˜æŠ€æœ¯ç»†èŠ‚ï¼Œéœ€è¦åŒ…å«å…·ä½“çš„æ•°å­¦åŸç†æ¨å¯¼ï¼Œä»¥åŠå…·ä½“å‚æ•°ã€‚",
            "answer": "## è®ºæ–‡å…³é”®æŠ€æœ¯æ–¹æ³•åˆ†æ\n\næœ¬æ–‡æå‡ºäº†ä¸€ç§**è§†è§‰æ¡ä»¶åŒ–å˜åˆ†è´å¶æ–¯æœ€åä¸€å±‚ï¼ˆVision-Conditioned Variational Bayesian Last Layer, VcVBLLï¼‰åŠ¨åŠ›å­¦æ¨¡å‹**ï¼Œæ—¨åœ¨é€šè¿‡è§†è§‰ä¿¡æ¯å®ç°è‡ªåŠ¨é©¾é©¶èµ›è½¦åœ¨è·¯é¢æ¡ä»¶çªå˜ï¼ˆå¦‚ç§¯æ°´ï¼‰ä¸‹çš„**å‰ç»æ€§ï¼ˆproactiveï¼‰æ§åˆ¶**ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†è§†è§‰è¯­ä¹‰ä¿¡æ¯ä½œä¸ºæ¡ä»¶ï¼ŒåŠ¨æ€è°ƒåˆ¶ä¸€ä¸ªè´å¶æ–¯åŠ¨åŠ›å­¦æ¨¡å‹çš„å†…éƒ¨ç‰¹å¾ï¼Œä»è€Œåœ¨æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆMPCï¼‰æ¡†æ¶å†…å®ç°åŸºäºç¯å¢ƒæ„ŸçŸ¥çš„é¢„é€‚åº”ã€‚\n\nä»¥ä¸‹è¡¨æ ¼è¯¦ç»†è¯´æ˜äº†è®ºæ–‡æå‡ºçš„å…³é”®æŠ€æœ¯æ–¹æ³•åŠå…¶ç»†èŠ‚ï¼š\n\n| æŠ€æœ¯æ¨¡å— | æ ¸å¿ƒæ€æƒ³ | å…·ä½“æŠ€æœ¯ç»†èŠ‚ä¸æ•°å­¦åŸç† | å…³é”®å‚æ•°ä¸å®ç° |\n| :--- | :--- | :--- | :--- |\n| **1. åŸºç¡€VBLLåŠ¨åŠ›å­¦æ¨¡å‹** | ä½¿ç”¨**å˜åˆ†è´å¶æ–¯æœ€åä¸€å±‚**ç½‘ç»œä½œä¸ºè½»é‡çº§ã€å¯æä¾›é¢„æµ‹ä¸ç¡®å®šæ€§çš„åŠ¨åŠ›å­¦æ¨¡å‹ã€‚å®ƒå­¦ä¹ çŠ¶æ€å·®åˆ†è€Œéç»å¯¹çŠ¶æ€ï¼Œæå‡æ•°å€¼ç¨³å®šæ€§ã€‚ | **1.1 æ¨¡å‹æ¶æ„ï¼š** <br> é¢„æµ‹æ¨¡å‹ä¸ºï¼š`Î”x_t = f_Î¸(z_t) = Ï†_Î¸(z_t)^T W` <br> å…¶ä¸­ï¼š <br> - `z_t = [x_{1,t}, u_t, u_{t+Î”t}] âˆˆ R^{n_z}` ä¸ºè¾“å…¥ï¼ˆçŠ¶æ€+å½“å‰åŠä¸‹ä¸€æ—¶åˆ»æ§åˆ¶ï¼‰ã€‚ <br> - `Ï†_Î¸: R^{n_z} â†’ R^{n_w}` ä¸ºç¥ç»ç½‘ç»œéª¨å¹²ï¼ˆç‰¹å¾æå–å™¨ï¼‰ã€‚ <br> - `W = [w_1, ..., w_d]` ä¸ºæœ€åä¸€å±‚æƒé‡çŸ©é˜µï¼Œæ¯ä¸ªè¾“å‡ºç»´åº¦ `i` å¯¹åº”ä¸€ä¸ªé«˜æ–¯éšæœºå˜é‡ `w_i ~ N(m_i, S_i)`ã€‚ <br><br> **1.2 æµ‹é‡æ¨¡å‹ä¸å˜åˆ†æ¨æ–­ï¼š** <br> å‡è®¾è§‚æµ‹å™ªå£°ï¼š`y_t = f_Î¸(z_t) + Îµ_t`, `Îµ_t ~ N(0, Î£)`, `Î£ = diag(Î£_1, ..., Î£_d)`ã€‚ <br> ä¸ºæƒé‡ `w_i` å’Œå™ªå£°æ–¹å·® `Î£_i` å®šä¹‰å˜åˆ†åéªŒ `q` å’Œå…ˆéªŒ `p`ï¼š <br> - åéªŒï¼š`q(w_i) = N(w_i; m_i, S_i)`, `S_i = L_i L_i^T`, `L_i = N_i + diag(exp(d_i))`ï¼ˆç¡®ä¿æ­£å®šï¼‰ã€‚ <br> - å…ˆéªŒï¼š`p(w_i) = N(w_i; 0, Î¾_i^âˆ˜ I)`, `p(Î£_i) = IG(Î£_i; Î±_i^âˆ˜, Î²_i^âˆ˜)`ã€‚ <br> - éª¨å¹²ç½‘ç»œå‚æ•°å…ˆéªŒï¼š`p(Î¸) = N(Î¸; 0, Î³^âˆ˜ I)`ã€‚ <br><br> **1.3 æŸå¤±å‡½æ•°ï¼š** <br> æœ€å¤§åŒ–è¯æ®ä¸‹ç•Œï¼ˆELBOï¼‰ï¼ŒæŸå¤±å‡½æ•°ä¸ºè´ŸELBOåŠ æ­£åˆ™é¡¹ï¼š <br> `L(Î·, Î¸) = -L_ELL(Î·, Î¸) + Î»_reg * R(Î·, Î¸)` <br> å…¶ä¸­ï¼š <br> - `L_ELL` ä¸ºæœŸæœ›å¯¹æ•°ä¼¼ç„¶ä¸‹ç•Œï¼ˆå¼12ï¼‰ï¼ŒåŒ…å«æ•°æ®æ‹Ÿåˆé¡¹å’Œç”±äºæƒé‡ä¸ç¡®å®šæ€§å¼•èµ·çš„æ–¹å·®æƒ©ç½šé¡¹ã€‚ <br> - `R` ä¸ºæ­£åˆ™é¡¹ï¼ˆå¼13ï¼‰ï¼Œæ˜¯å˜åˆ†åéªŒä¸å…ˆéªŒä¹‹é—´çš„è´ŸKLæ•£åº¦ï¼Œç”¨äºç¨³å®šè®­ç»ƒã€‚ <br> - `Î· = {m_i, N_i, d_i, Î£_i}_{i=1}^d` ä¸ºVBLLå¤´çš„å¯å­¦ä¹ å‚æ•°ã€‚ | **éª¨å¹²ç½‘ç»œï¼š** 4å±‚MLPï¼Œæ¯å±‚64ä¸ªç¥ç»å…ƒï¼Œæ¿€æ´»å‡½æ•°ä¸ºELUã€‚ <br> **å…ˆéªŒå‚æ•°ï¼š** `Î¾_i^âˆ˜ = 1`, `Î±_i^âˆ˜ = 0.5`, `Î²_i^âˆ˜ = 0.005`ã€‚ <br> **è®­ç»ƒï¼š** ä½¿ç”¨AdamWä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡ `5e-4`ï¼Œæƒé‡è¡°å‡ `1e-4`ï¼Œæ¢¯åº¦è£å‰ªä¸º1ï¼Œæ‰¹é‡å¤§å°1028ï¼Œè®­ç»ƒ5000è½®ã€‚ <br> **æ­£åˆ™åŒ–å¼ºåº¦ï¼š** `Î»_reg = 10`ã€‚ <br> **è¾“å…¥/è¾“å‡ºï¼š** æ‰€æœ‰ç‰¹å¾è¿›è¡Œæ ‡å‡†åŒ–ï¼ˆé›¶å‡å€¼ã€å•ä½æ–¹å·®ï¼‰ã€‚ |\n| **2. è§†è§‰ä¸Šä¸‹æ–‡æå–** | ä½¿ç”¨è¯­ä¹‰åˆ†å‰²æ¨¡å‹ä»å‰ç½®æ‘„åƒå¤´å›¾åƒä¸­æå–**è·¯é¢è¯­ä¹‰ä¿¡æ¯**ï¼ˆå¦‚æ°´ã€æ²¥é’ï¼‰ï¼Œå¹¶è®¡ç®—ä¸€ä¸ªæ—¶é—´åºåˆ—çš„**æ°´å­˜åœ¨åˆ†æ•°**ä½œä¸ºä¸Šä¸‹æ–‡ã€‚ | **2.1 è¯­ä¹‰åˆ†å‰²ï¼š** <br> ä½¿ç”¨ **SegMAN-t** æ¨¡å‹åœ¨Gooseæ•°æ®é›†ä¸Šé¢„è®­ç»ƒï¼Œå¹¶åœ¨å®éªŒåœºåœ°500å¼ æ‰‹åŠ¨æ ‡æ³¨å›¾åƒä¸Šå¾®è°ƒã€‚è¾“å‡ºåˆ†å‰²å›¾ `Ã_k âˆˆ {1,...,64}^{WÃ—H}`ï¼ŒåŒ…å«64ä¸ªè¯­ä¹‰ç±»åˆ«ã€‚ <br><br> **2.2 ç©ºé—´åŠ æƒä¸æ°´åˆ†æ•°è®¡ç®—ï¼š** <br> ä¸ºèšç„¦è½¦è¾†å‰æ–¹åŒºåŸŸï¼Œå®šä¹‰äºŒç»´é«˜æ–¯æƒé‡æ©ç ï¼ˆå¼17ï¼‰ï¼š <br> `w(h,w) = exp(-[(h-Î¼_h)^2/(2Ïƒ_h^2) + (w-Î¼_w)^2/(2Ïƒ_w^2)])` <br> åŸºäºåˆ†å‰²ç»“æœå’Œæƒé‡ï¼Œè®¡ç®—æ°´åˆ†æ•° `Ï_t`ï¼ˆå¼18ï¼‰ï¼š <br> `Ï_t = (Î£_{Î©} w(h,w) * 1{Ã_k = c_w}) / (Î£_{Î©} w(h,w) * [1{Ã_k = c_w} + 1{Ã_k = c_a}])` <br> å…¶ä¸­ `c_w` å’Œ `c_a` åˆ†åˆ«ä»£è¡¨æ°´å’Œæ²¥é’çš„ç±»åˆ«æ ‡ç­¾ï¼Œ`Î©` ä¸ºéé®æŒ¡ä¸”æƒé‡éé›¶çš„åƒç´ é›†åˆã€‚ <br><br> **2.3 ä¸Šä¸‹æ–‡å‘é‡ï¼š** <br> ä¸Šä¸‹æ–‡ `c_t` å®šä¹‰ä¸ºè¿‡å»ä¸€æ®µæ—¶é—´ï¼ˆæ–‡ä¸­ä¸º2ç§’ï¼‰çš„æ°´åˆ†æ•°åºåˆ—ï¼š`c_t = (Ï_{t-N}, ..., Ï_t)`ã€‚ | **åˆ†å‰²æ¨¡å‹ï¼š** SegMAN-t (Tinyç‰ˆæœ¬)ã€‚ <br> **å›¾åƒå°ºå¯¸ï¼š** `(W, H) = (1440, 928)`ã€‚ <br> **é«˜æ–¯æ©ç å‚æ•°ï¼š** `Î¼_h, Î¼_w` è®¾å®šåœ¨å›¾åƒä¸‹æ–¹ä¸­å¤®ï¼ˆé“è·¯åŒºåŸŸï¼‰ï¼Œ`Ïƒ_h, Ïƒ_w` æ§åˆ¶å…³æ³¨åŒºåŸŸå¤§å°ï¼ˆæ–‡ä¸­æœªç»™å‡ºå…·ä½“å€¼ï¼Œéœ€æ ¹æ®ç›¸æœºæ ‡å®šå’Œåœºæ™¯è®¾å®šï¼‰ã€‚ <br> **ä¸Šä¸‹æ–‡é•¿åº¦ï¼š** å¯¹åº”2ç§’çš„å†å²æ•°æ®ï¼Œå…·ä½“ `N` å–å†³äºé‡‡æ ·é¢‘ç‡ï¼ˆ~30Hzï¼‰ã€‚ |\n| **3. åŸºäºFiLMçš„è§†è§‰æ¡ä»¶åŒ–** | é€šè¿‡ **Feature-wise Linear Modulation (FiLM)** æœºåˆ¶ï¼Œå°†è§†è§‰ä¸Šä¸‹æ–‡ç¼–ç ä¸ºä»¿å°„å˜æ¢å‚æ•°ï¼ŒåŠ¨æ€è°ƒåˆ¶VBLLéª¨å¹²ç½‘ç»œçš„ç‰¹å¾ï¼Œå®ç°ç¯å¢ƒè‡ªé€‚åº”çš„åŠ¨åŠ›å­¦é¢„æµ‹ã€‚ | **3.1 ä¸Šä¸‹æ–‡ç¼–ç ï¼š** <br> ä½¿ç”¨LSTMç½‘ç»œ `g_Ïˆ` å°†æ—¶é—´åºåˆ—ä¸Šä¸‹æ–‡ `c_t` ç¼–ç ä¸ºè°ƒåˆ¶å‚æ•°ï¼ˆå¼19ï¼‰ï¼š <br> `(Î³_Ïˆ(c_t), Î²_Ïˆ(c_t)) = g_Ïˆ(c_t)` <br> å…¶ä¸­ `Î³` (ç¼©æ”¾) å’Œ `Î²` (å¹³ç§») çš„ç»´åº¦ä¸éª¨å¹²ç‰¹å¾ `Ï†_Î¸(z_t)` ç›¸åŒã€‚ <br><br> **3.2 ç‰¹å¾è°ƒåˆ¶ï¼ˆå¼20ï¼‰ï¼š** <br> å¯¹éª¨å¹²ç½‘ç»œæå–çš„ç‰¹å¾è¿›è¡Œé€å…ƒç´ ä»¿å°„å˜æ¢ï¼š <br> `Ï†Ìƒ_t = Ï†_{Î¸,Ïˆ}^{FiLM}(z_t, c_t) = Ï†_Î¸(z_t) âŠ™ Î³_Ïˆ(c_t) + Î²_Ïˆ(c_t)` <br> å…¶ä¸­ `âŠ™` è¡¨ç¤ºé€å…ƒç´ ç›¸ä¹˜ã€‚è°ƒåˆ¶åçš„ç‰¹å¾ `Ï†Ìƒ_t` å†è¾“å…¥åˆ°VBLLæœ€åä¸€å±‚è¿›è¡Œé¢„æµ‹ã€‚ <br><br> **3.3 æ¡ä»¶åŒ–åéªŒé¢„æµ‹ï¼ˆå¼21ï¼‰ï¼š** <br> çŠ¶æ€å·®åˆ†çš„é¢„æµ‹åˆ†å¸ƒå˜ä¸ºä»¥ `c_t` ä¸ºæ¡ä»¶ï¼š <br> `Î”x_{t+1,i} | z_t, c_t ~ N( Ï†Ìƒ_t^T m_i, Ï†Ìƒ_t^T S_i Ï†Ìƒ_t + Î£_i )` | **LSTMç½‘ç»œï¼š** éšçŠ¶æ€ç»´åº¦ä¸º16ï¼Œåæ¥çº¿æ€§å±‚è¾“å‡ºFiLMå‚æ•°ã€‚ <br> **è®­ç»ƒç­–ç•¥ï¼š** ä¸¤é˜¶æ®µè®­ç»ƒã€‚å…ˆè®­ç»ƒåŸºç¡€VBLLï¼ˆç»¿è‰²è·¯å¾„ï¼‰ï¼Œç„¶å**å†»ç»“åŸºç¡€VBLLçš„éª¨å¹²å’Œå¤´**ï¼Œä»…ç”¨**æœ‰é™æ¹¿æ»‘è·¯é¢æ•°æ®**è®­ç»ƒFiLMè·¯å¾„ï¼ˆLSTMå‚æ•° `Ïˆ`ï¼Œæ©™è‰²è·¯å¾„ï¼‰ã€‚ä¸ºé˜²æ­¢ç¾éš¾æ€§é—å¿˜ï¼Œåœ¨å¾®è°ƒæŸå¤±ä¸­åŠ å…¥**L2-SPæ­£åˆ™åŒ–**ï¼ˆå¼22ï¼‰ï¼Œæƒ©ç½šéª¨å¹²å‚æ•° `Î¸` åç¦»åˆå§‹å€¼ `Î¸_init`ï¼š`Î»_L2-SP * ||Î¸ - Î¸_init||_2^2`ã€‚ <br> **å¾®è°ƒå‚æ•°ï¼š** å­¦ä¹ ç‡ `1e-4`ï¼Œ`Î»_L2-SP = 10`ï¼Œè®­ç»ƒ1000è½®ã€‚ |\n| **4. é›†æˆè‡³æ¨¡å‹é¢„æµ‹æ§åˆ¶** | å°†å­¦ä¹ åˆ°çš„ **VcVBLL** åŠ¨åŠ›å­¦æ¨¡å‹ä½œä¸ºçº¦æŸï¼ŒåµŒå…¥ä¸€ä¸ª**æœ€å°æ—¶é—´MPC**æ¡†æ¶ä¸­ï¼Œå®ç°åŸºäºè§†è§‰å‰ç»ä¿¡æ¯çš„æœ€ä¼˜æ§åˆ¶ã€‚ | **4.1 åŠ¨åŠ›å­¦é›†æˆï¼š** <br> å°†VBLLé¢„æµ‹çš„MAPä¼°è®¡ï¼ˆ",
            "timestamp": "2026-01-20T18:00:32.991213",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "ä»–ä½¿ç”¨äº†å“ªäº›è¯„ä»·æŒ‡æ ‡ä¸æ•°æ®é›†ï¼Œåˆ—è¡¨æ ¼å…·ä½“è®²è®²ä»–çš„è¯„ä»·æŒ‡æ ‡çš„ç»†èŠ‚ä¸æ•°æ®é›†çš„ç»†èŠ‚",
            "answer": "## è®ºæ–‡è¯„ä»·æŒ‡æ ‡ä¸æ•°æ®é›†åˆ†æ\n\n### ä¸€ã€ è¯„ä»·æŒ‡æ ‡\n\nè¯¥è®ºæ–‡ä¸»è¦é‡‡ç”¨**ç¡¬ä»¶å®éªŒçš„æˆåŠŸç‡**ä½œä¸ºæ ¸å¿ƒè¯„ä»·æŒ‡æ ‡ï¼Œè¾…ä»¥**å®šæ€§åˆ†æ**å’Œ**å¯¹æ¯”å®éªŒ**ã€‚è®ºæ–‡æœªä½¿ç”¨ä¼ ç»Ÿçš„ç¦»çº¿å›å½’æŒ‡æ ‡ï¼ˆå¦‚MSEã€MAEï¼‰ï¼Œè€Œæ˜¯ç›´æ¥é€šè¿‡é—­ç¯æ§åˆ¶æ€§èƒ½æ¥éªŒè¯æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚\n\n| è¯„ä»·æŒ‡æ ‡ç±»åˆ« | å…·ä½“æŒ‡æ ‡ | ç»†èŠ‚æè¿° |\n| :--- | :--- | :--- |\n| **ä¸»è¦æ€§èƒ½æŒ‡æ ‡** | **å®Œæˆåœˆæ•°/æˆåŠŸç‡** | åœ¨åŒ…å«æ°´å‘çš„èµ›é“ä¸Šï¼Œæ§åˆ¶å™¨èƒ½å¦æˆåŠŸå®Œæˆå•åœˆæˆ–å¤šåœˆè¡Œé©¶è€Œä¸å¤±æ§ï¼ˆå¦‚æ‰“æ»‘ã€spin outï¼‰ã€‚è¿™æ˜¯è®ºæ–‡æœ€æ ¸å¿ƒçš„â€œé€šè¿‡/å¤±è´¥â€äºŒå…ƒæŒ‡æ ‡ã€‚ |\n| | **å•åœˆæ—¶é—´** | åœ¨å¹²ç‡¥èµ›é“ä¸Šï¼Œå¯¹æ¯”ä¸åŒåŠ¨åŠ›å­¦æ¨¡å‹ï¼ˆç‰©ç†æ¨¡å‹ã€VBLLã€VcVBLLï¼‰æ§åˆ¶ä¸‹çš„æœ€å¿«å•åœˆæ—¶é—´ï¼Œç”¨äºè¯æ˜å­¦ä¹ æ¨¡å‹åœ¨æé™æ€§èƒ½ä¸Šä¼˜äºä¼ ç»Ÿæ¨¡å‹ã€‚ |\n| **æ¨¡å‹é¢„æµ‹åˆ†æ** | **åéªŒé¢„æµ‹åˆ†å¸ƒå¯è§†åŒ–** | å¦‚å›¾4æ‰€ç¤ºï¼Œé€šè¿‡ç»˜åˆ¶ç»™å®šä¸åŒè§†è§‰ä¸Šä¸‹æ–‡ï¼ˆå¹²/æ¹¿ï¼‰æ—¶ï¼Œæ¨¡å‹å¯¹å…³é”®çŠ¶æ€ï¼ˆå¦‚è½¦è½®é€Ÿåº¦ã€ä¾§æ»‘è§’ï¼‰çš„åéªŒé¢„æµ‹åˆ†å¸ƒï¼ˆå‡å€¼å’Œä¸ç¡®å®šæ€§ï¼‰ï¼Œ**å®šæ€§**å±•ç¤ºè§†è§‰æ¡ä»¶å¦‚ä½•æ”¹å˜æ¨¡å‹çš„é¢„æµ‹è¡Œä¸ºï¼Œä½¿å…¶ç¬¦åˆç‰©ç†ç›´è§‰ï¼ˆæ¹¿è·¯é¢é¢„æµ‹æ›´å¤šæ‰“æ»‘å’Œä¸ç¡®å®šæ€§ï¼‰ã€‚ |\n| **å¯¹æ¯”å®éªŒåŸºçº¿** | **ä¸åŒæ¨¡å‹/é…ç½®çš„å¯¹æ¯”** | é€šè¿‡è®¾ç½®å¤šä¸ªåŸºçº¿æ¨¡å‹ï¼Œåœ¨ç›¸åŒå®éªŒæ¡ä»¶ä¸‹è¿›è¡Œå¯¹æ¯”ï¼Œç›´è§‚å±•ç¤ºè§†è§‰æ¡ä»¶åŒ–çš„å¿…è¦æ€§ï¼š<br>1. **VBLL (æ— è§†è§‰)**ï¼šä»…ä½¿ç”¨æœ¬ä½“æ„ŸçŸ¥æ•°æ®çš„åŸºæœ¬æ¨¡å‹ã€‚<br>2. **VBLL + RLS (æ— è§†è§‰)**ï¼šå¸¦é€’å½’æœ€å°äºŒä¹˜åœ¨çº¿é€‚åº”çš„VBLLæ¨¡å‹ã€‚<br>3. **VcVBLL (å¿½ç•¥ä¸Šä¸‹æ–‡)**ï¼šä½¿ç”¨VcVBLLæ¨¡å‹ä½†å¼ºåˆ¶è§†è§‰ä¸Šä¸‹æ–‡ä¸ºé›¶ã€‚<br>4. **VcVBLL (ä½¿ç”¨ä¸Šä¸‹æ–‡)**ï¼šå®Œæ•´çš„æ‰€ææ–¹æ³•ã€‚ |\n| **é²æ£’æ€§éªŒè¯** | **è·¨æ¡ä»¶å®éªŒæˆåŠŸç‡** | åœ¨ä¸åŒæ—¥æœŸï¼ˆå…‰ç…§æ¡ä»¶å˜åŒ–ï¼‰ã€ä¸åŒè½®èƒã€ä¸åŒç¯å¢ƒæ¸©åº¦ä¸‹é‡å¤å®éªŒï¼Œç»Ÿè®¡VcVBLLæ¨¡å‹åœ¨æ‰€æœ‰è¿™äº›æ¡ä»¶ä¸‹çš„æˆåŠŸç‡ï¼Œè¯æ˜å…¶é²æ£’æ€§ã€‚ |\n\n**æ€»ç»“**ï¼šè®ºæ–‡çš„è¯„ä»·ä½“ç³»ç´§å¯†å›´ç»•**å®é™…ç¡¬ä»¶éƒ¨ç½²çš„æˆåŠŸç‡**æ„å»ºï¼Œè¿™æ˜¯ä¸€ç§é¢å‘æœ€ç»ˆä»»åŠ¡æ€§èƒ½çš„ã€é«˜ç½®ä¿¡åº¦çš„è¯„ä¼°æ–¹å¼ï¼Œç›´æ¥è¯æ˜äº†æ–¹æ³•åœ¨çœŸå®ä¸–ç•Œé«˜é£é™©åœºæ™¯ï¼ˆé«˜é€Ÿè¿‡æ°´å‘ï¼‰ä¸­çš„æœ‰æ•ˆæ€§ã€‚\n\n### äºŒã€ æ•°æ®é›†\n\nè®ºæ–‡ä½¿ç”¨äº†ä¸¤ä¸ªè‡ªæ”¶é›†çš„**ä¸“æœ‰æ•°æ®é›†**ï¼Œåˆ†åˆ«ç”¨äºè®­ç»ƒåŸºç¡€æ¨¡å‹å’Œå¾®è°ƒè§†è§‰æ¡ä»¶åŒ–æ¨¡å—ã€‚æ‰€æœ‰æ•°æ®å‡æ¥è‡ªå®è½¦ï¼ˆLexus LC500ï¼‰é‡‡é›†ã€‚\n\n| æ•°æ®é›†åç§° | æ•°æ®å†…å®¹ä¸è§„æ¨¡ | é‡‡é›†ç»†èŠ‚ä¸ç”¨é€” |\n| :--- | :--- | :--- |\n| **åä¹‰ï¼ˆå¹²ç‡¥ï¼‰æ•°æ®é›†** | **æ ·æœ¬æ•°**: 12,229 ä¸ª `(çŠ¶æ€, æ§åˆ¶è¾“å…¥, çŠ¶æ€å·®åˆ†)` æ ·æœ¬å¯¹ã€‚<br>**çŠ¶æ€**: \\( \\boldsymbol{x}_1 = (r, v, \\beta, \\omega_r) \\) (æ¨ªæ‘†ç‡ã€çºµå‘é€Ÿåº¦ã€ä¾§æ»‘è§’ã€åè½®è½¬é€Ÿ)ã€‚<br>**æ§åˆ¶è¾“å…¥**: \\( \\boldsymbol{u} = (\\delta, \\tau_{\\text{combined}}, \\tau_f) \\) (è½¬å‘è§’ã€ç»¼åˆåè½´æ‰­çŸ©ã€å‰è½´åˆ¶åŠ¨æ‰­çŸ©)ã€‚<br>**ç›®æ ‡**: ä¸‹ä¸€æ—¶é—´æ­¥çš„çŠ¶æ€å·®åˆ† \\( \\Delta\\boldsymbol{x}_t \\)ã€‚ | **é‡‡é›†æ–¹å¼**: ç”±ä¸“ä¸šè½¦æ‰‹åœ¨å¹²ç‡¥çš„åœ†å½¢è¯•è½¦åœºï¼ˆskidpadï¼‰ä¸Šè¿›è¡Œ**æ¿€è¿›é©¾é©¶**ï¼Œä»¥æ¿€å‘è½¦è¾†åœ¨å¹²ç‡¥æ¡ä»¶ä¸‹çš„å…¨éƒ¨éçº¿æ€§åŠ¨åŠ›å­¦ç‰¹æ€§ã€‚<br>**ç”¨é€”**: ç”¨äºè®­ç»ƒ**åŸºç¡€VBLLåŠ¨åŠ›å­¦æ¨¡å‹**ï¼ˆå›¾3ä¸­çš„ç»¿è‰²è·¯å¾„ï¼‰ï¼Œå­¦ä¹ è½¦è¾†åœ¨æ­£å¸¸ï¼ˆé«˜æ‘©æ“¦ï¼‰è·¯é¢ä¸‹çš„é€šç”¨åŠ¨åŠ›å­¦å…ˆéªŒã€‚ |\n| **å¾®è°ƒï¼ˆæ¹¿æ»‘ï¼‰æ•°æ®é›†** | **æ ·æœ¬æ•°**: 6,349 ä¸ªæ ·æœ¬å¯¹ï¼ˆæ ¼å¼åŒå¹²ç‡¥æ•°æ®é›†ï¼‰ã€‚<br>**å…³é”®å­é›†**: å…¶ä¸­ä»…çº¦24%ï¼ˆ1,540ä¸ªæ ·æœ¬ï¼‰åŒ…å«**éé›¶çš„è§†è§‰ä¸Šä¸‹æ–‡å‘é‡** \\( \\boldsymbol{c}_t \\)ã€‚<br>**ä¸Šä¸‹æ–‡**: \\( \\boldsymbol{c}_t \\) æ˜¯åŸºäºè¿‡å»2ç§’å›¾åƒåºåˆ—è®¡ç®—çš„â€œæ°´åˆ†æ•°â€æ—¶é—´åºåˆ—ï¼ˆè§å…¬å¼18ï¼‰ã€‚ | **é‡‡é›†æ–¹å¼**: åœ¨è¯•è½¦åœºä¸Šè®¾ç½®**æ°´å‘**ï¼Œè½¦æ‰‹é‡å¤ç±»ä¼¼çš„æ¿€è¿›é©¾é©¶ï¼Œä»¥æ•æ‰è½®èƒä¸æ¹¿æ»‘è·¯é¢é—´çš„ç¬æ€ç›¸äº’ä½œç”¨ã€‚<br>**æŒ‘æˆ˜**: é«˜æ¸©å¯¼è‡´æ°´å¿«é€Ÿè’¸å‘ï¼Œæ•°æ®æ”¶é›†ç¼“æ…¢ä¸”è´¹åŠ›ï¼Œå‡¸æ˜¾äº†æ‰€æ**å°æ•°æ®å¾®è°ƒæ–¹æ³•**çš„ä»·å€¼ã€‚<br>**ç”¨é€”**: ç”¨äº**å¾®è°ƒè§†è§‰æ¡ä»¶åŒ–è·¯å¾„**ï¼ˆå›¾3ä¸­çš„æ©™è‰²è·¯å¾„ï¼‰ã€‚åœ¨åŸºç¡€VBLLæ¨¡å‹å‚æ•°å›ºå®šçš„æƒ…å†µä¸‹ï¼Œä»…è®­ç»ƒFiLMè°ƒåˆ¶ç½‘ç»œï¼ˆLSTMï¼‰çš„å‚æ•°ï¼Œä½¿æ¨¡å‹èƒ½æ ¹æ®è§†è§‰ä¸Šä¸‹æ–‡è°ƒæ•´åŠ¨åŠ›å­¦é¢„æµ‹ã€‚ |\n| **è¯­ä¹‰åˆ†å‰²é¢„è®­ç»ƒæ•°æ®é›†** | **å…¬å¼€æ•°æ®é›†**: Gooseæ•°æ®é›† [37]ã€‚<br>**è§„æ¨¡**: 10kå¼ å›¾åƒã€‚<br>**å†…å®¹**: å¾·å›½ä¹¡æ‘å’Œè¶Šé‡é©¾é©¶åœºæ™¯ï¼ŒåŒ…å«64ä¸ªå°é—­é›†ç±»åˆ«ã€‚ | **ç”¨é€”**: ç”¨äºä»å¤´å¼€å§‹è®­ç»ƒ**SegMAN-t**è¯­ä¹‰åˆ†å‰²ç½‘ç»œéª¨å¹²ã€‚é€‰æ‹©æ­¤æ•°æ®é›†æ˜¯å› ä¸ºå…¶ç¯å¢ƒæ›´æ¥è¿‘èµ›è½¦åœºæ™¯ï¼ˆä¹¡æ‘vsåŸå¸‚ï¼‰ã€‚<br>**é¢å¤–å¾®è°ƒ**: ä½¿ç”¨å®éªŒåœ°ç‚¹ï¼ˆåŠ å·ï¼‰çš„**500å¼ æ‰‹åŠ¨æ ‡æ³¨å›¾åƒ**å¯¹åˆ†å‰²ç½‘ç»œè¿›è¡Œè¿›ä¸€æ­¥å¾®è°ƒï¼Œä»¥æå‡åœ¨ç‰¹å®šæµ‹è¯•ç¯å¢ƒä¸‹çš„åˆ†å‰²ç²¾åº¦ã€‚ |\n\n**æ€»ç»“**ï¼šæ•°æ®é›†ç­–ç•¥ä½“ç°äº†**æ•°æ®é«˜æ•ˆæ€§**å’Œ**é’ˆå¯¹æ€§**ï¼š\n1.  **ä¸¤é˜¶æ®µè®­ç»ƒ**ï¼šåˆ©ç”¨å¤§é‡æ˜“å¾—çš„å¹²ç‡¥æ•°æ®å­¦ä¹ é€šç”¨åŠ¨åŠ›å­¦ï¼Œå†ç”¨å°‘é‡çè´µçš„æ¹¿æ»‘æ•°æ®ä¸“é—¨å­¦ä¹ æ¡ä»¶åŒ–è°ƒåˆ¶ï¼Œè§£å†³äº†é«˜é£é™©äº¤äº’æ•°æ®ç¨€ç¼ºçš„éš¾é¢˜ã€‚\n2.  **ä»»åŠ¡é©±åŠ¨**ï¼šæ‰€æœ‰æ•°æ®å‡æ¥è‡ªç›®æ ‡è½¦è¾†åœ¨ç›®æ ‡æ€§èƒ½åŒºé—´ï¼ˆæé™é©¾é©¶ï¼‰ä¸‹é‡‡é›†ï¼Œç¡®ä¿äº†æ¨¡å‹å­¦ä¹ åˆ°çš„æ˜¯ä¸æœ€ç»ˆä»»åŠ¡é«˜åº¦ç›¸å…³çš„åŠ¨åŠ›å­¦ã€‚\n3.  **æ„ŸçŸ¥ä¸åŠ¨åŠ›å­¦è§£è€¦**ï¼šåˆ†å‰²ç½‘ç»œåœ¨å…¬å¼€æ•°æ®é›†ä¸Šé¢„è®­ç»ƒå¹¶é’ˆå¯¹æ€§å¾®è°ƒï¼Œä¸åŠ¨åŠ›å­¦æ¨¡å‹è®­ç»ƒåˆ†ç¦»ï¼Œæ˜¯ä¸€ç§æ¨¡å—åŒ–ä¸”é«˜æ•ˆçš„è®¾è®¡ã€‚",
            "timestamp": "2026-01-20T18:01:17.469209",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "è®ºæ–‡åœ¨å“ªäº›æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Ÿä¸»è¦çš„è¯„ä¼°æŒ‡æ ‡å’Œæ€§èƒ½æå‡æ˜¯å¤šå°‘ï¼Ÿ",
            "answer": "## è®ºæ–‡å®éªŒæ•°æ®é›†ã€è¯„ä¼°æŒ‡æ ‡ä¸æ€§èƒ½æå‡åˆ†æ\n\n### ä¸€ã€ å®éªŒæ•°æ®é›†\nè®ºæ–‡ä½¿ç”¨äº†**ä¸¤ç±»æ•°æ®é›†**è¿›è¡Œæ¨¡å‹è®­ç»ƒä¸éªŒè¯ï¼š\n\n1.  **åä¹‰ï¼ˆå¹²ç‡¥è·¯é¢ï¼‰æ•°æ®é›†**ï¼š\n    *   **æ¥æº**ï¼šç”±ä¸“ä¸šé©¾é©¶å‘˜åœ¨å¹²ç‡¥çš„èµ›é“ä¸Šé©¾é©¶é›·å…‹è¨æ–¯LC500è¿›è¡Œä¸€ç³»åˆ—**æ¿€è¿›æ“çºµ**ï¼ˆå¦‚æ¼‚ç§»ã€æé™è¿‡å¼¯ï¼‰æ”¶é›†ã€‚\n    *   **è§„æ¨¡**ï¼šåŒ…å« **12,229 ä¸ªæ ·æœ¬**ã€‚\n    *   **ç›®çš„**ï¼šç”¨äºè®­ç»ƒåŸºç¡€çš„**å˜åˆ†è´å¶æ–¯æœ€åä¸€å±‚ï¼ˆVBLLï¼‰åŠ¨åŠ›å­¦æ¨¡å‹**ï¼Œå­¦ä¹ è½¦è¾†åœ¨æ ‡å‡†ï¼ˆå¹²ç‡¥ï¼‰æ¡ä»¶ä¸‹çš„åŸºæœ¬åŠ¨åŠ›å­¦ç‰¹æ€§ã€‚\n\n2.  **å¾®è°ƒï¼ˆæ¹¿æ»‘è·¯é¢ï¼‰æ•°æ®é›†**ï¼š\n    *   **æ¥æº**ï¼šåœ¨èµ›é“ä¸Šå¼•å…¥**æ°´å‘**ï¼Œé©¾é©¶å‘˜é‡å¤ç±»ä¼¼çš„æ¿€è¿›æ“çºµï¼Œä»¥æ•æ‰è½®èƒä¸æ¹¿æ»‘è·¯é¢é—´çš„ç¬æ€ç›¸äº’ä½œç”¨ã€‚\n    *   **è§„æ¨¡**ï¼šåŒ…å« **6,349 ä¸ªæ ·æœ¬**ï¼Œå…¶ä¸­ä»…æœ‰çº¦ **24%**ï¼ˆ1,540ä¸ªæ ·æœ¬ï¼‰åŒ…å«éé›¶çš„è§†è§‰ä¸Šä¸‹æ–‡ï¼ˆå³æ£€æµ‹åˆ°æ°´ï¼‰ã€‚\n    *   **æŒ‘æˆ˜**ï¼šç”±äºé«˜æ¸©å’Œè’¸å‘ï¼Œæ•°æ®æ”¶é›†å›°éš¾ä¸”è€—æ—¶ï¼Œå‡¸æ˜¾äº†è®ºæ–‡æ‰€æ**ä¸¤é˜¶æ®µå¾®è°ƒæ–¹æ³•**åœ¨æ•°æ®ç¨€ç¼ºåœºæ™¯ä¸‹çš„ä»·å€¼ã€‚\n    *   **ç›®çš„**ï¼šç”¨äºåœ¨åŸºç¡€VBLLæ¨¡å‹ä¹‹ä¸Šï¼Œ**å¾®è°ƒè§†è§‰æ¡ä»¶è·¯å¾„**ï¼Œä½¿æ¨¡å‹å­¦ä¼šæ ¹æ®è§†è§‰ä¿¡æ¯ï¼ˆæ°´ï¼‰è°ƒæ•´åŠ¨åŠ›å­¦é¢„æµ‹ã€‚\n\n3.  **è§†è§‰åˆ†å‰²æ¨¡å‹è®­ç»ƒæ•°æ®**ï¼š\n    *   **é¢„è®­ç»ƒ**ï¼šä½¿ç”¨å…¬å¼€çš„ **Goose æ•°æ®é›†**ï¼ˆåŒ…å«1ä¸‡å¼ å¾·å›½ä¹¡æ‘å’Œè¶Šé‡é©¾é©¶å›¾åƒï¼‰ã€‚\n    *   **å¾®è°ƒ**ï¼šä½¿ç”¨ä»å®éªŒåœ°ç‚¹ï¼ˆåŠ åˆ©ç¦å°¼äºšï¼‰æ‰‹åŠ¨æ ‡æ³¨çš„ **500 å¼ å›¾åƒ**ï¼Œä»¥æ›´å¥½åœ°åŒ¹é…å®é™…æ¯”èµ›ç¯å¢ƒã€‚\n\n### äºŒã€ ä¸»è¦è¯„ä¼°æŒ‡æ ‡\nè®ºæ–‡çš„è¯„ä¼°ä¸»è¦å›´ç»•**ç¡¬ä»¶é—­ç¯å®éªŒ**çš„æ€§èƒ½ï¼Œæ ¸å¿ƒæŒ‡æ ‡ä¸ºï¼š\n\n1.  **æˆåŠŸå®Œæˆåœˆæ•° / å¤±æ§ç‡**ï¼šè¿™æ˜¯æœ€æ ¸å¿ƒçš„**äºŒå€¼åŒ–å®‰å…¨ä¸æ€§èƒ½æŒ‡æ ‡**ã€‚ç³»ç»Ÿèƒ½å¦åœ¨å­˜åœ¨æ°´å‘çš„èµ›é“ä¸Š**å®‰å…¨å®Œæˆæ•´åœˆ**è€Œä¸å¤±æ§ï¼ˆå¦‚æ‰“æ»‘ã€æ—‹è½¬ï¼‰ã€‚\n2.  **å•åœˆæ—¶é—´**ï¼šåœ¨å¹²ç‡¥è·¯é¢ä¸Šï¼Œç”¨äºå¯¹æ¯”ä¸åŒåŠ¨åŠ›å­¦æ¨¡å‹ï¼ˆç‰©ç†æ¨¡å‹ã€VBLLã€VcVBLLï¼‰çš„**ç»å¯¹æ€§èƒ½**ã€‚\n3.  **é¢„æµ‹åéªŒåˆ†å¸ƒåˆ†æ**ï¼šå®šæ€§å±•ç¤ºè§†è§‰æ¡ä»¶å¦‚ä½•æ”¹å˜æ¨¡å‹å¯¹å…³é”®çŠ¶æ€ï¼ˆå¦‚è½¦è½®é€Ÿåº¦ã€ä¾§æ»‘è§’ï¼‰çš„**é¢„æµ‹å‡å€¼ä¸ä¸ç¡®å®šæ€§**ï¼Œä»¥éªŒè¯å…¶ç‰©ç†åˆç†æ€§ã€‚\n\n### ä¸‰ã€ æ€§èƒ½æå‡ä¸å®éªŒç»“æœ\nè®ºæ–‡é€šè¿‡å¯¹æ¯”å®éªŒï¼Œæ¸…æ™°å±•ç¤ºäº†æ‰€æ **VcVBLL æ¨¡å‹**å¸¦æ¥çš„æ˜¾è‘—æ€§èƒ½æå‡ï¼š\n\n| å®éªŒåœºæ™¯ | å¯¹æ¯”æ¨¡å‹ | å…³é”®ç»“æœä¸æ€§èƒ½æå‡ |\n| :--- | :--- | :--- |\n| **å¹²ç‡¥è·¯é¢ï¼ˆåŸºå‡†æ€§èƒ½ï¼‰** | 1. ç‰©ç†æ¨¡å‹ <br> 2. VBLLæ¨¡å‹ <br> 3. **VcVBLLæ¨¡å‹** | â€¢ **VBLL/VcVBLL å‡ä¼˜äºç‰©ç†æ¨¡å‹**ï¼šå­¦ä¹ æ¨¡å‹èƒ½æ›´å……åˆ†åœ°åˆ©ç”¨è½®èƒåŠ›ï¼Œäº§ç”Ÿæ›´é«˜çš„åè½®é€Ÿåº¦ã€ä¾§æ»‘è§’å’Œå‡ºå¼¯é€Ÿåº¦ï¼Œä»è€Œå®ç°æ›´å¿«çš„å•åœˆæ—¶é—´ï¼ˆVBLL: 24.06ç§’ï¼Œ VcVBLL: 24.24ç§’ï¼Œ ç‰©ç†æ¨¡å‹: 24.53ç§’ï¼‰ã€‚<br>â€¢ è¯æ˜å­¦ä¹ åˆ°çš„VBLLåŠ¨åŠ›å­¦æœ¬èº«æ˜¯æœ‰æ•ˆçš„åŸºçº¿ã€‚ |\n| **æ¹¿æ»‘è·¯é¢ï¼ˆæ ¸å¿ƒéªŒè¯ï¼‰** | 1. VBLL (æ— è§†è§‰) <br> 2. VBLL + RLSåœ¨çº¿é€‚åº” <br> 3. VcVBLL (å¿½ç•¥è§†è§‰) <br> 4. **VcVBLL (ä½¿ç”¨è§†è§‰)** | â€¢ **æ€§èƒ½é¸¿æ²Ÿ**ï¼šæ‰€æœ‰**æ— è§†è§‰æ¡ä»¶**çš„åŸºçº¿æ¨¡å‹ï¼ˆ1-3ï¼‰åœ¨é€šè¿‡æ°´å‘æ—¶**å…¨éƒ¨å¤±æ§ï¼ˆ0%æˆåŠŸç‡ï¼‰**ã€‚<br>â€¢ **VcVBLL (ä½¿ç”¨è§†è§‰) å–å¾—100%æˆåŠŸç‡**ï¼šåœ¨ä¸¤æ¬¡ä¸åŒçš„æµ‹è¯•ä¸­ï¼ˆ8æœˆå’Œ9æœˆï¼Œå…±12æ¬¡å°è¯•ï¼‰ï¼Œ**å…¨éƒ¨12åœˆå‡æˆåŠŸå®Œæˆ**ã€‚<br>â€¢ **å…³é”®æœºåˆ¶**ï¼šè§†è§‰ä¸Šä¸‹æ–‡ä½¿æ¨¡å‹**æå‰ï¼ˆé¢„è§æ€§ï¼‰** é¢„æµ‹åˆ°æ‘©æ“¦åŠ›å˜åŒ–ï¼ŒMPCæ§åˆ¶å™¨å› æ­¤åœ¨è½¦è¾†è¿›å…¥æ°´å‘å‰å°±**ä¸»åŠ¨é™ä½å‘åŠ¨æœºæ‰­çŸ©å¹¶æ–½åŠ åˆ¶åŠ¨**ï¼Œä»è€Œç¨³å®šè½¦è¾†ã€‚ |\n| **é²æ£’æ€§æµ‹è¯•** | VcVBLL (ä½¿ç”¨è§†è§‰) | åœ¨ä¸åŒè½®èƒã€15Â°Cæ¸©å·®ã€ä¸åŒå…‰ç…§æ¡ä»¶ï¼ˆè§å›¾7ï¼‰ä¸‹é‡å¤å®éªŒï¼Œ**VcVBLLæ¨¡å‹å‡ä¿æŒäº†100%çš„æˆåŠŸç‡**ï¼Œè¯æ˜äº†å…¶å¯¹äºç¯å¢ƒå˜åŒ–çš„é²æ£’æ€§ã€‚ |\n\n### æ€»ç»“\n*   **æ ¸å¿ƒåˆ›æ–°ä»·å€¼**ï¼šè®ºæ–‡å¹¶éè¿½æ±‚åœ¨æ ‡å‡†æ•°æ®é›†ä¸Šçš„ç²¾åº¦ç™¾åˆ†æ¯”æå‡ï¼Œè€Œæ˜¯è§£å†³ä¸€ä¸ª**å…³é”®çš„å®é™…å®‰å…¨æŒ‘æˆ˜**â€”â€”åœ¨åŠ¨æ€å˜åŒ–ç¯å¢ƒä¸­å®ç°**é¢„è§æ€§ï¼ˆproactiveï¼‰æ§åˆ¶**ã€‚\n*   **æ€§èƒ½æå‡çš„å®è´¨**ï¼šå°†æ§åˆ¶èŒƒå¼ä» **â€œæ„ŸçŸ¥-ååº”â€** è½¬å˜ä¸º **â€œæ„ŸçŸ¥-é¢„æµ‹-ä¸»åŠ¨è¡ŒåŠ¨â€** ã€‚è¿™ç§èƒ½åŠ›çš„æå‡æ˜¯**è´¨çš„é£è·ƒ**ï¼Œä½“ç°åœ¨ä» **â€œå¿…ç„¶å¤±æ§â€åˆ°â€œå®Œå…¨å¯æ§â€** çš„è½¬å˜ä¸Šï¼Œè¿™å¯¹äºé«˜é€Ÿè‡ªåŠ¨é©¾é©¶åœ¨æé™å·¥å†µä¸‹çš„å®‰å…¨æ€§è‡³å…³é‡è¦ã€‚\n*   **è¯„ä¼°æŒ‡æ ‡çš„ç‰¹ç‚¹**ï¼šè¯„ä¼°é«˜åº¦ä¾èµ–äº**çœŸå®çš„ç¡¬ä»¶é—­ç¯å®éªŒ**ï¼Œä»¥æœ€ç»ˆçš„ç³»ç»Ÿçº§è¡¨ç°ï¼ˆæˆåŠŸ/å¤±è´¥ï¼‰ä½œä¸ºæœ€æœ‰åŠ›çš„è¯æ˜ï¼Œè¿™æ¯”ä»¿çœŸæˆ–å¼€ç¯é¢„æµ‹è¯¯å·®æ›´èƒ½ä½“ç°å…¶å®é™…åº”ç”¨ä»·å€¼ã€‚",
            "timestamp": "2026-01-20T18:01:56.564324",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        },
        {
            "question": "è®ºæ–‡çš„ä¸»è¦å±€é™æ€§æœ‰å“ªäº›ï¼Ÿæœªæ¥å¯èƒ½çš„æ”¹è¿›æ–¹å‘æ˜¯ä»€ä¹ˆï¼Ÿ",
            "answer": "## è®ºæ–‡ä¸»è¦å±€é™æ€§åˆ†æ\n\nåŸºäºå¯¹è®ºæ–‡å†…å®¹çš„æ·±å…¥é˜…è¯»ï¼Œä»¥ä¸‹æ˜¯**Vision-Conditioned Variational Bayesian Last Layer (VcVBLL) åŠ¨åŠ›å­¦æ¨¡å‹**çš„ä¸»è¦å±€é™æ€§ï¼š\n\n### 1. **è§†è§‰ä¸Šä¸‹æ–‡æå–çš„ç®€åŒ–æ€§**\n- **å±€é™æ€§**ï¼š è§†è§‰æ¡ä»¶ä»…ä¾èµ–äºä¸€ä¸ªç®€åŒ–çš„â€œæ°´åˆ†æ•°â€ï¼ˆ`Ï_t`ï¼‰ï¼Œè¯¥åˆ†æ•°ä»…è®¡ç®—å›¾åƒä¸­**æ°´**ä¸**æ²¥é’**ä¸¤ç±»è¯­ä¹‰çš„åŠ æƒæ¯”ä¾‹ã€‚è¿™å¿½ç•¥äº†å…¶ä»–å¯èƒ½å½±å“åŠ¨åŠ›å­¦çš„å¤æ‚è§†è§‰ç‰¹å¾ï¼ˆå¦‚è·¯é¢çº¹ç†ã€ç§¯æ°´æ·±åº¦ã€å†°é¢ã€æ²¹æ¸ã€ç¢çŸ³ç­‰ï¼‰ã€‚\n- **å½±å“**ï¼š æ¨¡å‹åœ¨æ›´å¤æ‚å¤šå˜çš„ç¯å¢ƒï¼ˆå¦‚æ··åˆè·¯é¢ã€æ¸è¿›å¼æ¹¿æ»‘ã€éç»“æ„åŒ–è¶Šé‡ç¯å¢ƒï¼‰ä¸­çš„æ³›åŒ–èƒ½åŠ›å¯èƒ½å—é™ã€‚\n\n### 2. **æ•°æ®æ”¶é›†çš„æŒ‘æˆ˜ä¸æ•°æ®ç¨€ç¼ºæ€§**\n- **å±€é™æ€§**ï¼š\n    - **æ¹¿æ»‘è·¯é¢æ•°æ®ç¨€ç¼º**ï¼š ç”±äºé«˜æ¸©å¯¼è‡´æ°´å‘å¿«é€Ÿè’¸å‘ï¼Œæ”¶é›†æ¹¿æ»‘è·¯é¢çš„äº¤äº’æ•°æ®è¿‡ç¨‹ç¼“æ…¢ä¸”åŠ³åŠ¨å¯†é›†ã€‚å¾®è°ƒæ•°æ®é›†ä»…åŒ…å«çº¦24%çš„éé›¶ä¸Šä¸‹æ–‡æ ·æœ¬ã€‚\n    - **æ•°æ®å¤šæ ·æ€§æœ‰é™**ï¼š è®­ç»ƒå’Œæµ‹è¯•ä¸»è¦åœ¨ç‰¹å®šåœºåœ°ï¼ˆskidpadï¼‰è¿›è¡Œï¼Œä¸”ç¯å¢ƒå˜åŒ–ï¼ˆå…‰ç…§ã€æ¸©åº¦ï¼‰è™½ç»æµ‹è¯•ï¼Œä½†åœºæ™¯ç±»å‹ç›¸å¯¹å•ä¸€ã€‚\n- **å½±å“**ï¼š æ¨¡å‹å¯èƒ½å¯¹æœªè§è¿‡çš„å¤§è§„æ¨¡ç¯å¢ƒå˜åŒ–æˆ–æç«¯æ¡ä»¶ï¼ˆå¦‚æš´é›¨ã€å†°é›ªï¼‰çš„é€‚åº”æ€§ä¸è¶³ã€‚\n\n### 3. **æ¨¡å‹æ¶æ„ä¸è®¡ç®—æ•ˆç‡**\n- **å±€é™æ€§**ï¼š\n    - **ä¸²è¡Œå¤„ç†ä¸å¸§ç‡ä¸åŒ¹é…**ï¼š è§†è§‰åˆ†å‰²ï¼ˆ25-30Hzï¼‰ä¸æ§åˆ¶å™¨ï¼ˆ62.5Hzï¼‰è¿è¡Œåœ¨ä¸åŒçº¿ç¨‹ï¼Œä¸¢å¤±å¸§éœ€è¦é€šè¿‡æ’å€¼å¤„ç†ï¼Œå¯èƒ½å¼•å…¥å»¶è¿Ÿæˆ–ä¿¡æ¯æŸå¤±ã€‚\n    - **FiLMè°ƒåˆ¶é¢‘ç‡è¾ƒä½**ï¼š è°ƒåˆ¶ä¿¡å·è®¡ç®—é¢‘ç‡ä¸º7Hzï¼Œå¯èƒ½æ— æ³•æ•æ‰éå¸¸å¿«é€Ÿå˜åŒ–çš„è§†è§‰åœºæ™¯ã€‚\n- **å½±å“**ï¼š åœ¨éœ€è¦æä½å»¶è¿Ÿå“åº”çš„è¶…é«˜é€Ÿæˆ–çªå‘éšœç¢åœºæ™¯ä¸­ï¼Œç³»ç»Ÿçš„å®æ—¶æ€§å’Œæ€§èƒ½å¯èƒ½å—åˆ°å½±å“ã€‚\n\n### 4. **æ§åˆ¶æ¡†æ¶çš„å‡è®¾**\n- **å±€é™æ€§**ï¼š æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆMPCï¼‰ä¾èµ–äºé¢„è®¡ç®—çš„å‚è€ƒè½¨è¿¹ï¼ˆ`ğ’™_ref`ï¼‰ã€‚åœ¨åŠ¨æ€ç¯å¢ƒæˆ–å‚è€ƒè½¨è¿¹æ— æ³•é¢„çŸ¥çš„æƒ…å†µä¸‹ï¼ˆå¦‚åŠ¨æ€é¿éšœã€æœªçŸ¥èµ›é“ï¼‰ï¼Œè¯¥æ¡†æ¶çš„é€‚ç”¨æ€§éœ€è¦è¿›ä¸€æ­¥éªŒè¯ã€‚\n- **å½±å“**ï¼š æ–¹æ³•åœ¨å®Œå…¨æœªçŸ¥æˆ–é«˜åº¦åŠ¨æ€ç¯å¢ƒä¸­çš„è‡ªä¸»æ€§å¯èƒ½å—é™ã€‚\n\n### 5. **æ³›åŒ–èƒ½åŠ›éªŒè¯èŒƒå›´**\n- **å±€é™æ€§**ï¼š å®éªŒéªŒè¯ä¸»è¦é›†ä¸­åœ¨**è½¦è¾†èµ›é“ç«é€Ÿé€šè¿‡æ°´å‘**è¿™ä¸€ç‰¹å®šä»»åŠ¡ã€‚è™½ç„¶è®ºæ–‡æåŠå¯æ¨å¹¿è‡³æ¼‚ç§»ã€è¶Šé‡ç­‰ï¼Œä½†æœªæä¾›åœ¨è¿™äº›åœºæ™¯ä¸‹çš„å®è´¨æ€§ç¡¬ä»¶ç»“æœã€‚\n- **å½±å“**ï¼š è¯¥æ–¹æ³•åœ¨å…¶ä»–é«˜åŠ¨æ€æœºå™¨äººç³»ç»Ÿï¼ˆå¦‚è¶³å¼æœºå™¨äººã€æ— äººæœºï¼‰æˆ–æ›´å¹¿æ³›â€œå˜åŒ–æ¡ä»¶â€ä¸‹çš„æœ‰æ•ˆæ€§å°šæœªå¾—åˆ°è¯æ˜ã€‚\n\n---\n\n## æœªæ¥å¯èƒ½çš„æ”¹è¿›æ–¹å‘\n\n### 1. **å¢å¼ºè§†è§‰æ„ŸçŸ¥ä¸ä¸Šä¸‹æ–‡è¡¨å¾**\n- **æ–¹å‘**ï¼š åˆ©ç”¨æ›´å¼ºå¤§çš„**è§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆVLMsï¼‰æˆ–å¤šæ¨¡æ€æ¨¡å‹**ï¼Œä»å›¾åƒä¸­æå–æ›´ä¸°å¯Œã€æ›´ç‰©ç†ç›¸å…³çš„ç‰¹å¾ï¼ˆå¦‚æ‘©æ“¦ç³»æ•°ä¼°è®¡ã€è·¯é¢æè´¨åˆ†ç±»ã€åœ°å½¢å‡ ä½•ï¼‰ã€‚\n- **æ–¹æ³•**ï¼š å¼€å‘å¯è§£é‡Šçš„è§†è§‰ç‰¹å¾ç¼–ç å™¨ï¼Œå°†åƒç´ ç›´æ¥æ˜ å°„åˆ°åŠ¨åŠ›å­¦ç›¸å…³å‚æ•°ï¼ˆå¦‚é¢„æµ‹çš„æ‘©æ“¦ç³»æ•°èŒƒå›´ï¼‰ï¼Œè€Œä¸ä»…ä»…æ˜¯ç®€å•çš„ç±»åˆ«åˆ†æ•°ã€‚\n\n### 2. **æ”¹è¿›æ•°æ®æ•ˆç‡ä¸åˆæˆæ•°æ®åˆ©ç”¨**\n- **æ–¹å‘**ï¼š\n    - **ä»¿çœŸåˆ°çœŸå®ï¼ˆSim2Realï¼‰è¿ç§»**ï¼š åœ¨é€¼çœŸçš„ä»¿çœŸç¯å¢ƒä¸­ç”Ÿæˆå¤§é‡å¤šæ ·åŒ–çš„â€œè§†è§‰-åŠ¨åŠ›å­¦â€é…å¯¹æ•°æ®ï¼Œç„¶åé€šè¿‡åŸŸé€‚åº”æŠ€æœ¯è¿ç§»åˆ°çœŸå®ä¸–ç•Œã€‚\n    - **å…ƒå­¦ä¹ æˆ–å°‘æ ·æœ¬å­¦ä¹ **ï¼š è®¾è®¡èƒ½å¤Ÿä»æå°‘é‡æ–°ç¯å¢ƒæ•°æ®ä¸­å¿«é€Ÿé€‚åº”åŠ¨åŠ›å­¦å˜åŒ–çš„æ¨¡å‹æ¶æ„ã€‚\n- **æ–¹æ³•**ï¼š ç»“åˆç‰©ç†ä»¿çœŸå™¨å’Œç¥ç»æ¸²æŸ“ï¼Œç”Ÿæˆä¸åŒå¤©æ°”ã€å…‰ç…§ã€è·¯é¢æ¡ä»¶ä¸‹çš„æ•°æ®ï¼Œç”¨äºé¢„è®­ç»ƒæˆ–æ•°æ®å¢å¼ºã€‚\n\n### 3. **æå‡ç³»ç»Ÿæ•´ä½“æ€§ä¸å®æ—¶æ€§èƒ½**\n- **æ–¹å‘**ï¼š\n    - **ç«¯åˆ°ç«¯ä¼˜åŒ–**ï¼š æ¢ç´¢å°†è§†è§‰ç¼–ç ã€åŠ¨åŠ›å­¦å­¦ä¹ å’Œæ§åˆ¶ç­–ç•¥åœ¨**ä¸€ä¸ªå¯å¾®åˆ†çš„æ¡†æ¶å†…**è¿›è¡Œè”åˆè®­ç»ƒï¼Œè™½ç„¶å¯èƒ½ç‰ºç‰²éƒ¨åˆ†æ¨¡å—åŒ–ï¼Œä½†å¯èƒ½æå‡æ€§èƒ½ä¸å“åº”é€Ÿåº¦ã€‚\n    - **æ¨¡å‹è½»é‡åŒ–**ï¼š ä¼˜åŒ–åˆ†å‰²ç½‘ç»œå’ŒVBLLæ¨¡å‹ï¼Œä»¥å®ç°æ›´é«˜çš„å¤„ç†é¢‘ç‡ï¼Œå¹¶ä½¿è§†è§‰ä¸æ§åˆ¶å™¨å¾ªç¯æ›´ç´§å¯†åœ°è€¦åˆã€‚\n- **æ–¹æ³•**ï¼š ç ”ç©¶é€‚ç”¨äºå®æ—¶æœºå™¨äººæ§åˆ¶çš„é«˜æ•ˆTransformeræˆ–çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMï¼‰ä½œä¸ºè§†è§‰ç¼–ç å™¨ã€‚\n\n### 4. **æ‰©å±•ä»»åŠ¡ä¸åœºæ™¯å¤æ‚æ€§**\n- **æ–¹å‘**ï¼š\n    - **åŠ¨æ€ç¯å¢ƒä¸äº¤äº’**ï¼š å°†æ¨¡å‹åº”ç”¨äºåŒ…å«å…¶ä»–åŠ¨æ€æ™ºèƒ½ä½“ï¼ˆå¦‚å…¶ä»–è½¦è¾†ï¼‰çš„åœºæ™¯ï¼Œä½¿åŠ¨åŠ›å­¦é¢„æµ‹èƒ½å¤Ÿè€ƒè™‘äº¤äº’å½±å“ã€‚\n    - **æ— å‚è€ƒè½¨è¿¹çš„è‡ªä¸»æ¢ç´¢**ï¼š å°†VcVBLLä¸åŸºäºå­¦ä¹ çš„è·¯å¾„è§„åˆ’å™¨ç»“åˆï¼Œå®ç°å®Œå…¨è‡ªä¸»çš„â€œæ„ŸçŸ¥-é¢„æµ‹-è§„åˆ’-æ§åˆ¶â€é—­ç¯ã€‚\n- **æ–¹æ³•**ï¼š åœ¨MPCä¸­å¼•å…¥åŸºäºè§†è§‰çš„ä»£ä»·å‡½æ•°æˆ–çº¦æŸé¢„æµ‹ï¼Œä»¥åŒæ—¶å¤„ç†åŠ¨åŠ›å­¦å˜åŒ–å’Œéšœç¢ç‰©è§„é¿ã€‚\n\n### 5. **æ·±åŒ–ä¸ç¡®å®šæ€§é‡åŒ–ä¸å®‰å…¨ä¿è¯**\n- **æ–¹å‘**ï¼š è™½ç„¶VBLLæä¾›äº†é¢„æµ‹ä¸ç¡®å®šæ€§ï¼Œä½†æœªæ¥å·¥ä½œå¯ä»¥æ›´æ·±å…¥åœ°**å°†è¿™ç§ä¸ç¡®å®šæ€§é›†æˆåˆ°å®‰å…¨å…³é”®çš„å†³ç­–ä¸­**ã€‚\n- **æ–¹æ³•**ï¼š\n    - å¼€å‘**åˆ†å¸ƒé²æ£’MPC**æˆ–**åŸºäºé£é™©çš„MPC**ï¼Œæ˜ç¡®åˆ©ç”¨é¢„æµ‹åéªŒåˆ†å¸ƒæ¥æƒè¡¡æ€§èƒ½ä¸å®‰å…¨æ€§ã€‚\n    - ç ”ç©¶åœ¨æ¨¡å‹ä¸ç¡®å®šæ€§æ¿€å¢æ—¶ï¼ˆå¦‚é‡åˆ°å®Œå…¨æœªçŸ¥è·¯é¢ï¼‰çš„å®‰å…¨å›é€€ç­–ç•¥æˆ–è§¦å‘å¼ä¿å®ˆæ§åˆ¶ã€‚\n\n### 6. **è·¨å¹³å°ä¸è·¨ä»»åŠ¡éªŒè¯**\n- **æ–¹å‘**ï¼š åœ¨æ›´å¤šç±»å‹çš„æœºå™¨äººå¹³å°ï¼ˆå¦‚é«˜é€Ÿæ— äººæœºã€è…¿å¼æœºå™¨äººï¼‰å’Œä»»åŠ¡ï¼ˆå¦‚æé™æ“ä½œã€ç²¾å¯†è£…é…ï¼‰ä¸ŠéªŒè¯â€œè§†è§‰æ¡ä»¶åŒ–åŠ¨åŠ›å­¦å»ºæ¨¡â€èŒƒå¼çš„é€šç”¨æ€§ã€‚\n- **æ–¹æ³•**ï¼š æ„å»ºæ¨¡å—åŒ–æ¡†æ¶ï¼Œä½¿è§†è§‰æ¡ä»¶åŒ–æœºåˆ¶èƒ½å¤Ÿæ–¹ä¾¿åœ°é€‚é…åˆ°ä¸åŒæœ¬å¾åŠ¨åŠ›å­¦æ¨¡å‹ä¸Šã€‚\n\n---\n**æ€»ç»“**ï¼š æœ¬æ–‡çš„æ ¸å¿ƒåˆ›æ–°åœ¨äº**å°†è§†è§‰ä¸Šä¸‹æ–‡é€šè¿‡FiLMæœºåˆ¶å‰ç»æ€§åœ°èå…¥è´å¶æ–¯åŠ¨åŠ›å­¦æ¨¡å‹**ï¼Œå¹¶åœ¨æé™ç«é€Ÿä»»åŠ¡ä¸­è¯æ˜äº†å…¶å·¨å¤§ä»·å€¼ã€‚æœªæ¥çš„ç ”ç©¶å°†å›´ç»•**æå‡æ„ŸçŸ¥ä¸°å¯Œæ€§ã€æ•°æ®æ•ˆç‡ã€ç³»ç»Ÿå®æ—¶æ€§ã€ä»»åŠ¡æ³›åŒ–èƒ½åŠ›ä»¥åŠå®‰å…¨ä¿éšœ**å±•å¼€ï¼Œä»è€Œå°†è¿™ä¸€èŒƒå¼ä»æˆåŠŸçš„æ¼”ç¤ºæ¨å‘æ›´å¹¿æ³›ã€æ›´å¯é çš„è‡ªä¸»ç³»ç»Ÿåº”ç”¨ã€‚",
            "timestamp": "2026-01-20T18:02:42.109776",
            "thinking": null,
            "is_reasoning": false,
            "parent_qa_id": null
        }
    ],
    "is_hidden": false,
    "is_starred": false,
    "flag": true,
    "published_date": "2026-01-14T05:25:18Z",
    "created_at": "2026-01-20T17:49:48.463851",
    "updated_at": "2026-01-20T17:49:48.463859"
}