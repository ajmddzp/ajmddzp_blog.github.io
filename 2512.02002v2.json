{
  "id": "2512.02002v2",
  "title": "LLM-Driven Corrective Robot Operation Code Generation with Static Text-Based Simulation",
  "authors": [
    "Wenhao Wang",
    "Yi Rong",
    "Yanyan Li",
    "Long Jiao",
    "Jiawei Yuan"
  ],
  "abstract": "Recent advances in Large language models (LLMs) have demonstrated their promising capabilities of generating robot operation code to enable LLM-driven robots. To enhance the reliability of operation code generated by LLMs, corrective designs with feedback from the observation of executing code have been increasingly adopted in existing research. However, the code execution in these designs relies on either a physical experiment or a customized simulation environment, which limits their deployment due to the high configuration effort of the environment and the potential long execution time. In this paper, we explore the possibility of directly leveraging LLM to enable static simulation of robot operation code, and then leverage it to design a new reliable LLM-driven corrective robot operation code generation framework. Our framework configures the LLM as a static simulator with enhanced capabilities that reliably simulate robot code execution by interpreting actions, reasoning over state transitions, analyzing execution outcomes, and generating semantic observations that accurately capture trajectory dynamics. To validate the performance of our framework, we performed experiments on various operation tasks for different robots, including UAVs and small ground vehicles. The experiment results not only demonstrated the high accuracy of our static text-based simulation but also the reliable code generation of our LLM-driven corrective framework, which achieves a comparable performance with state-of-the-art research while does not rely on dynamic code execution using physical experiments or simulators.",
  "url": "https://arxiv.org/abs/2512.02002v2",
  "html_url": "https://arxiv.org/html/2512.02002v2",
  "html_content": "LLM-Driven Corrective Robot Operation Code Generation with Static Text-Based Simulation\nWenhao Wang\n, Yi Rong, Yanyan Li\n, Long Jiao\n, Jiawei Yuan\nThis work is supported by the US National Science Foundation awards 2318710 and 2318711.Wenhao Wang, Yi Rong, Long Jiao, and Jiawei Yuan are with the Department of CIS, University of Massachusetts Dartmouth\n{wwang5, yrong, ljiao, jyuan}@umassd.edu\nYanyan Li is with the Department of CSIS, California State University San Marcos.\nyali@csusm.edu\nAbstract\nRecent advances in Large language models (LLMs) have demonstrated their promising capabilities of generating robot operation code to enable LLM-driven robots. To enhance the reliability of operation code generated by LLMs, corrective designs with feedback from the observation of executing code have been increasingly adopted in existing research. However, the code execution in these designs relies on either a physical experiment or a customized simulation environment, which limits their deployment due to the high configuration effort of the environment and the potential long execution time. In this paper, we explore the possibility of directly leveraging LLM to enable static simulation of robot operation code, and then leverage it to design a new reliable LLM-driven corrective robot operation code generation framework. Our framework configures the LLM as a static simulator with enhanced capabilities that reliably simulate robot code execution by interpreting actions, reasoning over state transitions, analyzing execution outcomes, and generating semantic observations that accurately capture trajectory dynamics. To validate the performance of our framework, we performed experiments on various operation tasks for different robots, including UAVs and small ground vehicles. The experiment results not only demonstrated the high accuracy of our static text-based simulation but also the reliable code generation of our LLM-driven corrective framework, which achieves a comparable performance with state-of-the-art research while does not rely on dynamic code execution using physical experiments or simulators.\nI\nINTRODUCTION\nRobots are being increasingly deployed to execute tasks based on human instructions. However, designing a robot that has intelligence to perform complex tasks reliably remains challenging, as it demands both robust instruction interpretation and executing tasks with robust reasoning. Recent advances in LLMs\n[\nGPT4\n,\nGemini\n,\ndeepseek\n]\nhave demonstrated remarkable proficiency in robotic areas such as control\n[\nReal\n]\n, planning\n[\nplanning\n]\n, and navigation\n[\nL3MVN\n]\n. Their strong context understanding and generation capabilities enable the robot to comprehend human instructions and generate corresponding robot operation code\n[\nChatGPTRobotics\n,\nTypeFly\n,\nCodeasPolicies\n,\nGSCE\n]\n, thereby greatly simplifying the process of robot programming.\nUnlike text generation applications, where semantic-level accuracy is sufficient, executing logically inconsistent or syntactically incorrect code on a robot can lead to unexpected outcomes and even unsafe robot behaviors, such as UAV crashes. To improve the reliability of LLMs’ robot operation code generation, recent studies have incorporated a corrective process that leverages the observation of executing LLM-generated code in a physical experiment or simulator to identify issues and perform refinement\n[\nAutoTAMP\n,\nInteractivePlanning\n,\nCLGSCE\n]\n. While these corrective designs have shown their effectiveness in enhancing the reliability of LLM-generated operation code, they still face challenges from different aspects. Specifically, the configuration of a physical or simulation environment for robot code execution requires specialized expertise to support the tasks (e.g., designing scenes and modeling a robot’s replica), especially for custom-built robots. For example, the code execution in ref\n[\nCLGSCE\n]\nrequires a specific design of mapping that transforms numerical state representation to the semantic description, which needs to be customized case-by-case. In addition, existing corrective designs require multiple rounds of interactive refinements, which can lead to a long execution time in the experiment or simulation when the task is complicated or involves time-consuming operations (e.g., monitor the area for 15 minutes). Therefore, removing the dependence on dynamic execution in a physical experiment or simulator while still maintaining the corrective feedback and refinement features for LLM-driven robot operation code generation becomes a challenging gap to close.\nFigure 1:\nAn overview of LLM-driven corrective robot operation code generation with static text-based simulation.\nIn this paper, we explore the possibility of directly employing LLMs for static text-based simulation over robot operation code and obtaining effective semantic observation to enable the refinement of LLM-driven robot operation code generation. Specifically, we propose a novel static text-based simulation solution powered by LLM to statically simulate the execution of robot operation code and generate accurate simulation outcomes. As shown in Fig.\n1\n, our static simulation solution emulates the code execution by interpreting the actions encoded in the text of the code, reasoning about the corresponding state and environment-driven transitions, analyzing the next robot state after the action execution, and ultimately producing semantic observations that capture the robot’s trajectory dynamics. On top of that, we propose our corrective robot code generation with static text-based simulation that unfolds as follows: 1) An LLM configured as a code generator first generates the initial version of robot operation code based on the task description from the user; 2) The LLM-based simulator “executes” the code and produces a semantic observation of the robot’s trajectory; 3) An evaluator LLM analyzes the observation and identifies mismatches between the task description and the robot’s trajectory, and then provides feedback that depicts the mismatched actions; 4) Guided by the feedback, the code generator corrects the mismatches. This iterative correction process continues until the evaluation confirms alignment between the code and task objectives, after which the final version of code is deployed to the robot for task execution.\nWe extensively evaluated our proposed framework for the operation code generation of UAV tasks with various levels of task complexities. Our results show that our static text-based simulation achieves over\n97.5\n%\n97.5\\%\nof simulation accuracy compared with the widely adopted UAV simulators, i.e., AirSim\n[\nAirSim\n]\nand PX4-Gazebo\n[\nPX4\n]\n. In addition, our corrective code generation framework delivers comparable robot execution performance as the state-of-the-art (SOTA) method relying on dynamic code execution in physical experiment or simulator, with an\n85\n%\n+\n85\\%+\nsuccess rate and\n96.9\n%\n+\n96.9\\%+\ncompleteness on different UAV systems, i.e.,\n96.9\n%\n+\n96.9\\%+\nof required actions in all evaluated tasks are completed correctly and\n85\n%\n+\n85\\%+\nof tasks are entirely completed without any error. To demonstrate the adaptability of our framework and its performance on real-world robot deployment, we also evaluated it for the operation code generation for UAVs and ground robots. Our experiment results show that our framework can also achieve high success rates (\n87.5\n%\n+\n87.5\\%+\n) and completeness (\n96.9\n%\n+\n96.9\\%+\n).\nII\nRELATED WORK\nII-A\nLLM-Driven Corrective Robot Code Generation\nUsing LLMs to generate operation codes for robot tasks has become a prevalent trend in recent research. By configuring LLMs with appropriate system prompting techniques, existing research has shown that LLMs have the potential to generate robot operation codes\n[\nChatGPTRobotics\n,\nTypeFly\n,\nCodeasPolicies\n,\nGSCE\n]\n. To further enhance the reliability of LLMs’ output and support more complicated robot tasks, recent efforts have adopted corrective code generation such that the errors or mismatches are iteratively detected and corrected; therefore, the robot could perform the desired task accurately when executing the final code\n[\nCoPAL\n,\nCAPE\n,\ntrust\n]\n. However, the physical execution during the correction process may increase the hardware cost and raise safety risks, as executing code with errors could cause irreparable damage to robots, such as UAV crashes. More recent studies proposed a simulation-based pipeline that eliminates the potential risks during physical execution\n[\nCLGSCE\n,\nAutoTAMP\n,\nhu2024robo\n]\n. For example,\n[\nCLGSCE\n]\nleverages the AirSim\n[\nAirSim\n]\nsimulator to iteratively correct the UAV operation code until the code is ready for deployment. The authors also develop semantic observations rather than numerical representation\n[\nInteractivePlanning\n]\nto describe the UAV trajectory to further improve performance. Robo-Instruct\n[\nhu2024robo\n]\nfine-tuning LLM that checks LLM-generated robot programs with a simulator and revises them until correct.\nII-B\nLLM-based Simulation\nRecent advances in LLMs\n[\nGPT4\n,\nGemini\n,\ndeepseek\n]\nhave demonstrated their exceptional capabilities in world modeling. Previous studies have explored the integration of LLMs into agent-based modeling and simulation within the social\n[\nLLM-simulator-survey\n]\nand planning\n[\nyang2024evaluating\n]\ndomains. For example, BeSimulator\n[\nbesimulator\n]\nbuilt an LLM-powered framework towards behavior simulation on the behavior tree. However, studies on text game show that current LLMs are not yet able to reliably act as text world simulators as they are likely to make errors when arithmetic, common-sense, or scientific knowledge is needed\n[\nLLM-simulator\n]\n. This limitation highlights the need for further research to examine the use of LLMs for the robot code simulation domain and develop methods to enhance the ability of LLMs to perform accurate and reliable simulations of robot operation code.\nII-C\nPrompt Engineering\nPrompt engineering can effectively communicate and interact with LLM-driven tools\n[\nPromptEngineering\n]\n. Recent studies have increasingly used prompt engineering to improve the reliability of LLM-driven robotic systems. For example, PromptBook proposes a prompt framework as a system prompt to enhance the code generation\n[\nPromptBook\n]\n. On the one hand, prompt engineering leverages in-context learning\n[\nURIAL\n]\nand few-shot learning\n[\nllm-fewshot\n]\nto enable LLM to learn knowledge within the given context and identify patterns from a limited set of examples. These techniques facilitate the generation of code that adheres to robot policy and how to ground task descriptions from a few examples\n[\nCodeasPolicies\n]\n. On the other hand, CoT\n[\nCoT\n]\nprompts the LLM to articulate intermediate inference steps, which is valuable for robotic tasks that require sequential, stepwise decision-making. CoT encourages the production of code that aligns with each stage of the intended action plan. Previous studies have embedded CoT within the examples to guide LLMs through reasoning step-by-step\n[\nISR-LLM\n,\nPromptBook\n]\n. In this study, we utilize prompt engineering strategies to facilitate our text-based simulation.\nFigure 2:\nAn illustrative example of corrective code generation with text-based simulation. In the first iteration, the LLM-based simulator accurately produces an observation of UAV actions, while the evaluator identifies the mismatch and constructs feedback. Based on the feedback, the code generator corrects the mismatch and produces a valid code for robot operation in the second iteration.\nIII\nMETHOD\nIII-A\nOverview\nFig.\n2\npresents the overall framework of our corrective code generation with text-based simulation. When given a task by the user, the code generator first produces the initial version of the robot operation code. Then our LLM-based simulator produces an observation of the robot’s trajectory through text-based simulation of the code. After that, the evaluator analyzes the observation together with the task and generates feedback that depicts the mismatches (if any) in the robot’s actions. Based on the feedback, the code generator regenerates the code that corrects the mismatches. This iterative “generation-simulation-evaluation” loop continues until the evaluation confirms task objectives are achieved or the maximum number of iterations is reached. The following sections present the detailed design of our code generation, text-based simulation, and evaluation.\nIII-B\nCode Generation\nThe code generation in our method is achieved by configuring an LLM agent (code generator) with a robot operation-related system prompt. We adopt the strategies in the GSCE framework\n[\nGSCE\n]\n, which enhance the reasoning capabilities of LLMs in generating UAV operation code that aligns with task instructions. Additionally, the code generator regenerates the code that resolves the mismatches according to the feedback from the evaluator in section\nIII-D\n. In detail, given a task description or evaluation feedback, the code generator produces a robot operation code that aims to accomplish the task or resolve the mismatches.\nIII-C\nStatic Text-Based Simulation using LLM\nGiven the robot operation code generated by the code generator, the goal of our static text-based simulation is to accurately interpret the robot’s actions, reason about the state transitions, predict the robot states, and generate an observation of the robot’s trajectory. Specifically, we formulate our text-based simulation using LLM as\nO\n=\n⟨\nS\n,\nA\n,\nT\n,\nC\n⟩\nO=\\langle S,A,T,C\\rangle\n, where\nO\nO\ndenotes the robot trajectory observation produced by the simulation,\nS\n=\n(\ns\n0\n,\ns\n1\n,\ns\n2\n,\n…\n,\ns\nn\n)\nS=(s_{0},s_{1},s_{2},\\dots,s_{n})\ndenotes the finite set of discrete states,\nA\nA\ndenotes the finite set of robot actions,\nT\n:\nS\n×\nA\n→\nS\nT:S\\times A\\rightarrow S\ndenotes the state transition, and\nC\nC\ndenotes the text of robot operation code. The trajectory observation\nO\nO\ncaptures a sequence of robot actions\nl\n=\n(\na\n1\n,\na\n2\n,\n…\n,\na\nn\n)\nl=(a_{1},a_{2},\\dots,a_{n})\nthat transitions robot from the initial state\ns\n0\ns_{0}\nthrough intermediate states, to the final state\ns\nn\ns_{n}\n.\nO\nO\nalso embeds the history of the robot’s trajectory dynamics for each robot action\nl\nl\nand their transitions\nT\nT\nafter executing code\nC\nC\n. This observation enables the subsequent evaluation to identify the mismatches and correct them in the next code generation. Therefore, the reliability of LLM-driven robotics depends critically on the accuracy of\nO\nO\n.\nTo generate\nO\nO\n, our design leverages the semantic reasoning capabilities of LLMs to simulate the execution of\nC\nC\nby interpreting its textual content rather than executing the code in a real simulator. The LLM implements a function\nF\n:\nC\n×\nS\n×\nA\n→\nS\nF:C\\times S\\times A\\rightarrow S\nas a simulator that maps from a given code, current state, and action to the next state. Specifically, upon receiving a code script, the LLM-simulator simulates the execution of code, interprets the actions in the code, reasons about the corresponding state transitions, and predicts the next state. When the simulation completes, the LLM outputs its observation of the robot’s trajectory as the simulation outcome.\nTo further enhance the reliability and accuracy of our text-based simulation, we further design a system prompt framework. The system prompt of LLM-simulator is composed of\nrole\n,\nAPIs\n,\npolicies\n, and\nexamples\n1\n1\n1\nThe detailed design of the system prompt is provided in Appendix A\n.\n•\nRole:\nDefines the LLM agent responsible for simulating code execution by analyzing the provided code, inferring the intended actions, and outputting a description of the robot’s trajectory.\n•\nAPIs:\nProvide definitions of robot action that guide the LLM in understanding the code’s intent, enabling inference actions\nl\nl\nand their corresponding state transitions\nT\nT\nencoded within the text of the code\nC\nC\n.\n•\nPolicies:\nInstruct the LLM with the code execution polices where the LLM lacks prior knowledge. The policies clarify the APIs usage, state transition rules, and environmental settings.\n•\nExamples:\nConsist of pairs of code and trajectory that demonstrate how a robot operation code script\nC\nC\nshould be interpreted into semantic observation\nO\nO\n. These examples guide the LLM via few-shot learning, enabling the LLM-simulator to generate observations\nO\nO\nthat follow the same style and structure.\nAs demonstrated in Fig\n2\n, the structured system prompt enables the LLM simulation to accurately produce an observation of the UAV actions, which facilitates the subsequent evaluation to identify the mismatches.\nIII-D\nEvaluation\nIn evaluation, the evaluator identifies the mismatches (if any) between the observation\nO\nO\nand the task description, and then provides feedback specifying the mismatched actions. To ensure evaluation accuracy, we adopted the evaluator design in\n[\nCLGSCE\n]\n, which has demonstrated effectiveness in identifying the deviations between the UAV’s trajectory and task description. The feedback from the evaluation provides the code generator with a clearer understanding of the objectives implied by the task description, thereby steering the generation of corrected code to better align with the task.\nIV\nEXPERIMENT\nIV-A\nExperiment Setup\nIV-A1\nExperimental Environment\nWe implement our proposed method and comparison method using OpenAI “o3-mini” (o3-mini-2025-01-31)\n[\no3mini\n]\nand “o4-mini” (o4-mini-2025-04-16)\n[\no4mini\n]\nas the foundational LLMs. To measure the performance of the methods, the experiment is conducted on a quadcopter on both the simple_flight flight controller in AirSim\n[\nAirSim\n]\nand the PX4 flight controller\n[\nPX4\n]\nin Gazebo\n[\ngazebo\n]\n2\n2\n2\nSimulator configurations and setups are provided in Appendix B\n. During the experiment, UAV state information was accessible from the simulators and utilized for performance measurement purposes. Furthermore, all experiments are averaged over three repetitions to mitigate the randomness of LLM generation\n[\nLLMrandomness\n]\n.\nIV-A2\nTask Dataset\nFor the experiments, we adopt the Advanced task set from\n[\nCLGSCE\n]\nas the benchmark dataset to measure the performance. The Advanced task set contains 20 UAV operation tasks with varying levels of complexity, each involving 6-19 actions to reach the goal state. The tasks are designed to emulate real-world UAV operation scenarios that require complex reasoning about the UAV’s state in the world environment, such as flying complex geometric patterns with scenario requirements. To ensure the authenticity of the result, all tasks are manually validated in both AirSim and Gazebo to avoid potential simulation-induced errors that could affect the experiment result.\nIV-A3\nCompared Method\nWe compare our method against four methods:\n•\nDirect Analysis (Direct):\nUses the semantic checker from\n[\nAutoTAMP\n]\n, where an LLM agent directly analyzes whether the generated code aligns with the task and provides feedback for code correction.\n•\nSimulator-based (Numerical):\nDynamically executes the generated code in a simulator to obtain numerical state observations, which are then evaluated to provide feedback for code correction\n[\nInteractivePlanning\n]\n.\n•\nSimulator-based (Semantic):\nA SOTA method extends the Numerical method\n[\nInteractivePlanning\n]\nby transforming numerical state observations produced from the simulator into semantic trajectory descriptions\n[\nCLGSCE\n]\nto improve the code correction efficiency. During the experiments, we modified the transformation algorithm to accommodate different robots and simulators.\nIV-B\nEvaluation Setup\nIV-B1\nEvaluation Metrics\nFollowing\n[\nCLGSCE\n]\n, we evaluate performance using\nCompleteness\nand\nSuccess Rate (SR)\n.\nCompleteness\nmeasures the proportion of actions in a given task that are executed correctly. It is computed as the ratio between the number of correctly executed actions and the total number of actions in the ground-truth sequence. This metric provides insight into performance throughout the intermediate execution process. For a given task\ni\ni\n, the completeness is defined as:\nCompleteness\ni\n=\n|\na\ni\ncorrect\n|\n|\nl\ni\ngt\n|\n\\mathrm{Completeness}_{i}=\\frac{|a^{\\mathrm{correct}}_{i}|}{|l^{\\mathrm{gt}}_{i}|}\n(1)\nwhere (\na\ni\ncorrect\na^{\\mathrm{correct}}_{i}\n) denotes the count of actions correctly executed for task\ni\ni\n, and (\nl\ni\ngt\nl^{\\mathrm{gt}}_{i}\n) is the total number of actions in the task’s ground truth. The overall completeness is averaged over\nn\nn\ntasks.\nSR\nreflects task-level reliability by measuring whether the robot successfully reaches the final goal state while following the correct sequence of actions that produce the intended state transitions. A task is considered successful only if the complete trajectory is executed without errors (\nS\n​\nR\ni\n=\n1\n,\nif\n​\nCompleteness\ni\n≡\n1\nSR_{i}=1,\\text{ if }\\mathrm{Completeness}_{i}\\equiv 1\n).\nIV-B2\nGround Truth\nThe ground truth is represented by a list of state transitions. Each state transition is a vector of four elements:\n[\nx\n,\ny\n,\nz\n,\nθ\n]\n[x,y,z,\\theta]\n, where\nx\nx\n,\ny\ny\n, and\nz\nz\ndenote the robot’s position changes in the North, East, and Down axes, and\nθ\n\\theta\nrepresents yaw rotation.\nIV-C\nResult and Analysis\nIV-C1\nOverall Result\nThe overall performance of our proposed method and comparison methods on both simple_flight controller in AirSim and PX4 controller in Gazebo are summarized in Table\nI\nand Table\nII\n. For both LLM models, our LLM-simulator consistently supports reliable corrective code generation across different robot configurations, achieving success rates above\n85\n%\n85\\%\non the simple_flight controller and\n86.7\n%\n86.7\\%\non the PX4 controller. These results demonstrate both the reliability of our text-based simulation and its adaptability across diverse robot systems.\nIn particular, our method achieves performance comparable to the SOTA Semantic method\n[\nCLGSCE\n]\nwithout requiring dynamic code execution in simulators that are explicitly designed to support robot simulations. This highlights that the proposed LLM-simulator can reliably conduct static text-based simulation of robot code to support corrective code generation. Furthermore, our method outperforms the Numerical method\n[\nInteractivePlanning\n]\n, indicating that the semantic observations generated by our LLM-simulator capture richer semantics about the robot’s trajectory dynamics than the numerical representations. This enables an equally effective correction process as the SOTA Semantic method\n[\nCLGSCE\n]\n, but without the need for customizing algorithms for different robot configurations to transform numerical states into semantic descriptions. In contrast, the Direct method\n[\nAutoTAMP\n]\nyields unreliable performance, proving the limitations of directly configuring LLMs to analyze code and highlighting the necessity to strengthen LLM’s capabilities for LLM-based simulation.\nTABLE I:\nResults of UAV with Simple_Flight Controller\no3-mini\no4-mini\nSR\nCompleteness\nSR\nCompleteness\nDirect\n[\nAutoTAMP\n]\n43.3\n%\n43.3\\%\n70.9\n%\n70.9\\%\n33.3\n%\n33.3\\%\n57.6\n%\n57.6\\%\nNumerical\n[\nInteractivePlanning\n]\n73.3\n%\n73.3\\%\n92.4\n%\n92.4\\%\n81.7\n%\n81.7\\%\n96.1\n%\n96.1\\%\nSemantic\n[\nCLGSCE\n]\n85.0\n%\n\\mathbf{85.0}\\%\n98.5\n%\n\\mathbf{98.5}\\%\n88.3\n%\n88.3\\%\n98.1\n%\n98.1\\%\nOurs\n85.0\n%\n\\mathbf{85.0}\\%\n97.0\n%\n97.0\\%\n90.0\n%\n\\mathbf{90.0\\%}\n98.3\n%\n\\mathbf{98.3}\\%\nTABLE II:\nResults of UAV with PX4 Controller\no3-mini\no4-mini\nSR\nCompleteness\nSR\nCompleteness\nDirect\n[\nAutoTAMP\n]\n55.0\n%\n55.0\\%\n77.5\n%\n77.5\\%\n25.0\n%\n25.0\\%\n50.9\n%\n50.9\\%\nNumerical\n[\nInteractivePlanning\n]\n83.3\n%\n83.3\\%\n97.1\n%\n97.1\\%\n86.7\n%\n86.7\\%\n96.9\n%\n96.9\\%\nSemantic\n[\nCLGSCE\n]\n88.3\n%\n\\mathbf{88.3}\\%\n98.3\n%\n\\mathbf{98.3}\\%\n93.3\n%\n\\mathbf{93.3}\\%\n98.6\n%\n\\mathbf{98.6}\\%\nOurs\n86.7\n%\n86.7\\%\n97.7\n%\n97.7\\%\n93.3\n%\n\\mathbf{93.3}\\%\n96.9\n%\n96.9\\%\nIV-C2\nText-Based Simulation Accuracy\nTo further evaluate the reliability of our text-based simulation, we compare the accuracy of the trajectory observations generated by the LLM-simulator against those obtained using the Semantic method\n[\nCLGSCE\n]\nin the dynamic simulator. For each task in the Advanced task set, we construct a corresponding ground truth code (\nC\ncorrect\nC^{\\text{correct}}\n) that implements the task. The LLM-simulator is then used to statically simulate the execution of each\nC\ni\ncorrect\nC^{\\text{correct}}_{i}\nand produce trajectory observations. The accuracy of the simulation is computed as\nT\n​\nP\n/\nN\n×\n100\n%\nTP/N\\times 100\\%\n, where\nT\n​\nP\nTP\ndenotes the number of observations that accurately capture the robot trajectory dynamics, and\nN\nN\nis the total number of simulated code in\nC\ncorrect\nC^{\\text{correct}}\n.\nAs shown in Table\nIII\n, the LLM-simulator achieves\n97.5\n%\n97.5\\%\naccuracy on “o3-mini” and\n100\n%\n100\\%\non “o4-mini” in capturing robot trajectory dynamics. These results demonstrate that the proposed LLM-simulator can reliably simulate the execution of robot actions, reason over the state transitions, and predict subsequent robot states. Therefore, the observation from the text-based simulation accurately reflects the intended robot’s trajectory dynamics from the code, enabling the evaluator to effectively detect mismatched actions in the code.\nTABLE III:\nText-Base Simulation Observation Accuracy\no3-mini\no4-mini\nSemantic\n[\nCLGSCE\n]\n100.0\n%\n100.0\\%\n100.0\n%\n100.0\\%\nOurs\n97.5\n%\n97.5\\%\n100.0\n%\n100.0\\%\nIV-C3\nText-Based Simulation Evaluation Accuracy\nTABLE IV:\nEvaluation Accuracy over Observations from LLM-Simulator\no3-mini\no4-mini\nAvg.\nC\ncorrect\nC^{\\text{correct}}\nC\nincorrect\nC^{\\text{incorrect}}\nC\ncorrect\nC^{\\text{correct}}\nC\nincorrect\nC^{\\text{incorrect}}\nSemantic\n[\nCLGSCE\n]\n90.0\n%\n90.0\\%\n91.7\n%\n91.7\\%\n93.3\n%\n93.3\\%\n93.3\n%\n93.3\\%\n92.1\n%\n92.1\\%\nOurs\n91.7\n%\n91.7\\%\n90.0\n%\n90.0\\%\n93.3\n%\n93.3\\%\n91.7\n%\n91.7\\%\n91.7\n%\n91.7\\%\nWe further analyze whether the observations generated by the LLM-simulator can effectively support the evaluation process. Specifically, we compare the evaluation accuracy when using observations generated by our LLM-simulator against those produced from the Semantic method\n[\nCLGSCE\n]\n. This experiment leverages the ground-truth code set\nC\ncorrect\nC^{\\text{correct}}\nin section\nIV-C2\n, along with an additional set\nC\nincorrect\nC^{\\text{incorrect}}\nthat contains at least one error action in code for each task. The evaluation accuracy is computed as\n(\nT\n​\nP\n+\nT\n​\nN\n)\n/\nN\n×\n100\n%\n(TP+TN)/N\\times 100\\%\n, where\nT\n​\nP\nTP\ndenotes the number of correct evaluations on\nC\ncorrect\nC^{\\text{correct}}\nand\nC\nincorrect\nC^{\\text{incorrect}}\n(i.e., correctly identifying whether the trajectory matches with the task and providing a detailed explanation if mismatches are identified), and\nN\nN\nis the total number of evaluated code scripts.\nAs presented in Table\nIV\n, our method achieves over\n90\n%\n90\\%\naccuracy on “o3-mini” and\n91.7\n%\n91.7\\%\naccuracy on “o4-mini”. The results are comparable to the Semantic method\n[\nCLGSCE\n]\nwithout the need for modifying algorithms for each robot and simulator to transform numerical states into semantic descriptions. The results also demonstrate that the observations from the LLM-simulator are sufficient to support effective evaluation as the SOTA Semantic method\n[\nCLGSCE\n]\nand are adaptable to different robot systems.\nHowever, due to the non-determinism of LLM generation\n[\nNon-determinism\n]\n, identical actions may yield semantically equivalent but syntactically different observations. For example, the action “fly 5 meters south” from the text-based simulation may be produced as “followed by 5 meters back (returning in the north-south direction)”. While such descriptions remain interpretable to humans, their implicit ambiguity can cause misinterpretations for LLMs\n[\nambiguity-misinterpret\n]\n. Consequently, observations generated by the Semantic method\n[\nCLGSCE\n]\nexhibit slightly higher evaluation accuracy, as they are deterministic and free from linguistic variations.\nIV-D\nAblation Study on LLM-Simulator Design\nWe conduct an ablation study on the design of our LLM-simulator. Specifically, we investigate how different components of the LLM’s system prompt affect the overall system performance. As specified in Section\nIII-D\n, the\nrole\ndefines the LLM to be a simulator and the\nAPIs\nprovide definitions of robot action APIs, they serve as the essential component to ensure the LLM performs the text-based simulation. Thus, they are retained in the ablation study. For the remaining components, we remove\npolices\n,\nexamples\n, and both\npolices\nand\nexamples\nto measure their impact on the overall system performance. The results in Table\nV\nshow that removing either\npolices\nor\nexamples\nleads to degradation in performance, while removing both yields the largest decline. Furthermore, removing\nexamples\nproduces a larger negative impact than removing\npolices\n, which is consistent with prior evidence that LLMs exhibit strong few-shot learning capabilities\n[\nllm-fewshot\n]\n. The results of the ablation study highlight that both instructing the LLM with code execution rules (\npolices\n) and providing demonstrations (\nexamples\n) are essential for enhancing the performance of the LLM-simulator, and their combination yields the best overall performance.\nTABLE V:\nOverall System Performance over LLM-Simulator Design\nOurs\nw/o\nw/o\nw/o polices\npolices\nexamples\n& examples\no3-mini\nSR\n85.0\n%\n\\mathbf{85.0\\%}\n83.3\n%\n83.3\\%\n81.7\n%\n81.7\\%\n71.7\n%\n71.7\\%\nCompleteness\n97.0\n%\n\\mathbf{97.0\\%}\n94.9\n%\n94.9\\%\n94.0\n%\n94.0\\%\n90.8\n%\n90.8\\%\no4-mini\nSR\n91.7\n%\n\\mathbf{91.7\\%}\n83.3\n%\n83.3\\%\n83.3\n%\n83.3\\%\n68.3\n%\n68.3\\%\nCompleteness\n97.7\n%\n\\mathbf{97.7\\%}\n96.1\n%\n96.1\\%\n95.1\n%\n95.1\\%\n93.1\n%\n93.1\\%\nV\nREAL-WORLD DEPLOYMENT\nWe validate our method through the deployment of physical robotic platforms. For consistency, the deployment is conducted using OpenAI’s “o3-mini” and “o4-mini” models, and the performance of robot deployment is measured using the same metrics defined in section\nIV-A\n.\nV-A\nRobot Setup\nV-A1\nUAV\nWe deploy our method on the Holybro X500 V2 quadcopter equipped with a Pixhawk 6X flight controller running PX4 firmware. For the task set, we select two tasks from each complexity level of the Advanced task set, resulting in a total of 8 tasks for deployment. In the deployment, the user types the task description into a ground station computer that runs our method to generate the UAV operation code (the computer is connected to the Internet for accessing the OpenAI API). The generated code is then transmitted to the flight controller via MAVSDK\n[\nmavsdk\n]\nfor task execution. During the flight, the UAV’s state information is collected through MAVSDK for performance measurement.\nV-A2\nGround Vehicle\nWe further evaluate the method on a ROSMASTER X3 ground vehicle controlled by ROS\n[\nROS\n]\n. We then design 8 tasks for the ground vehicle to form patterns when driving on the ground. In the deployment, the user accesses the onboard computer remotely and types in the task descriptions, then the onboard computer (connected to the Internet for accessing the OpenAI API) runs our method to generate the ground vehicle operation code and then executes the code to control the vehicle’s movement.\nV-B\nResult and Analysis\nTABLE VI:\nRobot Deployment Performance\no3-mini\no4-mini\nSR\nCompleteness\nSR\nCompleteness\nUAV\n87.5\n%\n87.5\\%\n98.6\n%\n98.6\\%\n91.7\n%\n91.7\\%\n97.9\n%\n97.9\\%\nGround Vehicle\n87.5\n%\n87.5\\%\n96.9\n%\n96.9\\%\n87.5\n%\n87.5\\%\n97.2\n%\n97.2\\%\nThe results of the real-world deployment are summarized in Table\nVI\n. Overall, our method demonstrates consistent performance across both UAV and ground vehicle platforms, validating the effectiveness of the proposed LLM-simulator in real-world settings. On both the UAV and ground vehicle tasks, our approach achieves high success rates and completeness, confirming the reliability and adaptability of our framework to different robot systems. These findings highlight that the static text-based simulation framework is reliable in supporting corrective code generation in real-world robot execution.\nVI\nCONCLUSIONS\nThis paper presented an enhanced LLM-Driven corrective robot operation code generation framework. Different from existing solutions that require dynamic execution in a physical or simulation environment for code feedback and refinement, our framework is designed with a novel static text-based simulation solution powered by LLM, and hence addresses the challenges brought by the configuration of a dynamic code execution environment and potential long execution time for refinement.\nThe experiment results on both different UAV systems validated the performance of our simulation solution in terms of both simulation accuracy and the reliability of robot operation code generation. Moreover, real-world deployments on physical robots further demonstrated the adaptability of our framework across different configurations and environments.\nAPPENDIX\nVI-A\nLLM-Simulator System Prompt\nRole:\nYou will analyze and infer the intention of the provided Python drone control code, then generate a description of the drone actions in one paragraph.\nYou should focus on the code, not the comments. Because code will be the actual actions of the drone.\nAPIs:\nHere are the available functions for the drone when you infer the drone actions and their state transitions:\naw.takeoff()\n- takes off the drone.\naw.land()\n- lands the drone.\naw.fly_to([x, y, z])\n- flies the drone to the position specified as a list of three arguments corresponding to world XYZ coordinates.\naw.get_yaw()\n- returns the current yaw of the drone in degrees.\naw.set_yaw(yaw)\n- sets the yaw of the drone to the specified value in degrees.\naw.get_drone_position()\n- returns the current position of the drone as a list of 3 floats corresponding to world XYZ coordinates.\nPolices:\nImportant drone coordinate directional information and action polices:\n1. The horizontal axes are Y and X, the vertical axis is Z.\n2. When rotating the drone, turning right or clockwise means positive, the yaw angle should increase.\n3.\naw.fly_to([x, y, z])\nfunction uses NED coordinate system (world coordinates), positive X axis is North/forward, positive Y axis is East/right, positive Z axis is Down. When flying up, the Z value should decrease. When flying down, the Z value should increase.\n4. The drone is initialized facing north (Yaw = 0 degrees).\n5. Map Yaw angle degree from -180 to 180, for example: map 270 to -90.\nExamples:\nBelow are some examples; you should follow the output format in these examples in your answers.\nQuery: “\ncurrent_position = aw.get_drone_position()\naw.fly_to([current_position[0], current_position[1], current_position[2] - 10])\n”\nAnswer:\n“The drone flies 10 meters up.”\nQuery: “\naw.takeoff()\ncurrent_position = aw.get_drone_position()\naw.fly_to([current_position[0], current_position[1], current_position[2] - 5])\ncurrent_position = aw.get_drone_position()\naw.set_yaw(90)\naw.fly_to([current_position[0] + 5, current_position[1], current_position[2]])\ncurrent_position = aw.get_drone_position()\ncurrent_yaw = get_yaw()\naw.set_yaw(90 + current_yaw)\naw.fly_to([current_position[0], current_position[1] + 5, current_position[2]])\ncurrent_position = aw.get_drone_position()\ncurrent_yaw = get_yaw()\naw.set_yaw(90 + current_yaw)\naw.fly_to([current_position[0] - 5, current_position[1], current_position[2]])\ncurrent_position = aw.get_drone_position()\ncurrent_yaw = get_yaw()\naw.set_yaw(90 + current_yaw)\naw.fly_to([current_position[0], current_position[1] - 5, current_position[2]])\n”\nAnswer:\n“First, the drone takes off and climbs 5 m. Next, it rotates 90 degrees clockwise (now facing east) and flies to a point 5 m north along the world X axis. It then rotates 90 degrees clockwise (now facing south), and flies 5 m west along the world Y axis. Then rotate 90 degrees clockwise (now facing west), fly 5 m south along world X axis. Then rotate 90 degrees clockwise (now facing north) and fly 5 m east along world Y axis.”\nVI-B\nSimulator Configurations\nIn our experiments, we employ two widely used simulators: AirSim\n[\nAirSim\n]\nand Gazebo\n[\ngazebo\n]\n.\nVI-B1\nAirSim\nDeveloped by Microsoft, AirSim provides a high-fidelity virtual environment for research in autonomous systems such as UAVs, self-driving cars, and ground robots. Built on Unreal Engine\n[\nunreal\n]\n, it supports realistic rendering of robot dynamics. In our experiments, we use the pre-built “block”\n[\nBlocks\n]\nenvironment, which provides a clear and open airspace suitable for UAV testing.\nVI-B2\nGazebo\nGazebo\n[\ngazebo\n]\nmodels physical dynamics such as gravity, friction, and contact forces, making it applicable to both aerial and ground robots. It integrates seamlessly with the ROS operating system\n[\nROS\n]\n. For our experiments, we use the PX4\n[\nPX4\n]\nsoftware-in-the-loop (SITL) setup to control a simulated quadcopter within a virtual world environment of Gazebo.",
  "preview_text": "Recent advances in Large language models (LLMs) have demonstrated their promising capabilities of generating robot operation code to enable LLM-driven robots. To enhance the reliability of operation code generated by LLMs, corrective designs with feedback from the observation of executing code have been increasingly adopted in existing research. However, the code execution in these designs relies on either a physical experiment or a customized simulation environment, which limits their deployment due to the high configuration effort of the environment and the potential long execution time. In this paper, we explore the possibility of directly leveraging LLM to enable static simulation of robot operation code, and then leverage it to design a new reliable LLM-driven corrective robot operation code generation framework. Our framework configures the LLM as a static simulator with enhanced capabilities that reliably simulate robot code execution by interpreting actions, reasoning over state transitions, analyzing execution outcomes, and generating semantic observations that accurately capture trajectory dynamics. To validate the performance of our framework, we performed experiments on various operation tasks for different robots, including UAVs and small ground vehicles. The experiment results not only demonstrated the high accuracy of our static text-based simulation but also the reliable code generation of our LLM-driven corrective framework, which achieves a comparable performance with state-of-the-art research while does not rely on dynamic code execution using physical experiments or simulators.\n\nLLM-Driven Corrective Robot Operation Code Generation with Static Text-Based Simulation\nWenhao Wang\n, Yi Rong, Yanyan Li\n, Long Jiao\n, Jiawei Yuan\nThis work is supported by the US National Science Foundation awards 2318710 and 2318711.Wenhao Wang, Yi Rong, Long Jiao, and Jiawei Yuan are with the Department of CIS, University of Massachusetts Dartmouth\n{wwang5, yrong, ljia",
  "is_relevant": false,
  "relevance_score": 2.0,
  "extracted_keywords": [
    "LLM-driven code generation",
    "corrective framework",
    "static simulation",
    "robot operation",
    "text-based simulation"
  ],
  "one_line_summary": "本文提出了一种基于大语言模型的静态文本仿真框架，用于提升机器人操作代码生成的可靠性，不依赖物理实验或动态仿真环境。",
  "detailed_summary": "",
  "qa_pairs": [],
  "is_hidden": false,
  "is_starred": false,
  "published_date": "2025-12-01T18:57:10Z",
  "created_at": "2026-01-09T09:59:25.675240",
  "updated_at": "2026-01-09T09:59:25.675252"
}