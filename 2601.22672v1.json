{
    "id": "2601.22672v1",
    "title": "Postural Virtual Fixtures for Ergonomic Physical Interactions with Supernumerary Robotic Bodies",
    "authors": [
        "Theodora Kastritsi",
        "Marta Lagomarsino",
        "Arash Ajoudani"
    ],
    "abstract": "ä½œä¸ºé™„åŠ æœºæ¢°ä½“ï¼ˆSRBsï¼‰çš„ååŒæœºå™¨äººèƒ½å¤Ÿå¢å¼ºäººç±»çš„è´Ÿé‡èƒ½åŠ›ã€‚ç„¶è€Œï¼Œåœ¨æ¶‰åŠä¸äººä½“ç‰©ç†äº¤äº’çš„ä»»åŠ¡ä¸­ï¼Œç”¨æˆ·ä»å¯èƒ½é‡‡å–ä¸è‡ªç„¶ã€ä¸ç¬¦åˆäººä½“å·¥å­¦çš„å§¿åŠ¿ï¼Œé•¿æœŸå¦‚æ­¤å¯èƒ½å¯¼è‡´ä¸é€‚æˆ–æŸä¼¤ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹æ§åˆ¶æ¡†æ¶ï¼Œå½“æ£€æµ‹åˆ°éäººä½“å·¥å­¦å§¿åŠ¿æ—¶ï¼Œè¯¥æ¡†æ¶èƒ½ä¸ºSRBç”¨æˆ·æä¾›åŠ¨è§‰åé¦ˆï¼Œé€šè¿‡æ–½åŠ é˜»åŠ›æ¥é˜»æ­¢æ­¤ç±»è¡Œä¸ºã€‚è¯¥æ–¹æ³•æ—¨åœ¨ä¿ƒä½¿ç”¨æˆ·é•¿æœŸå­¦ä¹ ç¬¦åˆäººä½“å·¥å­¦çš„ä¹ æƒ¯ï¼Œå¹¶åœ¨ç‰©ç†äº¤äº’è¿‡ç¨‹ä¸­ä¿æŒæ­£ç¡®å§¿åŠ¿ã€‚ä¸ºå®ç°è¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§è™šæ‹Ÿå¤¹å…·æ–¹æ³•ï¼Œå¹¶å°†å…¶ä¸æŒç»­åœ¨çº¿çš„äººä½“å·¥å­¦å§¿åŠ¿è¯„ä¼°æ¡†æ¶ç›¸ç»“åˆã€‚æ­¤å¤–ï¼Œä¸ºæå‡æ“ä½œè€…ä¸SRBï¼ˆç”±å®‰è£…åœ¨æµ®åŠ¨åŸºåº§ä¸Šçš„æœºæ¢°è‡‚æ„æˆï¼‰ä¹‹é—´çš„åè°ƒæ€§ï¼Œç³»ç»Ÿä¼šæ ¹æ®éœ€è¦è°ƒæ•´æµ®åŠ¨åŸºåº§çš„ä½ç½®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥äººä½“å·¥å­¦é©±åŠ¨æ§åˆ¶æ¡†æ¶å…·æœ‰è‰¯å¥½åŠŸèƒ½ä¸æœ‰æ•ˆæ€§ï¼Œå…¶ä¸­åŒ…æ‹¬ä¸¤é¡¹æ¶‰åŠ14åå—è¯•è€…çš„å®é™…ç§»åŠ¨æ“ä½œä»»åŠ¡ç”¨æˆ·ç ”ç©¶ï¼Œå¹¶å°†æ‰€ææ¡†æ¶ä¸æœªè€ƒè™‘äººä½“å·¥å­¦å› ç´ çš„åŸºå‡†æ§åˆ¶æ¡†æ¶è¿›è¡Œäº†å¯¹æ¯”ã€‚",
    "url": "https://arxiv.org/abs/2601.22672v1",
    "html_url": "https://arxiv.org/html/2601.22672v1",
    "html_content": "\\corrauth\nTheodora Kastritsi,\nPostural Virtual Fixtures for Ergonomic Physical Interactions with Supernumerary Robotic Bodies\nTheodora Kastritsi\nMarta Lagomarsino\nand Arash Ajoudani\nAuthors are with Human-Robot Interfaces and Interaction Laboratory, Istituto Italiano di Tecnologia, Genoa, Italy.\ntkastrit@gmail.com\nAbstract\nConjoined collaborative robots, functioning as supernumerary robotic bodies (SRBs), can enhance human load tolerance abilities. However, in tasks involving physical interaction with humans, users may still adopt awkward, non-ergonomic postures, which can lead to discomfort or injury over time. In this paper, we propose a novel control framework that provides kinesthetic feedback to SRB users when a non-ergonomic posture is detected, offering resistance to discourage such behaviors. This approach aims to foster long-term learning of ergonomic habits and promote proper posture during physical interactions. To achieve this, a virtual fixture method is developed, integrated with a continuous, online ergonomic posture assessment framework. Additionally, to improve coordination between the operator and the SRB, which consists of a robotic arm mounted on a floating base, the position of the floating base is adjusted as needed. Experimental results demonstrate the functionality and efficacy of the ergonomics-driven control framework, including two user studies involving practical loco-manipulation tasks with 14 subjects, comparing the proposed framework with a baseline control framework that does not account for human ergonomics.\nkeywords:\nHuman Performance Augmentation,\nPhysical Human-Robot Interaction,\nCompliance and Impedance Control,\nWhole-Body Motion Planning and Control,\nHuman Factors and Human-in-the-loop\n1\nINTRODUCTION\nTechnological advancements have enabled the augmentation of human capabilities through robotics, transforming what was once a futuristic vision into reality. Exoskeletons, for instance, have shown significant promise in enhancing human strength, allowing users to perform physically demanding tasks more efficiently. However, some challenges remain, such the additional weight that strains joints and muscles\n(De Looze\net al.\n,\n2016\n; BÃ¤r\net al.\n,\n2021\n)\n, operational pressures that can lead to discomfort or tissue irritation\n(Kermavnar\net al.\n,\n2021\n)\n, and limitations in natural movement, mobility, and postural balance\n(Kermavnar\net al.\n,\n2021\n; Theurel and Desbrosses,\n2019\n)\n.\nAnother significant innovation in human augmentation is the development of supernumerary robotic limbs (SRLs), which are wearable robotics devices designed to extend human capabilities. SRLs by providing additional robotic limbs, such as extra arms, legs, or fingers, can also compensate for lost motor functions in individuals with physical impairments\n(Hendriks\net al.\n,\n2024\n)\n. SRLs hold substantial potential, as they can be attached at various points on the body and adopt diverse structural configurations, enabling them to support the user and perform a wide range of auxiliary functions. To achieve this, they require an interface with the human user, which can be implemented in multiple ways; for example, it may include motion tracking, EEG-based control, or EMG-based control\n(Eden\net al.\n,\n2022\n; Prattichizzo\net al.\n,\n2021\n)\n. Recent work has also demonstrated multimodal control of an extra robotic arm using gaze and respiration signals\n(Dominijanni\net al.\n,\n2023\n)\n. Despite their advantages, SRLs share several limitations with exoskeletons, including weight, discomfort, and reduced mobility\n(Tong and Liu,\n2021\n)\n, that limit their practical usability. Like exoskeletons, they rely heavily on human coupling for operation, often redistributing the load from one limb to another rather than fully alleviating it. In particular, in setups that incorporate large robotic limbs, the user must support not only the weight of the external loads but also the weight of the device itself. Although recent efforts have been made to develop lightweight systems\n(Hasanen\net al.\n,\n2024\n)\n, the limited durability of their components and low payload capacity continue to restrict their practical usability. Additionally, SRLs face unique challenges, such as compensating for interference from the wearerâ€™s body motion to achieve robot-like precision\n(Tong and Liu,\n2021\n)\n.\nToday, essential aspects such as wearability, efficiency, and usability remain unresolved for these technologies\n(Yang\net al.\n,\n2021\n)\n.\nTo overcome these limitations, supernumerary robotic bodies (SRBs) have recently emerged as a promising solution for physically assisting and augmenting humans in conjoined loco-manipulation tasks\n(Kim\net al.\n,\n2020\n; Giammarino\net al.\n,\n2024\n)\n. Unlike exoskeletons and SRLs, which are often constrained by their reliance on the human body and carry significant weight, SRBs are floating-base robotic manipulators that, like SRLs, can adopt various structural configurations but uniquely ground external loads, eliminating extra weight on the user and ensuring comfort and mobility. SRBs, like SRLs, require a human interface, which in the case of SRBs can be attached to or detached from the robot, enabling local control and teleoperation, respectively\n(Raei\net al.\n,\n2024\n)\n. In particular, the local control is equipped with an admittance-type interface that provides an intuitive modality for physical human-robot interaction (pHRI), allowing the users to directly command the robotâ€™s motion. By decoupling the human-exerted force from the environmental force, SRBs enable the robot to handle heavy tools while allowing the user to guide the end-effector effortlessly.\nFurthermore, when not operated by humans, SRBs can function autonomously, reducing equipment downtime and associated operational costs. While SRBs offer significant potential for enhancing task efficiency and reducing physical demands, improper usage during pHRI can still pose long-term health risks to workers. This is especially true in scenarios where human operators adopt and sustain awkward, non-ergonomic postures while interacting with the SRBs. Even in low-load situations, poor posture can result in increased musculoskeletal strain, reduced circulation, joint misalignment, and other related issues, ultimately compromising worker well-being over time\n(Lorenzini\net al.\n,\n2023\n)\n. This remaining issue can undermine the ergonomic benefits of SRBs, hence, advanced control strategies and online monitoring systems are essential to exploit their full potential. By integrating adaptive ergonomics monitoring and intelligent feedback mechanisms, SRBs can dynamically adjust their behavior to support the operatorâ€™s posture and minimize the risk of strain, thereby enhancing both safety and efficiency in collaborative work environments.\n1.1\nRelated Works\n1.1.1\nPostural Ergonomics:\nResearch on ergonomic posture assessment, such as in\nMcAtamney and Corlett (\n1993\n); Hignett and McAtamney (\n2000\n)\n, provides valuable insights into human body ergonomics through joint-angle-based evaluations. These assessments have been used to evaluate user comfort in human-robot interaction tasks offline\n(Morfino\net al.\n,\n2024\n)\nand have also contributed to the development of robotic strategies that support ergonomic collaboration, as reviewed in\nProia\net al.\n(\n2021\n); Lorenzini\net al.\n(\n2023\n)\n. In addition, online ergonomic assessments based on joint range of motion have been proposed in\nLorenzini\net al.\n(\n2022\n); Lagomarsino\net al.\n(\n2023\n)\n, assuming that the optimal joint position lies at the midpoint of its range, which may not hold true for all joints. Most existing strategies supporting ergonomic collaboration primarily focus on the planning level, aiming to position objects held by robots in ergonomically favorable poses for users\n(Shafti\net al.\n,\n2019\n; Zanchettin\net al.\n,\n2019\n)\n, without considering pHRI, which limits robotsâ€™ ability to dynamically respond to user-applied forces. To address this,\nFerraguti\net al.\n(\n2020\n)\nintroduced a framework that combines ergonomic positioning with admittance control. However, this approach does not account for user ergonomics during manipulation, allowing non-ergonomic postures to emerge despite an initially ergonomic setup. In a recent work,\nLiao\net al.\n(\n2023\n)\nutilizes an SRB for the co-transportation of an object and an admittance control model designed to guide the userâ€™s wrist toward a more ergonomic position via a virtual force. However, this approach only considers motion in the sagittal plane for generating the virtual force and lacks passivity analysis, which is crucial for ensuring stable pHRI\n(Keemink\net al.\n,\n2018\n)\n. Hence, the remaining challenge is to develop a method that can be integrated into the SRB control framework to effectively promote and maintain good postures during pHRI.\n1.1.2\nVirtual Fixture:\nTo provide kinesthetic feedback and assist human operators in scenarios with partial task knowledge, the concept of Virtual Fixture (VF) has been widely explored in the field of pHRI, as well as in other areas such as teleoperation, where it was first proposed\n(Rosenberg,\n1992\n)\n. Virtual Fixtures (VFs) are implemented to influence robot motion by guiding it within predefined desired regions, called Guidance VFs, or preventing it from entering forbidden or sensitive areas, known as Forbidden-Region VFs. A review of VFs can be found in\nBowyer\net al.\n(\n2013\n)\n. Various approaches to enforcing VFs exist; some use energy storage techniques, such as artificial potential fields\n(Kastritsi\net al.\n,\n2019\n)\nand the proxy/god-object approach\n(Ryden\net al.\n,\n2011\n)\n, while others avoid energy storage, incorporating friction models in impedance-controlled robots\n(Bowyer and y Baena,\n2015\n)\nor applying anisotropic projections of human-exerted forces in an admittance model\n(Castillo-Cruces and Wahrburg,\n2010\n)\n. However, the latter category does not provide kinesthetic feedback when the robot end-effector is stationary unless combined with an energy storage method. VFs are often represented using point clouds\n(Kastritsi\net al.\n,\n2019\n)\n, polygonal meshes\n(Zilles and Salisbury,\n1995\n; Ruspini\net al.\n,\n1997\n)\n, parametric curves or surfaces\n(Papageorgiou\net al.\n,\n2020a\n)\n, or Cartesian paths learned through demonstration\n(Papageorgiou\net al.\n,\n2020b\n)\n. However, these representations are typically defined in the robotâ€™s joint or task space, making them unsuitable for enforcing ergonomics-based virtual fixtures, as posture ergonomics is inherently human-centric and mapping between robot and human joint configurations is non-trivial. A recent work\n(Hu\net al.\n,\n2024\n)\nthat utilizes Guidance VF claims that by constraining the rotation of the robot end-effector, they achieve a more ergonomic posture for the user. However, this claim is not generally true and lacks support from both theoretical reasoning and experimental validation.\n1.1.3\nMobile Manipulators\n: Mobile manipulators, which combine a robotic arm with a mobile platform, offer enhanced mobility and adaptability in dynamic environments. However, they have not been widely adopted for physical human-robot collaboration. In recent years, advancements in sensor technology have facilitated their use in collaborative tasks with humans, such as hand-guiding\n(Navarro\net al.\n,\n2017\n)\n, co-transportation\n(Benzi\net al.\n,\n2022\n; Sirintuna\net al.\n,\n2024\n)\n, and assisted guidance\n(Balatti\net al.\n,\n2024\n)\n. Despite this progress, existing research has often overlooked the consideration of human ergonomics during collaboration, an important factor that can significantly impact user comfort, safety, and long-term effectiveness during physical interaction. Utilizing a mobile manipulator in the form of an SRB,\nLiao\net al.\n(\n2023\n)\nproposed an admittance control schema to guide the userâ€™s wrist ergonomically; however, it is limited to the sagittal plane and lacks passivity analysis. Furthermore, the framework overlooks the position of the human user, which can constrain their motion, hindering the task.\n1.2\nContributions\nFigure 1:\nBlock diagram illustrating the proposed methodology, outlining the key components and their interactions.\nMotivated by the aforementioned challenges and gaps, this work proposes a novel ergonomics-driven control framework for SRBs based on online human posture assessment and kinesthetic feedback. By providing kinesthetic feedback when non-ergonomic postures are detected, while dynamically adjusting the position of the floating base to optimize coordination between the user and the SRB, the proposed framework fosters a seamless and ergonomic pHRI. The key contributions of the proposed framework include:\nâ€¢\nErgonomics Postural Virtual Fixtures: For the first time, VF are designed with consideration for the userâ€™s postural ergonomics, helping to prevent poor ergonomics while preserving flexibility and autonomy in task execution.\nâ€¢\nPassivity Assurance: Through rigorous mathematical analysis, it is ensured that the desired dynamic behavior of the robot end-effector, combined with the Ergonomics Postural Virtual Fixtures, provides a passive framework. Passivity is not inherently guaranteed when using a VF approach and is particularly critical during physical human-robot interaction, as it ensures the safety of the user.\nâ€¢\nOnline Continuous RULA-based Ergonomics Assessment Metric: Based on the Rapid Upper Limb Assessment (RULA) of\nMcAtamney and Corlett (\n1993\n)\n, a metric is proposed and formulated as a continuous smooth function. Unlike conventional ergonomics metrics, which are often discontinuous or not designed with widely recognized ergonomics assessment tools in mind, the proposed method is specifically designed for seamless integration into robotic control frameworks and reflects a reliable ergonomic level of posture.\nâ€¢\nNull-space coordination: The redundancy of SRBs is exploited to ensure that the userâ€™s motion is not obstructed by repelling the SRBs floating base when the human is in close proximity, while simultaneously preventing the robot from colliding with obstacles in the environment.\nIn summary, this novel approach offers a robust solution for ergonomic-aware physical human-robot interaction, enhancing user safety and adaptability by reducing human physical load and avoiding non-ergonomic postures at the same time. This control framework surpasses a simple aggregation of a whole-body SRB controller, VF enforcement, null-space adaptation, and online human posture ergonomic assessment, making substantial contributions to the integration of these components and enhancing each individual aspect of the system. Two extensive user studies were conducted, demonstrating for the first time that Ergonomics Postural Virtual Fixtures help users adopt more ergonomic postures during conjoint loco-manipulation tasks, in addition to completely offloading the payloads at hand through the use of the proposed SRB, while also exhibiting a learning effect.\nThe rest of the paper is organized as follows. The\nPROPOSED METHODOLOGY\nsection presents the ergonomics-aware control framework illustrated by the block diagram in Figure\n1\n. Subsequently, the\nEXPERIMENTS\nsection outlines the implementation of the proposed solution, aimed at validating its effectiveness. This is followed by the\nEXPERIMENTAL RESULTS\nsection, which presents and analyzes the findings. Finally, the\nCONCLUSIONS\nsection summarizes the results and highlights potential future research directions.\n2\nPROPOSED METHODOLOGY\n2.1\nPostural Virtual Fixtures\nIn this subsection, the ergonomics-driven admittance model of the robot end-effector is proposed, introducing the motion dynamics of the postural virtual fixtures and providing the passivity analysis. One of the control objectives is to kinesthetically inform the user whenever a non-ergonomic posture is detected. To achieve this, the following admittance model is used to enable the robot to respond appropriately to the human generalized force\nğ…\nh\n=\n[\nğŸ\nh\nT\nâ€‹\nğ‰\nh\nT\n]\nT\nâˆˆ\nâ„\n6\n\\mathbf{F}_{h}=[\\mathbf{f}_{h}^{\\mathrm{T}}\\ \\bm{\\tau}_{h}^{\\mathrm{T}}]^{\\mathrm{T}}\\in\\mathbb{R}^{6}\nexerted on its end-effector:\nğŒ\nd\nâ€‹\nğ¯\nË™\n+\nğƒ\nd\nâ€‹\nğ¯\n=\nğ…\nh\n+\nğ®\nc\n\\mathbf{M}_{d}\\dot{\\mathbf{v}}+\\mathbf{D}_{d}\\mathbf{v}=\\mathbf{F}_{h}+\\mathbf{u}_{c}\n(1)\nwhere\nğ¯\n=\n[\nğ©\nË™\nâ€‹\nğ\n]\nT\nâˆˆ\nâ„\n6\n\\mathbf{v}=[\\dot{\\mathbf{p}}\\ \\;\\bm{\\omega}]^{\\mathrm{T}}\\in\\mathbb{R}^{6}\nis the robot end-effector generalised velocity,\nğŒ\nd\nâˆˆ\nâ„\n6\nÃ—\n6\n\\mathbf{M}_{d}\\in\\mathbb{R}^{6\\times 6}\nis a positive constant diagonal matrix of the target inertia\n,\nğƒ\nd\nâˆˆ\nâ„\n6\nÃ—\n6\n,\\ \\mathbf{D}_{d}\\in\\mathbb{R}^{6\\times 6}\nis a positive matrix of\nthe target damping, and\nğ®\nc\nâˆˆ\nâ„\n6\n\\mathbf{u}_{c}\\in\\mathbb{R}^{6}\nis a control term designed to provide kinesthetic feedback, encouraging the human operator to maintain an ergonomic posture.\nIn order to design the control term\nğ®\nc\n\\mathbf{u}_{c}\n, we introduce the concept of postural virtual fixtures, leveraging the idea of the god-object algorithm. Originally developed for haptic rendering in virtual environments, the god-object algorithm, also referred to as the proxy algorithm, allows the god-object to follow the robot end-effector in free space while remaining outside virtual obstacles defined in Cartesian space when contact between the obstacles and the god-object occurs. Then the deviation between the god-object and the robotâ€™s position is used to the robotâ€™s controller to generate haptic feedback, enabling realistic rendering of interactions. In contrast to the majority of existing works, here we express the motion of the god-object using a motion dynamics equation, rather than using an algorithmic approach, offering the possibility of providing passivity analysis in a closed form. Furthermore, the god-object here serves as an idealized representation of the robot end-effector pose, constrained to the space where the human posture is not at high risk, thus constructing the virtual fixture with consideration of the human side rather than the task. With this in mind, the motion dynamics of the god-object is expressed as follows:\nğ¯\ng\n=\nâˆ’\nk\nr\nâ€‹\nf\nâ€‹\n(\na\n,\nğ©\ne\n)\nâ€‹\n[\nğ©\ne\nÏµ\ne\n]\n{\\mathbf{v}}_{g}=-\\mathrm{k}_{r}f(a,\\mathbf{p}_{e})\\begin{bmatrix}\\mathbf{p}_{e}\\\\\n{\\bm{\\epsilon}_{e}}\\end{bmatrix}\n(2)\nwhere\nğ¯\ng\n=\n[\nğ©\nË™\ng\nâ€‹\nğ\ng\n]\nT\nâˆˆ\nâ„\n6\n{\\mathbf{v}}_{g}=[\\dot{\\mathbf{p}}_{g}\\ {\\bm{\\omega}_{g}}]^{\\mathrm{T}}\\in\\mathbb{R}^{6}\nis the god-object generalized velocity,\nk\nr\nâˆˆ\nâ„\n>\n\\mathrm{k_{r}}\\in\\mathbb{R}_{>}\nis a positive definite gain that, together with the value of the\nf\nâ€‹\n(\na\n,\nğ©\ne\n)\nf(a,\\mathbf{p}_{e})\n, affects the time of convergence,\nğ©\ne\n,\nÏµ\ne\nâˆˆ\nâ„\n3\n\\mathbf{p}_{e},\\ \\bm{\\epsilon}_{e}\\in\\mathbb{R}^{3}\nare the position and orientation deviations, respectively and\nf\nâ€‹\n(\na\n,\nğ©\ne\n)\nâˆˆ\n[\n0  1\n]\nf(a,\\mathbf{p}_{e})\\in[0\\ \\ 1]\nis a continuous variable that depends on the ergonomics of the human posture\na\nâˆˆ\n[\n0 1\n]\na\\in[0\\ 1]\nand on the position deviation.\nThe position deviation is defined as\nğ©\ne\n=\nğ©\ng\nâˆ’\nğ©\n\\mathbf{p}_{e}=\\mathbf{p}_{g}-\\mathbf{p}\n, representing the difference between the robot end-effector and the god-object.\nThe orientation deviation in quaternion terms, associated with the deviation rotation matrix\nğ‘\ne\n=\nğ‘\ng\nâ€‹\nğ‘\nT\nâˆˆ\nS\nâ€‹\nO\nâ€‹\n(\n3\n)\n{\\mathbf{R}}_{e}={\\mathbf{R}}_{g}{\\mathbf{R}}^{\\mathrm{T}}\\in SO(3)\n, is given by\nğ\ne\nâ‰œ\nğ\ng\nâŠ—\nğ\nâˆ’\n1\n=\n[\nÎ·\ne\nÏµ\ne\n]\nâˆˆ\nğ•Š\n3\n\\mathbf{Q}_{e}\\triangleq\\mathbf{Q}_{g}\\otimes\\mathbf{Q}^{-1}=\\begin{bmatrix}\\eta_{e}\\\\\n\\bm{\\epsilon}_{e}\\end{bmatrix}\\in\\mathbb{S}^{3}\nwhere\nÎ·\ne\n=\ncos\nâ¡\n(\nÏ•\ne\n2\n)\nâˆˆ\nâ„\nâ‰¥\n\\eta_{e}=\\cos\\left(\\frac{\\phi_{e}}{2}\\right)\\in\\mathbb{R}_{\\geq}\n, with\nÏ•\ne\nâˆˆ\n(\nâˆ’\nÏ€\n,\nÏ€\n)\n\\phi_{e}\\in(-\\pi,\\pi)\nbeing the deviation angle in the equivalent angle-axis representation. Here,\nğ\nâˆ’\n1\nâˆˆ\nğ•Š\n3\n\\mathbf{Q}^{-1}\\in\\mathbb{S}^{3}\ndenotes the inverse of the orientation quaternion\nğ\nâˆˆ\nğ•Š\n3\n\\mathbf{Q}\\in\\mathbb{S}^{3}\n, and\nâŠ—\n\\otimes\ndenotes quaternion multiplication. Notice that to calculate the orientation in quaternion terms\nğ\n\\mathbf{Q}\nand\nğ\ng\n\\mathbf{Q}_{g}\n, we integrate the angular velocities,\nğ\n\\bm{\\omega}\nand\nğ\ng\n\\bm{\\omega}_{g}\nprovided by (\n1\n) and (\n2\n), using the exponential map\nexp\nQ\n:\nâ„\n3\nâ†’\nğ•Š\n3\n\\mathrm{exp}_{Q}:\\,\\mathbb{R}^{3}\\rightarrow\\mathbb{S}^{3}\n, as follows:\nğ\ni\nâ€‹\n(\nt\n+\nT\nc\n)\n=\nexp\nQ\nâ€‹\n(\n1\n2\nâ€‹\nğ\ni\nâ€‹\nT\nc\n)\nâŠ—\nğ\ni\nâ€‹\n(\nt\n)\nâˆˆ\nğ•Š\n3\n\\mathbf{Q}_{i}(t+\\mathrm{T}_{c})=\\mathrm{exp}_{Q}{(\\frac{1}{2}{\\bm{\\omega}}_{i}\\mathrm{T}_{c})}\\,\\otimes\\,\\mathbf{Q}_{i}(t)\\ \\in\\mathbb{S}^{3}\n(3)\nwhere\nT\nc\nâˆˆ\nâ„\n>\n\\mathrm{T}_{c}\\in\\mathbb{R}_{>}\nis the robot control cycle.\nThe function\nf\nâ€‹\n(\na\n,\nğ©\ne\n)\nf(a,\\mathbf{p}_{e})\nis non-negative, well-defined, which modulates the impact of deviations on the motion of the god-object. Our goal is for the god-object to avoid following the robotâ€™s motion when the human is in a high-risk non-ergonomic posture, i.e., when\na\n=\n0\na=0\n, while following it when the human is or returns to an ergonomic posture with a velocity based on the value of\na\na\n. To achieve this, we define a unit vector\nğ§\nâˆˆ\nâ„\n3\n\\mathbf{n}\\in\\mathbb{R}^{3}\nto reflect the robotâ€™s motion vector when the motion is ergonomic, or to indicate the direction that caused the user to move away from an ergonomic posture when the humanâ€™s posture is non-ergonomic. To achieve this, the motion dynamics of the vector\nğ§\n\\mathbf{n}\nis designed as follows:\nğ§\nË™\n=\nâˆ’\nÏ‰\nn\nâ€‹\nğ§\nÃ—\n(\nğ§\nÃ—\nğ§\nd\n)\n,\nÏ‰\nn\n=\nk\nn\nâ€‹\na\nâ€‹\ns\nâ€‹\ni\nâ€‹\nn\nâ€‹\n(\n|\nÏ•\nn\n|\n/\n2\n)\n\\dot{\\mathbf{n}}=-{\\omega}_{n}\\mathbf{n}\\times(\\mathbf{n}\\times\\mathbf{n}_{d}),\\ \\ \\ {\\omega}_{n}=\\mathrm{k}_{n}\\,a\\,{sin(|\\phi_{n}|/2)}\n(4)\nğ§\nd\n=\n{\nğ©\nË™\nâ€–\nğ©\nË™\nâ€–\n,\nif\n|\n|\nğ©\nË™\n|\n|\n>\nÏµ\n0\n3\n,\notherwise\n.\nâˆˆ\nâ„\n3\n\\mathbf{n}_{d}=\\begin{cases}\\dfrac{\\dot{\\mathbf{p}}}{||\\dot{\\mathbf{p}}||}\\ \\ \\ \\ \\ ,\\ \\text{if}\\ ||\\dot{\\mathbf{p}}||>\\epsilon\\\\\n\\ \\ \\ \\mathbf{0}_{3}\\ \\ \\ \\ \\ \\ ,\\ \\text{otherwise}.\\end{cases}\\in\\mathbb{R}^{3}\n(5)\nwhere\nÃ—\n\\times\ndenotes the vector cross product,\nk\nn\nâˆˆ\nâ„\n>\n\\mathrm{k}_{n}\\in\\mathbb{R}_{>}\nis a gain term, and\nÏ•\nn\n=\na\nâ€‹\nn\nâ€‹\ng\nâ€‹\n(\nğ§\n,\nğ§\nd\n)\nâˆˆ\n[\nâˆ’\nÏ€\n,\nÏ€\n)\n\\phi_{n}=ang(\\mathbf{n},\\mathbf{n}_{d})\\ \\in[-\\pi,\\ \\pi)\ngives the angle between the current desired direction of motion\nğ§\nd\n\\mathbf{n}_{d}\nand the vector\nğ§\n\\mathbf{n}\nas follows:\na\nâ€‹\nn\nâ€‹\ng\nâ€‹\n(\nğ§\n,\nğ§\nd\n)\n=\n{\n0\n,\nif\nğ§\nT\nğ§\nd\n=\n|\n|\nğ§\nÃ—\nğ§\nd\n|\n|\n=\n0\na\nâ€‹\nt\nâ€‹\na\nâ€‹\nn\nâ€‹\n2\nâ€‹\n(\nâ€–\nğ§\nÃ—\nğ§\nd\nâ€–\n,\nğ§\nT\nâ€‹\nğ§\nd\n)\n,\notherwise\n.\nang(\\mathbf{n},\\mathbf{n}_{d})=\\begin{cases}\\ \\ \\ \\ \\ \\ \\ \\ 0\\ \\ \\ \\ ,\\text{ if }\\mathbf{n}^{\\mathrm{T}}\\mathbf{n}_{d}=||{\\mathbf{n}\\times\\mathbf{n}_{d}}||=0\\\\\natan2\\big(||{\\mathbf{n}\\times\\mathbf{n}_{d}}||,{\\mathbf{n}^{\\mathrm{T}}\\mathbf{n}_{d}}\\big),\\text{ otherwise}.\\end{cases}\n(6)\nTo calculate the vector\nğ§\n\\mathbf{n}\n, we integrate (\n4\n) using the exponential map\nexp\nR\n:\nâ„\n3\nâ†’\nS\nâ€‹\nO\nâ€‹\n(\n3\n)\n\\mathrm{exp}_{R}:\\mathbb{R}^{3}\\rightarrow SO(3)\n, as follows:\nğ§\nâ€‹\n(\nt\n+\nT\nc\n)\n=\nexp\nR\nâ€‹\n(\nÏ‰\nn\nâ€‹\nT\nc\nâ€‹\nğ§\nÃ—\nğ§\nd\n)\nâ€‹\nğ§\nâ€‹\n(\nt\n)\n.\n\\mathbf{n}(t+\\mathrm{T}_{c})=\\mathrm{exp}_{R}{({\\omega}_{n}\\mathrm{T}_{c}\\,\\mathbf{n}\\times\\mathbf{n}_{d})}\\,\\mathbf{n}(t).\n(7)\nFigure 2:\nVisualization of the sigmoid function\nh\nh\nused for\nfor smooth switching.\nIn the case where the human is in a non-ergonomic posture, the vector\nğ§\n\\mathbf{n}\nmust form an acute angle with the position deviation\nğ©\ne\n\\mathbf{p}_{e}\nto indicate that the human is moving back to the ergonomic space. Based on this principle, we define the function\nğŸ\nâ€‹\n(\na\n,\nğ©\ne\n)\n\\mathbf{f}(a,\\mathbf{p}_{e})\nto be zero when the user is in a non-ergonomic posture and moving further away from it. Conversely, it should be non-zero when the user is either in an ergonomic posture or attempting to return to it. The function that achieve these is defined as follows:\nğŸ\nâ€‹\n(\na\n,\nğ©\ne\n)\n=\na\nm\n+\n(\n1\nâˆ’\na\nm\n)\nâ€‹\nh\nâ€‹\n(\n|\na\nâ€‹\nn\nâ€‹\ng\nâ€‹\n(\nğ§\n,\nğ©\nğ\n)\n|\n;\nÏ•\nÂ¯\nn\nâˆ’\nÎ´\nn\n,\nÏ•\nÂ¯\nn\n)\n\\mathbf{f}(a,\\mathbf{p}_{e})={a}^{m}+(1-{a}^{m})h(|ang(\\mathbf{n},\\mathbf{p_{e}})|;\\overline{\\upphi}_{n}-\\updelta_{n},\\overline{\\upphi}_{n})\n(8)\nwhere\nm\nâˆˆ\nâ„\n>\nm\\in\\mathbb{R}_{>}\ncontrols the sensitivity of the function\nf\nâ€‹\n(\na\n,\nğ©\ne\n)\nf(a,\\mathbf{p}_{e})\nto changes in\na\na\n, with\nm\n>\n1\nm>1\namplifying the effect of\na\na\n,\nm\n=\n1\nm=1\nproducing a linear response, and\nm\n<\n1\nm<1\nsoftening the transformation for smoother behavior. The function\nh\n(\n.\n)\nh(.)\nâˆˆ\n[\n0 1\n]\n\\in[0\\ 1]\nis given by the following sigmoid function for smooth switching:\nh\nâ€‹\n(\nw\n;\nn\nÂ¯\n,\nn\nÂ¯\n)\n=\n{\n1\n,\nif\nw\n<\nn\nÂ¯\n0\n,\nif\nw\n>\nn\nÂ¯\n1\nâˆ’\n6\nâ€‹\nc\nâ€‹\n(\nw\n)\n5\n+\n15\nâ€‹\nc\nâ€‹\n(\nw\n)\n4\nâˆ’\n10\nâ€‹\nc\nâ€‹\n(\nw\n)\n3\n,\notherwise\n\\ h(w;\\underline{\\mathrm{n}},\\overline{\\mathrm{n}})\\hskip-2.27626pt=\\hskip-2.27626pt\\begin{cases}\\hskip-2.27626pt1,&\\hskip-8.5359pt\\text{if $w<\\underline{\\mathrm{n}}$ }\\\\\n\\hskip-2.27626pt0,&\\hskip-8.5359pt\\text{if $w>\\overline{\\mathrm{n}}$ }\\\\\n\\hskip-2.27626pt1-6c(w)^{5}+15c(w)^{4}-10c(w)^{3},&\\hskip-8.5359pt\\text{otherwise}\\end{cases}\n(9)\nwith\nc\nâ€‹\n(\nw\n)\n=\nw\nâˆ’\nn\nÂ¯\nn\nÂ¯\nâˆ’\nn\nÂ¯\nc(w)=\\dfrac{w-\\underline{\\mathrm{n}}}{\\overline{\\mathrm{n}}-\\underline{\\mathrm{n}}}\n. A visualization of this function can be seen in Figure\n2\n.\nÏ•\nÂ¯\nn\n\\overline{\\upphi}_{n}\nrepresents the angle below which the human is considered to be returning to the ergonomic space and\nÎ´\nn\n\\updelta_{n}\ndefines the range of angles where the sigmoid function\nh\nh\ntransitions from 1 to 0.\nTo enhance the maintenance of an ergonomic posture in a physical human-robot interaction framework, we introduce a stiffness term through the robot control term\nğ®\nc\n\\mathbf{u}_{c}\nbetween the robotâ€™s pose, determined by integrating the target admittance model (\n1\n) and the god-object pose, defined by integrating (\n2\n), as follow:\nğ®\nc\n=\nğŠ\nd\nâ€‹\n[\nğ©\ne\nğ‘\ne\nT\nâ€‹\nÏµ\ne\n]\n\\mathbf{u}_{c}=\\mathbf{K}_{d}\\begin{bmatrix}\\mathbf{p}_{e}\\\\\n\\mathbf{R}_{e}^{\\mathrm{T}}{\\bm{\\epsilon}_{e}}\\end{bmatrix}\n(10)\nwhere\nğŠ\nd\n=\n{\nk\np\nâ€‹\nğˆ\n3\nÃ—\n3\n,\nk\no\nâ€‹\nğˆ\n3\nÃ—\n3\n}\nâˆˆ\nâ„\n6\nÃ—\n6\n\\mathbf{K}_{d}=\\{\\mathrm{k}_{p}\\mathbf{I}_{3\\times 3},\\mathrm{k}_{o}\\mathbf{I}_{3\\times 3}\\}\\in\\mathbb{R}^{6\\times 6}\nis a positive definite constant stiffness\nmatrix. This control term provides kinesthetic feedback to the user about the ergonomics of their posture.\nRemark 1\n.\nNotice that the control term\nğ®\nc\n\\mathbf{u}_{c}\nallows the user to perceive deviations between the robot end-effector and the god-object pose. These deviations become significant when the user adopts a high-risk non-ergonomic posture and moves away from the god-object pose, i.e., when\nf\nâ€‹\n(\na\n,\nğ©\ne\n)\n=\n0\nf(a,\\mathbf{p}_{e})=0\n. However, when\nf\nâ€‹\n(\na\n,\nğ©\ne\n)\n=\n1\nf(a,\\mathbf{p}_{e})=1\n, the god-object can precisely follow the robot end-effector pose. In this case, the user can perceive the dynamics of the models (\n1\n) and (\n2\n); the parameters of these models should be selected appropriately to ensure the user experiences an enhanced sense of control during the task.\nTheorem 1\n.\nFor the system (\n1\n), (\n2\n), utilizing the control term (\n10\n), the following statements are\nvalid under the exertion of the human force\nğ…\nh\n\\mathbf{F}_{h}\n:\n1)\nthe generalized robot velocity\nğ¯\n\\mathbf{v}\nand human force\nğ…\nh\n\\mathbf{F}_{h}\nform a passive pair.\n2)\nthe pose deviations between the robot and the god-object is bounded.\nProof.\n1) Let us define the following storage function:\nV\n=\nğ¯\nT\nâ€‹\nğŒ\nd\n2\nâ€‹\nğ¯\n+\nğ©\ne\nT\nâ€‹\nk\np\n2\nâ€‹\nğ©\ne\n+\n2\nâ€‹\nk\no\nâ€‹\nÎ¨\ne\nâ‰¥\n0\nV=\\mathbf{v}^{\\mathrm{T}}\\dfrac{\\mathbf{M}_{d}}{2}\\mathbf{v}+\\mathbf{p}_{e}^{\\mathrm{T}}\\dfrac{\\mathrm{k}_{p}}{2}\\mathbf{p}_{e}+2\\mathrm{k_{o}}\\Psi_{e}\\geq 0\n(11)\nwhere\nÎ¨\ne\n=\n1\nâˆ’\nÎ·\ne\nâˆˆ\nâ„\nâ‰¥\n\\Psi_{e}=1-\\eta_{e}\\in\\mathbb{R}_{\\geq}\n. Notice that, since\nÎ·\ne\n=\ncos\nâ¡\n(\nÏ•\ne\n2\n)\n\\eta_{e}=\\cos\\left(\\frac{\\phi_{e}}{2}\\right)\n,\nÎ¨\ne\n\\Psi_{e}\nis non negative and equal to zero if and only if\nÏ•\ne\n=\n0\n\\phi_{e}=0\n, for all\nÏ•\ne\nâˆˆ\n(\nâˆ’\nÏ€\n,\nÏ€\n)\n\\phi_{e}\\in(-\\pi,\\pi)\n.\nTaking the time derivative of\n(\n11\n) and substituting\nğ¯\nË™\n\\dot{\\mathbf{v}}\nfrom (\n1\n) yields:\nV\nË™\n=\nâˆ’\nğ¯\nT\nâ€‹\nğƒ\nd\nâ€‹\nğ¯\n+\nk\np\nâ€‹\nğ©\nË™\nT\nâ€‹\nğ©\ne\n+\nk\no\nâ€‹\nğ\nT\nâ€‹\nğ‘\ne\nT\nâ€‹\nÏµ\ne\n+\nk\np\nâ€‹\nğ©\nË™\ne\nT\nâ€‹\nğ©\ne\nâˆ’\n2\nâ€‹\nk\no\nâ€‹\nÎ·\nË™\ne\n+\nğ¯\nT\nâ€‹\nğ…\nh\n.\n\\begin{split}\\dot{V}=&-\\mathbf{v}^{\\mathrm{T}}\\mathbf{D}_{d}\\mathbf{v}+\\mathrm{k}_{p}\\dot{\\mathbf{p}}^{\\mathrm{T}}\\mathbf{p}_{e}+\\mathrm{k}_{o}{\\bm{\\omega}}^{\\mathrm{T}}\\mathbf{R}_{e}^{\\mathrm{T}}\\bm{\\epsilon}_{e}\\\\\n&+\\mathrm{k}_{p}\\dot{\\mathbf{p}}_{e}^{\\mathrm{T}}\\mathbf{p}_{e}-2\\mathrm{k_{o}}\\dot{\\eta}_{e}+\\mathbf{v}^{\\mathrm{T}}\\mathbf{F}_{h}.\\end{split}\n(12)\nUtilising the property\nÎ·\nË™\ne\n=\nâˆ’\n1\n2\nâ€‹\nÏµ\ne\nT\nâ€‹\nğ\ne\n\\dot{\\eta}_{e}=-\\dfrac{1}{2}\\bm{\\epsilon}_{e}^{\\mathrm{T}}\\bm{\\omega}_{e}\nwhere\nğ\ne\n=\nğ\ng\nâˆ’\nğ‘\ne\nâ€‹\nğ\n\\bm{\\omega}_{e}=\\bm{\\omega}_{g}-{\\mathbf{R}}_{e}\\bm{\\omega}\nfrom\nKoutras and Doulgeri (\n2021\n)\nand substituting\nğ©\nË™\ne\n\\dot{\\mathbf{p}}_{e}\nwith\nğ©\nË™\ng\nâˆ’\nğ©\nË™\n\\dot{\\mathbf{p}}_{g}-\\dot{\\mathbf{p}}\n, (\n12\n) becomes:\nV\nË™\n=\nâˆ’\nğ¯\nT\nâ€‹\nğƒ\nd\nâ€‹\nğ¯\n+\nk\np\nâ€‹\nğ©\nË™\ng\nT\nâ€‹\nğ©\ne\n+\nk\no\nâ€‹\nğ\ng\nT\nâ€‹\nÏµ\ne\n+\nğ¯\nT\nâ€‹\nğ…\nh\n.\n\\dot{V}=-\\mathbf{v}^{\\mathrm{T}}\\mathbf{D}_{d}\\mathbf{v}+\\mathrm{k}_{p}\\dot{\\mathbf{p}}_{g}^{\\mathrm{T}}\\mathbf{p}_{e}+\\mathrm{k}_{o}{\\bm{\\omega}}_{g}^{\\mathrm{T}}\\bm{\\epsilon}_{e}+\\mathbf{v}^{\\mathrm{T}}\\mathbf{F}_{h}.\n(13)\nSubstituting\nğ©\nË™\ng\n\\dot{\\mathbf{p}}_{g}\nand\nğ\ng\n{\\bm{\\omega}}_{g}\nfrom (\n2\n) yields:\nV\nË™\n=\nâˆ’\nğ¯\nT\nâ€‹\nğƒ\nd\nâ€‹\nğ¯\nâˆ’\nk\nr\nâ€‹\nk\np\nâ€‹\nf\nâ€‹\n(\na\n,\nğ©\ne\n)\nâ€‹\nğ©\ne\nT\nâ€‹\nğ©\ne\nâˆ’\nk\nr\nâ€‹\nk\no\nâ€‹\nf\nâ€‹\n(\na\n,\nğ©\ne\n)\nâ€‹\nÏµ\ne\nT\nâ€‹\nÏµ\ne\n+\nğ¯\nT\nâ€‹\nğ…\nh\n.\n\\begin{split}\\dot{V}=&-\\mathbf{v}^{\\mathrm{T}}\\mathbf{D}_{d}\\mathbf{v}-\\mathrm{k}_{r}\\mathrm{k}_{p}f(a,\\mathbf{p}_{e})\\mathbf{p}_{e}^{\\mathrm{T}}\\mathbf{p}_{e}\\\\\n&-\\mathrm{k}_{r}\\mathrm{k}_{o}f(a,\\mathbf{p}_{e})\\bm{\\epsilon}_{e}^{\\mathrm{T}}\\bm{\\epsilon}_{e}+\\mathbf{v}^{\\mathrm{T}}\\mathbf{F}_{h}.\\end{split}\n(14)\nSince\nf\nâ€‹\n(\na\n,\nğ©\ne\n)\nf(a,\\mathbf{p}_{e})\nin not negative, and\nk\nr\n\\mathrm{k}_{r}\nand\nk\no\n\\mathrm{k}_{o}\nare positive,\nV\nË™\n\\dot{V}\ncan be written as:\nV\nË™\nâ‰¤\nâˆ’\nğ¯\nT\nâ€‹\nğƒ\nd\nâ€‹\nğ¯\n+\nğ¯\nT\nâ€‹\nğ…\nh\n.\n\\begin{split}\\dot{V}\\leq&-\\mathbf{v}^{\\mathrm{T}}\\mathbf{D}_{d}\\mathbf{v}+\\mathbf{v}^{\\mathrm{T}}\\mathbf{F}_{h}.\\end{split}\n(15)\nTherefore, the inequality (\n15\n) implies that the system is strictly passive (refer to Definition 6.3 in\nKhalil (\n2002\n)\n), thereby completing the proof of statement 1.\n2) Rewriting (\n15\n) by completing the squares, yields:\nV\nË™\n=\nâˆ’\nâ€–\nğƒ\nd\nâ€‹\nğ¯\nâˆ’\n1\n2\nâ€‹\nğƒ\nd\nâˆ’\n1\nâ€‹\nğ…\nh\nâ€–\n2\n+\n1\n4\nâ€‹\nğ…\nh\nT\nâ€‹\nğƒ\nd\nâˆ’\n1\nâ€‹\nğ…\nh\nâ‰¤\nÎ»\nm\nâ€‹\na\nâ€‹\nx\nâ€‹\n(\nğƒ\nd\nâˆ’\n1\n)\n4\nâ€‹\nğ…\nh\nT\nâ€‹\nğ…\nh\n.\n\\begin{split}\\dot{V}=&-||\\sqrt{\\mathbf{D}_{d}}\\mathbf{v}-\\dfrac{1}{2}\\sqrt{\\mathbf{D}_{d}}^{-1}\\mathbf{F}_{h}||^{2}+\\dfrac{1}{4}\\mathbf{F}_{h}^{T}\\mathbf{D}_{d}^{-1}\\ \\mathbf{F}_{h}\\\\\n&\\leq\\dfrac{\\lambda_{max}(\\mathbf{D}_{d}^{-1})}{4}\\mathbf{F}_{h}^{\\mathrm{T}}\\ \\mathbf{F}_{h}.\\end{split}\n(16)\nwhere\nÎ»\nm\nâ€‹\na\nâ€‹\nx\n(\n.\n)\n\\lambda_{max}(.)\nis the largest eigenvalue of the matrix\nâ€\n(\n.\n)\nâ€\n\"(.)\"\n. Notice that\nğ…\nh\n\\mathbf{F}_{h}\nrepresents the generalized force applied by the human\nto guide the robot. The human forces have bounded energy. Hence integrating (\n16\n) we get:\nV\nâ‰¤\nV\nâ€‹\n(\n0\n)\n+\nÎ»\nm\nâ€‹\na\nâ€‹\nx\nâ€‹\n(\nğƒ\nd\nâˆ’\n1\n)\n4\nâ€‹\nâˆ«\nğ…\nh\nT\nâ€‹\nğ…\nh\nâ€‹\nâˆ‚\nt\n<\nâˆ\nV\\leq V(0)+\\dfrac{\\lambda_{max}(\\mathbf{D}_{d}^{-1})}{4}\\int\\mathbf{F}_{h}^{\\mathrm{T}}\\mathbf{F}_{h}\\ \\partial t<\\infty\n(17)\nwhich implies the boundedness of\nV\nV\n. Therefore, the boundedness of\nV\nV\nas given by (\n11\n) indicates that\nğ¯\n\\mathbf{v}\n,\nğ©\ne\n\\mathbf{p}_{e}\nand\nÎ¨\ne\n\\Psi_{e}\nremain bounded under the exertion of human force. As a result, deviations between the robot end-effector and the god-object pose are also bounded, completing the proof of statement 2.\nâˆ\n2.2\nVariable Damping\nThe appropriate design of the damping term in the robotâ€™s admittance/impedance model is critical for ensuring a smooth and natural interaction experience, which is the focus of this subsection. Specifically, the damping matrix\nğƒ\nd\n\\mathbf{D}_{d}\nused in the robot end-effector admittance model (\n1\n) is constructed by combining a constant matrix\nğƒ\nc\nâˆˆ\nâ„\n6\nÃ—\n6\n\\mathbf{D}_{c}\\in\\mathbb{R}^{6\\times 6}\nand two variable matrices\nğƒ\nv\n=\nd\nâ€‹\ni\nâ€‹\na\nâ€‹\ng\nâ€‹\n{\nd\nv\nâ€‹\np\nâ€‹\nğˆ\n3\nÃ—\n3\n,\nd\nv\nâ€‹\no\nâ€‹\nğˆ\n3\nÃ—\n3\n}\n\\mathbf{D}_{v}=diag\\{d_{vp}\\mathbf{I}_{3\\times 3},d_{vo}\\mathbf{I}_{3\\times 3}\\}\n,\nğƒ\nf\n=\nd\nâ€‹\ni\nâ€‹\na\nâ€‹\ng\nâ€‹\n{\nd\nf\nâ€‹\np\nâ€‹\nğˆ\n3\nÃ—\n3\n,\nd\nf\nâ€‹\no\nâ€‹\nğˆ\n3\nÃ—\n3\n}\n\\mathbf{D}_{f}=diag\\{d_{fp}\\mathbf{I}_{3\\times 3},d_{fo}\\mathbf{I}_{3\\times 3}\\}\n, enhancing its ability to handle dynamic interaction scenarios. Therefore, the overall damping matrix is expressed as:\nğƒ\nd\n=\nğƒ\nc\n+\nğƒ\nv\n+\nğƒ\nf\nâˆˆ\nâ„\n6\nÃ—\n6\n.\n\\mathbf{D}_{d}=\\mathbf{D}_{c}+\\mathbf{D}_{v}+\\mathbf{D}_{f}\\in\\mathbb{R}^{6\\times 6}.\n(18)\n2.2.1\nPower-Based Variable Damping:\nVarious formulations of the variable admittance matrix have been proposed in the literature. In this work, we employ a power-based variable damping matrix\nğƒ\nv\n\\mathbf{D}_{v}\nproposed in\nSidiropoulos\net al.\n(\n2021\n)\n. The damping terms for translational and rotational motions are given by:\nd\nv\nâ€‹\np\n=\na\np\nâ€‹\ne\nâ€‹\nx\nâ€‹\np\nâ€‹\n(\nâˆ’\nb\np\nâ€‹\ns\np\n)\n,\nd\nv\nâ€‹\no\n=\na\no\nâ€‹\ne\nâ€‹\nx\nâ€‹\np\nâ€‹\n(\nâˆ’\nb\no\nâ€‹\ns\no\n)\nd_{vp}=\\mathrm{a}_{p}exp(-\\mathrm{b}_{p}s_{p}),\\ d_{vo}=\\mathrm{a}_{o}exp(-\\mathrm{b}_{o}s_{o})\n(19)\nwhere\ns\np\n=\nmax\nâ€‹\n(\n0\n,\nğ©\nË™\nT\nâ€‹\nğŸ\nh\n)\ns_{p}=\\mathrm{max}(0,\\dot{\\mathbf{p}}^{\\mathrm{T}}\\mathbf{f}_{h})\nrepresents the positive power associated with the linear motion of the robot,\ns\no\n=\nmax\nâ€‹\n(\n0\n,\nğ\nT\nâ€‹\nğ‰\nh\n)\ns_{o}=\\mathrm{max}(0,\\bm{\\omega}^{\\mathrm{T}}\\bm{\\tau}_{h})\nis the positive power related to the rotational motion, and\na\np\n,\na\no\n,\nb\np\n,\nb\no\nâˆˆ\nâ„\n>\n\\mathrm{a}_{p},\\mathrm{a}_{o},\\mathrm{b}_{p},\\mathrm{b}_{o}\\in\\mathbb{R}_{>}\nare scaling factors.\n2.2.2\nErgonomics-Based Variable Damping:\nIn addition to power-based damping, the ergonomics factor is also considered in the damping design to prevent potential oscillations during the interaction. When\nğŸ\nâ€‹\n(\na\n,\nğ©\ne\n)\n\\mathbf{f}(a,\\mathbf{p}_{e})\ndeviates from one, the deviation\nğ©\ne\n\\mathbf{p}_{e}\nbetween the god-object and admittance position may increase, raising the robotâ€™s resistance. This resistance can elevate the humanâ€™s internal stiffness, potentially inducing oscillations. To mitigate these effects, the variable damping terms\nd\nf\nâ€‹\np\nd_{fp}\nand\nd\nf\nâ€‹\no\nd_{fo}\nare designed as:\nd\nf\nâ€‹\np\n=\nc\np\nâ€‹\nâ€–\nğ©\ne\nâ€–\nâ€‹\n(\n1\nâˆ’\nf\nâ€‹\n(\na\n,\nğ©\ne\n)\n)\n,\nd\nf\nâ€‹\no\n=\nc\no\nâ€‹\nâ€–\nÏµ\ne\nâ€–\nâ€‹\n(\n1\nâˆ’\nf\nâ€‹\n(\na\n,\nğ©\ne\n)\n)\nd_{fp}=\\mathrm{c}_{p}||\\mathbf{p}_{e}||(1-f(a,\\mathbf{p}_{e})),\\ d_{fo}=\\mathrm{c}_{o}||\\bm{\\epsilon}_{e}||(1-f(a,\\mathbf{p}_{e}))\n(20)\nwhere\nc\np\n,\nc\no\nâˆˆ\nâ„\n>\n\\mathrm{c}_{p},\\mathrm{c}_{o}\\in\\mathbb{R}_{>}\nare positive gains. This formulation creates an adaptive damping mechanism that adjusts based on the deviation magnitude and the value of the function\nf\nâ€‹\n(\na\n,\nğ©\ne\n)\nf(a,\\mathbf{p}_{e})\n.\n2.3\nOnline Continuous Ergonomics Assessment\nThe ergonomics factor\na\na\nis a critical component of the proposed postural virtual fixture. In order to calculate it, we first calculate the key joint angles necessary for computing it and then introduce a continuous approach for its calculation.\nLet us assume we know the shoulder\nğ’\ni\n\\mathbf{S}_{i}\n, elbow\nğ„\ni\n\\mathbf{E}_{i}\n, wrist\nğ–\ni\n\\mathbf{W}_{i}\n, neck\nğğ\n\\mathbf{Ne}\n, middle of the thorax\nğ“ğ¡\n\\mathbf{Th}\n, middle of the pelvis\nğğ¥\n\\mathbf{Pl}\n, and knee\nğŠğ§\n\\mathbf{Kn}\nkeypoints, where\ni\n=\n{\nR\n,\nL\n}\ni=\\mathrm{\\{R,L\\}}\nindicates the right or left side of the human body, respectively (Figure\n3\n). This can be achieved using vision-based\n3\n3\nD skeleton tracking algorithms, such as YOLO and MediaPipe, or using wearable motion capture sensors like the inertial measurement unit-based Xsens suit. Using these keypoints, the shoulder abduction/adduction angle\nÎ¸\na\ni\n\\theta^{i}_{a}\n, shoulder flexion/extension angle\nÎ¸\nf\ni\n\\theta^{i}_{f}\n, shoulder internal/external rotation angle\nÎ¸\nr\ni\n\\theta^{i}_{r}\n, elbow flexion/extension angle\nÎ¸\ne\ni\n\\theta^{i}_{e}\n, and sagittal bending angle\nÎ¸\nb\n\\theta_{b}\n(see Figure\n3\n) can be computed based on the geometric relationships between the joints. These calculations are provided in the\nJoint Motion Analysis\nsubsection of the Appendix.\nFigure 3:\nAnalysis of human joint angles: (a) shoulder abduction/adduction, (b) shoulder flexion/extension, (c) shoulder internal/external rotation, (d) elbow flexion/extension, and (e) sagittal bending, across five movement scenarios. The figure illustrates key points identified by perception sensors, representing joint positions during each movement.\nThe risk level associated with the angle of the upper arm, lower arm, and forward trunk bending joints, as indicated by the RULA worksheet\n(McAtamney and Corlett,\n1993\n)\nis utilized to design the factor\na\na\n. The RULA worksheet provides a discrete score based on the range in which each angle falls; then, using a score table, all the scores for each body part are gathered to compute a discrete total score that evaluates the ergonomics of the body posture. In our approach, we move away from this discrete method of posture assessment. Instead, we formulate a continuous function ranging from zero to one, with one indicating an ergonomic position and zero representing a high-risk, non-ergonomic posture. This continuous function allows for a smoother integration of the ergonomic assessment factor into the robot end-effector admittance model.\nNote that other bounded continuous ergonomic metrics, such as the joint displacement metric from\nLorenzini\net al.\n(\n2022\n)\nor the range of motion ergonomic cost from\nLagomarsino\net al.\n(\n2023\n)\n, could potentially be utilized in place of factor\na\na\nin the proposed virtual fixture dynamics. However, these metrics assume that the best ergonomic position of each joint is at the midpoint of its range of motion, which is not generally true for every joint. Therefore, our metrics, which are constructed based on the RULA assessment and specifically designed for online, posture-based ergonomics evaluation (facilitated by the SRB grounding the payload and simplifying the evaluation to posture quality), are considered more appropriate for assessing human posture ergonomics. Moreover, unlike our proposed ergonomic metric, these alternatives lack smoothness, which can lead to abrupt changes in control behavior.\nFurthermore, fatigue-related metrics are unsuitable, as they may indicate ergonomic risk even when the userâ€™s current posture is ergonomic, due to the cumulative effect of previous non-ergonomic postures. This could hinder ergonomics recovery and task continuation.\n(a)\nErgonomics factor for shoulder abduction/adduction angle.\n(b)\nErgonomics factor for shoulder flexion/extension angle.\n(c)\nErgonomics factor for shoulder internal/external rotation angle.\n(d)\nErgonomics factor for elbow flexion/extension angle.\n(e)\nErgonomics factor for bending angle.\nFigure 4:\nVirtual representation of the ergonomics sub-factors.\nFor each angle calculated as described in the previous subsection, a function that calculates the posture ergonomics is designed based on the RULA worksheet. A virtual representation of these functions is presented in Figure\n4\n. In particular, for the shoulder abduction/adduction angle\nÎ¸\na\ni\n\\theta_{a}^{i}\n, no specific joint limit is mentioned in the RULA worksheet; however, it is noted that less rotation is preferable. Thus, the following ergonomics factor is utilized for the angle\nÎ¸\na\ni\n\\theta_{a}^{i}\n:\na\na\n=\nh\nâ€‹\n(\n|\nÎ¸\na\ni\n|\n;\nÎ¸\nÂ¯\na\nâ€‹\nu\nâˆ’\nÎ´\nÎ¸\n,\nÎ¸\nÂ¯\na\nâ€‹\nu\n)\na_{a}=h(|\\theta_{a}^{i}|;\\overline{\\uptheta}_{au}-\\updelta_{\\theta},\\overline{\\uptheta}_{au})\n(21)\nwhere\nÎ¸\nÂ¯\na\nâ€‹\nu\n\\overline{\\uptheta}_{au}\ndenotes the upper ergonomic limit of the shoulder abduction/adduction angle, beyond which the posture is deemed non-ergonomic, resulting in\na\na\n=\n0\na_{a}=0\n. The ergonomics factor\na\na\na_{a}\ntransitions smoothly from 1 to 0 within the range defined by\nÎ´\nÎ¸\n\\updelta_{\\theta}\n. For this assessment, we set\nÎ¸\nÂ¯\na\nâ€‹\nu\n=\n30\nâˆ˜\n\\overline{\\uptheta}_{au}=30^{\\circ}\nand\nÎ´\nÎ¸\n=\n10\nâˆ˜\n\\updelta_{\\theta}=10^{\\circ}\n.\nFor the shoulder flexion/extension\nÎ¸\nf\ni\n\\theta_{f}^{i}\n, a more ergonomic position is when the angle is in a region around zero, and the risk level is increased as the angle is in an increased region; thus it is designed as follows:\na\nf\n=\n{\n0.33\nâ€‹\nh\nâ€‹\n(\nÎ¸\nf\ni\n;\nÎ¸\nÂ¯\nf\nâ€‹\nl\nâˆ’\nÎ´\nÎ¸\n,\nÎ¸\nÂ¯\nf\nâ€‹\nl\n)\n+\n0.33\nâ€‹\nh\nâ€‹\n(\nÎ¸\nf\ni\n;\nÎ¸\nÂ¯\nf\nâ€‹\nm\nâˆ’\nÎ´\nÎ¸\n,\nÎ¸\nÂ¯\nf\nâ€‹\n2\n)\n+\n0.34\nâ€‹\nh\nâ€‹\n(\nÎ¸\nf\ni\n;\nÎ¸\nÂ¯\nf\nâ€‹\nu\nâˆ’\nÎ´\nÎ¸\n,\nÎ¸\nÂ¯\nf\nâ€‹\nu\n)\n,\nif\nâ€‹\nÎ¸\nf\ni\n>\n0\n1\nâˆ’\nh\nâ€‹\n(\nÎ¸\nf\ni\n;\nâˆ’\nÎ¸\nÂ¯\nf\nâ€‹\nl\n,\nâˆ’\nÎ¸\nÂ¯\nf\nâ€‹\nl\n+\nÎ´\nÎ¸\n)\n,\notherwise\na_{f}=\\begin{cases}\\begin{aligned} &0.33h(\\theta_{f}^{i};\\overline{\\uptheta}_{fl}-\\updelta_{\\theta},\\overline{\\uptheta}_{fl})\\\\\n&+0.33h(\\theta_{f}^{i};\\overline{\\uptheta}_{fm}-\\updelta_{\\theta},\\overline{\\uptheta}_{f2})\\\\\n&+0.34h(\\theta_{f}^{i};\\overline{\\uptheta}_{fu}-\\updelta_{\\theta},\\overline{\\uptheta}_{fu}),\\end{aligned}&\\text{if }\\theta_{f}^{i}>0\\\\\n1-h(\\theta_{f}^{i};-\\overline{\\uptheta}_{fl},-\\overline{\\uptheta}_{fl}+\\updelta_{\\theta}),&\\text{otherwise}\\end{cases}\n(22)\nwhere based on the RULA worksheet\nÎ¸\nÂ¯\nf\nâ€‹\nl\n=\n20\no\n\\overline{\\uptheta}_{fl}=20^{o}\n,\nÎ¸\nÂ¯\nf\nâ€‹\nm\n=\n45\no\n\\overline{\\uptheta}_{fm}=45^{o}\nand\nÎ¸\nÂ¯\nf\nâ€‹\nu\n=\n90\no\n\\overline{\\uptheta}_{fu}=90^{o}\n.\nFor shoulder internal/external rotation\nÎ¸\nr\ni\n\\theta_{r}^{i}\n,\nno specific joint limit is mentioned in the RULA worksheet; however, it is noted that less rotation is preferable. Therefore, the ergonomics factor is set as follows:\na\nr\n=\nh\nâ€‹\n(\n|\nÎ¸\nr\ni\n|\n;\nÎ¸\nÂ¯\nr\nâ€‹\nu\nâˆ’\nÎ´\nÎ¸\n,\nÎ¸\nÂ¯\nr\nâ€‹\nu\n)\na_{r}=h(|\\theta_{r}^{i}|;\\overline{\\uptheta}_{ru}-\\updelta_{\\theta},\\overline{\\uptheta}_{ru})\n(23)\nwhere the angle bound\nÎ¸\nÂ¯\nr\nâ€‹\nu\n\\overline{\\uptheta}_{ru}\nis set to\nÎ¸\nÂ¯\nr\nâ€‹\nu\n=\n30\no\n\\overline{\\uptheta}_{ru}=30^{o}\nsince the physical limit of absolute value of this shoulder angle is\n60\no\n60^{o}\n.\nFor elbow flexion/extension\nÎ¸\ne\ni\n\\theta_{e}^{i}\n, the factor is designed as:\na\ne\n=\nâˆ’\nh\nâ€‹\n(\nÎ¸\ne\ni\n;\nÎ¸\nÂ¯\ne\nâ€‹\nl\n,\nÎ¸\nÂ¯\ne\nâ€‹\nl\n+\nÎ´\nÎ¸\n)\n+\nh\nâ€‹\n(\nÎ¸\ne\ni\n;\nÎ¸\nÂ¯\ne\nâ€‹\nu\nâˆ’\nÎ´\nÎ¸\n,\nÎ¸\nÂ¯\ne\nâ€‹\nu\n)\na_{e}=-h(\\theta_{e}^{i};\\overline{\\uptheta}_{el},\\overline{\\uptheta}_{el}+\\updelta_{\\theta})+h(\\theta_{e}^{i};\\overline{\\uptheta}_{eu}-\\updelta_{\\theta},\\overline{\\uptheta}_{eu})\n(24)\nwhere based on the RULA worksheet\nÎ¸\nÂ¯\ne\nâ€‹\nl\n=\n80\no\n\\overline{\\uptheta}_{el}=80^{o}\nand\nÎ¸\nÂ¯\ne\nâ€‹\nu\n=\n120\no\n\\overline{\\uptheta}_{eu}=120^{o}\n.\nFor the bending angle\nÎ¸\nb\n\\theta_{b}\n, the ergonomics factor RULA worksheet states that only a zero-degree angle is considered ergonomic. To have a smooth transition, we add an extra range of motion around the zero-angle in addition to what is defined in the RULA worksheet. Consequently, the ergonomics factor is defined as:\na\nb\n=\n0.33\nh\n(\nÎ¸\nb\n;\nÎ¸\nÂ¯\nb\nâ€‹\nl\nâˆ’\nÎ´\nÎ¸\n,\nÎ¸\nÂ¯\nb\nâ€‹\n1\n)\n+\n0.33\nh\n(\nÎ¸\nb\n;\nÎ¸\nÂ¯\nb\nâ€‹\nm\nâˆ’\nÎ´\nÎ¸\n,\nÎ¸\nÂ¯\nb\nâ€‹\nm\n)\n+\n0.34\nh\n(\nÎ¸\nb\n;\nÎ¸\nÂ¯\nb\nâ€‹\nu\nâˆ’\nÎ´\nÎ¸\n,\nÎ¸\nÂ¯\nb\nâ€‹\nu\n)\n.\n\\begin{split}a_{b}=&0.33h(\\theta_{b};\\overline{\\uptheta}_{bl}-\\updelta_{\\theta},\\overline{\\uptheta}_{b1})+0.33h(\\theta_{b};\\overline{\\uptheta}_{bm}\\\\\n&-\\updelta_{\\theta},\\overline{\\uptheta}_{bm})+0.34h(\\theta_{b};\\overline{\\uptheta}_{bu}-\\updelta_{\\theta},\\overline{\\uptheta}_{bu}).\\end{split}\n(25)\nwhere\nÎ¸\nÂ¯\nb\nâ€‹\nl\n=\n10\no\n\\overline{\\uptheta}_{bl}=10^{o}\n,\nÎ¸\nÂ¯\nb\nâ€‹\nm\n=\n20\no\n\\overline{\\uptheta}_{bm}=20^{o}\n, and\nÎ¸\nÂ¯\nb\nâ€‹\nu\n=\n60\no\n\\overline{\\uptheta}_{bu}=60^{o}\n.\nTo calculate the total ergonomics assessment score\na\na\n, all sub-ergonomics factors are multiplied:\na\n=\na\na\nâ€‹\na\nf\nâ€‹\na\nl\nâ€‹\na\ne\nâ€‹\na\nb\nâˆˆ\n[\n0 1\n]\n.\na=a_{a}a_{f}a_{l}a_{e}a_{b}\\in[0\\ 1].\n(26)\nBy doing this, when at least one of them is at high risk, i.e., is zero, the total score is zero, indicating a high-risk non-ergonomic posture.\nRemark 2\n.\nIn this work, we consider the shoulder, elbow, and trunk bending angles. If the task requires the inclusion of additional angles, such as those of the wrist and legs, the ergonomics functions designed for the shoulder, elbow, and trunk can similarly be applied to these other angles. The total factor is then adjusted by multiplying it with the ergonomics factors corresponding to each of these angles.\n2.4\nSupernumerary Robotic Body Control with Base Adaptation\nThe final element of the control framework (Figure\n1\n) is an SRB with loco-manipulation capabilities, providing user support. This subsection addresses the closed-loop inverse kinematics with redundancy resolution for SRBs, ensuring the desired end-effector behavior (\n1\n) and coordination between the user and robot. The system integrates robotic platforms with\nn\nâ‰¥\n6\nn\\geq 6\ndegrees of freedom and a mobile base, and an interface, proposed in\nGiammarino\net al.\n(\n2024\n)\n, incorporating end-effectors like the Pisa/IIT SoftHand or vacuum grippers and an F/T sensor measures human-exerted forces,\nğ…\nh\n\\mathbf{F}_{h}\n, for the ergonomics-driven model (\n1\n). The interface decouples human forces from environmental ones, enabling the handling of heavy loads with minimal effort using high-payload manipulators, such as the UR16e (\n16\n16\nkg capacity).\nSolving the inverse kinematics problem is crucial for translating the desired end-effector behavior, as defined by (\n1\n), into precise SRB joint velocities\nğª\nË™\np\nâˆˆ\nâ„\n3\n+\nn\n\\dot{\\mathbf{q}}_{p}\\in\\mathbb{R}^{3+n}\n. These velocities are obtained using the Damped Least-Squares (DLS) method, detailed in the\nDLS for Whole-Body Inverse Kinematics\nsubsection of the Appendix. The velocity vector\nğª\nË™\np\n\\dot{\\mathbf{q}}_{p}\nrepresents the complete joint velocity configuration of the robot, defined as\nğª\nË™\np\n=\n[\nğª\nË™\nb\nT\nâ€‹\nğª\nË™\na\nT\n]\nT\nâˆˆ\nâ„\n3\n+\nn\n\\dot{\\mathbf{q}}_{p}=[\\dot{\\mathbf{q}}_{b}^{\\mathrm{T}}\\ \\dot{\\mathbf{q}}_{a}^{\\mathrm{T}}]^{\\mathrm{T}}\\in\\mathbb{R}^{3+n}\n, where\nğª\nË™\nb\n=\n[\nv\nx\nv\ny\nÏ‰\nz\n]\nT\nâˆˆ\nâ„\n3\n\\dot{\\mathbf{q}}_{b}=[v_{x}\\ \\ v_{y}\\ \\ \\omega_{z}]^{\\mathrm{T}}\\in\\mathbb{R}^{3}\ncorresponds to the floating-base velocities, and\nğª\nË™\na\nâˆˆ\nâ„\nn\n\\dot{\\mathbf{q}}_{a}\\in\\mathbb{R}^{n}\nrepresents the manipulator joint velocities.\nThe SRBâ€™s redundancy can be leveraged to improve coordination, especially when the operatorâ€™s motion is constrained by the floating base. To address this, we use the Jacobianâ€™s null space\nğ’©\nâˆˆ\nâ„\n{\n3\n+\nn\n}\nÃ—\n{\n3\n+\nn\n}\n\\mathcal{N}\\in\\mathbb{R}^{\\{3+n\\}\\times\\{3+n\\}}\n, provided in the\nDLS for Whole-Body Inverse Kinematics\nsubsection of the Appendix, to adjust the baseâ€™s movement as the operator approaches a threshold. The total commanded joint velocity is:\nğª\nË™\nc\n=\nğª\nË™\np\n+\nğ’©\nâ€‹\nğ¯\nr\nâˆˆ\nâ„\n3\n+\nn\n\\dot{\\mathbf{q}}_{c}=\\dot{\\mathbf{q}}_{p}+\\mathcal{N}\\mathbf{v}_{r}\\in\\mathbb{R}^{3+n}\n(27)\nwhere\nğ¯\nr\n=\n[\nğ¯\nx\nâ€‹\ny\nT\nâ€‹\n0\n(\n1\n+\nn\n)\n]\nT\nâˆˆ\nâ„\n3\n+\nn\n\\mathbf{v}_{r}=[\\mathbf{v}_{xy}^{\\mathrm{T}}\\ \\mathbf{0}_{(1+n)}]^{\\mathrm{T}}\\in\\mathbb{R}^{3+n}\nwith\nğ¯\nx\nâ€‹\ny\nâˆˆ\nâ„\n2\n\\mathbf{v}_{xy}\\in\\mathbb{R}^{2}\nbe repulsive velocity component that introduced into the null space of the Jacobian when the user is near the base. Then, the velocity\nğª\nË™\nc\n\\dot{\\mathbf{q}}_{c}\nis integrated based on the robotâ€™s motion input (joint velocities or positions).\nFigure 5:\nVisualization of the repulsive vector when the user is in close proximity to the robotic platform.\nTo calculate the repulsive velocity\nğ¯\nx\nâ€‹\ny\n\\mathbf{v}_{xy}\n, we drew inspiration from\nSirintuna\net al.\n(\n2024\n)\n, where the goal was for a human-mobile manipulator team to avoid obstacles in the environment during a co-transportation task. Without loss of generality, we consider as a floating base the robotic mobile platform shown in Figure\n5\n. In contrast to that previous work, which filtered the velocity generated from an admittance model based on whether the robot-human team is expected to collide with an obstacleâ€”thereby constraining the robotâ€™s motion to ensure safetyâ€”our current approach involves designing a vector that repels the robot platform when a human approaches its base in a distance less than\nd\n0\nâˆˆ\nâ„\n\\mathrm{d}_{0}\\in\\mathbb{R}\n. To implement this, we first enclose the robot in a capsule with radius\nr\nc\nâˆˆ\nâ„\n3\n\\mathrm{r}_{c}\\in\\mathbb{R}^{3}\nand length\nL\nâˆˆ\nâ„\n\\mathrm{L}\\in\\mathbb{R}\n, corresponding to the robotâ€™s dimensions. Following this, we fill the empty space created by the LiDAR-detected point cloud by drawing circles with a radius\nr\ns\nâˆˆ\nâ„\n\\mathrm{r}_{s}\\in\\mathbb{R}\naround these points. By doing so, we can identify the region of interest, which is the area close to the capsule, defined as:\nğ’ª\nc\n=\n{\nğ±\nâˆˆ\nâ„\n2\n:\nr\nc\n+\nr\ns\nâ‰¤\nâ€–\nğ±\nâ€–\n<\nd\n0\n+\nr\ns\n+\nr\nc\n}\n.\n\\mathcal{O}_{c}=\\{\\mathbf{x}\\in\\mathbb{R}^{2}:\\mathrm{r}_{c}+\\mathrm{r}_{s}\\leq||\\mathbf{x}||<\\mathrm{d}_{0}+\\mathrm{r}_{s}+\\mathrm{r}_{c}\\}.\n(28)\nRemark 3\n.\nFor simplicity, the robotic platform is enclosed within a capsule-shaped boundary. However, if a more precise fit is needed, other shapes, such as 2D superellipses, could be employed. These shapes have been shown to be effective for obstacle avoidance in autonomous robotic tasks involving fixed robotic manipulators\n(Stavridis\net al.\n,\n2017\n)\n.\nTo form the repulsive velocity, we consider the region that corresponds to half of the capsule where a human is expected to interact with the robot end-effector, denoted as\nğ’ª\nh\nâŠ‚\nğ’ª\nc\n\\mathcal{O}_{h}\\subset\\mathcal{O}_{c}\n. When points are detected in the opposite half\nğ’ª\no\n=\nğ’ª\nc\nâˆ’\nğ’ª\nh\n\\mathcal{O}_{o}=\\mathcal{O}_{c}-\\mathcal{O}_{h}\n, the null space control is deactivated to ensure that the environment remains safe from potential collisions and hazards. To ensure smooth behavior of the repulsive velocity when points are detected only in the half capsule closest to the human\nğ’ª\nh\n\\mathcal{O}_{h}\n,\ninstead of considering just the closest point, we compute a\nweighted average of all nearby points:\nğ©\nÂ¯\n=\nâˆ‘\nğ©\ni\nâˆˆ\nğ’ª\nh\nw\ni\nâ€‹\nğ©\ni\nc\nâˆ‘\nğ©\ni\nâˆˆ\nğ’ª\nh\nw\ni\nâˆˆ\nâ„\n2\n,\nw\ni\n=\nh\nâ€‹\n(\nd\nx\nâ€‹\ni\n;\n0\n,\nd\n0\n)\nâˆˆ\nâ„\n\\bar{\\mathbf{p}}=\\dfrac{\\sum_{\\mathbf{p}_{i}\\in\\mathcal{O}_{h}}w_{i}\\mathbf{p}_{i}^{c}}{\\sum_{\\mathbf{p}_{i}\\in\\mathcal{O}_{h}}w_{i}}\\in\\mathbb{R}^{2},\\ w_{i}=h(d_{xi};0,{\\mathrm{d}_{0}})\\in\\mathbb{R}\n(29)\nwhere\nğ©\ni\nc\nâˆˆ\nâ„\n2\n\\mathbf{p}_{i}^{c}\\in\\mathbb{R}^{2}\nis the closest point on the perimeter\nof the capsule to\nğ©\ni\nâˆˆ\nğ’ª\nh\n\\mathbf{p}_{i}\\in\\mathcal{O}_{h}\nthat can be calculated analytically (see Appendix) and\nd\nx\nâ€‹\ni\n=\n|\n|\nğ©\ni\nâˆ’\nğ©\ni\nâˆ—\n|\n|\nâˆ’\n(\nr\nc\n+\nr\ns\n)\nâˆˆ\n[\n0\nd\n0\n)\nd_{xi}=||\\mathbf{p}_{i}-\\mathbf{p}_{i}^{*}||-(\\mathrm{r}_{c}+\\mathrm{r}_{s})\\in[0\\ \\mathrm{d}_{0})\nwith\nğ©\ni\nâˆ—\n\\mathbf{p}_{i}^{*}\nis the nearest point on the capsuleâ€™s centerline to\nğ©\ni\n\\mathbf{p}_{i}\n, also calculable analytically (see subsection\nClosest Point on a 2D Capsule\nin the Appendix). This weighting scheme ensures that points closer to the robot have a greater influence on\nğ©\nÂ¯\n\\bar{\\mathbf{p}}\n. Then, this point is projected onto the capsule perimeter as:\nğ©\nc\n=\nğ©\nÂ¯\nâˆ—\n+\nğ©\nÂ¯\nâˆ’\nğ©\nÂ¯\nâˆ—\nâ€–\nğ©\nÂ¯\nâˆ’\nğ©\nÂ¯\nâˆ—\nâ€–\nâ€‹\nr\nc\nâˆˆ\nâ„\n2\n,\n\\mathbf{p}_{c}=\\bar{\\mathbf{p}}^{*}+\\frac{\\bar{\\mathbf{p}}-\\bar{\\mathbf{p}}^{*}}{\\|\\bar{\\mathbf{p}}-\\bar{\\mathbf{p}}^{*}\\|}\\mathrm{r}_{c}\\in\\mathbb{R}^{2},\nwhere\nğ©\nÂ¯\nâˆ—\nâˆˆ\nâ„\n2\n\\bar{\\mathbf{p}}^{*}\\in\\mathbb{R}^{2}\nis the nearest point on the capsule centerline to\nğ©\nÂ¯\n\\bar{\\mathbf{p}}\n.\nFinally, The repulsive force vector\nğ¯\nx\nâ€‹\ny\n\\mathbf{v}_{xy}\nis given by:\nğ¯\nx\nâ€‹\ny\n=\nk\nv\nâ€‹\nğ‘\nw\nb\nâ€‹\nğ©\nc\nâˆ—\nâˆ’\nğ©\nc\nâ€–\nğ©\nc\nâˆ—\nâˆ’\nğ©\nc\nâ€–\nâˆˆ\nâ„\n2\n\\mathbf{v}_{xy}=k_{v}\\mathbf{R}^{b}_{w}\\dfrac{\\mathbf{p}_{c}^{*}-\\mathbf{p}_{c}}{||\\mathbf{p}_{c}^{*}-\\mathbf{p}_{c}||}\\in\\mathbb{R}^{2}\n(30)\nwhere\nğ©\nc\nâˆ—\nâˆˆ\nâ„\n2\n{\\mathbf{p}}^{*}_{c}\\in\\mathbb{R}^{2}\nis the nearest point on the capsule line to\nğ©\nc\n{\\mathbf{p}}_{c}\n,\nğ‘\nw\nb\n\\mathbf{R}^{b}_{w}\nis the 2D matrix mapping the x-y axis vectors expressed in the world frame to the mobile robotâ€™s base frame, and\nk\nv\n=\na\nk\nâ€‹\nh\nâ€‹\n(\nmin\nğ©\ni\nâˆˆ\nğ’ª\nh\nâ¡\n{\nd\nx\nâ€‹\ni\n}\n;\n0\n,\nd\n0\n)\nk_{v}=\\mathrm{a}_{k}h\\left(\\min\\limits_{\\mathbf{p}_{i}\\in\\mathcal{O}_{h}}\\{d_{xi}\\};0,\\mathrm{d}_{0}\\right)\nwith\na\nk\nâˆˆ\nâ„\n>\n\\mathrm{a}_{k}\\in\\mathbb{R_{>}}\nbeing a gain factor. Notice that\nk\nv\nk_{v}\nis a gain that increases as the distance between the human and the platform decreases.\nRemark 4\n.\nHere, we consider a predefined area\nğ’ª\nh\n\\mathcal{O}_{h}\nwith respect to the mobile platform where the user is expected to interact with the robot. For more flexible solution leg detection methods utilizing 2D LiDARs\n(Leigh\net al.\n,\n2015\n)\n, could also be utilized in order to adapt the area\nğ’ª\nh\n\\mathcal{O}_{h}\n.\n3\nEXPERIMENTS\nTo validate the functionality and effectiveness of the proposed control framework, with respect to ergonomic performance and user interaction, we conducted two multi-subject experiments.\nThe first, referred to as the\nProlonged Manipulation Task\n(Figure\n6\n), aimed to quantify the ergonomics improvement enabled by the proposed postural virtual fixtures and to evaluate the overall user experience in comparison to a baseline admittance model.\nThe second experiment, termed the\nLong Distance Loco-Manipulation Task\n(Figure\n7\n), involved lifting and carrying a load over an extended distance. This task was designed to validate the ergonomics-driven robot whole-body adaptation during co-manipulation and to determine whether the conditional activation of the base-prioritization functionality promote ergonomic behavior during extended loco-manipulation, even in the absence of kinesthetic feedback.\nThe video of the presented experiments can be found in the multimedia attachment or at\nhttps://youtu.be/fZYz6XOJ1Po\n.\n3.1\nExperimental Setup\nBoth experiments used the Kairos mobile manipulator, which consists of a Robotnik SUMMIT-XL STEEL mobile platform paired with a 6 degrees of freedom (DoFs) Universal Robot UR16e manipulator.\nFor grasping tasks, the Pisa/IIT SoftHand was attached as the end-effector.\nAdditionally, a 3D-printed handle integrating an F/T sensor was positioned near the SoftHand to measure human forces. Mounted on top of the handle was an M5Stack interface, which allowed participants to control various control modalities including the switching between\narm prioritization\nmode (setting\nğ–\nğª\n=\nd\nâ€‹\ni\nâ€‹\na\nâ€‹\ng\nâ€‹\n{\n10\n4\nâ€‹\nğˆ\n3\nÃ—\n3\n,\nğˆ\n6\nÃ—\n6\n}\n\\mathbf{W_{q}}=diag\\{10^{4}\\mathbf{I}_{3\\times 3},\\mathbf{I}_{6\\times 6}\\}\n, with the operator\nd\nâ€‹\ni\nâ€‹\na\nâ€‹\ng\nâ€‹\n{\nâ€¦\n}\n{diag}\\{...\\}\nused to represent block diagonal matrices) and\nbase prioritization\nmode (setting\nğ–\nğª\n=\nd\nâ€‹\ni\nâ€‹\na\nâ€‹\ng\nâ€‹\n{\nğˆ\n3\nÃ—\n3\n,\nğˆ\n6\nÃ—\n6\n}\n\\mathbf{W_{q}}=diag\\{\\mathbf{I}_{3\\times 3},\\mathbf{I}_{6\\times 6}\\}\n) by touch, thus prioritizing either the arm joints or the DoFs of the mobile base, respectively.\nThe mode switch was manually operated by the user for intuitive control based on immediate needs. While future work could explore autonomous switching via human action recognition (e.g., detecting motion size), this was not the focus of the proposed control framework. Additionally, the touch user interface enabled users to control the open or closed status of the SoftHand for grasping objects. The robotic base is also equipped with two 2D SICK Microscan LiDAR sensors to detect the proximity of the human or obstacles on the x-y plane.\nTo demonstrate that the proposed methodology is independent of the skeleton tracking approach, a\npreliminary experiment was conducted using a single camera, while the remainder of the experimental\ncampaign relied on an IMU-based suit. However, a direct comparison between these motion capture\nmethods is beyond the scope of this work. For the single-camera setup, an RGB-D (Intel RealSense) camera monitored operator motion at approximately 20 Hz. In that case, we exploited YOLO algorithm to track the human skeleton and compute joint angles and the ergonomics factor as described in the previous section. However, YOLO did not provide positions for the neck (\nğğ\n\\mathbf{Ne}\n), the pelvis (\nğğ¥\n\\mathbf{Pl}\n), and the middle of the thorax (\nğ“ğ¡\n\\mathbf{Th}\n). We calculated\nğğ\n\\mathbf{Ne}\nas the midpoint between the shoulder points\nğ’\nğ‘\n\\mathbf{S_{R}}\nand\nğ’\nğ‹\n\\mathbf{S_{L}}\n,\nğğ¥\n\\mathbf{Pl}\nas the midpoint of the hips, and\nğ“ğ¡\n\\mathbf{Th}\nas the point two-third of the way between\nğğ\n\\mathbf{Ne}\nand\nğğ¥\n\\mathbf{Pl}\n. For tasks requiring greater spatial coverage, the limited field of view and susceptibility to occlusions of a single camera necessitated more stable tracking. To address this, we then employed a wearable MVN Biomech suit (Xsens Tech.BV), which relies on inertial measurement unit (IMU) sensors, to track the skeleton keypoints. This system ensured reliable tracking even during occlusions or large displacements that could move participants out of the cameraâ€™s view, hence, contributed to a more consistent evaluation of the proposed algorithm in our multi-subject studies.\nFigure 6:\nSetup of the\nProlonged Manipulation Task\n, including the human operator, SRB, glueing tool, Xsens devices, and target tracking paths with numbers indicating the order.\nFigure 7:\nSetup of the\nLong Distance Loco-Manipulation Task\n, involving lifting a load, carrying it, and repositioning it onto a shelf. Note that the chests of drawers serve as obstacles in the environment.\n3.2\nExperimental Protocol\nThe\nProlonged Manipulation Task\ninvolved completing a series of target-tracking paths arranged in various configurations on a table, five consecutive times. This task was designed to showcase the potential of the ergonomics-driven pHRI module in tasks that require prolonged and precise arm movements. Such tasks, commonly performed with low- or medium-weight tools (e.g., for gluing or polishing), often lead to non-ergonomic postures and pose long-term health risks. Participants were instructed to complete three target paths in the sequence shown in Figure\n6\n, with the SRB grasping a hotmelt glue gun. To do so, the users exerted forces at the SRB handle to guide the tool through the target paths.\nFor this task, the\narm prioritization mode\nwas utilized with the parameter values of the proposed control scheme presented in Table\n1\n.\nThe parameters of the proposed control framework were selected to balance performance and user intuitiveness, ensuring responsiveness while maintaining ergonomic comfort. Considering static motion, the stiffness matrix has been defined in order to establish a proportional relationship: a 2 cm deviation from the last ergonomic posture in translational space results in 12 N force feedback, while a 4\no\ndeviation in rotational space produces 1.4 Nm torque feedback. The damping values were experimentally determined to allow for smooth responses during rapid movements while minimizing oscillations when the ergonomic factor is zero. Similarly, the inertia values of the admittance model were chosen experimentally to provide a compliant, responsive, and intuitive user experience. This selection process was conducted before the main experiments using a subject outside the user study. For the god object, the motion dynamics gain was tuned to achieve fast convergence at an ergonomic factor of 1, preventing motion constraints when the human posture is ergonomic.\nIn the\nLong Distance Loco-Manipulation Task\n, the operator collaborated with the SRB to lift and transport a load across a larger workspace, as illustrated in Figure\n7\n. They were instructed to approach the box, grasp it, carry it to the designated drop location, and place it on a shelf, while obstacles were also present in the surrounding environment.\nTo facilitate both precise manipulation and long-distance movement, the touch user interface was used to switch between\narm prioritization mode\nand\nbase prioritization mode\n. Transition from\narm prioritization mode\nto\nbase prioritization mode\nwas permitted only when the userâ€™s ergonomics factor exceeded a predefined threshold (\na\nt\nâ€‹\nh\n=\n0.5\na_{th}=0.5\n). During the\nbase prioritization mode\n, posture-based kinesthetic feedback was deactivated by setting\nğŠ\nd\n=\n0\n\\mathbf{K}_{d}=0\n, as providing such feedback during locomotion was found to be potentially disruptive. Instead of offering real-time postural guidance while walking, the system ensured that switching occurred only when the user was already in an ergonomic posture, thereby promoting the adoption and maintenance of ergonomic postures throughout the task. The underlying hypothesis was that promoting ergonomics during manipulation could also positively influence posture during the\nbase prioritization mode\n, exploiting the natural tendency of humans to prioritize walking without significantly altering arm configurations during long transportation tasks. Since, according to the literature\n(Lamy\net al.\n,\n2009\n; Lecours\net al.\n,\n2012\n)\n, the minimum allowed target inertia value depends on the actual inertia of the physical plant in order for the overall system to remain passive, and because prioritizing the robotic base joints increases the actual inertia, an increase in the corresponding admittance gains is required. Therefore, we set the admittance matrices\nğŒ\nd\n\\mathbf{M}_{d}\nand\nğƒ\nc\n\\mathbf{D}_{c}\nas given in Table\n2\nwith the remaining parameters set to the same values as in the\narm prioritization mode\n.\nTable 1:\nValue of parameters used in the experimental setup.\nRobot and God-object Motion\nğŒ\nd\n\\mathbf{M}_{d}\nd\nâ€‹\ni\nâ€‹\na\nâ€‹\ng\nâ€‹\n{\n5\nâ€‹\nğˆ\n3\nÃ—\n3\n,\n0.25\nâ€‹\nğˆ\n3\nÃ—\n3\n}\ndiag\\{5\\,\\mathbf{I}_{3\\times 3},0.25\\,\\mathbf{I}_{3\\times 3}\\}\nğŠ\nd\n\\mathbf{K}_{d}\nd\nâ€‹\ni\nâ€‹\na\nâ€‹\ng\nâ€‹\n{\n600\nâ€‹\nğˆ\n3\nÃ—\n3\n,\n40\nâ€‹\nğˆ\n3\nÃ—\n3\n}\ndiag\\{\\mathrm{6}00\\mathbf{I}_{3\\times 3},40\\,\\mathbf{I}_{3\\times 3}\\}\nk\nr\n\\mathrm{k}_{r}\n200\nm\n\\mathrm{m}\n0.5\nk\nn\n\\mathrm{k}_{n}\n10\n3\n10^{3}\nÎ´\nn\n\\mathrm{\\delta_{n}}\n5 deg\nÏ•\nÂ¯\nn\n\\overline{\\upphi}_{n}\n55 deg\nDamping term\nğƒ\nd\n\\mathbf{D}_{d}\nğƒ\nc\n\\mathbf{D}_{c}\nd\nâ€‹\ni\nâ€‹\na\nâ€‹\ng\nâ€‹\n{\n20\nâ€‹\nğˆ\n3\nÃ—\n3\n,\nğˆ\n3\nÃ—\n3\n}\ndiag\\{20\\,\\mathbf{I}_{3\\times 3},\\mathbf{I}_{3\\times 3}\\}\na\np\n\\mathrm{a}_{p}\n20\na\no\n\\mathrm{a}_{o}\n4\nb\np\n\\mathrm{b}_{p}\n1\nb\no\n\\mathrm{b}_{o}\n5\nc\np\n\\mathrm{c}_{p}\n2500\nc\no\n\\mathrm{c}_{o}\n20\nSRB Control Framework\nn\n\\mathrm{n}\n6\nğŠ\nx\n\\mathbf{K}_{x}\nd\nâ€‹\ni\nâ€‹\na\nâ€‹\ng\nâ€‹\n{\n0.01\nâ€‹\nğˆ\n1\nÃ—\n3\n,\n0.004\nâ€‹\nğˆ\n1\nÃ—\n3\n}\ndiag\\{0.01\\,\\mathbf{I}_{1\\times 3},0.004\\ \\mathbf{I}_{1\\times 3}\\}\nğ–\nx\n\\mathbf{W}_{x}\n10\n3\nâ€‹\nğˆ\n6\nÃ—\n6\n10^{3}\\,\\mathbf{I}_{6\\times 6}\nr\nc\n\\mathrm{r}_{c}\n37.5 cm\nr\ns\n\\mathrm{r}_{s}\n2 cm\nd\n0\n\\mathrm{d}_{0}\n10 cm\nL\n\\mathrm{L}\n31 cm\na\nk\n\\mathrm{a}_{k}\n0.11\nTable 2:\nParameter values during mobile\nbase prioritization\n.\nAdjusted parameter values\nğŒ\nd\n\\mathbf{M}_{d}\nd\nâ€‹\ni\nâ€‹\na\nâ€‹\ng\nâ€‹\n{\n15\nâ€‹\nI\n3\nÃ—\n3\n,\n0.5\nâ€‹\nI\n3\nÃ—\n3\n}\ndiag\\{15\\,\\mathrm{I}_{3\\times 3},0.5\\,\\mathrm{I}_{3\\times 3}\\}\nğƒ\nc\n\\mathbf{D}_{c}\nd\nâ€‹\ni\nâ€‹\na\nâ€‹\ng\nâ€‹\n{\n40\nâ€‹\nI\n3\nÃ—\n3\n,\nI\n3\nÃ—\n3\n}\ndiag\\{40\\mathrm{\\,}\\mathrm{I}_{3\\times 3},\\mathrm{I}_{3\\times 3}\\}\nğŠ\nd\n\\mathbf{K}_{d}\nğŸ\n6\nÃ—\n6\n\\mathbf{0}_{6\\times 6}\nc\np\n,\nc\no\n\\mathrm{c_{p}},\\ \\mathrm{c_{o}}\n0\nFourteen healthy participants (\n9\n9\nmales and\n5\n5\nfemales, aged\n28.7\nÂ±\n2.9\n28.7\\pm 2.9\nyears), all right-handed, were recruited for the user study.\nThe experimental campaign was carried out at the Human-Robot Interfaces and Interaction (HRII) Laboratory of IIT, in accordance with the revised Declaration of Helsinki. The protocol was approved by the ethics committee Azienda Sanitaria Locale (ASL) Genovese N.3 (Protocol IIT_HRII_ERGOLEAN 156/2020).\nBoth tasks were repeated twice by each participant under two different conditions: Postural Virtual Fixtures (PVFs) and Baseline (B). In the PVFs condition, kinesthetic feedback was provided to promote postures that avoided non-ergonomic configurations in\narm prioritization mode\n, and switching to\nbase prioritization mode\nwas permitted only when the participantâ€™s posture met the ergonomic threshold (\na\nâ‰¥\na\nt\nâ€‹\nh\na\\geq a_{th}\n). In the B condition, the system operated without integrating human posture in the control loop. To achieve this, the ergonomics factor\na\na\nwas fixed at\n1\n1\nthroughout the experiments. This caused the god-object to follow the desired end-effector motion, thereby not providing posture-based kinesthetic feedback. Mode switching from\narm prioritization\nto\nbase prioritization\nwas always possible for the user, and there was no check on the userâ€™s posture.\nBefore the main trials, participants underwent a familiarization phase with the admittance interfaces without being informed of their specific functionalities, allowing them to interpret the systemâ€™s feedback on their own. To minimize learning effects and cumulative workload that could affect the statistical results, the order of the two conditions was randomized, and a break was provided between sessions.\n3.3\nMeasurements and Derived Metrics\nThis subsection outlines the measurements and the metrics used to assess the proposed control framework. Statistical analysis was performed to compare our results with those obtained from the baseline framework (i.e., PVFs condition vs B condition) and identify any significant differences between the two. Initially, the gathered data were tested for normality using the Anderson-Darling test. For normally distributed data, paired t-tests were employed for pairwise comparisons, and repeated measures ANOVA was used for metrics involving multiple repetitions, such as the five iterations per participant in the\nProlonged Manipulation Task\n. For data that did not meet the normality assumption, non-parametric alternatives were applied, including the Wilcoxon signed-rank test for pairwise comparisons and the Friedman test for repeated measures, to identify significant differences.\n3.3.1\nErgonomics Metrics:\nTo assess overall ergonomic performance during the tasks, the mean ergonomics factor\na\nÂ¯\n\\bar{a}\nwas computed as the average value of the factor\na\na\nin (\n26\n) over the entire task duration:\na\nÂ¯\n=\n1\nT\nk\nâ€‹\nâˆ‘\nk\n=\n1\nT\nk\na\nâ€‹\n[\nk\n]\n,\n\\bar{a}=\\frac{1}{T_{k}}\\sum_{k=1}^{T_{k}}a[k],\n(31)\nwhere\nk\nk\nrepresents the time samples and\nT\nk\nT_{k}\nis the total number of samples during the task.\nThe percentage of non-ergonomic time\nÎ¶\nn\nâ€‹\ne\n\\zeta_{ne}\nwas calculated to assess the effectiveness of the proposed method in promoting the avoidance of prolonged non-ergonomic postures, which are associated with increased health risks. This metric is expressed as:\nÎ¶\nn\nâ€‹\ne\n=\n(\n1\nT\nk\nâ€‹\nâˆ‘\nk\n=\n1\nT\nk\nğ•€\nâ€‹\n(\na\nâ€‹\n[\nk\n]\n=\n0\n)\n)\nÃ—\n100\n,\n\\zeta_{ne}=\\left(\\frac{1}{T_{k}}\\sum_{k=1}^{T_{k}}\\mathbb{I}(a[k]=0)\\right)\\times 100,\n(32)\nto quantify the proportion of the task duration spent in non-ergonomic postures (\na\n=\n0\na=0\n).\nğ•€\nâ€‹\n(\nâ‹…\n)\n\\mathbb{I}(\\cdot)\nis the indicator function, which equals\n1\n1\nwhen the condition in parenthesis is true, i.e., in this case\na\nâ€‹\n[\nk\n]\n=\n0\na[k]=0\n, and\n0\notherwise.\nTo capture how frequently the user transitioned into non-ergonomic postures, the non-ergonomic boundary touch count\nÎ²\n\\beta\nwas calculated. This metric counts the instances when the ergonomics factor dropped from a valid ergonomic state to a non-ergonomic state, defined as:\nÎ²\n=\nâˆ‘\nk\n=\n2\nT\nk\nğ•€\nâ€‹\n(\n0\n<\na\nâ€‹\n[\nk\nâˆ’\n1\n]\nâ‰¤\n1\nâˆ§\na\nâ€‹\n[\nk\n]\n=\n0\n)\n.\n\\beta=\\sum_{k=2}^{T_{k}}\\mathbb{I}(0<a[k-1]\\leq 1\\,\\land\\,a[k]=0).\n(33)\nAdditionally, the percentage of time the robotic base was within a critical proximity threshold was computed to estimate potential interference with human manipulation. This metric is expressed as:\nÎ¶\nd\n=\n(\n1\nT\nk\nâ€‹\nâˆ‘\nk\n=\n1\nT\nk\nğ•€\nâ€‹\n(\nd\nâ€‹\n[\nk\n]\n<\nd\n0\n)\n)\nÃ—\n100\n,\n\\zeta_{d}=\\left(\\frac{1}{T_{k}}\\sum_{k=1}^{T_{k}}\\mathbb{I}(\\mathrm{d}[k]<\\mathrm{d}_{0})\\right)\\times 100,\n(34)\nwhere\nd\nâ€‹\n[\nk\n]\n\\mathrm{d}[k]\nis the distance on the horizontal plane between the userâ€™s leg and the robotic base at each time step\nk\nk\n, and\nd\n0\n\\mathrm{d}_{0}\nis the defined proximity threshold.\n3.3.2\nSubjective Rating Scales:\nAt the end of the experiments, participants were asked to complete a custom questionnaire (Table\n3\n) designed to evaluate their experience with the SRB assistance across the two testing conditions. To mitigate bias, we counterbalanced positive and negative items, assessing key factors such as the promotion of postural ergonomics, learning effects, control freedom, and the effectiveness of null-space adaptation. Selected items from the System Usability Scale (SUS)\n(Lewis,\n2018\n)\nwere also included in the questionnaire to examine whether the PVFs impacted the systemâ€™s usability. All feedback was collected using a five-point Likert scale. Additionally, the NASA Task Load Index (NASA-TLX) questionnaire\n(Hart,\n2006\n)\nwas used to evaluate participantsâ€™ perceived workload.\nTable 3:\nCustom Questionnaire\nQ1\n:\nThe interface effectively helped me adopt and maintain an ergonomic posture during the task.\nQ2\n:\nIt was challenging to recognize when I was close to a non-ergonomic posture.\nQ3\n:\nIt was easy to correct my posture to complete the task ergonomically.\nQ4\n:\nAfter a few repetitions, I had learned to be more ergonomic during the task.\nQ5\n:\nI felt in control of the system while performing the task.\nQ6\n:\nThe robotic mobile base interfered with my movement and task completion.\nQ7\n:\nI was concerned that the robotic mobile base could collide with obstacles, e.g., walls.\nSystem Usability Scale (SUS)\nSUS1\n:\nI found the various functions of the system were well integrated.\nSUS2\n:\nI thought the interface was easy to use.\nSUS3\n:\nI felt very confident using the system.\n4\nEXPERIMENTAL RESULTS\n4.1\nExperiment 1: Partial Prolonged Manipulation Task - RGBD Camera Skeleton Tracking\nTo showcase the functionality of the proposed control scheme and highlight its flexibility to different motion\ncapture systems, we first used vision-based skeleton tracking to calculate the ergonomics factor. A right-handed expert user performed one subsection of the gluing task, following the third target path, which was positioned at a low height. The results are illustrated in Figures\n8\nand\n9\n.\nFigure 8:\nVisualization of the robot end-effector trace with color gradients representing the values of\nf\nâ€‹\n(\na\n,\nğ©\ne\n)\nf(a,\\mathbf{p}_{e})\n, alongside an RGB-D camera image processed with YOLO for skeleton detection (Experiment 1), marking a time-stamped instance when the userâ€™s posture was non-ergonomic due to elbow extension.\n(a)\nFrom top to bottom, the plots display the human joint angles (\nÎ¸\nr\n,\nÎ¸\ne\n,\nÎ¸\nb\n\\theta_{r},\\theta_{e},\\theta_{b}\n) with their corresponding ergonomic ranges, the ergonomics factor\na\na\n, the norm of the deviations of the robotâ€™s position from the god-object position (\nâ€–\nğ©\ne\nâ€–\n||\\mathbf{p}_{e}||\n), and the norm of the human-exerted force (\nâ€–\nğŸ\nh\nâ€–\n||\\mathbf{f}_{h}||\n).\n(b)\nVisualization of the damping components.\nFigure 9:\nExperimental results utilizing an RGB-D camera and YOLO detector for skeleton tracking (Experiment 1).\nIn Figure\n8\n, the trace of the robot end-effector and a timestamp of a human non-ergonomic posture are shown. The color of the end-effectorâ€™s trace varies based on the output of the function\nf\nâ€‹\n(\na\n,\nğ©\ne\n)\nf(a,\\mathbf{p}_{e})\n, providing immediate visual feedback about the functionâ€™s value at different points. The image represents a posture where the user is at risk due to the elbow angle exceeding the upper threshold.\nFigure\n9\n(a) shows a series of plots depicting, from top to bottom, the most relevant human joint angles for this task, the total ergonomics factor, the norm of the position deviation between the robot end-effector and the god-object position, and the norm of human-exerted force throughout the task. The angles\nÎ¸\na\n\\theta_{a}\nand\nÎ¸\nf\n\\theta_{f}\nare not visualized as they remain almost constant to zero throughout the task. As we can observe at the beginning of the task, the user starts with an ergonomic posture, i.e.,\na\nâ‰ˆ\n1\na\\approx 1\n. While the user tried to reach the line, her elbow angle\nÎ¸\ne\n\\theta_{e}\nincreased to the risk value\nÎ¸\nÂ¯\ne\nâ€‹\nu\n\\overline{\\uptheta}_{eu}\n, dropping the ergonomics factor to zero. During this phase (time window 8 - 10.8 sec), notable deviations between the robot end-effector and the god-object occur, which leads to increased resistance felt by the user. This resistance is evidenced by the corresponding increase in user-exerted force. It is important to note that while the user could perceive the resistance with less exerted force, in this proof-of-concept experiment, the subject was instructed to push the boundary intentionally. This was done to demonstrate the kinesthetic feedback mechanism inhibiting task continuation and to simulate a worst-case scenario. Under normal conditions, users should reconfigure their posture as soon as they perceive the PVFs.\nThe user then adjusts her posture to a more ergonomic one, enabling her to reach the line with improved ergonomics. While gluing the line, her shoulder rotation angle\nÎ¸\nr\n\\theta_{r}\nexceeds its risk limit\nÎ¸\nÂ¯\nu\nâ€‹\nr\n\\overline{\\uptheta}_{ur}\n(time window 17.5 - 18.8 sec), resistance increases again, prompting another posture correction. After this adjustment, the user continues the task more ergonomically.\nIn Figure\n9\n(b), the damping terms related to the translational motion are only illustrated since the terms associated with rotational motion remain nearly constant, as the task predominantly involves translational motion. As observed, the damping term\nd\nf\nâ€‹\np\nd_{fp}\nassociated with the ergonomics factor\na\na\nand with the deviation between the robot end-effector and the god-object increases as the deviation increases. For the other variable damping term\nd\nv\nâ€‹\np\nd_{vp}\n, which varies based on the power transmitted from the user to the robot, it is observed that\nd\nv\nâ€‹\np\nd_{vp}\ntakes its maximum value when\na\n=\n0\na=0\n. This is because the motion in that case is almost zero, and therefore, the transmitted power is also minimal. The lack of motion can be explained by the fact that kinesthetic feedback is provided to the user, warning them of a non-ergonomic posture. Consequently, the user instinctively stops the end-effectorâ€™s motion and adjusts his/her posture to adopt a more ergonomic one.\nFigure 10:\nVisualization of the robot end-effector trace with color gradients representing\nf\nâ€‹\n(\na\n,\nğ©\ne\n)\nf(a,\\mathbf{p}_{e})\nvalues, alongside a time- stamped indication of a non-ergonomic period during the gluing task of the\nProlonged Manipulation Experiment\n(Experiment 2). Risk areas are labeled with A, B, and C, while D and E denote areas where at least one joint angle nears its risk limit without exceeding it.\nIn the presented experiment, we demonstrated the functionality of the proposed control scheme with a single expert user, showing that the system performs well using a single RGB-D camera for skeleton tracking, provided it is not occluded and lighting conditions are adequate. However, this approach has inherent limitations, such as a restricted field of view and potential inaccuracies due to occlusions. To address these challenges, alternative approachesâ€”such as employing multiple cameras or other monitoring devicesâ€”can be considered. In the subsequent experiments, the Xsens motion capture suit was utilized to overcome these limitations.\nFigure 11:\nFrom top to bottom, plots display human joint angles (\nÎ¸\na\n,\nÎ¸\nf\n,\nÎ¸\nr\n,\nÎ¸\ne\n,\nÎ¸\nb\n\\theta_{a},\\theta_{f},\\theta_{r},\\theta_{e},\\theta_{b}\n) with their corresponding ergonomic ranges, the ergonomics factor\na\na\n, the distance metrics related to the robot pose from the god-object pose (translational\nâ€–\nğ©\ne\nâ€–\n||\\mathbf{p}_{e}||\nand rotational\n1\nâˆ’\nÎ·\ne\n1-\\eta_{e}\n), the ergonomics-based variable damping terms in the translational (\nd\nf\nâ€‹\np\nd_{fp}\n) and rotational (\nd\nf\nâ€‹\no\nd_{fo}\n) motion, and the norms of human exerted force (\nâ€–\nğŸ\nh\nâ€–\n||\\mathbf{f}_{h}||\n) and torque (\nâ€–\nÏ„\nh\nâ€–\n||\\tau_{h}||\n) for the\nProlonged Manipulation Experiment\n, using IMU-based motion tracking system (Experiment 2). The risk areas are labeled with A, B, and C, while D and E denote regions where at least one joint angle is near its risk limit without exceeding it.\nFigure 12:\nNull-space adaptation data for the\nProlonged Manipulation\ntask, utilizing IMU-based motion tracking system (Experiment 2).\n(a)\nHuman physical factors and ergonomics metrics\n(b)\nUser experience assessed through custom questionnaire\nFigure 13:\nPerformance evaluation in the\nProlonged Manipulation Task\n(Experiment 2), comparing the proposed Postural Virtual Fixtures (PVFs) with the baseline condition (B) across all participants. Statistical significance levels are indicated at *\np\n<\n0.05\np<0.05\nand **\np\n<\n0.01\np<0.01\n.\n4.2\nExperiment 2: Prolonged Manipulation Task - IMUs Skeleton Tracking\nThe objective of this experiment is to evaluate the proposed control framework in the prolonged manipulation task. An expert user first performs the task to demonstrate method functionality, and then the analysis is extended to multiple participants, each performing the task five consecutive times.\n4.2.1\nDemonstration of Method Functionality:\nFigures\n10\n-\n12\npresent the results of tracking the complete set of target paths in the\nProlonged Manipulation Task\n. As in the previous case, Figure\n10\nshows the trace of the robot end-effector, color-mapped according to the\nf\nâ€‹\n(\na\n,\nğ©\ne\n)\nf(a,\\mathbf{p}_{e})\nfunction, along with the end-effector frame indicating the orientation of the tool at the beginning and end of the task, as well as at the beginning and end of each tracking-target paths.\nAdditionally, an image is shown where the human operator adopts a non-ergonomic posture due to pronounced shoulder abduction and elbow extension.\nFigure\n11\npresents the angles of the human joints, the ergonomics factor, the pose deviation between the god-object and the robot end-effector, the ergonomics-based variable damping terms, and the human-exerted generalized force. As also observed in the previous experiment, when the angles enter the risk area, labeled A, B, and C, the pose deviation between the end effector and the god-object increases, causing the human operator to experience resistance, which serves as kinesthetic feedback for corrective human posture. This increase in pose deviation leads to a rise in the damping term\nd\nf\nâ€‹\np\nd_{fp}\nas the translation deviation\nâ€–\nğ©\ne\nâ€–\n||\\mathbf{p}_{e}||\ngrows, and similarly, the damping term\nd\nf\nâ€‹\no\nd_{fo}\nincreases as the rotational deviation\n(\n1\nâˆ’\nn\ne\n)\n(1-n_{e})\ngrows. When the angles are near the risk angle limits but have not yet exceeded them (labeled D and E), we can observe that the deviation between the end effector and the god-object increases slightly. However, this does not constrain their movement, as the angles have not yet exceeded the risk threshold, but the resistance is still noticeable. Notice that the highlighted areas A, B, C, D, and E are also connected with specific regions in the path plot shown in Figures\n10\n. The peaks in the torque around 11 seconds and 37 seconds are due to the applied torque to change the orientation of the tool, as can also be observed in the plot of the end effector frame in Figures\n10\n.\nIn Figure\n12\n, the functionality of the null-space adaptation can be observed when the user is in close proximity. In the top plot, we can see the minimum distance from the human point cloud to the platform, followed by the repulsive vector and the norm of the velocity platform. We can observe that as the user gets closer, the higher the repulsive vector, resulting in a higher velocity of the robotic platform, increasing the distance between the human and the platform. This demonstrates that the platform maintains a safe distance from the humanâ€™s legs, providing her with enough space to complete the task.\n4.2.2\nMulti-subject Validation:\nFigure\n13\n(a) presents the ergonomics metrics and corresponding statistical analysis for the two experimental conditions. A significant increase in the mean ergonomics factor\na\nÂ¯\n\\bar{a}\nwas observed when postural kinesthetic feedback was provided to the users, indicating that participants adopted and maintained a more ergonomic posture during the task with the proposed control framework.\nAdditionally, the comparison with the baseline condition revealed a significant reduction in both the time spent in non-ergonomic configurations (\nÎ¶\nn\nâ€‹\ne\n\\zeta_{ne}\n) and the frequency of crossing into the non-ergonomic posture region (\nÎ²\n\\beta\n).\nThis demonstrates that participants effectively perceived the kinesthetic feedback, allowing them to quickly move away from non-ergonomic postures to complete the task.\nInterestingly, the reduction in\nÎ²\n\\beta\nsuggests that PVFs not only helps avoid non-ergonomic postures at the moment but also encourages users to avoid such postures and non-ergonomic boundaries in the future, thereby promoting ergonomics awareness.\nFigure 14:\nEffect of experimental condition order on ergonomic metrics in the\nProlonged Manipulation Task\n(Experiment 2), highlighting the learning to adopt a more ergonomic posture in participants who tested the Postural Virtual Fixtures (PVFs) condition first, even during the subsequent baseline condition (B) without kinesthetic feedback.\nFigure 15:\nExcerpts of the main steps of the\nLong Distance Loco-Manipulation Task\n(Experiment 3) with corresponding RViz visualizations: (1) As the userâ€™s legs approach the robotic base, a repulsive velocity is generated, prompting the base to move along the\narm prioritization\npath (blue) to avoid interfering with human movements; (2) the human-robot system grasps the box, with the robotic base halting to prevent collisions with obstacles; (3-4) the human-robot system transports the box to the drop-off location, switching to\nbase prioritization\n(green path) only when the userâ€™s posture is ergonomic; (5) the system places the box on the shelf.\nParticipantsâ€™ qualitative feedback, collected through the custom questionnaire for both experimental conditions, is shown in Figure\n13\n(b). The bars represent the mean values assigned by participants to the items, while the error bars indicate the\n95\n%\n95\\%\nconfidence intervals of these means. For clarity, all results are reported such that higher values correspond to better outcomes. For items where the original scale indicated the opposite, a bar above the question number denotes that the scale has been inverted.\nThe statistical analysis revealed that the PVFs significantly enhanced participantsâ€™ perception of adopting and maintaining a more ergonomic posture during the task (\nQ1\n), recognizing when they were approaching a non-ergonomic posture (\nQ2\n), and the ease of reconfiguring their posture to complete tasks ergonomically (\nQ3\n).\nImportantly, the kinesthetic feedback did not compromise participantsâ€™ sense of control or confidence in using the system, as evidenced by no significant differences in\nQ5\n(\np\n=\n0.44\np=0.44\n) or\nSUS3\n(\np\n=\n1.00\np=1.00\n). Participants also rated the SRB as comparably easy to use (\nSUS2\n,\np\n=\n0.77\np=0.77\n) across both conditions, while they found the PVFs to be particularly well-integrated with the SRBâ€™s various functions (\nSUS1\n,\np\n<\n0.01\np<0.01\n).\nInterestingly, the significant increase in values for\nQ4\nacross the two conditions suggests that participants felt the PVFs supported their learning to adopt and maintain ergonomic postures over repetitions. This perception was also confirmed by quantitative data. Regardless of the order in which participants performed the conditions, the PVFs significantly improved ergonomic metrics compared to the baseline. Howeover, participants who experienced the PVFs condition first demonstrated a significant improvement in the mean ergonomics factor (see the left plot of Figure\n14\n) and reduction of time spent in non-ergonomic configurations (see the right plot of Figure\n14\n) during the subsequent baseline condition (without kinesthetic feedback), compared to those who started with the baseline condition.\nNASA-TLX results showed a significant reduction in perceived physical demand with the PVFs feedback (\np\n<\n0.05\np<0.05\n). Notably, the PVFs did not affect other scales, such as perceived mental demand, temporal demand, performance, effort, or frustration.\nThis finding is meaningful, as it highlights the effectiveness of the proposed framework in improving physical ergonomics without introducing additional cognitive burden, thereby maintaining overall task performance and user experience.\n4.3\nExperiment 3: Long Distance Loco-Manipulation Task - IMUs Skeleton Tracking\nThe objective of this experiment is to evaluate the proposed control framework in the long distance loco-manipulation task. First, the functionality is analyzed for an expert user, and then the analysis is extended to multiple participants.\n4.3.1\nDemonstration of Method Functionality:\nFigures\n15\n-\n16\nshow the results of executing the\nLong Distance Loco-Manipulation Task\n. Figure\n15\ncaptures key moments of the task with corresponding RViz visualizations, illustrating the designed capsule, the point cloud of the human legs, and the point cloud of the obstacle. The path of the platformâ€™s center is depicted in blue during\narm prioritization\nand in green during\nbase prioritization\n. The blue path highlights the platformâ€™s motion when the human is in close proximity to the base during manipulation facilitating the adoption of an ergonomic posture by the user.\nFigure 16:\nResults of the proposed controller for the\nLong Distance Loco-Manipulation Task\n(Experiment 3).\nFigure 17:\nPerformance evaluation in the\nLong Distance Loco-Manipulation Task\n(Experiment 3). The top plots illustrate the quantitative and qualitative results demonstrating reduced robotic base interference with human movements during\narm prioritization\n. The bottom plots highlight the effect of improved ergonomics during\nbase prioritization\nas a result of the conditional switch that allows\nbase prioritization\nonly when an ergonomic posture is assumed during\narm prioritization\n.\nIn Figure\n16\n, the phase prioritizing the robotic arm is highlighted with blue shading. Pink shaded regions show the attempt to switch priority to the base, which was temporarily delayed to allow the user to adopt a more ergonomic posture before transitioning to base prioritization for long-distance loco-manipulation. Green shaded areas indicate periods of active base prioritization.\nAt the top, the elbow angle is shown as the only angle causing the ergonomics factor to drop to zero when exceeding its risk value around\nt\n=\n5\nâ€‹\ns\nt=5$\\mathrm{s}$\n.\nIn the subsequent plot, the ergonomics factor\na\na\nand the function\nğŸ\nâ€‹\n(\na\n,\nğ©\ne\n)\n\\mathbf{f}(a,\\mathbf{p}_{e})\nare illustrated. With\nm\n=\n0.5\nm=0.5\nset in (\n8\n), the results yield\nf\nâ‰¥\na\nf\\geq a\n, as observed also in the figure. Around\nt\n=\n7\nâ€‹\ns\nt=7$\\mathrm{s}$\n, we observe that the\nğŸ\nâ€‹\n(\na\n,\nğ©\ne\n)\n=\n1\n\\mathbf{f}(a,\\mathbf{p}_{e})=1\nwhile\na\na\nis almost zero. This occurred because, at that time, the user opted to utilize the frameworkâ€™s functionality to replan the movement by bringing her hand back before continuing the task, instead of reconfiguring her posture while maintaining the same hand pose. Specifically, the value of\nğŸ\nâ€‹\n(\na\n,\nğ©\ne\n)\n\\mathbf{f}(a,\\mathbf{p}_{e})\nenabled the god-objectâ€”and, consequently, the userâ€™s handâ€”to move in the direction of returning to the last ergonomic posture.\nThe last three plots in the figure illustrate the functionality of the null-space adaptation. When priority is given to the manipulator and points are detected in the obstacle-related region, the adaptation of the robotâ€™s null space to support ergonomic posture adoption is disabled to prevent dangerous collisions with the environment, even if the user moves close to the platform. Consequently, the repulsive vector remains zero, and the base velocity is also zero. Notably, once the ergonomics factor\na\na\nreaches 0.5, the system automatically switches to base prioritization. What stands out in the plot is that\na\na\nmaintains high values, never dropping to zero, even if kinesthetic feedback is not provided during this phase. In the present experiment, the obstacles in the environment are static; however, the proposed framework also supports time-variable obstacles, as shown in the attached video.\n4.3.2\nMulti-subject Validation:\nAcross all subjects, as was expected, the proposed control framework, which accounts for the proximity of the user to the robotic base, led to a significant reduction in the percentage of time the robotic base remained within the critical proximity threshold compared to the baseline, as shown in the top-left plot of Figure\n17\n. This is also reflected in the custom questionnaire, where participants reported less interference (\nQ6\n, top-right plot) and fewer concerns about collisions with surrounding obstacles (\nQ7\n, top-left plot). Furthermore, this base adaptation, combined with PVF feedback, resulted in significant improvement in ergonomic metrics compared to the baseline (\np\n<\n0.01\np<0.01\n), indicating that the proposed control framework enabled participants to adopt ergonomic postures without interference from the robotic base during precise manipulation.\nNotably, the carryover effect induced by conditional switching, which allowed\nbase prioritization\nonly when the user assumed an ergonomic posture, confirmed our hypothesis that promoting ergonomics during\narm prioritization\nwould positively influence posture during\nbase prioritization\n. Specifically, the mean ergonomics factor\na\nÂ¯\n\\bar{a}\nduring\nbase prioritization\nincreased by\n136\n%\n136\\%\n(marginal significant,\np\n=\n0.08\np=0.08\n), accompanied by a significant reduction in the time spent in non-ergonomic postures, even in the absence of kinesthetic feedback during\nbase prioritization\n(see the bottom plots of Figure\n17\n).\nThe results of other questionnaire items (\nQ1\n-\nQ5\nand NASA-TLX measures across both task phases, i.e.,\narm prioritization\nand\nbase prioritization\n) aligned with findings from the previous experiment. These outcomes confirm that the proposed framework enhances both ergonomics and user experience in human-robot collaborative loco-manipulation tasks.\n4.4\nDiscussion\nThe experimental results highlight the functionality and effectiveness of the proposed control scheme in providing kinesthetic feedback to enhance posture awareness and promote ergonomic practices among SRB users. Users were observed to adopt more ergonomic postures when provided with kinesthetic feedback, spending less time in ergonomically risky postures and engaging in such postures less frequently. This suggests that the feedback immediately positively impacted posture, reducing the time spent in potentially harmful configurations.\nFurthermore, the comparison of ergonomics metrics across the two condition orders (with and without feedback) provides initial evidence that the feedback may have a learning effect, as users exhibited improved ergonomics even after the feedback was removed, compared to those who had not previously experienced the proposed control framework. This indicates that the feedback not only promoted short-term improvements but also helped users establish better posture habits that persisted beyond the active intervention.\nIn addition to improving posture, the results revealed enhanced human-robot coordination, with users spending less time in close proximity to the robotic platform, suggesting that the platform does not hinder human movement. A particularly notable finding is that enabling the robotic base prioritization in the SRB controller only when users achieved an ergonomic posture above a defined threshold promoted better posture maintenance throughout the task, reducing the likelihood of users adopting risky postures during locomotion. This suggests that starting with a good posture can have a lasting effect on maintaining better ergonomics during locomotion tasks involving long transportation, as users tend to maintain the same arm posture throughout these tasks.\nQuality results using questionnaires further support the quantitative findings.\nImportantly, the proposed control framework is versatile, as it is not limited to specific robotic devices. It can be applied to any system that accepts position or velocity commands.\nFurthermore, testing with both vision-based and IMU-based setups shows that a specific motion-tracking approach is not required, as long as the critical joint positions of the user are monitored.\nThis flexibility suggests that the framework has the potential for widespread application in pHRI tasks, both within SRB setups and in broader contexts.\n5\nCONCLUSIONS\nThis study introduced a novel control framework for SRBs designed to promote ergonomic posture through kinesthetic feedback, utilizing virtual fixture techniques integrated with a continuous and online ergonomic assessment framework. Additionally, the floating base of the SRB could dynamically adjust based on the operatorâ€™s proximity, ensuring that the platform avoids collisions with obstacles in the environment and further enhances coordination between the robot and the operator. To evaluate the effectiveness of the proposed framework, a user study involving fourteen participants was conducted. The study included two distinct tasks: the first task focused on fine motion, prioritizing the robotic arm of the SRB, while the second task combined fine and larger motions, requiring prioritization of both the arm and the base. Statistical analysis of both quantitative and qualitative metrics demonstrated that the proposed SRB solution effectively helps users maintain a more ergonomic posture, with additional evidence of a learning effect, suggesting that the benefits of the framework extend beyond immediate usage. A key limitation of the current framework is that the online ergonomic assessment focuses exclusively on the upper body, even though, in the pHRI tasks, the lower limbs (i.e., hips, thighs, knees, ankles, and feet) are also potentially susceptible to strain and discomfort. Additionally, IMU sensor drift may impact motion tracking, and the 2D LiDAR representation limits the effectiveness of collision avoidance. To address these issues, future research will incorporate lower body joint angles, use sensor fusion to reduce drift, and explore 3D LiDAR or sensor combinations for better environmental mapping. The current framework focuses on ergonomic assessment based on human kinematics, but does not account for forces. Future work will also integrate the dynamics of human movement, such as forces, torques, and energy exchanges. Another planned improvement is shifting from an IMU-based motion-tracking suit to a multi-camera setup for human skeleton detection. This would provide more flexibility by eliminating the need for a wearable device and avoiding the drift associated with IMU-based tracking.\nAPPENDIX\n5.1\nJoint Motion Analysis\nGiven the shoulder\nğ’\ni\n\\mathbf{S}_{i}\n, elbow\nğ„\ni\n\\mathbf{E}_{i}\n, wrist\nğ–\ni\n\\mathbf{W}_{i}\n, neck\nğğ\n\\mathbf{Ne}\n, middle of the thorax\nğ“ğ¡\n\\mathbf{Th}\n, middle of the pelvis\nğğ¥\n\\mathbf{Pl}\n, and knee\nğŠğ§\n\\mathbf{Kn}\nkeypoints, where\ni\n=\n{\nR\n,\nL\n}\ni=\\mathrm{\\{R,L\\}}\nindicates the right or left side of the human body, respectively, we can first define the frontal/coronal plane and the sagittal/lateral plane, described by the normal vectors\nğŸ\ni\n\\mathbf{f}_{i}\nand\nğ¬\ni\n\\mathbf{s}_{i}\n, respectively, as follows:\nğŸ\ni\n=\nğğğ’\ni\nâ†’\nÃ—\nğğğ“ğ¡\nâ†’\nâ€–\nğğğ’\ni\nâ†’\nÃ—\nğğğ“ğ¡\nâ†’\nâ€–\nâ€‹\nand\nâ€‹\nğ¬\ni\n=\nğğğ’\ni\nâ†’\nâ€–\nğğğ’\ni\nâ†’\nâ€–\n.\n\\mathbf{f}_{i}=\\dfrac{\\overrightarrow{\\mathbf{Ne}\\mathbf{S}_{i}}\\times\\overrightarrow{\\mathbf{NeTh}}}{\\|\\overrightarrow{\\mathbf{Ne}\\mathbf{S}_{i}}\\times\\overrightarrow{\\mathbf{NeTh}}\\|}\\text{ and }\\mathbf{s}_{i}=\\dfrac{\\overrightarrow{\\mathbf{NeS}_{i}}}{\\|\\overrightarrow{\\mathbf{NeS}_{i}}\\|}.\n(35)\nNote that the vectors are orthogonal, i.e.,\nğŸ\ni\nT\nâ€‹\nğ¬\ni\n=\n0\n\\mathbf{f}_{i}^{\\mathrm{T}}\\mathbf{s}_{i}=0\n.\nThe shoulder movement can be characterized by three angles:\nabduction/adduction\nÎ¸\na\ni\n\\theta^{i}_{a}\n, flexion/extension\nÎ¸\nf\ni\n\\theta^{i}_{f}\n, and internal/external rotation\nÎ¸\nr\ni\n\\theta^{i}_{r}\n. The shoulder abduction/adduction angle\nÎ¸\na\ni\n\\theta^{i}_{a}\nis defined as the angle between the upper arm and trunk in the frontal plane, and it can be measured based on the angle between the vectors\nğğğ’\ni\nâ†’\n\\overrightarrow{\\mathbf{NeS}_{i}}\nand\nğ’\ni\nâ€‹\nğ„\ni\nâ†’\n\\overrightarrow{\\mathbf{S}_{i}\\mathbf{E}_{i}}\nprojected in the coronal plane (see Figure\n3\n(a)) as follows:\nÎ¸\na\ni\n=\n{\nâˆ’\ncos\nâˆ’\n1\nâ¡\n(\nâˆ’\nğ’\ni\nâ€‹\nğ„\ni\nâ†’\nT\nâ€²\nâ€‹\nğ¬\ni\nâ€–\nğ’\ni\nâ€‹\nğ„\ni\nâ†’\nâ€²\nâ€–\n)\n+\n3\nâ€‹\nÏ€\n2\n,\nif\n(\nr\na\ni\n<\n0\nâˆ§\nğ’\ni\nâ€‹\nğ„\ni\nâ†’\nT\nâ€²\nğ¬\ni\n>\n0\n)\nr\na\ni\nâ€‹\ncos\nâˆ’\n1\nâ¡\n(\nâˆ’\nğ’\ni\nâ€‹\nğ„\ni\nâ†’\nT\nâ€²\nâ€‹\nğ¬\ni\nâ€–\nğ’\ni\nâ€‹\nğ„\ni\nâ†’\nâ€²\nâ€–\n)\nâˆ’\nÏ€\n2\n,\notherwise\n\\theta^{i}_{a}=\\begin{cases}-\\cos^{-\\mathrm{1}}\\left(-\\dfrac{{{\\overrightarrow{\\mathbf{S}_{i}\\mathbf{E}_{i}}}^{{}^{\\prime}\\mathrm{T}}}{\\mathbf{s}_{i}}}{\\|{\\overrightarrow{\\mathbf{S}_{i}\\mathbf{E}_{i}}^{{}^{\\prime}}}\\|}\\right)+\\dfrac{3\\pi}{2},&\\text{if }({r_{a}^{i}}<0\\ \\land\\\\\n&\\hskip-8.5359pt{\\overrightarrow{\\mathbf{S}_{i}\\mathbf{E}_{i}}}^{{}^{\\prime}\\mathrm{T}}\\mathbf{s}_{i}>0)\\vskip 5.69046pt\\\\\n{r_{a}^{i}}\\cos^{-\\mathrm{1}}\\left(-\\dfrac{{{\\overrightarrow{\\mathbf{S}_{i}\\mathbf{E}_{i}}}^{{}^{\\prime}\\mathrm{T}}}{\\mathbf{s}_{i}}}{\\|{\\overrightarrow{\\mathbf{S}_{i}\\mathbf{E}_{i}}^{{}^{\\prime}}}\\|}\\right)-\\dfrac{\\pi}{2},&\\text{otherwise}\\end{cases}\n(36)\nwhere\nr\na\ni\n=\nsign\nâ€‹\n(\nğŸ\ni\nT\nâ€‹\n(\nğ¬\ni\nÃ—\nğ’\ni\nâ€‹\nğ„\ni\nâ†’\nâ€²\n)\n)\n{r_{a}^{i}}=\\mathrm{sign}\\big(\\mathbf{f}_{i}^{\\mathrm{T}}(\\mathbf{s}_{i}\\times{\\overrightarrow{\\mathbf{S}_{i}\\mathbf{E}_{i}}}^{{}^{\\prime}})\\big)\nand\nğ’\ni\nâ€‹\nğ„\ni\nâ†’\nâ€²\n=\n(\nğˆ\nâˆ’\nğŸ\ni\nâ€‹\nğŸ\ni\nT\n)\nâ€‹\nğ’\ni\nâ€‹\nğ„\ni\nâ†’\n{\\overrightarrow{\\mathbf{S}_{i}\\mathbf{E}_{i}}}^{{}^{\\prime}}=(\\mathbf{I}-\\mathbf{f}_{i}\\mathbf{f}_{i}^{\\mathrm{T}}){\\overrightarrow{\\mathbf{S}_{i}\\mathbf{E}_{i}}}\n.\nThe shoulder flexion/extension angle\nÎ¸\nf\ni\n\\theta^{i}_{f}\nis measured within the sagittal plane. As presented in Figure\n3\n(b), it can be calculated using the triangles shown in the figure by determining the cosine of the angles between the normal unit vectors of each corresponding triangle as follows\n(Miyashita\net al.\n,\n2008\n)\n:\nÎ¸\nf\ni\n=\nr\nf\ni\nâ€‹\ncos\nâˆ’\n1\nâ¡\n(\nğŸ\ni\nT\nâ€‹\nğ®\ni\n)\n\\theta^{i}_{f}={r_{f}^{i}}\\cos^{-\\mathrm{1}}({{{\\mathbf{f}_{i}}}^{\\mathrm{T}}\\mathbf{u}_{i}})\n(37)\nwhere\nğ®\ni\n=\nğğğ’\ni\nâ†’\nÃ—\nğğğ„\ni\nâ†’\nâ€–\nğğğ’\ni\nâ†’\nÃ—\nğğğ„\ni\nâ†’\nâ€–\n\\mathbf{u}_{i}=\\dfrac{\\overrightarrow{\\mathbf{Ne}\\mathbf{S}_{i}}\\times\\overrightarrow{\\mathbf{NeE}_{i}}}{\\|\\overrightarrow{\\mathbf{Ne}\\mathbf{S}_{i}}\\times\\overrightarrow{\\mathbf{NeE}_{i}}\\|}\n,\nr\nf\nR\n=\nsign\nâ€‹\n(\nğ¬\nR\nT\nâ€‹\n(\nğŸ\nR\nÃ—\nğ®\nR\n)\n)\n{r_{f}^{\\mathrm{R}}}=\\mathrm{sign}\\big(\\mathbf{s}_{\\mathrm{R}}^{\\mathrm{T}}(\\mathbf{f}_{\\mathrm{R}}\\times\\mathbf{u}_{\\mathrm{R}})\\big)\\vskip 14.22636pt\nand\nr\nf\nL\n=\nsign\nâ€‹\n(\nâˆ’\nğ¬\nL\nT\nâ€‹\n(\nğŸ\nL\nÃ—\nğ®\nL\n)\n)\n{r_{f}^{\\mathrm{L}}}=\\mathrm{sign}\\big(-\\mathbf{s}_{\\mathrm{L}}^{\\mathrm{T}}(\\mathbf{f}_{\\mathrm{L}}\\times\\mathbf{u}_{\\mathrm{L}})\\big)\n.\nThe shoulder internal/ external angle\nÎ¸\nr\ni\n\\theta^{i}_{r}\nis calculated using the triangles shown in Figure\n3\n(c) as follows:\nÎ¸\nr\ni\n=\n{\nâˆ’\ncos\nâˆ’\n1\nâ¡\n(\nğ®\ni\nT\nâ€‹\nğ¯\ni\n)\n+\n3\nâ€‹\nÏ€\n2\n,\nif\nâ€‹\n(\nr\nl\ni\n<\n0\nâˆ§\nğ®\ni\nT\nâ€‹\nğ¯\ni\n<\n0\n)\nr\nl\ni\nâ€‹\ncos\nâˆ’\n1\nâ¡\n(\nğ®\ni\nT\nâ€‹\nğ¯\ni\n)\nâˆ’\nÏ€\n2\n,\notherwise\n\\theta^{i}_{r}=\\begin{cases}-\\cos^{-\\mathrm{1}}\\left({\\mathbf{u}_{i}}^{\\mathrm{T}}\\mathbf{v}_{i}\\right)+\\dfrac{3\\pi}{2},&\\text{if }({r_{l}^{i}}<0\\ \\land{\\mathbf{u}_{i}}^{\\mathrm{T}}\\mathbf{v}_{i}<0)\\vskip 5.69046pt\\\\\nr_{l}^{i}\\cos^{-\\mathrm{1}}\\left({\\mathbf{u}_{i}}^{\\mathrm{T}}\\mathbf{v}_{i}\\right)-\\dfrac{\\pi}{2},&\\text{otherwise}\\end{cases}\n(38)\nwhere\nğ¯\ni\n=\nğ„\ni\nâ€‹\nğ’\ni\nâ†’\nÃ—\nğ„\ni\nâ€‹\nğ–\ni\nâ†’\nâ€–\nğ„\ni\nâ€‹\nğ’\ni\nâ†’\nÃ—\nğ„\ni\nâ€‹\nğ–\ni\nâ†’\nâ€–\n\\mathbf{v}_{i}=\\dfrac{\\overrightarrow{\\mathbf{E}_{i}\\mathbf{S}_{i}}\\times\\overrightarrow{\\mathbf{E}_{i}\\mathbf{W}_{i}}}{\\|\\overrightarrow{\\mathbf{E}_{i}\\mathbf{S}_{i}}\\times\\overrightarrow{\\mathbf{E}_{i}\\mathbf{W}_{i}}\\|}\n,\nr\nl\nR\n=\nsign\nâ€‹\n(\nğ„\nR\nâ€‹\nğ’\nR\nâ†’\nT\nâ€‹\n(\nğ®\nR\nÃ—\nğ¯\nR\n)\n)\n{r_{l}^{\\mathrm{R}}}=\\mathrm{sign}\\big({\\overrightarrow{\\mathbf{E}_{\\mathrm{R}}\\mathbf{S}_{\\mathrm{R}}}}^{\\mathrm{T}}(\\mathbf{u}_{\\mathrm{R}}\\times\\mathbf{v}_{\\mathrm{R}})\\big)\nand\nr\nl\nL\n=\nsign\nâ€‹\n(\nğ„\nL\nâ€‹\nğ’\nL\nâ†’\nT\nâ€‹\n(\nğ¯\nL\nÃ—\nğ®\nL\n)\n)\n{r_{l}^{\\mathrm{L}}}=\\mathrm{sign}\\big({\\overrightarrow{\\mathbf{E}_{\\mathrm{L}}\\mathbf{S}_{\\mathrm{L}}}}^{\\mathrm{T}}(\\mathbf{v}_{\\mathrm{L}}\\times\\mathbf{u}_{\\mathrm{L}})\\big)\n.\nThe elbow flexion/extension angle\nÎ¸\ne\ni\n\\theta^{i}_{e}\ncan be calculated based on the angle between the vectors\nğ„\ni\nâ€‹\nğ–\ni\nâ†’\n\\overrightarrow{\\mathbf{E}_{i}\\mathbf{W}_{i}}\nand\nğ„\ni\nâ€‹\nğ’\ni\nâ†’\n\\overrightarrow{\\mathbf{E}_{i}\\mathbf{S}_{i}}\n(see Figure\n3\n(d)) as follows:\nÎ¸\ne\ni\n=\ncos\nâˆ’\n1\nâ¡\n(\nğ„\ni\nâ€‹\nğ–\ni\nâ†’\nT\nâ€‹\nğ„\ni\nâ€‹\nğ’\ni\nâ†’\nâ€–\nğ„\ni\nâ€‹\nğ–\ni\nâ†’\nâ€–\nâ€‹\nâ€–\nğ„\ni\nâ€‹\nğ’\ni\nâ†’\nâ€–\n)\n\\theta^{i}_{e}=\\cos^{-\\mathrm{1}}\\bigg(\\dfrac{\\overrightarrow{\\mathbf{E}_{i}\\mathbf{W}_{i}}^{\\mathrm{T}}\\overrightarrow{\\mathbf{E}_{i}\\mathbf{S}_{i}}}{\\|\\overrightarrow{\\mathbf{E}_{i}\\mathbf{W}_{i}}\\|\\|\\overrightarrow{\\mathbf{E}_{i}\\mathbf{S}_{i}}\\|}\\bigg)\n(39)\nThe bending angle can be calculated based on the angle between the vectors\nğŠğ§ğğ¥\nâ†’\n{\\overrightarrow{\\mathbf{KnPl}}}\nand\nğğ¥ğğ\nâ†’\n\\overrightarrow{\\mathbf{PlNe}}\n(see Figure\n3\n(e)) as follows:\nÎ¸\nb\n=\nr\nb\nâ€‹\ncos\nâˆ’\n1\nâ¡\n(\nğŠğ§ğğ¥\nâ†’\nT\nâ€‹\nğğ¥ğğ\nâ†’\nâ€–\nğŠğ§ğğ¥\nâ†’\nâ€–\nâ€‹\nâ€–\nğğ¥ğğ\nâ†’\nâ€–\n)\n\\theta_{b}=r_{b}\\cos^{-\\mathrm{1}}\\bigg(\\dfrac{{\\overrightarrow{\\mathbf{KnPl}}}^{\\mathrm{T}}\\overrightarrow{\\mathbf{PlNe}}}{\\|{\\overrightarrow{\\mathbf{KnPl}}}\\|\\|\\overrightarrow{\\mathbf{PlNe}}\\|}\\bigg)\n(40)\nwhere\nr\nb\n=\nsign\nâ€‹\n(\nğğğ’\nğ‘\nâ†’\nT\nâ€‹\n(\nğğ¥ğğ\nâ†’\nÃ—\nğŠğ§ğğ¥\nâ†’\n)\n)\n{r_{b}}=\\mathrm{sign}\\big({\\overrightarrow{\\mathbf{Ne}\\mathbf{S_{R}}}}^{\\mathrm{T}}({\\overrightarrow{\\mathbf{PlNe}}}\\times{\\overrightarrow{\\mathbf{KnPl}}})\\big)\n.\nRemark 5\n.\nTo ensure consistency in the results, the previously calculated angle is used when the vector norms involved in the divisions are zero.\n5.2\nDLS for Whole-Body Inverse Kinematics\nConsider the Jacobian\nğ‰\nb\nâˆˆ\nâ„\n6\nÃ—\n3\n\\mathbf{J}_{b}\\in\\mathbb{R}^{6\\times 3}\n, which maps the floating base joint velocities to the generalized velocities of the end-effector, and\nğ‰\na\nâˆˆ\nâ„\n6\nÃ—\nn\n\\mathbf{J}_{a}\\in\\mathbb{R}^{6\\times n}\n, the Jacobian associated with the manipulatorâ€™s joints. The complete robot body Jacobian is then given by:\nğ‰\n=\n[\nğ‰\nb\nğ‰\na\n]\nâˆˆ\nâ„\n6\nÃ—\n(\n3\n+\nn\n)\n\\mathbf{J}=[\\mathbf{J}_{b}\\ \\ \\mathbf{J}_{a}]\\in\\mathbb{R}^{6\\times(3+n)}\n.\nTo solve the inverse kinematics problem, we employ the Damped Least-Squares (DLS) method, originally proposed in\nNakamura and Hanafusa (\n1986\n)\nand later utilized by\nGiammarino\net al.\n(\n2024\n)\nfor SRBs. This approach introduces a damping factor to regularize the solution, ensuring smooth and stable joint movements while maintaining robustness in singular configurations. The solution to the damped least-squares problem is given by:\nğª\nË™\np\n=\n(\nğ‰\nT\nâ€‹\nğ–\nx\nâ€‹\nğ‰\n+\nğ–\nq\n)\nâˆ’\n1\nâ€‹\nğ‰\nT\nâ€‹\nğ–\nx\nâ€‹\n(\nğ¯\nâˆ’\nğŠ\nx\nâ€‹\nğ±\ne\n)\n=\nğ‰\nâˆ—\nâ€‹\n(\nğ¯\nâˆ’\nğŠ\nx\nâ€‹\nğ±\ne\n)\nâˆˆ\nâ„\n(\n3\n+\nn\n)\n\\begin{split}\\dot{\\mathbf{q}}_{p}&=(\\mathbf{J}^{\\mathrm{T}}\\mathbf{W}_{x}\\mathbf{J}+\\mathbf{W}_{q})^{-1}\\mathbf{J}^{\\mathrm{T}}\\mathbf{W}_{x}(\\mathbf{v}-\\mathbf{K}_{x}\\mathbf{x}_{e})\\\\\n&=\\mathbf{J}^{*}(\\mathbf{v}-\\mathbf{K}_{x}\\mathbf{x}_{e})\\in\\mathbb{R}^{(3+n)}\\end{split}\n(41)\nwhere\nğ¯\nâˆˆ\nâ„\n6\n\\mathbf{v}\\in\\mathbb{R}^{6}\nis the generalized desired velocity of the robot end effector, which is calculated by performing the numerical integration of the admittance model (\n1\n),\nğ±\ne\nâˆˆ\nâ„\n6\n\\mathbf{x}_{e}\\in\\mathbb{R}^{6}\nrepresents the pose error between the admittance model pose and the actual end-effector pose,\nğŠ\nx\nâˆˆ\nâ„\n6\nÃ—\n6\n\\mathbf{K}_{x}\\in\\mathbb{R}^{6\\times 6}\nis the pose-error feedback gain matrix that helps minimize deviations caused by the introduction of the joint velocity damping matrix\nğ–\nq\nâˆˆ\nâ„\n(\n3\n+\nn\n)\nÃ—\n(\n3\n+\nn\n)\n\\mathbf{W}_{q}\\in\\mathbb{R}^{(3+n)\\times(3+n)}\nand\nğ‰\nâˆ—\nâˆˆ\nâ„\n(\n3\n+\nn\n)\nÃ—\n6\n\\mathbf{J}^{*}\\in\\mathbb{R}^{(3+n)\\times 6}\nis the so-called Singularity Robust Inverse. The weighting matrices\nğ–\nx\nâˆˆ\nâ„\n6\nÃ—\n6\n\\mathbf{W}_{x}\\in\\mathbb{R}^{6\\times 6}\nand\nğ–\nq\n\\mathbf{W}_{q}\nare positive defined, thus the matrix\nğ‰\nT\nâ€‹\nğ–\nx\nâ€‹\nğ‰\n+\nğ–\nq\n\\mathbf{J}^{\\mathrm{T}}\\mathbf{W}_{x}\\mathbf{J}+\\mathbf{W}_{q}\nis positive definite and hence nonsingular, i.e., invertible. As in\nGiammarino\net al.\n(\n2024\n)\n, the matrix\nğ–\nx\n\\mathbf{W}_{x}\nis designed to introduce priority into the task vector, while the weight matrix\nğ–\nq\n\\mathbf{W}_{q}\ncan be adjusted to prioritize specific joints by assigning higher weight values to those with lower priority, increasing their damping relative to others, and it can also normalize the effects of different joint types by adjusting their weights accordingly. Notice that for redundancy resolution, the null-space projection matrix\nğ’©\n=\n(\nğˆ\nâˆ’\nğ‰\nâˆ—\nâ€‹\nğ‰\n)\n\\mathcal{N}=(\\mathbf{I}-\\mathbf{J}^{\\mathrm{*}}\\mathbf{J})\n, is utilized to project a vector onto the null space of the Jacobian.\n5.3\nClosest Point on a 2D Capsule\nLet us consider a capsule in 2D space defined by a line segment with length\nL\nâˆˆ\nâ„\nâ‰¥\n0\n\\mathrm{L}\\in\\mathbb{R}_{\\geq 0}\nand radius\nr\nc\nâˆˆ\nâ„\nâ‰¥\n0\n\\mathrm{r}_{c}\\in\\mathbb{R}_{\\geq 0}\n. The axis of the capsule is described by\nKastritsi and Doulgeri (\n2022\n)\n:\nğ©\nl\nâ€‹\n(\nÏƒ\n)\n=\nğ©\nf\n+\nğ®\nr\nâ€‹\nf\nâ€‹\nL\nâ€‹\nÏƒ\n,\nÏƒ\nâˆˆ\n[\n0\n,\n1\n]\n,\n\\mathbf{p}_{l}(\\sigma)=\\mathbf{p}_{f}+\\mathbf{u}_{rf}\\mathrm{L}\\sigma,\\quad\\sigma\\in[0,1],\n(42)\nwhere\nğ©\nf\nâˆˆ\nâ„\n2\n\\mathbf{p}_{f}\\in\\mathbb{R}^{2}\nis the front point of the line and\nğ®\nr\nâ€‹\nf\nâˆˆ\nâ„\n2\n\\mathbf{u}_{rf}\\in\\mathbb{R}^{2}\nis the unit vector pointing in the direction of the capsuleâ€™s length.\nFor each point\nğ©\ni\nâˆˆ\nâ„\n2\n\\mathbf{p}_{i}\\in\\mathbb{R}^{2}\n,\nclosest point on the capsuleâ€™s perimeter is computed by:\nğ©\ni\nc\n=\nğ©\ni\nâˆ—\n+\nğ©\ni\nâˆ’\nğ©\ni\nâˆ—\nâ€–\nğ©\ni\nâˆ’\nğ©\ni\nâˆ—\nâ€–\nâ€‹\nr\nc\n\\mathbf{p}_{i}^{c}=\\mathbf{p}_{i}^{*}+\\frac{\\mathbf{p}_{i}-\\mathbf{p}_{i}^{*}}{\\|\\mathbf{p}_{i}-\\mathbf{p}_{i}^{*}\\|}\\mathrm{r}_{c}\n(43)\nwhere\nğ©\ni\nâˆ—\n=\nğ©\ni\nâ€‹\n(\nÏƒ\nâˆ—\n)\n\\mathbf{p}_{i}^{*}=\\mathbf{p}_{i}(\\sigma^{*})\nis the nearest point on the capsuleâ€™s line with\nÏƒ\nâˆ—\n\\sigma^{*}\ngiven by :\nÏƒ\ni\nâˆ—\n=\n{\nÎ¶\ni\nif\nâ€‹\n0\nâ‰¤\nÎ¶\ni\nâ‰¤\n1\n,\n1\nif\nâ€‹\nÎ¶\ni\n>\n1\n,\n0\nif\nâ€‹\nÎ¶\ni\n<\n0\n,\nÎ¶\ni\n=\n1\nL\nâ€‹\nğ®\nr\nâ€‹\nf\nT\nâ€‹\n(\nğ©\ni\nâˆ’\nğ©\nf\n)\n.\n\\sigma_{i}^{*}=\\begin{cases}\\zeta_{i}&\\text{if }0\\leq\\zeta_{i}\\leq 1,\\\\\n1&\\text{if }\\zeta_{i}>1,\\\\\n0&\\text{if }\\zeta_{i}<0,\\end{cases}\\quad\\zeta_{i}=\\frac{1}{\\mathrm{L}}\\mathbf{u}_{rf}^{\\mathrm{T}}(\\mathbf{p}_{i}-\\mathbf{p}_{f}).\n(44)\nAcknowledgments\nWe would like to express our sincere appreciation to Dr. Francisco Jesus Ruiz for the design of the robot handler and his technical support in the 3D printing process.\nDeclaration of conflicting interests\nThe author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.\nFunding\nThis work was supported by the Italian Ministry of University and Research (MUR) under the Fondo Italiano per la Scienza (FIS), call FIS 3, project EPIC (code FIS-2024-02654), and the Italian National Institute for Insurance against Accidents at Work (INAIL) ergoCub Core Project.\n6\nORCID iDs\nTheodora Kastritsi\nhttps://orcid.org/0000-0002-5379-0259\nMarta Lagomarsino\nhttps://orcid.org/0000-0001-9121-1812\nArash Ajoudani\nhttps://orcid.org/0000-0002-1261-737X\nReferences\nP. Balatti, I. Ozdamar, D. Sirintuna, L. Fortini, M. Leonori, J. M. Gandarias, and A. Ajoudani (2024)\nRobot-assisted navigation for visually impaired through adaptive impedance and path planning\n.\nIn\n2024 IEEE International Conference on Robotics and Automation (ICRA)\n,\npp.Â 2310â€“2316\n.\nCited by:\nÂ§1.1.3\n.\nM. BÃ¤r, B. Steinhilber, M. A. Rieger, and T. Luger (2021)\nThe influence of using exoskeletons during occupational tasks on acute physical stress and strain compared to no exoskeletonâ€“a systematic review and meta-analysis\n.\nApplied Ergonomics\n94\n,\npp.Â 103385\n.\nCited by:\nÂ§1\n.\nF. Benzi, C. Mancus, and C. Secchi (2022)\nWhole-body control of a mobile manipulator for passive collaborative transportation\n.\nIFAC-PapersOnLine\n55\n(\n38\n),\npp.Â 106â€“112\n.\nCited by:\nÂ§1.1.3\n.\nS. A. Bowyer, B. L. Davies, and F. R. y Baena (2013)\nActive constraints/virtual fixtures: a survey\n.\nIEEE Transactions on Robotics\n30\n(\n1\n),\npp.Â 138â€“157\n.\nCited by:\nÂ§1.1.2\n.\nS. A. Bowyer and F. R. y Baena (2015)\nDissipative control for physical humanâ€“robot interaction\n.\nIEEE Transactions on Robotics\n31\n(\n6\n),\npp.Â 1281â€“1293\n.\nCited by:\nÂ§1.1.2\n.\nR. A. Castillo-Cruces and J. Wahrburg (2010)\nVirtual fixtures with autonomous error compensation for humanâ€“robot cooperative tasks\n.\nRobotica\n28\n(\n2\n),\npp.Â 267â€“277\n.\nCited by:\nÂ§1.1.2\n.\nM. P. De Looze, T. Bosch, F. Krause, K. S. Stadler, and L. W. Oâ€™sullivan (2016)\nExoskeletons for industrial application and their potential effects on physical work load\n.\nErgonomics\n59\n(\n5\n),\npp.Â 671â€“681\n.\nCited by:\nÂ§1\n.\nG. Dominijanni, D. L. Pinheiro, L. Pollina, B. Orset, M. Gini, E. Anselmino, C. Pierella, J. Olivier, S. Shokur, and S. Micera (2023)\nHuman motor augmentation with an extra robotic arm without functional interference\n.\nScience Robotics\n8\n(\n85\n),\npp.Â eadh1438\n.\nCited by:\nÂ§1\n.\nJ. Eden, M. BrÃ¤cklein, J. IbÃ¡Ã±ez, D. Y. Barsakcioglu, G. Di Pino, D. Farina, E. Burdet, and C. Mehring (2022)\nPrinciples of human movement augmentation and the challenges in making it a reality\n.\nNature Communications\n13\n(\n1\n),\npp.Â 1345\n.\nCited by:\nÂ§1\n.\nF. Ferraguti, R. Villa, C. T. Landi, A. M. Zanchettin, P. Rocco, and C. Secchi (2020)\nA unified architecture for physical and ergonomic humanâ€“robot collaboration\n.\nRobotica\n38\n(\n4\n),\npp.Â 669â€“683\n.\nCited by:\nÂ§1.1.1\n.\nA. Giammarino, J. M. Gandarias, P. Balatti, M. Leonori, M. Lorenzini, and A. Ajoudani (2024)\nSUPER-man: supernumerary robotic bodies for physical assistance in humanâ€“robot conjoined actions\n.\nMechatronics\n103\n,\npp.Â 103240\n.\nCited by:\nÂ§1\n,\nÂ§2.4\n,\nÂ§5.2\n,\nÂ§5.2\n.\nS. G. Hart (2006)\nNasa-task load index (nasa-tlx); 20 years later\n.\nProceedings of the Human Factors and Ergonomics Society Annual Meeting\n50\n(\n9\n),\npp.Â 904â€“908\n.\nExternal Links:\nDocument\n,\nLink\n,\nhttps://doi.org/10.1177/154193120605000909\nCited by:\nÂ§3.3.2\n.\nB. Hasanen, B. Suthar, Y. Zweiri, L. Seneviratne, and I. Hussain (2024)\nDesign of twisted string actuated flexure joint for supernumerary robotic arm for bi-manual tasks\n.\nIEEE Sensors Journal\n.\nCited by:\nÂ§1\n.\nS. Hendriks, B. Hasanen, N. Afzal, I. Hussain, and M. Obaid (2024)\nEnhancing functional and extra motor abilities: a focus group study on the re-design of an extra-robotic finger\n.\nIn\n2024 33rd IEEE International Conference on Robot and Human Interactive Communication (ROMAN)\n,\npp.Â 667â€“673\n.\nCited by:\nÂ§1\n.\nS. Hignett and L. McAtamney (2000)\nRapid entire body assessment (reba)\n.\nApplied ergonomics\n31\n(\n2\n),\npp.Â 201â€“205\n.\nCited by:\nÂ§1.1.1\n.\nW. Hu, X. Pan, and H. Wang (2024)\nProxy-based guidance virtual fixtures with orientation constraints\n.\nInternational Journal of Intelligent Robotics and Applications\n,\npp.Â 1â€“11\n.\nCited by:\nÂ§1.1.2\n.\nT. Kastritsi and Z. Doulgeri (2022)\nA passive admittance controller to enforce remote center of motion and tool spatial constraints with application in hands-on surgical procedures\n.\nRobotics and Autonomous Systems\n152\n,\npp.Â 104073\n.\nCited by:\nÂ§5.3\n.\nT. Kastritsi, D. Papageorgiou, I. Sarantopoulos, Z. Doulgeri, and G. A. Rovithakis (2019)\nStability of active constraints enforcement in sensitive regions defined by point-clouds for robotic surgical procedures\n.\nIn\n2019 18th European Control Conference (ECC)\n,\npp.Â 1604â€“1609\n.\nCited by:\nÂ§1.1.2\n.\nA. Q. Keemink, H. Van der Kooij, and A. H. Stienen (2018)\nAdmittance control for physical humanâ€“robot interaction\n.\nThe International Journal of Robotics Research\n37\n(\n11\n),\npp.Â 1421â€“1444\n.\nCited by:\nÂ§1.1.1\n.\nT. Kermavnar, A. W. de Vries, M. P. de Looze, and L. W. Oâ€™Sullivan (2021)\nEffects of industrial back-support exoskeletons on body loading and user experience: an updated systematic review\n.\nErgonomics\n64\n(\n6\n),\npp.Â 685â€“711\n.\nCited by:\nÂ§1\n.\nH. Khalil (2002)\nNonlinear systems\n.\nThird edition\n,\nPrentice Hall\n.\nCited by:\nÂ§2.1\n.\nW. Kim, P. Balatti, E. Lamon, and A. Ajoudani (2020)\nMOCA-man: a mobile and reconfigurable collaborative robot assistant for conjoined human-robot actions\n.\nIn\n2020 IEEE international conference on robotics and automation (ICRA)\n,\npp.Â 10191â€“10197\n.\nCited by:\nÂ§1\n.\nL. Koutras and Z. Doulgeri (2021)\nExponential stability of trajectory tracking control in the orientation space utilizing unit quaternions\n.\nIn\n2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\n,\npp.Â 8151â€“8158\n.\nCited by:\nÂ§2.1\n.\nM. Lagomarsino, M. Lorenzini, M. D. Constable, E. De Momi, C. Becchio, and A. Ajoudani (2023)\nMaximising coefficiency of human-robot handovers through reinforcement learning\n.\nIEEE Robotics and Automation Letters\n8\n(\n8\n),\npp.Â 4378â€“4385\n.\nCited by:\nÂ§1.1.1\n,\nÂ§2.3\n.\nX. Lamy, F. Colledani, F. Geffard, Y. Measson, and G. Morel (2009)\nAchieving efficient and stable comanipulation through adaptation to changes in human arm impedance\n.\nIn\n2009 IEEE international conference on Robotics and automation\n,\npp.Â 265â€“271\n.\nCited by:\nÂ§3.2\n.\nA. Lecours, B. Mayer-St-Onge, and C. Gosselin (2012)\nVariable admittance control of a four-degree-of-freedom intelligent assist device\n.\nIn\n2012 IEEE international conference on robotics and automation\n,\npp.Â 3903â€“3908\n.\nCited by:\nÂ§3.2\n.\nA. Leigh, J. Pineau, N. Olmedo, and H. Zhang (2015)\nPerson tracking and following with 2d laser scanners\n.\nIn\n2015 IEEE international conference on robotics and automation (ICRA)\n,\npp.Â 726â€“733\n.\nCited by:\nRemark 4\n.\nJ. R. Lewis (2018)\nThe system usability scale: past, present, and future\n.\nInternational Journal of Humanâ€“Computer Interaction\n34\n(\n7\n),\npp.Â 577â€“590\n.\nCited by:\nÂ§3.3.2\n.\nZ. Liao, M. Lorenzini, M. Leonori, F. Zhao, G. Jiang, and A. Ajoudani (2023)\nAn ergo-interactive framework for human-robot collaboration via learning from demonstration\n.\nIEEE Robotics and Automation Letters\n.\nCited by:\nÂ§1.1.1\n,\nÂ§1.1.3\n.\nM. Lorenzini, W. Kim, and A. Ajoudani (2022)\nAn online multi-index approach to human ergonomics assessment in the workplace\n.\nIEEE Transactions on Human-Machine Systems\n52\n(\n5\n),\npp.Â 812â€“823\n.\nCited by:\nÂ§1.1.1\n,\nÂ§2.3\n.\nM. Lorenzini, M. Lagomarsino, L. Fortini, S. Gholami, and A. Ajoudani (2023)\nErgonomic human-robot collaboration in industry: a review\n.\nFrontiers in Robotics and AI\n9\n,\npp.Â 813907\n.\nCited by:\nÂ§1.1.1\n,\nÂ§1\n.\nL. McAtamney and E. N. Corlett (1993)\nRULA: a survey method for the investigation of work-related upper limb disorders\n.\nApplied ergonomics\n24\n(\n2\n),\npp.Â 91â€“99\n.\nCited by:\n3rd item\n,\nÂ§1.1.1\n,\nÂ§2.3\n.\nK. Miyashita, Y. Urabe, H. Kobayashi, K. Yokoe, S. Koshida, M. Kawamura, and K. Ida (2008)\nRelationship between maximum shoulder external rotation angle during throwing and physical variables\n.\nJournal of Sports Science & Medicine\n7\n(\n1\n),\npp.Â 47\n.\nCited by:\nÂ§5.1\n.\nR. Morfino, C. Lauretti, F. Cordella, and L. Zollo (2024)\nA hybrid position/force control for robot-aided pedicle tapping in spinal surgery\n.\nIn\n2024 10th IEEE RAS/EMBS International Conference for Biomedical Robotics and Biomechatronics (BioRob)\n,\npp.Â 1004â€“1010\n.\nCited by:\nÂ§1.1.1\n.\nY. Nakamura and H. Hanafusa (1986)\nInverse kinematic solutions with singularity robustness for robot manipulator control\n.\nJournal of Dynamic Systems, Measurement, and Control\n108\n(\n3\n),\npp.Â 163â€“171\n.\nExternal Links:\nISSN 0022-0434\n,\nDocument\n,\nLink\n,\nhttps://asmedigitalcollection.asme.org/dynamicsystems/article-pdf/108/3/163/5482965/163_1.pdf\nCited by:\nÂ§5.2\n.\nB. Navarro, A. Cherubini, A. Fonte, G. Poisson, and P. Fraisse (2017)\nA framework for intuitive collaboration with a mobile manipulator\n.\nIn\n2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\n,\npp.Â 6293â€“6298\n.\nCited by:\nÂ§1.1.3\n.\nD. Papageorgiou, T. Kastritsi, Z. Doulgeri, and G. A. Rovithakis (2020a)\nA passive phri controller for assisting the user in partially known tasks\n.\nIEEE Transactions on Robotics\n36\n(\n3\n),\npp.Â 802â€“815\n.\nCited by:\nÂ§1.1.2\n.\nD. Papageorgiou, T. Kastritsi, and Z. Doulgeri (2020b)\nA passive robot controller aiding human coaching for kinematic behavior modifications\n.\nRobotics and Computer-Integrated Manufacturing\n61\n,\npp.Â 101824\n.\nCited by:\nÂ§1.1.2\n.\nD. Prattichizzo, M. Pozzi, T. L. Baldi, M. Malvezzi, I. Hussain, S. Rossi, and G. Salvietti (2021)\nHuman augmentation by wearable supernumerary robotic limbs: review and perspectives\n.\nProgress in Biomedical Engineering\n3\n(\n4\n),\npp.Â 042005\n.\nCited by:\nÂ§1\n.\nS. Proia, R. Carli, G. Cavone, and M. Dotoli (2021)\nControl techniques for safe, ergonomic, and efficient human-robot collaboration in the digital industry: a survey\n.\nIEEE Transactions on Automation Science and Engineering\n19\n(\n3\n),\npp.Â 1798â€“1819\n.\nCited by:\nÂ§1.1.1\n.\nH. Raei, J. M. Gandarias, E. De Momi, P. Balatti, and A. Ajoudani (2024)\nA multipurpose interface for close-and far-proximity control of mobile collaborative robots\n.\nIn\n2024 10th IEEE RAS/EMBS International Conference for Biomedical Robotics and Biomechatronics (BioRob)\n,\npp.Â 457â€“464\n.\nCited by:\nÂ§1\n.\nL. B. Rosenberg (1992)\nThe use of virtual fixtures as perceptual overlays to enhance operator performance in remote environments\n.\nAir force material command\n,\npp.Â 1â€“42\n.\nCited by:\nÂ§1.1.2\n.\nD. C. Ruspini, K. Kolarov, and O. Khatib (1997)\nThe haptic display of complex graphical environments\n.\nIn\nProceedings of the 24th annual conference on Computer graphics and interactive techniques\n,\npp.Â 345â€“352\n.\nCited by:\nÂ§1.1.2\n.\nF. Ryden, S. N. Kosari, and H. J. Chizeck (2011)\nProxy method for fast haptic rendering from time varying point clouds\n.\nIn\n2011 IEEE/RSJ International Conference on Intelligent Robots and Systems\n,\npp.Â 2614â€“2619\n.\nCited by:\nÂ§1.1.2\n.\nA. Shafti, A. Ataka, B. U. Lazpita, A. Shiva, H. A. Wurdemann, and K. Althoefer (2019)\nReal-time robot-assisted ergonomics\n.\nIn\n2019 International Conference on Robotics and Automation (ICRA)\n,\npp.Â 1975â€“1981\n.\nCited by:\nÂ§1.1.1\n.\nA. Sidiropoulos, T. Kastritsi, D. Papageorgiou, and Z. Doulgeri (2021)\nA variable admittance controller for human-robot manipulation of large inertia objects\n.\nIn\n2021 30th IEEE International Conference on Robot & Human Interactive Communication (RO-MAN)\n,\npp.Â 509â€“514\n.\nCited by:\nÂ§2.2.1\n.\nD. Sirintuna, T. Kastritsi, I. Ozdamar, J. M. Gandarias, and A. Ajoudani (2024)\nEnhancing humanâ€“robot collaborative transportation through obstacle-aware vibrotactile warning and virtual fixtures\n.\nRobotics and Autonomous Systems\n178\n,\npp.Â 104725\n.\nCited by:\nÂ§1.1.3\n,\nÂ§2.4\n.\nS. Stavridis, D. Papageorgiou, and Z. Doulgeri (2017)\nDynamical system based robotic motion generation with obstacle avoidance\n.\nIEEE Robotics and Automation Letters\n2\n(\n2\n),\npp.Â 712â€“718\n.\nCited by:\nRemark 3\n.\nJ. Theurel and K. Desbrosses (2019)\nOccupational exoskeletons: overview of their benefits and limitations in preventing work-related musculoskeletal disorders\n.\nIISE Transactions on Occupational Ergonomics and Human Factors\n7\n(\n3-4\n),\npp.Â 264â€“280\n.\nCited by:\nÂ§1\n.\nY. Tong and J. Liu (2021)\nReview of research and development of supernumerary robotic limbs\n.\nIEEE/CAA Journal of Automatica Sinica\n8\n(\n5\n),\npp.Â 929â€“952\n.\nCited by:\nÂ§1\n.\nB. Yang, J. Huang, X. Chen, C. Xiong, and Y. Hasegawa (2021)\nSupernumerary robotic limbs: a review and future outlook\n.\nIEEE Transactions on Medical Robotics and Bionics\n3\n(\n3\n),\npp.Â 623â€“639\n.\nCited by:\nÂ§1\n.\nA. M. Zanchettin, E. Lotano, and P. Rocco (2019)\nCollaborative robot assistant for the ergonomic manipulation of cumbersome objects\n.\nIn\n2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\n,\npp.Â 6729â€“6734\n.\nCited by:\nÂ§1.1.1\n.\nC. B. Zilles and J. K. Salisbury (1995)\nA constraint-based god-object method for haptic display\n.\nIn\nProceedings 1995 ieee/rsj international conference on intelligent robots and systems. Human robot interaction and cooperative robots\n,\nVol.\n3\n,\npp.Â 146â€“151\n.\nCited by:\nÂ§1.1.2\n.",
    "preview_text": "Conjoined collaborative robots, functioning as supernumerary robotic bodies (SRBs), can enhance human load tolerance abilities. However, in tasks involving physical interaction with humans, users may still adopt awkward, non-ergonomic postures, which can lead to discomfort or injury over time. In this paper, we propose a novel control framework that provides kinesthetic feedback to SRB users when a non-ergonomic posture is detected, offering resistance to discourage such behaviors. This approach aims to foster long-term learning of ergonomic habits and promote proper posture during physical interactions. To achieve this, a virtual fixture method is developed, integrated with a continuous, online ergonomic posture assessment framework. Additionally, to improve coordination between the operator and the SRB, which consists of a robotic arm mounted on a floating base, the position of the floating base is adjusted as needed. Experimental results demonstrate the functionality and efficacy of the ergonomics-driven control framework, including two user studies involving practical loco-manipulation tasks with 14 subjects, comparing the proposed framework with a baseline control framework that does not account for human ergonomics.\n\n\\corrauth\nTheodora Kastritsi,\nPostural Virtual Fixtures for Ergonomic Physical Interactions with Supernumerary Robotic Bodies\nTheodora Kastritsi\nMarta Lagomarsino\nand Arash Ajoudani\nAuthors are with Human-Robot Interfaces and Interaction Laboratory, Istituto Italiano di Tecnologia, Genoa, Italy.\ntkastrit@gmail.com\nAbstract\nConjoined collaborative robots, functioning as supernumerary robotic bodies (SRBs), can enhance human load tolerance abilities. However, in tasks involving physical interaction with humans, users may still adopt awkward, non-ergonomic postures, which can lead to discomfort or injury over time. In this paper, we propose a novel control framework that provides kinesthetic feedback to SRB users when a non-ergonomic posture is detec",
    "is_relevant": true,
    "relevance_score": 4.0,
    "extracted_keywords": [
        "locomotion",
        "whole body control",
        "fine tune",
        "constrained reinforcement learning",
        "safe reinforcement learning"
    ],
    "one_line_summary": "è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§ç”¨äºè¶…æ•°æœºå™¨äººä½“çš„å§¿æ€è™šæ‹Ÿå¤¹å…·æ§åˆ¶æ¡†æ¶ï¼Œé€šè¿‡åœ¨çº¿å§¿æ€è¯„ä¼°å’Œæµ®åŠ¨åŸºåº§è°ƒæ•´ï¼Œä¿ƒè¿›äººæœºåä½œä¸­çš„ç¬¦åˆäººä½“å·¥ç¨‹å­¦çš„ç‰©ç†äº¤äº’ã€‚",
    "detailed_summary": "",
    "qa_pairs": [],
    "is_hidden": false,
    "is_starred": false,
    "flag": true,
    "published_date": "2026-01-30T07:44:41Z",
    "created_at": "2026-02-03T15:53:05.964559",
    "updated_at": "2026-02-03T15:53:05.964569"
}