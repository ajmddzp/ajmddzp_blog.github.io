{
  "id": "2601.11231v1",
  "title": "Adaptive Monitoring of Stochastic Fire Front Processes via Information-seeking Predictive Control",
  "authors": [
    "Savvas Papaioannou",
    "Panayiotis Kolios",
    "Christos G. Panayiotou",
    "Marios M. Polycarpou"
  ],
  "abstract": "We consider the problem of adaptively monitoring a wildfire front using a mobile agent (e.g., a drone), whose trajectory determines where sensor data is collected and thus influences the accuracy of fire propagation estimation. This is a challenging problem, as the stochastic nature of wildfire evolution requires the seamless integration of sensing, estimation, and control, often treated separately in existing methods. State-of-the-art methods either impose linear-Gaussian assumptions to establish optimality or rely on approximations and heuristics, often without providing explicit performance guarantees. To address these limitations, we formulate the fire front monitoring task as a stochastic optimal control problem that integrates sensing, estimation, and control. We derive an optimal recursive Bayesian estimator for a class of stochastic nonlinear elliptical-growth fire front models. Subsequently, we transform the resulting nonlinear stochastic control problem into a finite-horizon Markov decision process and design an information-seeking predictive control law obtained via a lower confidence bound-based adaptive search algorithm with asymptotic convergence to the optimal policy.",
  "url": "https://arxiv.org/abs/2601.11231v1",
  "html_url": "https://arxiv.org/html/2601.11231v1",
  "html_content": "Adaptive Monitoring of Stochastic Fire Front Processes via Information-seeking Predictive Control\nSavvasÂ Papaioannou,Â PanayiotisÂ Kolios,Â ChristosÂ G.Â Panayiotou andÂ MariosÂ M.Â Polycarpou\nThe authors are with the KIOS Research and Innovation Centre of Excellence (KIOS CoE) and the Department of Electrical and Computer Engineering, University of Cyprus, Nicosia, 1678, Cyprus. E-mail:\n{papaioannou.savvas, pkolios, christosp, mpolycar}@ucy.ac.cy\nThis work is supported by the European Unionâ€™s Horizon Europe program under grant agreement No 101187121 (EUSOME) and the Civil Protection Knowledge for Action in Prevention & Preparedness under grant agreement No. 101193719 (COLLARIS2). It is also supported from the Republic of Cyprus through the Deputy Ministry of Research, Innovation and Digital Policy.\nAbstract\nWe consider the problem of adaptively monitoring a wildfire front using a mobile agent (e.g., a drone), whose trajectory determines where sensor data is collected and thus influences the accuracy of fire propagation estimation.\nThis is a challenging problem, as the stochastic nature of wildfire evolution requires the seamless integration of sensing, estimation, and control, often treated separately in existing methods. State-of-the-art methods either impose linear-Gaussian assumptions to establish optimality or rely on approximations and heuristics, often without providing explicit performance guarantees. To address these limitations, we formulate the fire front monitoring task as a stochastic optimal control problem that integrates sensing, estimation, and control. We derive an optimal recursive Bayesian estimator for a class of stochastic nonlinear elliptical-growth fire front models. Subsequently, we transform the resulting nonlinear stochastic control problem into a finite-horizon Markov decision process and design an information-seeking predictive control law obtained via a lower confidence bound-based adaptive search algorithm with asymptotic convergence to the optimal policy.\nI\nIntroduction\nThe 2025 Southern California wildfires were among the most devastating in the stateâ€™s history: the Palisades Fire in Los Angeles and the Eaton Fire in Altadena burned nearly 40,000 acres, destroyed over 16,000 structures, and displaced hundreds of thousands of people\n[\n7\n]\n. Accurate estimation of wildfire propagation is therefore critical for effective disaster response and informed decision-making. Motivated by this need, this work investigates adaptive monitoring of a stochastic wildfire front using a mobile agent.\nThe task requires planning the agentâ€™s trajectory over a rolling finite horizon to minimize uncertainty in estimating the fireâ€™s evolution from sensor data. At each step, the agent re-plans based on the current environment, yielding a complex problem that demands an integrated approach to sensing, estimation, and control. Existing methods often address only parts of this problem, either by decoupling sensing, estimation, and control, or by simplifying assumptions\n[\n11\n,\n15\n]\n.\nThe problem considered in this work relates to\nactive sensing\n[\n9\n]\n,\ninformation gathering\n[\n1\n]\n, and\nsensor management\n[\n5\n]\n. Sensor management approaches typically address stateless sensors without dynamics, focusing on placement or node selection, and are therefore limited in scenarios where sensor states evolve (e.g., drones equipped with onboard sensors). In such dynamic settings, adaptive control strategies are required. For stochastic dynamic processes, many methods adopt myopic control\n[\n3\n]\n, whereas non-myopic schemes are typically greedy\n[\n13\n]\nor heuristic with sub-optimality guarantees\n[\n6\n]\n. Approaches that provide optimality guarantees often assume linear dynamics with Gaussian noise and apply the certainty equivalence principle (CEP), thereby reducing the problem to deterministic optimal control\n[\n8\n]\n. These assumptions, however, do not hold for the problem addressed in this work.\nIn summary, this work integrates sensing, estimation, and control within a unified stochastic optimal control (SOC) framework for adaptive wildfire-front monitoring using a mobile agent. We develop a recursive Bayesian estimator for elliptical fire-front dynamics under limited sensing and uncertainty, and reformulate the nonlinear SOC problem as a finite-horizon Markov decision process (MDP). The MDP is solved via a lower-confidence-bound (LCB) guided adaptive search that asymptotically converges to the optimal policy.\nII\nProblem Formulation\nII-A\nProblem Objective\nLet a mobile agent be at state\ny\nt\ny_{t}\nat time step\nt\nt\n, and let the agentâ€™s belief distribution over the fire front state\nX\nt\nX_{t}\nbe denoted by\nâ„¬\nt\nâ€‹\n(\nX\nt\n|\nZ\n1\n:\nt\n)\n\\mathcal{B}_{t}(X_{t}|Z_{1:t})\n(abbreviated as\nâ„¬\nt\n\\mathcal{B}_{t}\n) which was computed using measurements\nZ\n1\n:\nt\n=\n[\nZ\n1\n,\nâ€¦\n,\nZ\nt\n]\nZ_{1:t}=[Z_{1},\\ldots,Z_{t}]\nup to time step\nt\nt\n. The objective is to compute the optimal sequence of control inputs\n{\nu\nt\n|\nt\n,\nâ€¦\n,\nu\nt\n+\nT\nâˆ’\n1\n|\nt\n}\n\\{u_{t|t},\\ldots,u_{t+T-1|t}\\}\nover a finite rolling planning horizon of\nT\nT\ntime steps that minimizes:\nğ”¼\nZ\nt\n1\n:\nT\nâ€‹\n{\nâˆ‘\nÏ„\n=\n1\nT\nğ’\nÏ„\nâ€‹\n(\nâ„¬\nt\n+\nÏ„\n|\nt\nâˆ’\n,\nZ\nt\n+\nÏ„\n|\nt\nâ€‹\n(\nu\nt\n+\nÏ„\nâˆ’\n1\n|\nt\n)\n)\n}\n.\n\\mathbb{E}_{Z_{t}^{1:T}}\\left\\{\\sum_{\\tau=1}^{T}\\mathcal{C}_{\\tau}\\left(\\mathcal{B}^{-}_{t+\\tau|t},Z_{t+\\tau|t}(u_{t+\\tau-1|t})\\right)\\right\\}.\n(1)\nHere, the subscript\nt\n+\nÏ„\n|\nt\nt+\\tau|t\ndenotes predicted quantities at time step\nt\n+\nÏ„\nt+\\tau\nfor\nÏ„\nâˆˆ\n{\n1\n,\nâ€¦\n,\nT\n}\n\\tau\\in\\{1,\\dots,T\\}\nwithin the planning horizon, based on information available at time step\nt\nt\n. The cost function\nğ’\nÏ„\n\\mathcal{C}_{\\tau}\nis a bounded, real-valued function that takes as input: a) the predictive density\nâ„¬\nt\n+\nÏ„\n|\nt\nâˆ’\n\\mathcal{B}^{-}_{t+\\tau|t}\ni.e.,\nâ„¬\nt\n+\nÏ„\n|\nt\nâˆ’\nâ€‹\n(\nX\nt\n+\nÏ„\n|\nt\n|\nZ\n1\n:\nt\n+\nÏ„\nâˆ’\n1\n|\nt\n)\n\\mathcal{B}^{-}_{t+\\tau|t}(X_{t+\\tau|t}|Z_{1:t+\\tau-1|t})\n, of the fire front state at time\nt\n+\nÏ„\n|\nt\nt+\\tau|t\n, and b) the future i.e., predicted, measurement\nZ\nt\n+\nÏ„\n|\nt\nâ€‹\n(\nu\nt\n+\nÏ„\nâˆ’\n1\n|\nt\n)\nZ_{t+\\tau|t}(u_{t+\\tau-1|t})\n, which will be received given that the agent executes the control input\nu\nt\n+\nÏ„\nâˆ’\n1\n|\nt\nu_{t+\\tau-1|t}\nand moves to the predicted state\ny\nt\n+\nÏ„\n|\nt\ny_{t+\\tau|t}\n. It then returns a value representing the uncertainty of the fire front state captured in the resulting (pseudo) posterior belief\nâ„¬\nt\n+\nÏ„\n|\nt\n\\mathcal{B}_{t+\\tau|t}\n. An information-rich measurement set is one that reduces the dispersion in the posterior, which is the agentâ€™s objective over the planning horizon. The expectation is taken with respect to the future measurement set\nZ\nt\n1\n:\nT\n=\n{\nZ\nt\n+\n1\n|\nt\n,\nâ€¦\n,\nZ\nt\n+\nT\n|\nt\n}\nZ_{t}^{1:T}=\\{Z_{t+1|t},\\ldots,Z_{t+T|t}\\}\n. Subsequently, the agent executes the first control input in the sequence, i.e.,\nu\nt\n|\nt\nu_{t|t}\n, transitions to its new state\ny\nt\n+\n1\ny_{t+1}\n, receives the real measurement\nZ\nt\n+\n1\nZ_{t+1}\n, computes the posterior belief\nâ„¬\nt\n+\n1\nâ€‹\n(\nX\nt\n+\n1\n|\nZ\n1\n:\nt\n+\n1\n)\n\\mathcal{B}_{t+1}(X_{t+1}|Z_{1:t+1})\n, and repeats the process described above for time step\nt\n+\n1\nt+1\n.\nII-B\nFire Front Propagation Model\nIn this work, as we discuss next, we employ a stochastic adaptation of the deterministic elliptical fire propagation model proposed in\n[\n12\n]\n. This model, which is currently utilized in various fire-area simulators\n[\n4\n]\n, describes the spatiotemporal evolution of a fire front using a nonlinear system of first-order differential equations. Specifically, the fire front is represented as an ellipse defined by a series of\nN\nN\nvertices that collectively delineate the propagating fireâ€™s edge at a specific moment. The spatiotemporal discrete-time dynamics of vertex\ni\nâˆˆ\n{\n1\n,\nâ€¦\n,\nN\n}\ni\\in\\{1,\\ldots,N\\}\nat time step\nt\nt\nare given by:\nx\nt\ni\n=\nx\nt\nâˆ’\n1\ni\n+\nÎ”\nâ€‹\nt\nâ€‹\nx\nË™\nt\nâˆ’\n1\ni\n,\nx^{i}_{t}=x^{i}_{t-1}+\\Delta t\\,\\dot{x}^{i}_{t-1},\n(2)\nwhere\nx\nt\ni\n=\n[\nx\nt\ni\n,\ny\nt\ni\n]\nâŠ¤\nâˆˆ\nâ„\n2\nx^{i}_{t}=[\\text{x}^{i}_{t},\\text{y}^{i}_{t}]^{\\top}\\in\\mathbb{R}^{2}\nis the state of vertex\ni\ni\ncomposed of 2D Cartesian coordinates,\nÎ”\nâ€‹\nt\n\\Delta t\nis the sampling interval, and the fire growth velocity at vertex\ni\ni\nis given by\nx\nË™\nt\nâˆ’\n1\ni\n=\n\\dot{x}^{i}_{t-1}=\n[\nÎ±\n1\n2\nâ€‹\n(\ni\n)\nâ€‹\ncos\nâ¡\n(\nÎ¸\nâ€‹\n(\ni\n)\n)\nâ€‹\nS\nâ€‹\nC\nâ€‹\n(\ni\n)\nâˆ’\nÎ±\n2\n2\nâ€‹\n(\ni\n)\nâ€‹\nsin\nâ¡\n(\nÎ¸\nâ€‹\n(\ni\n)\n)\nâ€‹\nC\nâ€‹\nS\nâ€‹\n(\ni\n)\nÎ±\n2\n2\nâ€‹\n(\ni\n)\nâ€‹\nC\nâ€‹\nS\nâ€‹\n(\ni\n)\n2\n+\nÎ±\n1\n2\nâ€‹\n(\ni\n)\nâ€‹\nS\nâ€‹\nC\nâ€‹\n(\ni\n)\n2\n+\nC\n1\nâ€‹\n(\ni\n)\nâˆ’\nÎ±\n1\n2\nâ€‹\n(\ni\n)\nâ€‹\nsin\nâ¡\n(\nÎ¸\nâ€‹\n(\ni\n)\n)\nâ€‹\nS\nâ€‹\nC\nâ€‹\n(\ni\n)\nâˆ’\nÎ±\n2\n2\nâ€‹\n(\ni\n)\nâ€‹\ncos\nâ¡\n(\nÎ¸\nâ€‹\n(\ni\n)\n)\nâ€‹\nC\nâ€‹\nS\nâ€‹\n(\ni\n)\nÎ±\n2\n2\nâ€‹\n(\ni\n)\nâ€‹\nC\nâ€‹\nS\nâ€‹\n(\ni\n)\n2\n+\nÎ±\n1\n2\nâ€‹\n(\ni\n)\nâ€‹\nS\nâ€‹\nC\nâ€‹\n(\ni\n)\n2\n+\nC\n2\nâ€‹\n(\ni\n)\n]\n,\n\\begin{bmatrix}\\displaystyle\\frac{\\alpha_{1}^{2}(i)\\cos\\left(\\theta(i)\\right)SC(i)-\\alpha_{2}^{2}(i)\\sin\\left(\\theta(i)\\right)CS(i)}{\\sqrt{\\alpha_{2}^{2}(i)CS(i)^{2}+\\alpha_{1}^{2}(i)SC(i)^{2}}}+C_{1}(i)\\!\\\\\n\\displaystyle\\frac{-\\alpha_{1}^{2}(i)\\sin\\left(\\theta(i)\\right)SC(i)-\\alpha_{2}^{2}(i)\\cos\\left(\\theta(i)\\right)CS(i)}{\\sqrt{\\alpha_{2}^{2}(i)CS(i)^{2}+\\alpha_{1}^{2}(i)SC(i)^{2}}}+C_{2}(i)\\!\\end{bmatrix},\nwhere\nS\nâ€‹\nC\nâ€‹\n(\ni\n)\n=\nx\ns\ni\nâ€‹\nsin\nâ¡\n(\nÎ¸\nâ€‹\n(\ni\n)\n)\n+\ny\ns\ni\nâ€‹\ncos\nâ¡\n(\nÎ¸\nâ€‹\n(\ni\n)\n)\nSC(i)=\\text{x}^{i}_{s}\\sin\\left(\\theta(i)\\right)+\\text{y}^{i}_{s}\\cos\\left(\\theta(i)\\right)\n,\nC\nâ€‹\nS\nâ€‹\n(\ni\n)\n=\nx\ns\ni\nâ€‹\ncos\nâ¡\n(\nÎ¸\nâ€‹\n(\ni\n)\n)\nâˆ’\ny\ns\ni\nâ€‹\nsin\nâ¡\n(\nÎ¸\nâ€‹\n(\ni\n)\n)\nCS(i)=\\text{x}^{i}_{s}\\cos\\left(\\theta(i)\\right)-\\text{y}^{i}_{s}\\sin\\left(\\theta(i)\\right)\n,\nC\n1\nâ€‹\n(\ni\n)\n=\nÎ±\n3\nâ€‹\n(\ni\n)\nâ€‹\nsin\nâ¡\n(\nÎ¸\nâ€‹\n(\ni\n)\n)\nC_{1}(i)=\\alpha_{3}(i)\\sin\\left(\\theta(i)\\right)\n,\nC\n2\nâ€‹\n(\ni\n)\n=\nÎ±\n3\nâ€‹\n(\ni\n)\nâ€‹\ncos\nâ¡\n(\nÎ¸\nâ€‹\n(\ni\n)\n)\nC_{2}(i)=\\alpha_{3}(i)\\cos\\left(\\theta(i)\\right)\n, and\n[\nx\ns\ni\n,\ny\ns\ni\n]\nâŠ¤\n[\\text{x}^{i}_{s},\\text{y}^{i}_{s}]^{\\top}\nare the components of the tangent vector at vertex\ni\ni\n, providing the local orientation of the fire front at that point.\nEnvironmental conditions, such as fuel type and weather, local to each vertex, affect the forward fire propagation rate and direction. These factors include wind direction and speed, denoted by\nÎ¸\n\\theta\nand\nw\ns\nw_{s}\n, respectively, as well as the fire spread rate due to fuel type, denoted by\nr\nf\nr_{f}\n. These parameters are stochastic and can vary throughout the environment. Therefore, each vertex may be affected differently depending on the fire frontâ€™s extent and the environmental variability. Specifically, we denote\nÎ¸\nâ€‹\n(\ni\n)\nâˆˆ\n[\n0\n,\n2\nâ€‹\nÏ€\n]\n\\theta(i)\\in[0,2\\pi]\nas the wind direction affecting vertex\ni\ni\n, the wind speed at the location of vertex\ni\ni\nas\nw\ns\nâ€‹\n(\ni\n)\nâˆˆ\nâ„\n+\nw_{s}(i)\\in\\mathbb{R}^{+}\n, and the fire spread rate as\nr\nf\nâ€‹\n(\ni\n)\nâˆˆ\nâ„\n+\nr_{f}(i)\\in\\mathbb{R}^{+}\n. Here,\nÎ¸\nâ€‹\n(\ni\n)\n,\nw\ns\nâ€‹\n(\ni\n)\n,\nr\nf\nâ€‹\n(\ni\n)\n\\theta(i),w_{s}(i),r_{f}(i)\n,\nâˆ€\ni\n\\forall i\n, are random realizations of the wind direction, wind speed, and fire spread rate at the location of vertex\ni\ni\n.\nThe parameters\nÎ±\n1\nâ€‹\n(\ni\n)\n\\alpha_{1}(i)\n,\nÎ±\n2\nâ€‹\n(\ni\n)\n\\alpha_{2}(i)\n, and\nÎ±\n3\nâ€‹\n(\ni\n)\n\\alpha_{3}(i)\ndenote the shape parameters governing the elliptical fire growth from vertex\ni\ni\n, representing respectively the lengths of the semi-minor axis, the semi-major axis, and the distance from the ignition point to the center of the ellipse, defined respectively as:\nÎ±\n1\nâ€‹\n(\ni\n)\n=\nr\nf\nâ€‹\n(\ni\n)\n+\nr\nf\nâ€‹\n(\ni\n)\nH\nâ€‹\nB\nâ€‹\n(\ni\n)\n2\nâ€‹\nL\nâ€‹\nB\nâ€‹\n(\ni\n)\n\\alpha_{1}(i)=\\frac{r_{f}(i)+\\frac{r_{f}(i)}{HB(i)}}{2LB(i)}\n,\nÎ±\n2\nâ€‹\n(\ni\n)\n=\nr\nf\nâ€‹\n(\ni\n)\n+\nr\nf\nâ€‹\n(\ni\n)\nH\nâ€‹\nB\nâ€‹\n(\ni\n)\n2\n\\alpha_{2}(i)=\\frac{r_{f}(i)+\\frac{r_{f}(i)}{HB(i)}}{2}\n, and\nÎ±\n3\nâ€‹\n(\ni\n)\n=\nÎ±\n2\nâ€‹\n(\ni\n)\nâˆ’\nr\nf\nâ€‹\n(\ni\n)\nH\nâ€‹\nB\nâ€‹\n(\ni\n)\n\\alpha_{3}(i)=\\alpha_{2}(i)-\\frac{r_{f}(i)}{HB(i)}\n, where\nH\nâ€‹\nB\nâ€‹\n(\ni\n)\nHB(i)\nis the head-to-back ratio accounting for the difference between the fireâ€™s forward (head) and backward (back) spread from the ignition point, while\nL\nâ€‹\nB\nâ€‹\n(\ni\n)\nLB(i)\nis the length-to-breadth ratio which determines the overall elongation of the fireâ€™s elliptical shape. These are defined as:\nH\nâ€‹\nB\nâ€‹\n(\ni\n)\n=\nL\nâ€‹\nB\nâ€‹\n(\ni\n)\n+\n(\nL\nâ€‹\nB\nâ€‹\n(\ni\n)\n2\nâˆ’\n1\n)\n0.5\nL\nâ€‹\nB\nâ€‹\n(\ni\n)\nâˆ’\n(\nL\nâ€‹\nB\nâ€‹\n(\ni\n)\n2\nâˆ’\n1\n)\n0.5\nHB(i)=\\frac{LB(i)+(LB(i)^{2}-1)^{0.5}}{LB(i)-(LB(i)^{2}-1)^{0.5}}\n, and\nL\nâ€‹\nB\nâ€‹\n(\ni\n)\n=\n0.936\nâ€‹\nexp\nâ¡\n(\n0.2566\nâ€‹\nw\ns\nâ€‹\n(\ni\n)\n)\n+\n0.461\nâ€‹\nexp\nâ¡\n(\nâˆ’\n0.1548\nâ€‹\nw\ns\nâ€‹\n(\ni\n)\n)\nâˆ’\n0.397\nLB(i)=0.936\\exp(0.2566w_{s}(i))+0.461\\exp(-0.1548w_{s}(i))-0.397\n. For a more in-depth description these parameters we refer the reader to\n[\n4\n]\n. Subsequently, the propagation of the fire front process\nX\nt\n=\n[\nx\nt\n1\n,\nâ€¦\n,\nx\nt\nN\n]\nâŠ¤\nâˆˆ\nğ’³\nX_{t}=[x^{1}_{t},\\ldots,x^{N}_{t}]^{\\top}\\in\\mathcal{X}\nis more compactly expressed as:\nX\nt\n=\nÎ¾\nâ€‹\n(\nX\nt\nâˆ’\n1\n,\nE\nt\nâˆ’\n1\n)\nX_{t}=\\xi(X_{t-1},E_{t-1})\n, where\nE\nt\nâˆ¼\nP\nE\nE_{t}\\sim P_{E}\n, with\nE\nt\nâˆˆ\n[\n0\n,\n2\nâ€‹\nÏ€\n]\nN\nÃ—\n[\n0\n,\nâˆ\n)\nN\nÃ—\n[\n0\n,\nâˆ\n)\nN\nE_{t}\\in[0,2\\pi]^{N}\\times[0,\\infty)^{N}\\times[0,\\infty)^{N}\n, denotes a random realization of\n{\nÎ¸\nâ€‹\n(\ni\n)\n,\nw\ns\nâ€‹\n(\ni\n)\n,\nr\nf\nâ€‹\n(\ni\n)\n}\ni\n=\n1\nN\n\\{\\theta(i),w_{s}(i),r_{f}(i)\\}_{i=1}^{N}\ndrawn from the PDF\nP\nE\nP_{E}\n, which captures the stochasticity of the fire front propagation acting as a stationary process noise.\nII-C\nAgent Dynamics and Sensing Model\nAn autonomous mobile agent represented by a point-mass object, evolves inside a bounded planar environment\nâ„°\nâŠ‚\nâ„\n2\n\\mathcal{E}\\subset\\mathbb{R}^{2}\naccording to discrete-time dynamics of the form\ny\nt\n=\nf\na\nâ€‹\n(\ny\nt\nâˆ’\n1\n,\nu\nt\nâˆ’\n1\n)\ny_{t}=f_{a}(y_{t-1},u_{t-1})\n[\n10\n]\n, where\ny\nt\nâˆˆ\nğ’´\ny_{t}\\in\\mathcal{Y}\nis the state of agent at time\nt\nt\n, and\nu\nt\nâˆˆ\nğ’°\nu_{t}\\in\\mathcal{U}\nis the control input. In addition, the agent has a finite sensing range for observing its surroundings (i.e., through a camera), which is given by a circular region with radius\nR\na\nR_{a}\ni.e.,\nO\nt\n=\n{\nx\nâˆˆ\nâ„\n2\nâˆ£\nâ€–\nx\nâˆ’\ny\nt\np\nâ€–\nâ‰¤\nR\na\n}\nO_{t}=\\{x\\in\\mathbb{R}^{2}\\mid\\|x-y^{p}_{t}\\|\\leq R_{a}\\}\n, where\ny\nt\np\ny^{p}_{t}\nis the agentâ€™s position at time\nt\nt\n.\nThe agent uses its camera to observe the state of the fire front, i.e., by taking snapshots and determining the location of the fire front from the image snapshots using image processing (i.e., object detection). Due to sensing and image processing imperfections, this process carries a certain degree of inaccuracy, resulting in noisy observations. Specifically, for fire front vertex\ni\ni\nwith true state\nx\nt\ni\nx^{i}_{t}\n, the agent observes the measurement\nz\nt\ni\nz^{i}_{t}\ninside its sensing range according to:\nz\nt\ni\n=\nh\nâ€‹\n(\nx\nt\ni\n)\n+\nw\nt\ni\n,\nz^{i}_{t}=h(x^{i}_{t})+w^{i}_{t},\nwhere\nh\nâ€‹\n(\nâ‹…\n)\nh(\\cdot)\nis a function that relates the true states to the received measurements, and\nw\nt\ni\nâˆ¼\nğ’©\nâ€‹\n(\n0\n,\nÏƒ\nz\n2\nâ€‹\nI\n2\nÃ—\n2\n)\nw^{i}_{t}\\sim\\mathcal{N}(0,\\sigma^{2}_{z}I_{2\\times 2})\nrepresents measurement noise. The noise is independent and identically distributed (i.i.d.) according to a zero-mean Gaussian distribution with variance\nÏƒ\nz\n2\n\\sigma^{2}_{z}\n, where\nI\n2\nÃ—\n2\nI_{2\\times 2}\nis the\n2\nÃ—\n2\n2\\times 2\nidentity matrix. Additionally,\nw\nt\ni\nw^{i}_{t}\nis independent of the process noise described in the previous section.\nThe object detection algorithm often produces multiple fragmented pixel blobs for the same fire-front vertex, so that\nx\nt\ni\nx^{i}_{t}\nis associated with the measurement vector\n[\nz\nt\ni\n,\n1\n,\nâ€¦\n,\nz\nt\ni\n,\nn\nt\ni\n]\n[z^{i,1}_{t},\\ldots,z^{i,n^{i}_{t}}_{t}]\n. The number of such blobs depends on the true vertex location, and is modeled as a Poisson random variable with rate\nÎ»\nt\ni\nâ€‹\n(\nx\nt\ni\n)\n\\lambda^{i}_{t}(x^{i}_{t})\n. Thus, a vertex\nx\nt\ni\nx^{i}_{t}\nmay yield\nn\nt\ni\nâˆ¼\nPois\nâ€‹\n(\nÎ»\nt\ni\nâ€‹\n(\nx\nt\ni\n)\n)\nn^{i}_{t}\\sim\\text{Pois}(\\lambda^{i}_{t}(x^{i}_{t}))\ndetections within the sensing range. The resulting measurement set follows a Poisson point process\n[\n14\n]\nwith intensity\nÎ³\nt\ni\nâ€‹\n(\nz\n|\nx\nt\ni\n,\ny\nt\n)\n=\nÎ»\nt\ni\nâ€‹\n(\nx\nt\ni\n)\nâ€‹\np\nâ€‹\n(\nz\n|\nx\nt\ni\n)\n,\nx\nt\ni\nâˆˆ\nO\nt\n,\n\\gamma^{i}_{t}(z|x^{i}_{t},y_{t})=\\lambda^{i}_{t}(x^{i}_{t})\\,p(z|x^{i}_{t}),\\quad x^{i}_{t}\\in O_{t},\n(3)\nand\nÎ³\nt\ni\nâ€‹\n(\nz\n|\nx\nt\ni\n,\ny\nt\n)\n=\n0\n\\gamma^{i}_{t}(z|x^{i}_{t},y_{t})=0\notherwise, where\np\nâ€‹\n(\nz\n|\nx\nt\ni\n)\n=\nğ’©\nâ€‹\n(\nz\n;\nh\nâ€‹\n(\nx\nt\ni\n)\n,\nÏƒ\nz\n2\nâ€‹\nI\n2\nÃ—\n2\n)\np(z|x^{i}_{t})=\\mathcal{N}(z;h(x^{i}_{t}),\\sigma^{2}_{z}I_{2\\times 2})\nis the normalized measurement likelihood restricted to\nO\nt\nO_{t}\n.\nIII\nAdaptive Monitoring via Information-seeking Predictive Control\nIII-A\nFire Front Recursive State Estimation\nBayesian recursive state estimation for systems with fixed-dimensional state and measurement vectors is formulated through the predictor-corrector recursion:\nâ„¬\nt\nâˆ’\nâ€‹\n(\nx\nt\n|\nz\n1\n:\nt\nâˆ’\n1\n)\n=\nâˆ«\np\nâ€‹\n(\nx\nt\n|\nx\nt\nâˆ’\n1\n)\nâ€‹\nâ„¬\nt\nâˆ’\n1\nâ€‹\n(\nx\nt\nâˆ’\n1\n|\nz\n1\n:\nt\nâˆ’\n1\n)\nâ€‹\nğ‘‘\nx\nt\nâˆ’\n1\n,\n\\displaystyle\\mathcal{B}^{-}_{t}(x_{t}|z_{1:t-1})=\\int p(x_{t}|x_{t-1})\\,\\mathcal{B}_{t-1}(x_{t-1}|z_{1:t-1})\\,dx_{t-1},\nâ„¬\nt\nâ€‹\n(\nx\nt\n|\nz\n1\n:\nt\n)\n=\np\nâ€‹\n(\nz\nt\n|\nx\nt\n)\nâ€‹\nâ„¬\nt\nâˆ’\nâ€‹\n(\nx\nt\n|\nz\n1\n:\nt\nâˆ’\n1\n)\nâˆ«\np\nâ€‹\n(\nz\nt\n|\nx\nt\n)\nâ€‹\nâ„¬\nt\nâˆ’\nâ€‹\n(\nx\nt\n|\nz\n1\n:\nt\nâˆ’\n1\n)\nâ€‹\nğ‘‘\nx\nt\n,\n\\displaystyle\\mathcal{B}_{t}(x_{t}|z_{1:t})=\\frac{p(z_{t}|x_{t})\\,\\mathcal{B}^{-}_{t}(x_{t}|z_{1:t-1})}{\\int p(z_{t}|x_{t})\\,\\mathcal{B}^{-}_{t}(x_{t}|z_{1:t-1})\\,dx_{t}},\n(4)\nwhere with slight abuse of notation in Eq. (\nIII-A\n)\nx\nt\nâˆˆ\nâ„\nd\nx\nx_{t}\\in\\mathbb{R}^{d_{x}}\nis the state of the system,\nz\nt\nâˆˆ\nâ„\nd\nz\nz_{t}\\in\\mathbb{R}^{d_{z}}\nis the received measurement,\np\nâ€‹\n(\nx\nt\n|\nx\nt\nâˆ’\n1\n)\np(x_{t}|x_{t-1})\nis the transitional density governed by the stochastic process dynamics,\np\nâ€‹\n(\nz\nt\n|\nx\nt\n)\np(z_{t}|x_{t})\nis the measurement likelihood function,\nâ„¬\nt\nâˆ’\nâ€‹\n(\nx\nt\n|\nz\n1\n:\nt\nâˆ’\n1\n)\n\\mathcal{B}^{-}_{t}(x_{t}|z_{1:t-1})\nis the predictive belief distribution at time\nt\nt\n, and\nâ„¬\nt\nâ€‹\n(\nx\nt\n|\nz\n1\n:\nt\n)\n\\mathcal{B}_{t}(x_{t}|z_{1:t})\nis the posterior belief of\nx\nt\nx_{t}\nwhen all measurements\nz\n1\n:\nt\n=\n[\nz\n1\n,\nâ€¦\n,\nz\nt\n]\nz_{1:t}=[z_{1},\\ldots,z_{t}]\nup to time\nt\nt\nhave been received. Subsequently, given the recursion in Eq. (\nIII-A\n) the minimum mean square estimator (MMSE)\nx\n^\nt\nMMSE\n\\hat{x}^{\\text{MMSE}}_{t}\nis given by:\nx\n^\nt\nMMSE\n=\nâˆ«\nx\nt\nâ€‹\nâ„¬\nt\nâ€‹\n(\nx\nt\n|\nz\n1\n:\nt\n)\nâ€‹\nğ‘‘\nx\nt\n\\hat{x}^{\\text{MMSE}}_{t}=\\int x_{t}\\,\\mathcal{B}_{t}(x_{t}|z_{1:t})\\,dx_{t}\n.\nHowever, in our problem, at time\nt\nt\nthe observation is a point pattern of random cardinality, not a fixed-length vector, hence the standard vector-likelihood underlying Eq. (\nIII-A\n) is not directly applicable. We therefore replace the likelihood in Eq.Â (\nIII-A\n) with the appropriate set-likelihood and apply Bayesâ€™ rule with that form.\nTo achieve this, first observe that the transitional density\np\nâ€‹\n(\nx\nt\n|\nx\nt\nâˆ’\n1\n)\np(x_{t}|x_{t-1})\nin Eq. (\nIII-A\n) becomes\np\nâ€‹\n(\nX\nt\n|\nX\nt\nâˆ’\n1\n)\n=\nâˆ«\nÎ´\nâ€‹\n(\nX\nt\nâˆ’\nÎ¾\nâ€‹\n(\nX\nt\nâˆ’\n1\n,\nE\nt\nâˆ’\n1\n)\n)\nâ€‹\nP\nE\nâ€‹\n(\nE\nt\nâˆ’\n1\n)\nâ€‹\nğ‘‘\nE\nt\nâˆ’\n1\np(X_{t}|X_{t-1})=\\int\\delta(X_{t}-\\xi(X_{t-1},E_{t-1}))\\,P_{E}(E_{t-1})\\,dE_{t-1}\nas direct consequence of the fire front stochastic dynamics, where\nÎ´\nâ€‹\n(\nâ‹…\n)\n\\delta(\\cdot)\nis the Dirac delta function.\nSubsequently, we can compute the predicted belief\nâ„¬\nt\nâˆ’\nâ€‹\n(\nX\nt\n|\nZ\n1\n:\nt\nâˆ’\n1\n)\n\\mathcal{B}^{-}_{t}(X_{t}|Z_{1:t-1})\nat time step\nt\nt\n, assuming the posterior density at the previous time step,\nâ„¬\nt\nâˆ’\n1\nâ€‹\n(\nX\nt\nâˆ’\n1\n|\nZ\n1\n:\nt\nâˆ’\n1\n)\n\\mathcal{B}_{t-1}(X_{t-1}|Z_{1:t-1})\n, is known. The posterior belief\nâ„¬\nt\nâ€‹\n(\nX\nt\n|\nZ\n1\n:\nt\n)\n\\mathcal{B}_{t}(X_{t}|Z_{1:t})\ncan then be obtained by incorporating the measurement set\nZ\nt\nZ_{t}\nvia the correction step shown in Eq.Â (\nIII-A\n), provided that an expression for the measurement likelihood function\np\nâ€‹\n(\nZ\nt\n|\nX\nt\n,\ny\nt\n)\np(Z_{t}|X_{t},y_{t})\nis available. This process can then be recursively applied to the next time step.\nProposition:\nLet\nX\nt\n=\n[\nx\nt\n1\n,\nâ€¦\n,\nx\nt\nN\n]\nâŠ¤\nX_{t}=[x^{1}_{t},\\ldots,x^{N}_{t}]^{\\top}\nbe the state of the fire front at time\nt\nt\n, and let\nZ\nt\n=\n[\nz\nt\n1\n,\nâ€¦\n,\nz\nt\nm\nt\n]\nZ_{t}=[z^{1}_{t},\\ldots,z^{m_{t}}_{t}]\ndenote the received measurement vector at time step\nt\nt\n. The likelihood of\nZ\nt\nZ_{t}\ngiven\nX\nt\nX_{t}\nand\ny\nt\ny_{t}\nis given by:\np\nâ€‹\n(\nZ\nt\n|\nX\nt\n,\ny\nt\n)\n=\np(Z_{t}|X_{t},y_{t})=\n1\nm\nt\n!\nâ€‹\nexp\nâ¡\n(\nâˆ’\nâˆ‘\ni\n=\n1\nN\nÎ»\ni\nâ€‹\n(\nx\nt\ni\n)\n)\nâ€‹\nâˆ\nk\n=\n1\nm\nt\n(\nâˆ‘\ni\n=\n1\nN\nÎ³\nt\ni\nâ€‹\n(\nz\nk\n|\nx\nt\ni\n,\ny\nt\n)\n)\n,\n\\frac{1}{m_{t}!}\\exp\\left(-\\sum_{i=1}^{N}\\lambda_{i}(x^{i}_{t})\\right)\\prod_{k=1}^{m_{t}}\\left(\\,\\sum_{i=1}^{N}\\gamma^{i}_{t}\\bigl(z_{k}|x^{i}_{t},y_{t}\\bigr)\\right),\n(5)\nwhere\nÎ»\nt\ni\nâ€‹\n(\nx\nt\ni\n)\n=\nâˆ«\nO\nt\nÎ³\nt\ni\nâ€‹\n(\nz\n|\nx\nt\ni\n,\ny\nt\n)\nâ€‹\nğ‘‘\nz\n\\lambda^{i}_{t}(x^{i}_{t})=\\int_{O_{t}}\\gamma^{i}_{t}(z\\,|\\,x^{i}_{t},y_{t})\\,dz\nis the expected number of detections from vertex\ni\ni\n,\nÎ³\nt\ni\nâ€‹\n(\nz\n|\nx\nt\ni\n,\ny\nt\n)\n\\gamma^{i}_{t}(z\\,|\\,x^{i}_{t},y_{t})\nis the Poisson intensity corresponding to vertex\ni\ni\nwithin the sensing region\nO\nt\nO_{t}\nas defined in Eq.Â (\n3\n), and\nm\nt\n!\nm_{t}!\ndenotes the factorial of\nm\nt\nm_{t}\n. Consequently,\np\nâ€‹\n(\nZ\nt\n|\nX\nt\n,\ny\nt\n)\np(Z_{t}|X_{t},y_{t})\ncan be used directly in Eq.Â (\nIII-A\n) enabling the handling of multiple objects and multiple measurements without requiring explicit measurement-to-object association, and allowing the computation of the MMSE as discussed previously.\nIII-B\nInformation-seeking Predictive Control\nThe problem in Sec.\nII-A\nis addressed via the information-seeking predictive controller shown in ProblemÂ (P1), formulated as a receding horizon SOC problem. The goal is to compute control inputs\n{\nu\nt\n+\nÏ„\nâˆ’\n1\n|\nt\n}\nÏ„\n=\n1\nT\n\\{u_{t+\\tau-1|t}\\}_{\\tau=1}^{T}\nthat optimize the agentâ€™s sensing behavior by minimizing the cumulative uncertainty in the (pseudo) posterior beliefs of the fire front states, as defined in Eq.Â (\n6a\n). At each time step\nt\nt\n, only the first control input\nu\nt\n|\nt\nu_{t|t}\nis applied, and the process is repeated over a shifted horizon.\nFor each prediction time step\nÏ„\nâˆˆ\n{\n1\n,\nâ€¦\n,\nT\n}\n\\tau\\in\\{1,\\ldots,T\\}\nin the horizon, the agent predicts the fire front state\nX\nÏ„\nX_{\\tau}\nforward in time using the Bayesian prediction step, based on the transition density\np\nâ€‹\n(\nX\nÏ„\n|\nX\nÏ„\nâˆ’\n1\n)\np(X_{\\tau}|X_{\\tau-1})\nand the (pseudo) posterior belief from the previous time step,\nâ„¬\nt\n+\nÏ„\nâˆ’\n1\n|\nt\nâ€‹\n(\nX\nÏ„\nâˆ’\n1\n|\nZ\n1\n:\nt\n+\nÏ„\nâˆ’\n1\n|\nt\n)\n\\mathcal{B}_{t+\\tau-1|t}(X_{\\tau-1}|Z_{1:t+\\tau-1|t})\n, as shown in Eqs.Â (\n6b\n)-(\n6c\n). The constraints in Eqs.Â (\n6d\n)-(\n6e\n) arise from the agent dynamics, which are assumed to be deterministic in this work. At the predicted time step\nÏ„\n\\tau\n, given the agentâ€™s predicted state\ny\nt\n+\nÏ„\n|\nt\ny_{t+\\tau|t}\nand sensing range\nO\nt\n+\nÏ„\n|\nt\nO_{t+\\tau|t}\n, the agent receives the predicted measurement set\nZ\nt\n+\nÏ„\n|\nt\nZ_{t+\\tau|t}\n. This set is then used to compute the posterior belief\nâ„¬\nt\n+\nÏ„\n|\nt\nâ€‹\n(\nX\nÏ„\n|\nZ\n1\n:\nt\n+\nÏ„\n|\nt\n)\n\\mathcal{B}_{t+\\tau|t}(X_{\\tau}|Z_{1:t+\\tau|t})\nvia the Bayesian correction step, as shown in Eq.Â (\n6f\n), using the joint likelihood function\np\nâ€‹\n(\nZ\nt\n+\nÏ„\n|\nt\n|\nX\nÏ„\n,\ny\nt\n+\nÏ„\n|\nt\n)\np(Z_{t+\\tau|t}|X_{\\tau},y_{t+\\tau|t})\nand the predicted density. This posterior distribution subsequently becomes the prior for the next prediction step, continuing the recursive process.\nThe predicted measurements\nZ\nt\n+\nÏ„\n|\nt\nZ_{t+\\tau|t}\nrepresent hypothetical observations based on the planned control inputs and the anticipated fire front state. Since actual measurements are only available after executing the control actions, the objective in Eq.Â (\n6a\n) requires taking an expectation over all possible future measurement sequences. This enables informed decision-making by accounting for potential outcomes without executing the corresponding trajectories.\nProblem (P1):\nInformation-seeking Predictive Control\nmin\n{\nu\nt\n+\nÏ„\nâˆ’\n1\n|\nt\n}\nÏ„\n=\n1\nT\nğ”¼\nZ\nt\n1\n:\nT\n{\nâˆ‘\nÏ„\n=\n1\nT\nÎ½\nÏ„\nğ’\nÏ„\n(\nâ„¬\nt\n+\nÏ„\n|\nt\n(\nâ‹…\n|\nZ\n1\n:\nt\n+\nÏ„\n|\nt\n)\n)\n}\n\\displaystyle\\hskip-8.53581pt\\underset{\\{u_{t+\\tau-1|t}\\}_{\\tau=1}^{T}}{\\min}\\mathbb{E}_{Z_{t}^{1:T}}\\left\\{\\sum_{\\tau=1}^{T}\\nu^{\\tau}\\mathcal{C}_{\\tau}\\!\\left(\\mathcal{B}_{t+\\tau|t}(\\cdot|Z_{1:t+\\tau|t})\\right)\\right\\}\n(6a)\nsubject to:\nâ„¬\nt\n+\nÏ„\n|\nt\nâˆ’\n=\nâˆ«\np\nâ€‹\n(\nX\nÏ„\n|\nX\nÏ„\nâˆ’\n1\n)\nâ€‹\nâ„¬\nt\n+\nÏ„\nâˆ’\n1\n|\nt\nâ€‹\n(\nX\nÏ„\nâˆ’\n1\n|\nâ‹…\n)\nâ€‹\nğ‘‘\nX\nÏ„\nâˆ’\n1\n,\n\\displaystyle\\hskip-8.53581pt\\mathcal{B}^{-}_{t+\\tau|t}=\\int p(X_{\\tau}|X_{\\tau-1})\\,\\mathcal{B}_{t+\\tau-1|t}(X_{\\tau-1}|\\cdot)\\,dX_{\\tau-1},\n(6b)\nâ„¬\nt\n|\nt\n=\nâ„¬\nt\n|\nt\nâˆ’\n1\n,\n\\displaystyle\\hskip-8.53581pt\\mathcal{B}_{t|t}=\\mathcal{B}_{t|t-1},\n(6c)\ny\nt\n+\nÏ„\n|\nt\n=\nf\na\nâ€‹\n(\ny\nt\n+\nÏ„\nâˆ’\n1\n|\nt\n,\nu\nt\n+\nÏ„\nâˆ’\n1\n|\nt\n)\n,\n\\displaystyle\\hskip-8.53581pty_{t+\\tau|t}=f_{a}(y_{t+\\tau-1|t},u_{t+\\tau-1|t}),\n(6d)\ny\nt\n|\nt\n=\ny\nt\n|\nt\nâˆ’\n1\n,\n\\displaystyle\\hskip-8.53581pty_{t|t}=y_{t|t-1},\n(6e)\nâ„¬\nt\n+\nÏ„\n|\nt\n(\nâ‹…\n|\nZ\n1\n:\nt\n+\nÏ„\n|\nt\n)\nâˆ\np\n(\nZ\nt\n+\nÏ„\n|\nt\n|\nX\nÏ„\n,\ny\nt\n+\nÏ„\n|\nt\n)\nâ„¬\nt\n+\nÏ„\n|\nt\nâˆ’\n,\n\\displaystyle\\hskip-8.53581pt\\mathcal{B}_{t+\\tau|t}(\\cdot|Z_{1:t+\\tau|t})\\propto p\\left(Z_{t+\\tau|t}|X_{\\tau},y_{t+\\tau|t}\\right)\\mathcal{B}^{-}_{t+\\tau|t},\n(6f)\ny\nt\nâˆˆ\nğ’´\n,\nu\nt\nâˆˆ\nğ’°\n,\nX\nt\nâˆˆ\nğ’³\n,\nZ\nt\nâˆˆ\nğ’µ\n,\n\\displaystyle\\hskip-8.53581pty_{t}\\in\\mathcal{Y},u_{t}\\in\\mathcal{U},X_{t}\\in\\mathcal{X},Z_{t}\\in\\mathcal{Z},\n(6g)\nğ’\nÏ„\nâˆˆ\n[\n0\n,\n1\n]\n,\nÎ½\nâˆˆ\n(\n0\n,\n1\n]\n,\nÏ„\n=\n{\n1\n,\nâ€¦\n,\nT\n}\n.\n\\displaystyle\\hskip-8.53581pt\\mathcal{C}_{\\tau}\\in[0,1],\\nu\\in(0,1],\\tau=\\{1,\\ldots,T\\}.\n(6h)\nEquations (\n6b\n)-(\n6f\n) admit no closed form: the model is nonlinear and non-Gaussian with set-valued (multi-object, multi-measurement) observations, so Kalman-type filters are inapplicable. Therefore, the recursion is implemented using Sequential Importance Resampling (SIR), i.e., particle filtering. Specifically, the belief\nâ„¬\nÏ„\n\\mathcal{B}_{\\tau}\nis represented by a set of weighted particles\nâ„¬\nÏ„\n=\n{\nw\nÏ„\n(\ni\n)\n,\nX\nÏ„\n(\ni\n)\n}\ni\n=\n1\nN\ns\n\\mathcal{B}_{\\tau}=\\{w^{(i)}_{\\tau},X^{(i)}_{\\tau}\\}_{i=1}^{N_{s}}\n, where\nX\nÏ„\n(\ni\n)\n=\n[\nx\nÏ„\n1\n,\nâ€¦\n,\nx\nÏ„\nN\n]\nâŠ¤\nX^{(i)}_{\\tau}=[x^{1}_{\\tau},\\ldots,x^{N}_{\\tau}]^{\\top}\n. These particles are propagated to the next time step according to the process dynamics and reweighted using the likelihood function to compute the posterior. For notational convenience, we will often write\nt\n+\nÏ„\n|\nt\nt+\\tau|t\nas\nÏ„\n\\tau\nwhen no ambiguity arises. The functional\nğ’\nt\n+\nÏ„\n|\nt\n:\nâ„¬\nt\n+\nÏ„\n|\nt\nâ€‹\n(\nX\nt\n+\nÏ„\n|\nt\n|\nZ\n1\n:\nt\n+\nÏ„\n|\nt\n)\nâ†’\n[\n0\n,\n1\n]\n\\mathcal{C}_{t+\\tau|t}:\\mathcal{B}_{t+\\tau|t}(X_{t+\\tau|t}|Z_{1:t+\\tau|t})\\rightarrow[0,1]\nin Eq. (\n6a\n) quantifies the uncertainty of the fire-front state\nX\nt\n+\nÏ„\n|\nt\nX_{t+\\tau|t}\nencoded in the posterior distribution at time\nt\n+\nÏ„\n|\nt\nt+\\tau|t\n, conditioned on all hypothetical measurements\nZ\n1\n:\nt\n+\nÏ„\n|\nt\nZ_{1:t+\\tau|t}\n. This uncertainty is measured by the\nRisk-Weighted Dispersion\n(RWD) defined as:\nğ’\nt\n+\nÏ„\n|\nt\nâ€‹\n(\nâ„¬\nt\n+\nÏ„\n|\nt\n)\n=\n1\nÏ‰\nâ€‹\nâˆ‘\nÎµ\nâˆˆ\nâ„°\n~\nâ„›\nâ€‹\n(\nÎµ\n)\nâ€‹\ndet\n(\nÎ£\nt\n+\nÏ„\n|\nt\nÎµ\n)\n,\n\\mathcal{C}_{t+\\tau|t}(\\mathcal{B}_{t+\\tau|t})=\\frac{1}{\\omega}\\sum_{\\varepsilon\\in\\tilde{\\mathcal{E}}}\\mathcal{R}(\\varepsilon)\\det(\\Sigma^{\\varepsilon}_{t+\\tau|t}),\n(7)\nwhere the environment\nâ„°\n\\mathcal{E}\nis discretized in space to form a 2D grid\nâ„°\n~\n\\tilde{\\mathcal{E}}\n, composed of a finite number of non-overlapping, equally sized cells\nâ„°\n~\n=\n{\nÎµ\n1\n,\nâ€¦\n,\nÎµ\n|\nâ„°\n~\n|\n}\n\\tilde{\\mathcal{E}}=\\{\\varepsilon_{1},\\ldots,\\varepsilon_{|\\tilde{\\mathcal{E}}|}\\}\n, such that\nâ‹ƒ\ni\n=\n1\n|\nâ„°\n~\n|\nÎµ\ni\n=\nâ„°\n\\bigcup_{i=1}^{|\\tilde{\\mathcal{E}}|}\\varepsilon_{i}=\\mathcal{E}\n. The term\nâ„›\nâ€‹\n(\nÎµ\n)\nâˆˆ\n[\n0\n,\n1\n]\n\\mathcal{R}(\\varepsilon)\\in[0,1]\ndenotes the risk value associated with cell\nÎµ\n\\varepsilon\n, reflecting the severity of fire presence in that region. The random quantity\ndet\n(\nÎ£\nt\n+\nÏ„\n|\nt\nÎµ\n)\n\\det(\\Sigma_{t+\\tau|t}^{\\varepsilon})\nis the determinant of the sample covariance matrix\nÎ£\nt\n+\nÏ„\n|\nt\nÎµ\n\\Sigma_{t+\\tau|t}^{\\varepsilon}\ncomputed from all particle points residing in cell\nÎµ\n\\varepsilon\nat time step\nt\n+\nÏ„\n|\nt\nt+\\tau|t\n, and\nÏ‰\n\\omega\nis a scaling factor ensuring that\nğ’\nt\n+\nÏ„\n|\nt\nâ€‹\n(\nâ„¬\nt\n+\nÏ„\n|\nt\n)\nâˆˆ\n[\n0\n,\n1\n]\n\\mathcal{C}_{t+\\tau|t}(\\mathcal{B}_{t+\\tau|t})\\in[0,1]\n. Finally, the parameter\nÎ½\nâˆˆ\n(\n0\n,\n1\n]\n\\nu\\in(0,1]\nin Eq. (\n6a\n) is a discount factor that controls the relative importance of future decisions.\nIII-C\nAdaptive LCB-guided Policy Search\nProblem (P1) is a stochastic, multi-dimensional, non-linear, and non-convex optimization problem that cannot be directly solved in its original form. However, we can address an equivalent version by reformulating (P1) as a Markov Decision Process (MDP)\n[\n16\n]\n. To achieve this, we assume that the agentâ€™s control inputs\nu\nt\nâˆˆ\nğ’°\nu_{t}\\in\\mathcal{U}\ncan be reduced to a finite set\nğ•Œ\n\\mathbb{U}\n, consisting of\n|\nğ•Œ\n|\n|\\mathbb{U}|\ndiscrete control vectors\nu\n^\nt\nâˆˆ\nğ•Œ\n\\hat{u}_{t}\\in\\mathbb{U}\n. This discretization, in turn, leads to a finite set of possible agent states\ny\n^\nt\nâˆˆ\nğ•\nt\n\\hat{y}_{t}\\in\\mathbb{Y}_{t}\n. Consequently, (P1) can be reformulated as an MDP\nâŸ¨\nğ’®\n,\nğ•Œ\n,\nğ’¯\n,\nğ’\nâŸ©\n\\langle\\mathcal{S},\\mathbb{U},\\mathcal{T},\\mathcal{C}\\rangle\n, where\nğ’®\n\\mathcal{S}\nis the state space of the system, and an individual state\ns\nâˆˆ\nğ’®\ns\\in\\mathcal{S}\nis represented as the tuple\ns\nt\n=\n(\nâ„¬\nt\n,\ny\n^\nt\n)\ns_{t}=(\\mathcal{B}_{t},\\hat{y}_{t})\n. Note that the fire front process evolves independently of the agentâ€™s actions. The transition function\nğ’¯\n:\nğ’®\nÃ—\nğ•Œ\nâ†’\nğ’®\n\\mathcal{T}:\\mathcal{S}\\times\\mathbb{U}\\rightarrow\\mathcal{S}\ndescribes the evolution of the system in response to agent actions. Although the agentâ€™s actions are deterministic in our setting, the transition function\nğ’¯\n\\mathcal{T}\nremains stochastic due to the randomness in the agentâ€™s observations upon executing an action. Specifically, we have:\nğ’¯\n:\np\n(\ns\nt\nâ€²\n=\n(\nâ„¬\nâ€²\n,\ny\n^\nâ€²\n)\nâˆ£\ns\nt\nâˆ’\n1\n=\n(\nâ„¬\n,\ny\n^\n)\n,\nu\n^\nt\nâˆ’\n1\n=\nu\n)\n\\mathcal{T}:p\\left(s^{\\prime}_{t}=(\\mathcal{B}^{\\prime},\\hat{y}^{\\prime})\\mid s_{t-1}=(\\mathcal{B},\\hat{y}),\\hat{u}_{t-1}=u\\right)\n. The cost function\nğ’\n\\mathcal{C}\nassigns a cost to a specific state\ns\nâ€²\ns^{\\prime}\nresulting from applying action\nu\n^\n\\hat{u}\nat state\ns\ns\n. With slight abuse of notation, we denote it as\nğ’\nâ€‹\n(\ns\nâ€²\n=\n(\nâ„¬\n,\ny\n^\n)\n)\n\\mathcal{C}(s^{\\prime}=(\\mathcal{B},\\hat{y}))\n, which effectively operates on the posterior belief\nâ„¬\n\\mathcal{B}\nin state\ns\nâ€²\ns^{\\prime}\n, derived from the agent state\ny\n^\n\\hat{y}\n. The cost is defined according to Eq. (\n7\n).\nWe define a finite-horizon open-loop policy over\nT\nT\nsteps as the control input sequence\nÏ€\n=\n{\nu\n^\nt\n+\nÏ„\nâˆ’\n1\n|\nt\n}\nÏ„\n=\n1\nT\nâˆˆ\nğ•Œ\nT\n\\pi=\\{\\hat{u}_{t+\\tau-1|t}\\}_{\\tau=1}^{T}\\in\\mathbb{U}^{T}\n. Let\nÎ \nT\n=\nğ•Œ\nT\n\\Pi_{T}=\\mathbb{U}^{T}\ndenote the set of all such admissible policies. Each policy is a predetermined sequence of actions evaluated via simulation of the MDPâ€™s stochastic state transitions. Given that the agent starts from an initial state\ns\nt\n=\n(\nâ„¬\nt\n,\ny\n^\nt\n)\ns_{t}=(\\mathcal{B}_{t},\\hat{y}_{t})\nat time step\nt\nt\n, a policy\nÏ€\nâˆˆ\nÎ \nT\n\\pi\\in\\Pi_{T}\ncan then be simulated under the MDP to obtain:\nV\nt\nÏ€\nâ€‹\n(\ns\nt\n)\n=\nğ”¼\nâ€‹\n{\nâˆ‘\nÏ„\n=\n1\nT\nÎ½\nÏ„\nâ€‹\nğ’\nÏ„\nâ€‹\n(\ns\nt\n+\nÏ„\n|\nt\nÏ€\n)\n}\n,\nV^{\\pi}_{t}(s_{t})=\\mathbb{E}\\left\\{\\sum_{\\tau=1}^{T}\\nu^{\\tau}\\mathcal{C}_{\\tau}\\left(s^{\\pi}_{t+\\tau|t}\\right)\\right\\},\n(8)\nwhere\ns\nt\n+\nÏ„\n|\nt\nÏ€\ns^{\\pi}_{t+\\tau|t}\nis the state encountered at level\nÏ„\n\\tau\nin the horizon under policy\nÏ€\n\\pi\nwhen starting from state\ns\nt\ns_{t}\n. Subsequently, the optimal policy that minimizes the expected cumulative cost over the horizon is given by\nÏ€\nâ‹†\n=\narg\nâ¡\nmin\nÏ€\nâˆˆ\nÎ \nT\nâ¡\nV\nt\nÏ€\nâ€‹\n(\ns\nt\n)\n\\pi^{\\star}=\\arg\\min_{\\pi\\in\\Pi_{T}}\\,V^{\\pi}_{t}(s_{t})\n. To solve this problem we build upon the Upper Confidence Bound 1 (UCB1) framework\n[\n2\n]\nand we treat each sequence\nÏ€\n=\n{\nu\n^\nt\n+\nÏ„\nâˆ’\n1\n|\nt\n}\nÏ„\n=\n1\nT\nâˆˆ\nğ•Œ\nT\n\\pi=\\{\\hat{u}_{t+\\tau-1|t}\\}_{\\tau=1}^{T}\\in\\mathbb{U}^{T}\nas an\narm\nin a multi-armed bandit. We use rollouts to simulate policy outcomes and employ a UCB1-like adaptive selection strategy to efficiently balance exploration and exploitation.\nAlgorithm 1\nAdaptive LCB-guided Search\n1:\nInput:\nPolicy set\nÎ \nT\n\\Pi_{T}\n, Initial state\ns\nt\n=\n(\nâ„¬\nt\n,\ny\n^\nt\n)\ns_{t}=(\\mathcal{B}_{t},\\hat{y}_{t})\n2:\nInitialize\nI\n0\nâ€‹\n(\nÏ€\n)\n=\n0\n,\nâˆ€\nÏ€\nâˆˆ\nÎ \nT\nI^{0}(\\pi)=0,\\forall\\pi\\in\\Pi_{T}\n3:\nfor\nn\n=\n1\n,\nâ€¦\n,\n(\nn\nmax\nâ‰¥\n|\nÎ \nT\n|\n)\nn=1,\\dots,(n_{\\max}\\geq|\\Pi_{T}|)\ndo\n4:\nSample policy:\nÏ€\n^\n=\narg\nâ¡\nmin\nâ¡\nLCB\nn\nâ€‹\n(\nÏ€\n,\ns\nt\n)\n\\hat{\\pi}\\!=\\!\\arg\\min\\mathrm{LCB}^{n}(\\pi,s_{t})\n(Eq. (\n9\n))\n5:\nfor\nÏ„\n=\n1\n,\nâ€¦\n,\nT\n\\tau=1,\\dots,T\ndo\n6:\nCompute predictive density:\nâ„¬\nt\n+\nÏ„\n|\nt\nâˆ’\n\\mathcal{B}^{-}_{t+\\tau|t}\nvia Eq. (\n6b\n)\n7:\nMove to new state:\ny\n^\nt\n+\nÏ„\n|\nt\n=\nf\na\nâ€‹\n(\ny\n^\nt\n+\nÏ„\nâˆ’\n1\n|\nt\n,\nÏ€\n^\nÏ„\n)\n\\hat{y}_{t+\\tau|t}=f_{a}\\left(\\hat{y}_{t+\\tau-1|t},\\hat{\\pi}_{\\tau}\\right)\n8:\nSample meas.:\nZ\nt\n+\nÏ„\n|\nt\nâˆ¼\np\nâ€‹\n(\nZ\n|\nX\nt\n+\nÏ„\n|\nt\n,\ny\n^\nt\n+\nÏ„\n|\nt\n)\nZ_{t+\\tau|t}\\sim p(Z|X_{t+\\tau|t},\\hat{y}_{t+\\tau|t})\n9:\nCompute posterior:\nâ„¬\nt\n+\nÏ„\n|\nt\n\\mathcal{B}_{t+\\tau|t}\nvia Eq. (\n6f\n)\n10:\nCompute stage cost:\nc\nÏ„\n=\nc\nÏ„\nâˆ’\n1\n+\nÎ½\nÏ„\nâ€‹\nğ’\nÏ„\nâ€‹\n(\nâ„¬\nt\n+\nÏ„\n|\nt\n)\nc_{\\tau}=c_{\\tau-1}+\\nu^{\\tau}\\mathcal{C}_{\\tau}(\\mathcal{B}_{t+\\tau|t})\n11:\nend\nfor\n12:\nUpdate LCB:\nQ\nn\nâ€‹\n(\nÏ€\n^\n,\ns\nt\n)\n=\nmean\nâ€‹\n(\nQ\nn\nâˆ’\n1\nâ€‹\n(\nÏ€\n^\n,\ns\nt\n)\n,\nc\nT\n)\nQ^{n}(\\hat{\\pi},s_{t})=\\mathrm{mean}\\left(Q^{n-1}(\\hat{\\pi},s_{t}),c_{T}\\right)\n13:\nI\nn\nâ€‹\n(\nÏ€\n^\n)\n=\nI\nn\nâ€‹\n(\nÏ€\n^\n)\n+\n1\nI^{n}(\\hat{\\pi})=I^{n}(\\hat{\\pi})+1\n14:\nend\nfor\n15:\nOutput:\nOptimal policy\nÏ€\nâ‹†\n=\narg\nâ¡\nmin\nâ¡\nLCB\nn\nmax\nâ€‹\n(\nÏ€\n,\ns\nt\n)\n\\pi^{\\star}=\\arg\\min~\\mathrm{LCB}^{n_{\\text{max}}}(\\pi,s_{t})\nFigure 1:\nSimulation Setup: (a) Fire front true evolution, (b)(c) Wind speed parameters, (d) Risk map, and (e)(f) Fire spread rate parameters.\nThe proposed adaptive-search algorithm iteratively computes a Lower Confidence Bound (LCB) on the expected total cost associated with each\nT\nT\n-finite control sequence, which is then used to adaptively select the next policy to simulate. Specifically, for an agent at state\ns\nt\ns_{t}\n, we define the LCB score of a policy\nÏ€\nâˆˆ\nÎ \nT\n\\pi\\in\\Pi_{T}\nat iteration\nn\nn\nas:\nLCB\nn\nâ€‹\n(\nÏ€\n,\ns\nt\n)\n=\n{\nQ\nn\nâ€‹\n(\nÏ€\n,\ns\nt\n)\nâˆ’\n2\nâ€‹\nln\nâ¡\nn\nI\nn\nâ€‹\n(\nÏ€\n)\n,\nif\nâ€‹\nI\nn\nâ€‹\n(\nÏ€\n)\nâ‰ \n0\n,\nLCB\nmin\nn\n,\notherwise\n,\n\\mathrm{LCB}^{n}(\\pi,s_{t})=\\begin{cases}Q^{n}(\\pi,s_{t})-\\sqrt{\\frac{2\\ln n}{I^{n}(\\pi)}},&\\text{if }I^{n}(\\pi)\\neq 0,\\\\\n\\mathrm{LCB}^{n}_{\\min},&\\text{otherwise},\\end{cases}\n(9)\nwhere\nI\nn\nâ€‹\n(\nÏ€\n)\nI^{n}(\\pi)\ndenotes the number of times policy\nÏ€\n\\pi\nhas been simulated up to iteration\nn\nn\n, and\nQ\nn\nâ€‹\n(\nÏ€\n,\ns\nt\n)\n=\n1\nI\nn\nâ€‹\n(\nÏ€\n)\nâ€‹\nâˆ‘\ni\n=\n1\nn\nÎ´\nâ€‹\n(\nÏ€\ni\nâˆ’\nÏ€\n)\nâ€‹\nL\nâ€‹\n(\nÏ€\n,\ns\nt\n)\nQ^{n}(\\pi,s_{t})=\\frac{1}{I^{n}(\\pi)}\\sum_{i=1}^{n}\\delta(\\pi^{i}-\\pi)L(\\pi,s_{t})\nis the sample mean of the cumulative cost incurred by policy\nÏ€\n\\pi\n. Here,\nL\nâ€‹\n(\nÏ€\n,\ns\nt\n)\n=\nâˆ‘\nÏ„\n=\n1\nT\nÎ½\nÏ„\nâ€‹\nğ’\nÏ„\nâ€‹\n(\ns\nt\n+\nÏ„\n|\nt\nÏ€\n)\nL(\\pi,s_{t})=\\sum_{\\tau=1}^{T}\\nu^{\\tau}\\mathcal{C}_{\\tau}\\left(s^{\\pi}_{t+\\tau|t}\\right)\nis the total discounted cost of executing policy\nÏ€\n\\pi\nstarting from state\ns\nt\ns_{t}\n, and\nÎ´\nâ€‹\n(\nâ‹…\n)\n\\delta(\\cdot)\nis the discrete Dirac delta function. The constant\nLCB\nmin\nn\n<\nâˆ’\n2\nâ€‹\nln\nâ¡\nn\n\\mathrm{LCB}^{n}_{\\min}<-\\sqrt{2\\ln n}\nensures that any policy not yet selected by iteration\nn\nn\nwill have an LCB value lower than that of any previously selected policy, thereby guaranteeing it will be explored with higher probability in subsequent iterations. Finally, the term\n2\nâ€‹\nln\nâ¡\nn\nI\nn\nâ€‹\n(\nÏ€\n)\n\\sqrt{\\frac{2\\ln n}{I^{n}(\\pi)}}\nserves as an exploration bonus, encouraging the selection of under-explored policies. Under the standard UCB1 assumptions, the expected fraction of iterations on which LCB selects a suboptimal policy is\nO\nâ€‹\n(\nln\nâ¡\nn\nn\n)\nO\\!\\big(\\tfrac{\\ln n}{n}\\big)\n; hence the optimal policy is selected with asymptotic frequency\n1\n1\nin expectation as\nn\nâ†’\nâˆ\nn\\to\\infty\n.\nThe complete LCB-guided adaptive search algorithm is shown in AlgorithmÂ 1. At each time step\nt\nt\n, the algorithm identifies the optimal policy\nÏ€\nâ‹†\n\\pi^{\\star}\nover the horizon\n{\nt\n+\nÏ„\n|\nt\n}\nÏ„\n=\n1\nT\n\\{t+\\tau|t\\}_{\\tau=1}^{T}\n. The agent then executes the first control input of\nÏ€\nâ‹†\n\\pi^{\\star}\n, transitions to a new state, receives the â€œrealâ€ measurement, computes the posterior belief\nâ„¬\nt\n+\n1\n\\mathcal{B}_{t+1}\n, and the algorithm is re-applied at the next time step\nt\n+\n1\nt+1\n.\nWe should note that intelligent pruning techniques, such as\nÏµ\n\\epsilon\n-suboptimal reductions\n[\n1\n]\n, can be designed and integrated into the proposed approach to focus on the most promising set of control inputs at each time step thereby reducing the runtime complexity.\nIV\nEvaluation\nIV-\n1\nSimulation Setup\nTo evaluate the proposed approach, we used the following setup: the environment\nâ„°\nâŠ‚\nâ„\n2\n\\mathcal{E}\\subset\\mathbb{R}^{2}\nis square, with side length\n3\nÃ—\n10\n3\nâ€‹\nm\n3\\times 10^{3}~\\mathrm{m}\nin each dimension, whereas its discrete representation\nâ„°\n~\n\\tilde{\\mathcal{E}}\nconsists of a\n10\nÃ—\n10\n10\\times 10\ngrid with equally sized cells, as shown in Fig.\n1\n(a) with gray dotted lines. The fire front state\nX\nt\nX_{t}\ncomprises\nN\n=\n20\nN=20\nfire front vertices (shown in Fig.\n1\n(a)), initially forming an ellipse centered at\n(\nx\n,\ny\n)\n=\n(\n800\n,\n900\n)\n(x,y)=(800,900)\n, i.e., the ignition point, with semi-major and semi-minor axes of lengths\n120\nâ€‹\nm\n120~\\mathrm{m}\nand\n60\nâ€‹\nm\n60~\\mathrm{m}\n, respectively. Each of these vertices evolves according to Eq.Â (\n2\n) with\nÎ”\nâ€‹\nt\n=\n60\nâ€‹\ns\n\\Delta t=60\\mathrm{s}\n. The environmental conditions are as follows: wind direction\nÎ¸\n\\theta\n, wind speed\nw\ns\nw_{s}\n, and fire spread rate\nr\nf\nr_{f}\ndue to fuel are defined for each cell\nÎµ\nâˆˆ\nâ„°\n~\n\\varepsilon\\in\\tilde{\\mathcal{E}}\n. Specifically, the mean wind direction (with North aligned with the\ny\ny\n-axis) varies uniformly across the\nx\nx\n-axis from North to North-East to East, as illustrated by the blue arrows in Fig.\n1\n(a), following a von Mises distribution with concentration parameter\nÎº\n=\n500\n\\kappa=500\nin every cell i.e.,\nÎ¸\nâ€‹\n(\nÎµ\n)\nâˆ¼\nğ’±\nâ€‹\nâ„³\nâ€‹\n(\nÎ¼\nÎ¸\nâ€‹\n(\nÎµ\n)\n,\nÎº\nÎ¸\nâ€‹\n(\nÎµ\n)\n)\n\\theta(\\varepsilon)\\sim\\mathcal{VM}(\\mu_{\\theta(\\varepsilon)},\\kappa_{\\theta(\\varepsilon)})\n. Subsequently, the wind speed and fire spread rate are modeled as rectified Gaussian distributions, i.e.,\nw\ns\nâ€‹\n(\nÎµ\n)\nâˆ¼\nğ’©\nR\nâ€‹\n(\nÎ¼\nw\ns\nâ€‹\n(\nÎµ\n)\n,\nÏƒ\nw\ns\nâ€‹\n(\nÎµ\n)\n2\n)\nw_{s}(\\varepsilon)\\sim\\mathcal{N}_{R}(\\mu_{w_{s}(\\varepsilon)},\\sigma^{2}_{w_{s}(\\varepsilon)})\nand\nr\nf\nâ€‹\n(\nÎµ\n)\nâˆ¼\nğ’©\nR\nâ€‹\n(\nÎ¼\nr\nf\nâ€‹\n(\nÎµ\n)\n,\nÏƒ\nr\nf\nâ€‹\n(\nÎµ\n)\n2\n)\nr_{f}(\\varepsilon)\\sim\\mathcal{N}_{R}(\\mu_{r_{f}(\\varepsilon)},\\sigma^{2}_{r_{f}(\\varepsilon)})\n. The superposition of these random variables over the grid for each\nÎµ\nâˆˆ\nâ„°\n~\n\\varepsilon\\in\\tilde{\\mathcal{E}}\nis shown in Fig.\n1\n(b) and Fig.\n1\n(c) for the wind speed, and in Fig.\n1\n(e) and Fig.\n1\n(f) for the fire spread rate, respectively.\nFinally, the risk\nâ„›\nâ€‹\n(\nÎµ\n)\n\\mathcal{R}(\\varepsilon)\nassociated with each cell, indicating the severity of fire in that region is shown in Fig.\n1\n(d). Consequently, the fire front state\nX\nt\nX_{t}\nevolves in continuous space and the environmental parameters\nÎ¸\n\\theta\n,\nw\ns\nw_{s}\n, and\nr\nf\nr_{f}\ninfluencing each fire front vertex are obtained by associating it with the nearest cell in the discretized environment. The mobile agent (i.e., a drone) evolves according to\ny\n^\nt\n=\ny\n^\nt\nâˆ’\n1\n+\nd\nR\nâ€‹\n[\ncos\nd\nâ¡\n(\nÏ‘\n)\n,\nsin\nd\nâ¡\n(\nÏ‘\n)\n]\nâŠ¤\n\\hat{y}_{t}=\\hat{y}_{t-1}+d_{R}\\bigl[\\cos_{d}(\\vartheta),\\sin_{d}(\\vartheta)\\bigr]^{\\top}\n, and is controlled via the input\nu\n^\nt\n=\n[\nd\nR\nâ€‹\nÎ”\nâ€‹\nt\n,\nÏ‘\n]\n\\hat{u}_{t}=[d_{R}\\Delta t,\\ \\vartheta]\n, where\nd\nR\nâˆˆ\n{\n3\n,\n6\n}\nâ€‹\nm\n/\ns\nd_{R}\\in\\{3,6\\}~\\mathrm{m/s}\nand\nÏ‘\nâˆˆ\n{\n0\n,\n90\n,\n180\n,\n270\n}\nâ€‹\ndeg\n\\vartheta\\in\\{0,90,180,270\\}~\\mathrm{deg}\n. We assume that the drone operates at a fixed altitude of\n250\nâ€‹\nm\n250~\\mathrm{m}\nand is equipped with a wide-angle field-of-view camera with a viewing angle of\n120\nâ€‹\ndeg\n120~\\mathrm{deg}\n, resulting in a circular sensing range with radius\nR\na\n=\n250\nâ€‹\ntan\nd\nâ¡\n(\n120\n/\n2\n)\nâ‰ˆ\n430\nâ€‹\nm\nR_{a}=250\\tan_{d}(120/2)\\approx 430~\\mathrm{m}\n. The measurement noise is set to\nÏƒ\nz\n=\n3.5\nâ€‹\nm\n\\sigma_{z}=3.5~\\mathrm{m}\n, and we assume a fixed intensity\nÎ»\nt\ni\nâ€‹\n(\nx\nt\ni\n)\n=\n5\n\\lambda^{i}_{t}(x^{i}_{t})=5\n, for all\ni\nâˆˆ\n{\n1\n,\nâ€¦\n,\nN\n}\ni\\in\\{1,\\ldots,N\\}\nand all\nt\nt\n. Finally,\nÎ½\n=\n0.99\n\\nu=0.99\n,\nn\nmax\nn_{\\text{max}}\nvaries depending on the horizon, and the Bayes recursion in Eq.Â (\nIII-A\n) is implemented as a SIR particle filter with\nN\ns\n=\n2000\nN_{s}=2000\nparticles.\nFigure 2:\nPerformance Evaluation: (a) Agent trajectory (\nâ‹†\n\\star\nand\nÃ—\n\\times\nindicate start and stop states respectively), and fire front state (i.e., estimated with solid line, and true state with dotted line) obtained with Alg. 1, over 25-steps experiment, with myopic settings (i.e., horizon\nT\n=\n1\nT=1\n), (b) Same result with non-myopic settings (i.e. horizon\nT\n=\n3\nT=3\n), (c) Estimation error for different configurations of the proposed approach and comparisons with baselines.\nIV-\n2\nResults\nFigure\n1\n(a) illustrates the true evolution of the fire front over a simulation period of\nT\ns\n=\n25\nT_{s}=25\ntime steps, influenced by the environmental conditions described above. The fire-spread physics in this model support propagation in all directions from the ignition point. As a result, even under strong wind and fuel conditions, the upwind (back) perimeter of the fire continues to advance, albeit at a slower rate, as depicted. Furthermore, Fig.\n1\n(a)-(c) illustrates how variations in wind direction, wind speed, and spread rate influence the propagation of the fire front, either by accelerating or decelerating its advancement.\nThe output of Alg.Â 1 for this setup is shown in Fig.\n2\n(a) and Fig.\n2\n(b), corresponding to horizon lengths of\nT\n=\n1\nT=1\n(myopic) and\nT\n=\n3\nT=3\n(non-myopic), respectively. The agent is initialized at position\n(\nx\n,\ny\n)\n=\n(\n700\n,\n800\n)\n(x,y)=(700,800)\n, as indicated by the green asterisk, running Alg.Â 1 in a rolling horizon fashion, as discussed in Sec.\nIII-C\n. The green line in the figures is the agentâ€™s final trajectory over 25 time steps, resulting from the minimization of the expected cumulative RWD over the planning horizon at each time step. The dotted black lines show the true evolution of the fire front, while the time color-coded lines represent the estimated front; ideally, these two should align closely.\nAs shown, the non-myopic approach plans multiple steps ahead and achieves improved performance compared to the myopic strategy, which plans greedily. Specifically, the myopic behavior of the agent in Fig.\n2\n(a) prevents it from targeting the high-risk region in the top-left corner of Fig.\n1\n(d), which in this scenario is also associated with high uncertainty, as illustrated in Figs.\n1\n(c) and\n1\n(f). This limitation results in significant estimation errors, as shown.\nSubsequently, Fig.\n2\n(c) illustrates the performance of the proposed approach in terms of root mean square error (RMSE) i.e.,\nğ”¼\nâ€‹\n(\n(\nX\n^\nt\nâˆ’\nX\nt\n)\n2\n)\n\\sqrt{\\mathbb{E}\\big((\\hat{X}_{t}-X_{t})^{2}\\big)}\n, between the estimated fire front state\nX\n^\nt\n\\hat{X}_{t}\nand the true state\nX\nt\nX_{t}\nover 25 time steps, using a uniform risk map. Specifically, we conducted 50 Monte Carlo trials, randomly initializing both the fire front and the agentâ€™s position within the simulation environment described earlier.\nThe figure presents the average\nlog\n10\nâ¡\nRMSE\n\\log_{10}\\mathrm{RMSE}\nper time step per vertex over the 25-step simulation, comparing six different approaches. The baseline, denoted as\nInf. SR\n, corresponds to an agent with infinite sensing range that remains stationary and simply runs the particle filter. In this case, the RMSE arises solely from measurement noise and multiple detections, with no influence from control actions-representing the best achievable performance under the given settings.\nThe\nStatic\napproach involves a stationary agent with a finite sensing range, while the\nRandom\napproach uses an agent also with finite sensing range that selects a random control input at each time step. As expected, both approaches result in significant errors. The figure also includes the proposed method evaluated with different planning horizon lengths, i.e.,\nT\n=\n1\nT=1\n(myopic), and non-myopic settings with\nT\n=\n3\nT=3\nand\nT\n=\n5\nT=5\n, and clearly demonstrates improved performance as the planning horizon increases. Note that the baseline is unattainable in this setting due to the agentâ€™s limited sensing capabilities.\nV\nConclusion\nThis paper considers the problem of fire front monitoring under uncertainty by formulating it as a stochastic optimal control problem that integrates sensing, estimation, and control. A recursive Bayesian estimator was developed for elliptical-growth fire front processes, and the control problem was formulated as a finite-horizon Markov Decision Process (MDP). An information-seeking control law was then derived using a lower confidence bound (LCB)-based adaptive search, enabling optimal risk-aware planning.\nReferences\n[1]\nN. Atanasov, J. Le Ny, K. Daniilidis, and G. J. Pappas\n(2014)\nInformation acquisition with sensing robots: algorithms and error bounds\n.\nIn\n2014 IEEE International conference on robotics and automation (ICRA)\n,\npp.Â 6447â€“6454\n.\nCited by:\nÂ§I\n,\nÂ§\nIII-C\n.\n[2]\nP. Auer, N. Cesa-Bianchi, and P. Fischer\n(2002)\nFinite-time analysis of the multiarmed bandit problem\n.\nMachine Learning\n47\n,\npp.Â 235â€“256\n.\nCited by:\nÂ§\nIII-C\n.\n[3]\nP. Dames, M. Schwager, V. Kumar, and D. Rus\n(2012)\nA decentralized control policy for adaptive information gathering in hazardous environments\n.\nIn\n2012 IEEE 51st IEEE Conference on Decision and Control (CDC)\n,\npp.Â 2807â€“2813\n.\nCited by:\nÂ§I\n.\n[4]\nM. A. Finney\n(1998)\nFARSITE, fire area simulatorâ€“model development and evaluation\n.\nUS Department of Agriculture, Forest Service, Rocky Mountain Research Station\n.\nCited by:\nÂ§\nII-B\n,\nÂ§\nII-B\n.\n[5]\nA. O. Hero and D. Cochran\n(2011)\nSensor management: past, present, and future\n.\nIEEE Sensors Journal\n11\n(\n12\n),\npp.Â 3064â€“3075\n.\nCited by:\nÂ§I\n.\n[6]\nG. A. Hollinger and G. S. Sukhatme\n(2014)\nSampling-based robotic information gathering algorithms\n.\nThe International Journal of Robotics Research\n33\n(\n9\n),\npp.Â 1271â€“1287\n.\nCited by:\nÂ§I\n.\n[7]\nE. Kajita\n(2025)\nNotes from the field: emergency department use during the los angeles county wildfires, january 2025\n.\nMMWR. Morbidity and Mortality Weekly Report\n74\n.\nCited by:\nÂ§I\n.\n[8]\nY. Kantaros, B. Schlotfeldt, N. Atanasov, and G. J. Pappas\n(2021)\nSampling-based planning for non-myopic multi-robot information gathering\n.\nAutonomous Robots\n45\n(\n7\n),\npp.Â 1029â€“1046\n.\nCited by:\nÂ§I\n.\n[9]\nM. Lauri and R. Ritala\n(2014)\nStochastic control for maximizing mutual information in active sensing\n.\nIn\nIEEE International Conference on Robotics and Automation\n,\npp.Â 1â€“6\n.\nCited by:\nÂ§I\n.\n[10]\nS. Papaioannou, P. Kolios, T. Theocharides, C. G. Panayiotou, and M. M. Polycarpou\n(2022)\nUAV-based receding horizon control for 3D inspection planning\n.\nIn\n2022 International Conference on Unmanned Aircraft Systems (ICUAS)\n,\nVol.\n,\npp.Â 1121â€“1130\n.\nCited by:\nÂ§\nII-C\n.\n[11]\nH. X. Pham, H. M. La, D. Feil-Seifer, and M. C. Deans\n(2020)\nA distributed control framework of multiple unmanned aerial vehicles for dynamic wildfire tracking\n.\nIEEE Transactions on Systems, Man, and Cybernetics: Systems\n50\n(\n4\n),\npp.Â 1537â€“1548\n.\nCited by:\nÂ§I\n.\n[12]\nG. D. Richards\n(1990)\nAn elliptical growth model of forest fire fronts and its numerical solution\n.\nInternational Journal for Numerical Methods in Engineering\n30\n(\n6\n),\npp.Â 1163â€“1179\n.\nCited by:\nÂ§\nII-B\n.\n[13]\nA. Singh, A. Krause, C. Guestrin, and W. J. Kaiser\n(2009)\nEfficient informative sensing using multiple robots\n.\nJournal of Artificial Intelligence Research\n34\n,\npp.Â 707â€“755\n.\nCited by:\nÂ§I\n.\n[14]\nR. L. Streit and R. L. Streit\n(2010)\nThe Poisson point process\n.\nSpringer\n.\nCited by:\nÂ§\nII-C\n.\n[15]\nP. Sujit, D. Kingston, and R. Beard\n(2007)\nCooperative forest fire monitoring using multiple UAVs\n.\nIn\n2007 46th IEEE conference on decision and control\n,\npp.Â 4875â€“4880\n.\nCited by:\nÂ§I\n.\n[16]\nR.S. Sutton and A.G. Barto\n(1998)\nReinforcement learning: an introduction\n.\nIEEE Transactions on Neural Networks\n9\n(\n5\n),\npp.Â 1054â€“1054\n.\nCited by:\nÂ§\nIII-C\n.",
  "preview_text": "We consider the problem of adaptively monitoring a wildfire front using a mobile agent (e.g., a drone), whose trajectory determines where sensor data is collected and thus influences the accuracy of fire propagation estimation. This is a challenging problem, as the stochastic nature of wildfire evolution requires the seamless integration of sensing, estimation, and control, often treated separately in existing methods. State-of-the-art methods either impose linear-Gaussian assumptions to establish optimality or rely on approximations and heuristics, often without providing explicit performance guarantees. To address these limitations, we formulate the fire front monitoring task as a stochastic optimal control problem that integrates sensing, estimation, and control. We derive an optimal recursive Bayesian estimator for a class of stochastic nonlinear elliptical-growth fire front models. Subsequently, we transform the resulting nonlinear stochastic control problem into a finite-horizon Markov decision process and design an information-seeking predictive control law obtained via a lower confidence bound-based adaptive search algorithm with asymptotic convergence to the optimal policy.\n\nAdaptive Monitoring of Stochastic Fire Front Processes via Information-seeking Predictive Control\nSavvasÂ Papaioannou,Â PanayiotisÂ Kolios,Â ChristosÂ G.Â Panayiotou andÂ MariosÂ M.Â Polycarpou\nThe authors are with the KIOS Research and Innovation Centre of Excellence (KIOS CoE) and the Department of Electrical and Computer Engineering, University of Cyprus, Nicosia, 1678, Cyprus. E-mail:\n{papaioannou.savvas, pkolios, christosp, mpolycar}@ucy.ac.cy\nThis work is supported by the European Unionâ€™s Horizon Europe program under grant agreement No 101187121 (EUSOME) and the Civil Protection Knowledge for Action in Prevention & Preparedness under grant agreement No. 101193719 (COLLARIS2). It is also supported from the Republic of Cyprus through the Deputy Ministry of Research, Innovation and Digital Po",
  "is_relevant": false,
  "relevance_score": 0.0,
  "extracted_keywords": [
    "stochastic optimal control",
    "adaptive monitoring",
    "wildfire front",
    "information-seeking control",
    "Markov decision process",
    "Bayesian estimation"
  ],
  "one_line_summary": "è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºä¿¡æ¯å¯»æ±‚é¢„æµ‹æ§åˆ¶çš„è‡ªé€‚åº”æ–¹æ³•ï¼Œç”¨äºä½¿ç”¨ç§»åŠ¨ä»£ç†ï¼ˆå¦‚æ— äººæœºï¼‰ç›‘æµ‹éšæœºé‡ç«å‰æ²¿ï¼Œé€šè¿‡æ•´åˆæ„ŸçŸ¥ã€ä¼°è®¡å’Œæ§åˆ¶æ¥ä¼˜åŒ–ç›‘æµ‹è½¨è¿¹ã€‚",
  "detailed_summary": "",
  "qa_pairs": [],
  "is_hidden": false,
  "is_starred": false,
  "flag": "",
  "published_date": "2026-01-16T12:21:27Z",
  "created_at": "2026-01-20T17:49:59.843497",
  "updated_at": "2026-01-20T17:49:59.843505"
}