{
  "id": "2601.08491v1",
  "title": "AUV Trajectory Learning for Underwater Acoustic Energy Transfer and Age Minimization",
  "authors": [
    "Mohamed Afouene Melki",
    "Mohammad Shehab",
    "Mohamed-Slim Alouini"
  ],
  "abstract": "Internet of underwater things (IoUT) is increasingly gathering attention with the aim of monitoring sea life and deep ocean environment, underwater surveillance as well as maintenance of underwater installments. However, conventional IoUT devices, reliant on battery power, face limitations in lifespan and pose environmental hazards upon disposal. This paper introduces a sustainable approach for simultaneous information uplink from the IoUT devices and acoustic energy transfer (AET) to the devices via an autonomous underwater vehicle (AUV), potentially enabling them to operate indefinitely. To tackle the time-sensitivity, we adopt age of information (AoI), and Jain's fairness index. We develop two deep-reinforcement learning (DRL) algorithms, offering a high-complexity, high-performance frequency division duplex (FDD) solution and a low-complexity, medium-performance time division duplex (TDD) approach. The results elucidate that the proposed FDD and TDD solutions significantly reduce the average AoI and boost the harvested energy as well as data collection fairness compared to baseline approaches.",
  "url": "https://arxiv.org/abs/2601.08491v1",
  "html_url": "https://arxiv.org/html/2601.08491v1",
  "html_content": "AUV Trajectory Learning for Underwater Acoustic Energy Transfer and Age Minimization\nMohamed Afouene Melki, Mohammad Shehab, and Mohamed-Slim Alouini\nThis work is supported by the KAUST Office of Sponsored Research under Award ORA-CRG2021-4695.The authors are with CEMSE Division, King Abdullah University of Science and Technology (KAUST), Thuwal 23955-6900, Saudi Arabia (emails: mohamed.melki@kaust.edu.sa, mohammad.shehab@kaust.edu.sa, slim.alouini@kaust.edu.sa).\nAbstract\nInternet of underwater things (IoUT) is increasingly gathering attention with the aim of monitoring sea life and deep ocean environment, underwater surveillance as well as maintenance of underwater installments. However, conventional IoUT devices, reliant on battery power, face limitations in lifespan and pose environmental hazards upon disposal. This paper introduces a sustainable approach for simultaneous information uplink from the IoUT devices and acoustic energy transfer (AET) to the devices via an autonomous underwater vehicle (AUV), potentially enabling them to operate indefinitely. To tackle the time-sensitivity, we adopt age of information (AoI), and Jain‚Äôs fairness index. We develop two deep-reinforcement learning (DRL) algorithms, offering a high-complexity, high-performance frequency division duplex (FDD) solution and a low-complexity, medium-performance time division duplex (TDD) approach. The results elucidate that the proposed FDD and TDD solutions significantly reduce the average AoI and boost the harvested energy as well as data collection fairness compared to baseline approaches.\nI\nIntroduction\nThe health of our planet relies heavily on the well-being of its oceans, which serve as vital sources of oxygen, sustenance, and energy. Communication in extreme environments such as seas and deep oceans is of paramount importance due to its role in search and rescue operations, surveillance, maintenance of optical fibers and gas pipelines, and environmental monitoring among many other applications\n[\n7\n,\n14\n]\n. Each application has specific requirements in terms of communication range, energy consumption, data rate, and latency tolerance. Over time, underwater connectivity is becoming more vital.\nThe Internet-of-Underwater-Things (IoUTs), a global network connecting underwater objects, facilitates continuous monitoring of oceans. This network generates high-resolution data essential for training machine learning (ML) algorithms to swiftly evaluate potential climate change solutions and aid in decision-making processes. In addition, recent advances highlighted the potential of IoUT for underwater localization\n[\n2\n]\nand the defense against attacks for such localization approaches\n[\n22\n]\n. Furthermore, and within the efforts leading to enhanced underwater connectivity for divers, the authors of\n[\n25\n]\ndeveloped the world‚Äôs first underwater wifi ‚ÄùAqua-Fi‚Äù to transfer data from a diver‚Äôs smartphone to a gateway device mounted on their equipment. This gateway then relays the data through a light beam to a surface computer, which is connected to the internet via satellite. However, the light beam is only suitable for short distances and suffers from disruptions due to tides and underwater movements. In response to these limitations, recent advancements have explored alternative acoustic approaches to achieve long-range, low-power underwater communication. For instance, the work in\n[\n9\n]\npresents an underwater backscatter communication system that enables long-distance communication by encoding data in sound waves reflected back to a receiver. Tested in river and ocean environments, this system demonstrated a significantly greater communication range than previous technologies, while maintaining low power consumption, marking a substantial improvement for sustained underwater connectivity.\nDue to their ability to navigate freely and reach remote and risky locations for divers, AUVs are considered to be a very attractive solution for gathering information from IoUT devices. In this context, the work in\n[\n23\n]\nillustrated the application of federated learning in collaborative information processing via AUVs in IoUT. Nevertheless, the nature of underwater communication is different from other environments. For instance, conventional IoUT sensors, reliant on battery power, face limitations in lifespan, difficulties with battery replacement, and pose environmental hazards upon disposal. Unlike terrestrial systems, underwater communication suffers from significant signal attenuation, tidal turbulence and multi-path effects. These challenges necessitate innovative approaches to optimize the paths of AUVs for effective data collection and wireless energy transfer.\nUnderstanding and overcoming the limitations of communication in underwater environments can lead to more robust and efficient systems, paving the way for future innovation in the field. In this context, the work in\n[\n21\n,\n26\n]\npresented a comprehensive summary on different communication and energy transfer technologies underwater. However, no single technology can meet all requirements across different activities simultaneously. Hence, each system is tailored to suit specific applications. According to their discussion and many other works such as\n[\n13\n]\n, it is evident that despite the drawback of low data rates and slow propagation, the adoption of acoustic transmission is superior to optical transmission and magnetic induction in terms of resilience and long range. This is further elaborated in\n[\n13\n]\n, where the attenuation coefficients for magnetic induction and electromagnetic-based energy transfer are too high compared to AET. This in turn affects the efficiency of energy transmission causing a great loss when the distance of energy transfer is longer than few meters. This preference is further supported in\n[\n28\n]\n, which provides a comparative analysis of both commercial and research acoustic modems. This study highlights the modem parameters crucial for underwater applications, such as operating range, data rate, modulation schemes, and power consumption, identifying current trends and key design challenges. Additionally, the survey in\n[\n16\n]\nemphasizes the importance of acoustic technology for underwater communication systems, particularly as underwater IoUT devices typically transmit small, delay-tolerant data packets such as sensor readings, making acoustic technology well-suited for our endeavor. Despite the infancy of the idea of underwater AET, an example of new advances in hardware design for AET can be found in\n[\n27\n]\n, which illustrates transducer structure for underwater AET system.\nAssuming instant reception, AoI is defined as the time elapsed since the reception of the last information update from an IoUT device\n[\n17\n,\n18\n]\n. AoI minimization is of paramount importance since the lower the AoI, the fresher the information received from a specific IoUT device. A lot of research has been conducted on applying machine learning in order to minimize the AoI of devices in above-water environments. For instance, the authors of\n[\n1\n]\napplied deep reinforcement learning (DRL) to design the trajectory of UAV collecting information from a small number of grounded devices with the goal of minimizing the AoI of these devices. Moreover, the study in\n[\n10\n]\nexplored the use of multiple Unmanned Aerial Vehicles (UAVs) to optimize both AoI and power consumption of a relatively larger number of devices. In\n[\n11\n]\n, the same authors expanded their setup further, where a swarm of UAVs collects data from device clusters constituting a massive IoT network. These efforts highlight the importance of efficient path planning, scheduling, and power management to ensure timely data collection and energy efficiency.\nTo this end, authors generally resorted to RL due to the high complexity and dimensionality of the trajectory optimization problem in such cases, especially when taking the energy and environmental details into consideration. In particular, when dealing with problems of high dimensional state and action spaces, DRL is known for its efficiency. This is because DRL is able to sample and reduce the dimensionality of those spaces, which renders a faster, yet highly sub-optimal solution. Similar research in underwater environments remains sparse. This area has not been extensively studied until Omoke et al.\n[\n20\n]\npublished the first attempt to apply RL to perform simultaneous wireless power transfer and data collection in an underwater system. They demonstrated relatively good results, despite their setup being somewhat similar to terrestrial systems, where a vehicle needs to get very close to devices to power them up and exchange data. However, their model did not account for AoI and its trade-off with the energy harvesting goal.\nHence, the exploration of RL in underwater environments is crucial due to the unique challenges posed by underwater communication and navigation. In this context, the authors of\n[\n19\n]\npresented a wide discussion on how RL could help tackle IoUT challenges. The online nature of RL was shown to be well-tailored to the dynamic nature of underwater channel, link outages, bandwidth allocation as well as AUV control problems. Moreover, in\n[\n8\n]\n, Dai et al. proposed an RL approach for underwater relay selection and power control. By focusing on RL to optimize AUV trajectories, this work aims to address the challenge of battery-constrained IoUT and information uplink, which contributes to the advancement of underwater wireless communication technologies. We assume a set of underwater IoT devices that rely mainly on harvested energy from acoustic sources to transmit information The target is to optimize the underwater AUV trajectory and device scheduling in order to minimize the average AoI and implicitly maximize the harvested energy via AET.\nI-A\nContributions\nThe motivation behind this work stems from its novelty in accounting for AoI minimization and solving the problem of battery replacement for IoUT devices. This leads to avoiding hazardous material underwater, which might affect sea life. Our research also complements the acoustic communication system in a sustainable framework. Particularly, in the context of planning paths and scheduling for underwater simultaneous wireless communication and energy transfer, the contributions of this paper are summarized as follows:\n‚Ä¢\nWith the goal of minimizing the average weighted AoI of IoUT devices, we develop a couple of DRL solutions for AUV trajectory planning for simultaneous AET and information uplink\n‚Ä¢\nThe first approach is FDD-based high performance, high complexity, and two antenna-based solution.\n‚Ä¢\nThe second one is a TDD-based low complexity, low-cost alternative solution that adopts only one antenna for both AET and information reception and the AUV.\n‚Ä¢\nCompared to baseline approaches such as random walk (RW), round robin (RR), and the greedy algorithm (GA), the proposed FDD and TDD DRL-based approaches jointly minimize the AoI and maximize the harvested energy and data collection fairness at the IoUT devices.\nI-B\nOutline\nThe rest of the paper is organized as follows: Section\nII\ndescribes the system model and basic information about underwater communication. Next, Section\nIII\nformulates the simultaneous AET and information uplink problem and elucidates TDD and FDD. Section\nIV\nproposes the DRL-PPO, while Section\nV\ndepicts the experimental results. Finally, Section\nVI\nconcludes the paper. The appendices include some mathematical proofs and derivations that serve the solution of the presented optimization problem.\nII\nSystem Model\nFigure 1:\nAUV and IoUT network in the underwater grid world\nII-A\nNetwork Model\nAs illustrated in Fig.\n1\n, we consider an IoUT network, comprising an AUV deployed from a surface buoy station, and\nK\nK\nIoUT nodes dispersed randomly in a 3-D underwater space. Each IoUT device\nk\nk\nis spatially distributed across the 3D equally spaced grid world and is assigned fixed coordinates\nc\nk\n=\n(\nx\nk\n,\ny\nk\n,\nz\nk\n)\nc_{k}=(x_{k},y_{k},z_{k})\n. Similarly, at time\nt\nt\nthe AUV is designated coordinates\nl\na\n‚Äã\nu\n‚Äã\nv\n‚Äã\n(\nt\n)\n=\n(\nx\na\n‚Äã\nu\n‚Äã\nv\n‚Äã\n(\nt\n)\n,\ny\na\n‚Äã\nu\n‚Äã\nv\n‚Äã\n(\nt\n)\n,\nz\na\n‚Äã\nu\n‚Äã\nv\n‚Äã\n(\nt\n)\n)\nl_{auv}(t)=(x_{auv}(t),y_{auv}(t),z_{auv}(t))\n. Each IoUT device is equipped with sensors designed for monitoring essential underwater parameters such as temperature, pH level, and dissolved oxygen concentration. The AUV maneuvers through the grid world to establish communication with the underwater sensor nodes, where communication is facilitated through an acoustic modem/hydrophone.\nMoreover, as the AUV traverses the network, it employs AET to provide energy, thereby recharging energy-constrained IoUT nodes.\nII-B\nChannel Model\nIn acoustic communication, the received level (RL) in dB at an IoUT device that is located at distance\nd\nd\nfrom the source (i.e, AUV) is calculated as\n[\n5\n]\nR\n‚Äã\nL\n=\nS\n‚Äã\nL\n‚àí\nA\n‚Äã\nL\n‚àí\nN\n‚Äã\nL\n,\nRL=SL-AL-NL,\n(1)\nwhere\nS\n‚Äã\nL\nSL\nis the acoustic source level,\nA\n‚Äã\nL\nAL\ncharacterizes the total attenuation level and\nN\n‚Äã\nL\nNL\nis the ambient noise level. The SL of an underwater acoustic transmitter is given by\nS\n‚Äã\nL\n=\n170.8\n+\n10\n‚Äã\nlog\n10\n‚Å°\nP\ne\n‚Äã\nl\n‚Äã\ne\n‚Äã\nc\n+\n10\n‚Äã\nlog\n10\n‚Å°\nŒ∑\n+\nD\n‚Äã\nI\n,\nSL=170.8+10\\log_{10}P_{elec}+10\\log_{10}\\eta+DI,\n(2)\nwhere DI is the directivity index of the source in dB,\nP\ne\n‚Äã\nl\n‚Äã\ne\n‚Äã\nc\nP_{elec}\nis the electrical input power at the source, while the electro-acoustic power conversion efficiency\nŒ∑\n\\eta\nvaries between 0.2 and 0.7 for practical modems.\nAssuming deep water characteristics and neglecting reflection from the air and bottom surfaces throughout the analysis, combining absorption, channel spreading loss, and noise, the total attenuation level (AL) in dB is given by\n1\n1\n1\nFor simplicity and focusing on the main system optimization, we assumed flat fading\nA\n‚Äã\nL\n=\nk\ns\n‚ãÖ\n10\n‚Äã\nlog\n10\n‚Å°\nd\n+\nd\n‚ãÖ\n10\n‚Äã\nlog\n10\n‚Å°\nŒ±\n‚Äã\n(\nf\n)\n,\nAL=k_{s}\\cdot 10\\log_{10}d+d\\cdot 10\\log_{10}\\alpha\\left(f\\right),\n(3)\nwhere and\nk\ns\nk_{s}\nis the spreading factor that takes the value of 1 or 2 depending on the assumptions;\nk\ns\n=\n2\nk_{s}=2\nis referred to as spherical spreading experienced when a sound wave propagates away from the source uniformly in 3 directions, when\nd\n<\nwater depth\nd<\\text{water depth}\n. Meanwhile,\nk\ns\n=\n1\nk_{s}=1\nis referred to as cylindrical spreading experienced when the acoustic signal systematically hits the sea surface and sea floor before reaching the destination.\nŒ±\n‚Äã\n(\nf\n)\n\\alpha\\left(f\\right)\nis the absorption coefficient of acoustic waves underwater that can be expressed using Thorp‚Äôs formula\nfor frequencies above a few hundred Hz,\n[\n13\n]\nŒ±\n‚Äã\n(\nf\n)\n=\n0.11\n‚Äã\nf\n2\nf\n2\n+\n1\n+\n44\n‚Äã\nf\n2\nf\n2\n+\n4100\n+\n2.75\n√ó\n10\n‚àí\n4\n‚Äã\nf\n2\n+\n0.003\n,\n\\alpha\\!\\left(f\\right)\\!=\\!0.11\\!\\frac{f^{2}}{f^{2}+1}\\!+44\\frac{f^{2}}{f^{2}+4100}\\!+2.75\\times 10^{-4}f^{2}\\!+\\!0.003,\n(4)\nwhere\nf\nf\nis the acoustic transmission frequency.\nIII\nProblem formulation\nIII-A\nAcoustic Energy Transfer and Information Uplink\nIII-A\n1\nAcoustic Energy Transfer\nThe process of AET begins with the emission of acoustic waves by the AUV through its hydrophone. These waves carry transmitted power and propagate as fluctuating pressure waves characterized by their amplitude, frequency, and phase. Subsequently, the IoUT nodes‚Äô hydrophones receive these energy waves. The process also involves the use of transducers that can convert acoustic pressure waves into electrical energy. This electrical energy is then stored in a battery onboard the IoUT node. The pressure fluctuations can be expressed as\n[\n5\n]\np\n=\n10\nR\n‚Äã\nL\n/\n20\n.\np=10^{{RL}/{20}}.\n(5)\nThe fluctuations generate a voltage at its open circuit terminals as mentioned earlier. The receiving voltage sensitivity (RVS) of a hydrophone is defined as\n[\n5\n]\nR\n‚Äã\nV\n‚Äã\nS\n=\n20\n‚Äã\nlog\n10\n‚Å°\nM\n,\nRVS=20\\log_{10}M,\n(6)\nwhere\nM\nM\nis the sensitivity in\nV\n/\nŒº\n‚Äã\nP\n‚Äã\na\nV/\\mu Pa\n. Using (\n5\n) and (\n6\n), the induced voltage, at the receiver hydrophone terminals\nV\ni\n‚Äã\nn\n‚Äã\nd\nV_{ind}\nis given by\nV\ni\n‚Äã\nn\n‚Äã\nd\n=\np\n‚ãÖ\nM\n=\n10\nR\n‚Äã\nL\n+\nR\n‚Äã\nV\n‚Äã\nS\n20\n.\nV_{ind}=p\\cdot M=10^{\\frac{RL+RVS}{20}}.\n(7)\nThe electrical power available for harvesting,\nP\na\n‚Äã\nv\n‚Äã\na\n‚Äã\ni\n‚Äã\nl\n‚Äã\na\n‚Äã\nb\n‚Äã\nl\n‚Äã\ne\nP_{available}\ndepends on\nthe impedance matching between the receiver hydrophone and\nthe surrounding seawater. For a single hydrophone, this can be\nexpressed as\nP\na\n‚Äã\nv\n‚Äã\na\n‚Äã\ni\n‚Äã\nl\n‚Äã\na\n‚Äã\nb\n‚Äã\nl\n‚Äã\ne\n=\nV\ni\n‚Äã\nn\n‚Äã\nd\n2\n4\n‚Äã\nR\np\n,\nP_{available}={{V_{ind}^{2}}\\over{4R_{p}}},\n(8)\nwhere\nR\np\nR_{p}\nis the load resistance required to ensure impedance matching. This gives us the total harvestable power, which is given by\nP\nh\n‚Äã\na\n‚Äã\nr\n‚Äã\nv\n=\nŒ∑\n‚ãÖ\nP\na\n‚Äã\nv\n‚Äã\na\n‚Äã\ni\n‚Äã\nl\n‚Äã\na\n‚Äã\nb\n‚Äã\nl\n‚Äã\ne\n=\nŒ∑\n‚ãÖ\n10\n(\nR\n‚Äã\nL\n+\nR\n‚Äã\nV\n‚Äã\nS\n)\n/\n10\n4\n‚Äã\nR\np\n,\nP_{harv}=\\eta\\cdot P_{available}=\\eta\\cdot{{10^{{\\left({RL+RVS}\\right)}/{10}}}\\over{4R_{p}}},\n(9)\nwhere\nŒ∑\n\\eta\nis the acoustic-electric power conversion efficiency. Then, the energy harvested is calculated as\nE\nh\n‚Äã\na\n‚Äã\nr\n‚Äã\nv\n=\nP\nh\n‚Äã\na\n‚Äã\nr\n‚Äã\nv\n‚ãÖ\nœÑ\nc\n‚Äã\nh\n‚Äã\na\n‚Äã\nr\n‚Äã\ng\n‚Äã\ni\n‚Äã\nn\n‚Äã\ng\n,\nE_{harv}=P_{harv}\\cdot\\tau_{charging},\n(10)\nwhere\nœÑ\nc\n‚Äã\nh\n‚Äã\na\n‚Äã\nr\n‚Äã\ng\n‚Äã\ni\n‚Äã\nn\n‚Äã\ng\n\\tau_{charging}\nrepresents the time taken by the AUV to transmit energy to the IoUT node.\nIII-A\n2\nInformation Uplink\nDuring the communication between the IoUT nodes and the AUV, the latter collects data. The SNR,\nŒ≥\nk\n\\gamma_{k}\nbetween the\nk\nt\n‚Äã\nh\nk^{th}\nnode and the AUV can be expressed as\nŒ≥\nk\n=\n2\n(\nùíÆ\n/\nB\n)\n‚àí\n1\n,\n\\gamma_{\\mathrm{k}}=2^{\\left({{\\mathcal{S}}}/{B}\\right)}-1,\n(11)\nwhere\nùíÆ\n{\\mathcal{S}}\nis the system throughput and\nB\nB\nis the bandwidth. The transmit power of the\nk\nt\n‚Äã\nh\nk^{th}\nnode\nP\nt\n‚Äã\nr\n‚Äã\na\n‚Äã\nn\n‚Äã\ns\n,\nk\nP_{trans,k}\nis\n[\n20\n]\nP\nt\n‚Äã\nr\n‚Äã\na\n‚Äã\nn\n‚Äã\ns\n,\nk\n=\nŒ≥\nk\n‚ãÖ\n10\nN\n‚Äã\nL\n10\n‚ãÖ\n10\nA\n‚Äã\nL\nk\n,\na\n‚Äã\nu\n‚Äã\nv\n10\n,\nP_{trans,k}=\\gamma_{k}\\cdot 10^{\\frac{NL}{10}}\\cdot 10^{\\frac{AL_{k,auv}}{10}},\n(12)\nwhere\nA\n‚Äã\nL\nk\n,\na\n‚Äã\nu\n‚Äã\nv\nAL_{k,auv}\nis the transmission loss between the\nk\nt\n‚Äã\nh\nk^{th}\nnode and the AUV. The energy required by a node\nk\nk\nto transmit information to the AUV is\nE\nr\n‚Äã\ne\n‚Äã\nq\n,\nk\n=\nP\nt\n‚Äã\nr\n‚Äã\na\n‚Äã\nn\n‚Äã\ns\n,\nk\n‚ãÖ\nœÑ\nd\n‚Äã\na\n‚Äã\nt\n‚Äã\na\n,\nE_{req,k}=P_{trans,k}\\cdot\\tau_{data},\n(13)\nwhere\nœÑ\nD\n‚Äã\na\n‚Äã\nt\n‚Äã\na\n\\tau_{Data}\nis the time required to transmit the payload from the sensor to the AUV.\nIII-A\n3\nAge Of Information\nUpon transmission of a packet by a selected IoUT device\nk\nk\nat time step\nt\nt\n, its AoI\nA\nk\n‚Äã\n(\nt\n)\nA_{k}(t)\nresets to 1, which indicates that fresh information has just been received from that device.\nIII-B\nDuplexing Techniques\nIn underwater simultaneous communication and AET,\nduplexing techniques play a crucial role in determining the efficiency and effectiveness of data and energy transmission. Herein, we adopt two primary types of duplexing, namely FDD and TDD. Each technique has its own set of advantages and challenges as noted in\n[\n3\n]\n, which impacts their applicability in various circumstances. The two techniques are illustrated in Fig.\n2\nFigure 2:\nAET and information uplink using FDD vs TDD\nIII-B\n1\nFrequency-Division Duplexing\nFDD is a duplexing method where separate frequency bands are allocated for AET and information uplink. This means that AET and data transmission can occur simultaneously but on different frequencies. FDD is particularly useful in scenarios where separate and large uplink and downlink bandwidth requirements are needed, providing continuity and high capacity for energy and information transmission with limited interference.\nAs shown in the left part of Fig.\n2\n, the AUV utilizes two distinct frequency bands with different central frequencies\nf\nc\n‚Äã\nh\n‚Äã\na\n‚Äã\nr\n‚Äã\ng\n‚Äã\ni\n‚Äã\nn\n‚Äã\ng\nf_{charging}\nfor AET to\ni\nt\n‚Äã\nh\ni^{th}\nnode and\nf\nd\n‚Äã\na\n‚Äã\nt\n‚Äã\na\nf_{data}\nfor data uplink from\nj\nt\n‚Äã\nh\nj^{th}\nnode.This separation of frequencies ensures that the two processes can occur without interference.\nIn our case, FDD can be advantageous due to its ability to handle simultaneous bidirectional AET and information uplink, reducing latency and improving throughput. However, the need for separate frequency bands can lead to spectrum inefficiency, as it requires a broader range of frequencies to operate. Additionally, the hardware complexity increases because of the necessity for duplexers as well as multiple antennas to separate the data and AET at the transmitter and receiver.\nIII-B\n2\nTime-Division Duplexing\nTDD is a method where the same frequency band is used for both AET and information uplink but at different times. This technique involves switching between transmitting and receiving modes within designated time slots, effectively utilizing the same frequency spectrum for both operations. TDD is particularly useful in scenarios where limited hardware and frequency resources exist, allowing for dynamic adjustment of AET and information uplink based on real-time demand.\nAs shown in the right part of Fig.\n2\n, the AUV shares the same frequency band for AET and data uplink but allocates different durations for each operation. The total communication duration\nœÑ\n\\tau\nis divided into\nŒ≤\n‚Äã\nœÑ\n\\beta\\tau\nfor AET and\n(\n1\n‚àí\nŒ≤\n)\n‚Äã\nœÑ\n(1-\\beta)\\tau\nfor data uplink, where\nŒ≤\n\\beta\nrepresents the time-splitting factor. This allocation ensures efficient use of the available spectrum by sequentially performing energy transfer and data communication.\nTDD is advantageous in the sense of its efficient spectrum usage and flexibility. It simplifies the hardware design by eliminating the need for separate frequency bands, antennas, and duplexers. However, precise time synchronization is crucial to avoid interference between data uplink and energy downlink transmissions.\nIII-C\nProblem Formulation\nInspired by existing works such as\n[\n1\n]\n,\n[\n11\n]\n, and\n[\n15\n]\nwhich focus on minimizing the AoI and improving fairness in UAV-based communication systems, we extend these concepts to address the specific challenges in AUVs.To minimize the weighted average AoI of collected data, the AUV trajectory planning problem can be formulated as follows\n2\n2\n2\nIn this problem formulation, we focus on the communication between the AUV and sensor nodes. The dynamics of the AUV and its energy consumption are beyond the scope of this work. For simplicity, we assume the AUV has sufficient energy throughout the entire navigation time.\nùêèùüè\n:\n\\displaystyle\\mathbf{P1:}\\quad\nmin\n{\nx\nk\n‚Äã\n(\nt\n)\n}\nt\n=\n0\nT\n,\n{\nùíç\na\n‚Äã\nu\n‚Äã\nv\n‚Äã\n(\nt\n)\n}\nt\n=\n0\nT\n\\displaystyle\\underset{\\{x_{k}(t)\\}_{t=0}^{T},\\,\\{\\boldsymbol{l}_{auv}(t)\\}_{t=0}^{T}}{\\min}\n(\n1\n‚àí\nùí•\nT\n)\nT\n‚ãÖ\n‚àë\nt\n=\n1\nT\n1\nK\n‚Äã\n‚àë\nk\n=\n1\nK\nŒ¥\nk\n‚ãÖ\nA\nk\n‚Äã\n(\nt\n)\n\\displaystyle\\frac{(1-\\mathcal{J}_{T})}{T}\\cdot\\sum_{t=1}^{T}\\frac{1}{K}\\sum_{k=1}^{K}\\delta_{k}\\cdot A_{k}(t)\nSubject to:\nA\nk\n‚Äã\n(\nt\n)\n‚©Ω\nA\nmax\n,\n‚àÄ\nk\n,\n‚àÄ\nt\n\\displaystyle A_{k}(t)\\leqslant A_{\\text{max}},\\quad\\forall k,\\;\\forall t\nùí•\nT\n‚©æ\nùí•\nT\nmin\n\\displaystyle\\mathcal{J}_{T}\\geqslant\\mathcal{J}_{T_{\\min}}\nx\nk\n‚Äã\n(\nt\n)\n‚Äã\ne\nk\n‚Äã\n(\nt\n)\n‚©æ\nx\nk\n‚Äã\n(\nt\n)\n‚Äã\nE\nreq\n,\nk\n‚Äã\n(\nt\n)\n,\n‚àÄ\nk\n,\n‚àÄ\nt\n\\displaystyle x_{k}(t)\\,e_{k}(t)\\geqslant x_{k}(t)\\,E_{\\text{req},k}(t),\\forall k,\\;\\forall t\n‚àë\nk\n=\n1\nK\nx\nk\n‚Äã\n(\nt\n)\n=\n1\n,\n‚àÄ\nt\n\\displaystyle\\sum_{k=1}^{K}x_{k}(t)=1,\\quad\\forall t\nx\nk\n‚Äã\n(\nt\n)\n‚àà\n{\n0\n,\n1\n}\n,\n‚àÄ\nk\n,\n‚àÄ\nt\n\\displaystyle x_{k}(t)\\in\\{0,1\\},\\quad\\forall k,\\;\\forall t\nùíç\na\n‚Äã\nu\n‚Äã\nv\n‚Äã\n(\nt\n)\n‚àà\nùí≥\n,\n‚àÄ\nt\n\\displaystyle\\boldsymbol{l}_{auv}(t)\\in\\mathcal{X},\\quad\\forall t\nIn this formulation,\nŒ¥\nk\n\\delta_{k}\nrepresents the importance weight assigned to device\nk\nk\nand\nA\nmax\nA_{\\text{max}}\nis the maximum allowed AoI in the system. The binary variable\nx\nk\nx_{k}\nindicates whether device\nk\nk\nis selected for data transmission (\nx\nk\n=\n1\nx_{k}=1\n) or not (\nx\nk\n=\n0\nx_{k}=0\n). The energy stored in device\nk\nk\nat time\nt\nt\nis denoted by\ne\nk\n‚Äã\n(\nt\n)\ne_{k}(t)\n, while\nE\nreq\n,\nk\n‚Äã\n(\nt\n)\nE_{\\text{req},k}(t)\nrepresents the minimum energy required for device\nk\nk\nto transmit data. The constraint\nx\nk\n‚ãÖ\ne\nk\n‚Äã\n(\nt\n)\n‚©æ\nx\nk\n‚ãÖ\nE\nreq\n,\nk\n‚Äã\n(\nt\n)\nx_{k}\\cdot e_{k}(t)\\geqslant x_{k}\\cdot E_{\\text{req},k}(t)\nensures that the selected device has enough energy to transmit. The condition\n‚àë\nk\n=\n1\nK\nx\nk\n=\n1\n\\sum_{k=1}^{K}x_{k}=1\nenforces that only one device is selected at each time step. Finally, the constraint\nl\na\n‚Äã\nu\n‚Äã\nv\n‚Äã\n(\nt\n)\n‚àà\nùí≥\nl_{auv}(t)\\in\\mathcal{X}\nensures that the AUV remains within the defined grid world, where\nùí≥\n\\mathcal{X}\ndenotes the set of all possible locations within the grid.\nThe weighted average AoI, as expressed in the objective function, allows assigning varying levels of importance to different nodes. This is particularly useful in scenarios involving critical and non-critical nodes, where higher priority can be given to nodes with stricter data freshness requirements\n[\n12\n]\n. In this work, we simplify the analysis by setting all weights\nŒ¥\nk\n\\delta_{k}\nto 1, ensuring that all nodes are treated equally in terms of importance. This assumption allows us to focus on evaluating the overall performance of the proposed approach without introducing additional bias in the optimization objective.\nThe main objective of problem\nP1\nis to minimize the average AoI. To achieve this, the solution should ensure that sufficient energy is available at each IoUT node for data transmission, which implicitly maximizes the harvested energy. However, this approach may lead to an unfair distribution of data collection among devices despite boosting the overall global performance. To address this issue, we make use of Jain‚Äôs fairness index,\nùí•\nT\n\\mathcal{J}_{T}\n, as a metric to ensure fair data gathering\n[\n15\n]\n. This index is defined based on the frequency of data collection from each device over a period\nT\nT\n, where\nùí•\nT\n=\n(\n‚àë\nk\n=\n1\nK\nD\nT\n‚Äã\n(\nk\n)\n)\n2\nK\n‚Äã\n‚àë\nk\n=\n1\nK\nD\nT\n‚Äã\n(\nk\n)\n2\n,\n\\mathcal{J}_{T}=\\frac{\\left(\\sum_{k=1}^{K}D_{T}(k)\\right)^{2}}{K\\sum_{k=1}^{K}D_{T}(k)^{2}},\n(15)\nwhere\nD\nT\n‚Äã\n(\nk\n)\nD_{T}(k)\ndenotes the total number of times the data was collected from the device\nk\nk\nover the period\nT\nT\n.\nThe value of\nùí•\nT\n\\mathcal{J}_{T}\nlies within the range [0, 1], and it can be interpreted as follows:\n‚Ä¢\nIf\nùí•\nT\n\\mathcal{J}_{T}\nis close to 1, it indicates that all nodes are receiving equal attention during data collection, meaning the data collection process is balanced and fair.\n‚Ä¢\nIf\nùí•\nT\n\\mathcal{J}_{T}\nis close to 0, it implies an unbalanced distribution where some nodes are prioritized significantly more than others, leading to neglect of certain nodes.\nIn the context of this work, Jain‚Äôs fairness index ensures that no IoUT node is overly prioritized or ignored, even as the global performance (e.g., minimizing AoI) is optimized. By monitoring\nùí•\nT\n\\mathcal{J}_{T}\n, we achieve a balance between performance and fairness, which is crucial in applications where uniform data collection across nodes is essential,\nIn our problem, we aim to maximize Jain‚Äôs fairness index. Moreover, this index is not allowed to fall below a specific threshold\nùí•\nm\n‚Äã\ni\n‚Äã\nn\n\\mathcal{J}_{{min}}\nto guarantee a reasonable amount of fairness on data collection.\nIn summary, our objective is to simultaneously achieve fair data gathering and minimize the average AoI. Given the complexity and NP-hard nature of this problem, traditional optimization techniques are impractical. To model the association and interaction pattern between the AUV and IoUT devices, the AUV trajectory planning problem is formulated as a Markov decision process (MDP) that captures the dynamics of the AUV. DRL is employed for this MDP due to its ability to manage large state and action spaces and adapt to complex, nonlinear systems, robustly optimizing the AUV‚Äôs trajectory while ensuring energy-efficient communication and fair data collection across the network.\nIV\nThe proposed DRL solution\nIV-A\nMarkov Decision Process Formulation\nWe formulate the problem as an MDP that is defined by the tuple\n‚ü®\nùíÆ\n,\nùíú\n,\nR\n,\nP\n‚ü©\n\\langle\\mathcal{S},\\mathcal{A},R,P\\rangle\n, where\nùíÆ\n\\mathcal{S}\nis the state space,\nùíú\n\\mathcal{A}\nrepresents the action space,\nR\nR\ndenotes the reward function. We consider a finite horizon MDP with a probabilistic state transition function\nP\n:\nùíÆ\n√ó\nùíú\n√ó\nùíÆ\n‚Üí\n‚Ñù\nP:\\mathcal{S}\\times\\mathcal{A}\\times\\mathcal{S}\\rightarrow\\mathbb{R}\n. At time instant\nt\nt\n, the agent (AUV) observes the current state\ns\n‚Äã\n(\nt\n)\ns(t)\nfrom the environment and tries to follow the optimal policy by selecting the best action\na\n‚Äã\n(\nt\n)\na(t)\n, which maximizes the reward\nr\n‚Äã\n(\nt\n)\nr(t)\nand transiting to the next state\ns\n‚Äã\n(\nt\n+\n1\n)\ns(t+1)\nwith a probability\np\n‚Äã\n(\ns\n‚Äã\n(\nt\n)\n,\ns\n‚Äã\n(\nt\n+\n1\n)\n)\np(s(t),s(t+1))\n. The agent can then rely on these policies to make all future data transfer and AET decisions as illustrated in Fig.\n3\n. For convenience, we propose an episodic MDP. This means that the AUV‚Äôs data collection and energy transmission is over at time\nT\n‚àà\n‚Ñï\nT\\in\\mathbb{N}\n, where the total navigation time\nT\nT\nis dictated by the amount of navigation energy available at the AUV and the dimensions of the network. Time slots are discretely divided as\nt\n=\n{\nœÑ\n,\n2\n‚Äã\nœÑ\n,\n‚Ä¶\n,\nT\n}\nt=\\{\\tau,2\\tau,\\dots,T\\}\n, where\nœÑ\n\\tau\nis the time that the AUV takes to move from one grid point to another adjacent one.\nœÑ\n\\tau\nis dictated by the AUV‚Äôs velocity and the spacing between grids.\nFigure 3:\nThe interaction between the agent and the environment\nIV-A\n1\nState space\nThe state space of the system at time slot\nt\nt\nis defined as\ns\n‚Äã\n(\nt\n)\n=\n(\nùíç\nùíÇ\n‚Äã\nùíñ\n‚Äã\nùíó\n‚Äã\n(\nt\n)\n,\nùë®\n‚Äã\n(\nt\n)\n,\nùìî\n‚Äã\n(\nt\n)\n)\ns(t)=(\\boldsymbol{l_{auv}}(t),\\boldsymbol{A}(t),\\boldsymbol{\\mathcal{E}}(t))\n, where\nùíç\nùíÇ\n‚Äã\nùíñ\n‚Äã\nùíó\n‚Äã\n(\nt\n)\n\\boldsymbol{l_{auv}}(t)\nis a vector containing the current position of the AUV at time slot\nt\nt\n.\nùë®\n‚Äã\n(\nt\n)\n\\boldsymbol{A}(t)\nis a vector that contains the current AoI of all the IoUT devices at time slot\nt\nt\n, where\nA\nk\n‚Äã\n(\nt\n)\n‚àà\n‚Ñê\n=\n[\n1\n,\n2\n,\n‚Ä¶\n,\nA\nm\n‚Äã\na\n‚Äã\nx\n]\nA_{k}(t)\\in\\mathcal{I}=[1,2,...,A_{max}]\nand\nA\nm\n‚Äã\na\n‚Äã\nx\nA_{max}\nis the maximum allowed AoI in the model, which is chosen to be arbitrarily high.\nùìî\n‚Äã\n(\nt\n)\n\\boldsymbol{\\mathcal{E}}(t)\nrepresents a vector of the available energy at each IoUT node, which belongs to a discrete set\n‚Ñ∞\n\\mathcal{E}\n. . Without loss of generality, we will consider the discrete 3D coordinates of the AUV and IoUT to be integers to reduce the computational demand of representing the system state. Note that the state is updated before being fed to the agent. Considering the three described components, the dimensionality of the state space could be described as\nùíÆ\n=\nùí≥\n3\n‚èü\nAuv Position\n√ó\n‚Ñ∞\nK\n‚èü\nEnergy Stored\n√ó\n‚Ñê\nK\n‚èü\nDevice age of information\n,\n\\mathcal{S}=\\underbrace{\\mathcal{X}^{3}}_{\\text{ Auv Position}}\\times\\underbrace{\\mathcal{E}^{K}}_{\\text{Energy Stored}}\\times\\underbrace{\\mathcal{I}^{K}}_{\\text{Device age of information}},\n(16)\nRemark 1\n.\nThese components were selected to capture the critical spatial (\nùê•\nùêö\n‚Äã\nùêÆ\n‚Äã\nùêØ\n‚Äã\n(\nt\n)\n\\boldsymbol{l_{auv}}(t)\n), temporal (\nùêÄ\n‚Äã\n(\nt\n)\n\\boldsymbol{A}(t)\n), and energy (\nùìî\n‚Äã\n(\nt\n)\n\\boldsymbol{\\mathcal{E}}(t)\n) dynamics of the system, enabling the agent to make informed decisions for AoI minimization and fairness. Excluding\nùìî\n‚Äã\n(\nt\n)\n\\boldsymbol{\\mathcal{E}}(t)\nfrom the state space results in failed data transmissions, as the agent is unable to account for energy availability at the nodes. Similarly, removing\nùêÄ\n‚Äã\n(\nt\n)\n\\boldsymbol{A}(t)\nleads to poor AoI optimization, as the agent lacks awareness of data freshness.\nIV-A\n2\nAction space\nWe have developed two approaches for defining the action space in our RL framework: a 3D action space for FDD communication and a 2D action space for TDD communication.\nFirst Approach: 3D Action Space (FDD)\nThe AUV action at time slot\nt\nt\nis defined as\na\n‚Äã\n(\nt\n)\n=\n(\nd\n‚Äã\n(\nt\n)\n,\nW\n‚Äã\n(\nt\n)\n,\nI\n‚Äã\n(\nt\n)\n)\na(t)=(d(t),W(t),I(t))\n, where\nd\n‚Äã\n(\nt\n)\nd(t)\nrepresents the movement of the AUV in a given direction,\nW\n‚Äã\n(\nt\n)\n=\n(\nw\n1\n‚Äã\n(\nt\n)\n,\nw\n2\n‚Äã\n(\nt\n)\n,\n‚Ä¶\n,\nw\nK\n‚Äã\n(\nt\n)\n)\nW(t)=(w_{1}(t),w_{2}(t),\\ldots,w_{K}(t))\nis a sparse vector representing the node chosen for WET with\nw\nk\n‚Äã\n(\nt\n)\n=\n1\nw_{k}(t)=1\nindicating that node\nk\nk\nis selected, and\nI\n‚Äã\n(\nt\n)\n=\n(\ni\n1\n‚Äã\n(\nt\n)\n,\ni\n2\n‚Äã\n(\nt\n)\n,\n‚Ä¶\n,\ni\nK\n‚Äã\n(\nt\n)\n)\nI(t)=(i_{1}(t),i_{2}(t),\\ldots,i_{K}(t))\nis a sparse vector representing the node chosen for Information transmission with\ni\nk\n‚Äã\n(\nt\n)\n=\n1\ni_{k}(t)=1\nindicating that node\nk\nk\nis selected for information uplink. The action space is given by:\nùíú\n=\nùîª\n1\n‚èü\ndirection\n√ó\n{\n0\n,\n1\n}\nK\n‚èü\nsparse vector for WET\n√ó\n{\n0\n,\n1\n}\nK\n‚èü\nsparse vector for data collection\n,\n\\mathcal{A}=\\underbrace{\\mathbb{D}^{1}}_{\\text{direction}}\\times\\underbrace{\\{0,1\\}^{K}}_{\\text{sparse vector for WET}}\\times\\underbrace{\\{0,1\\}^{K}}_{\\text{sparse vector for data collection}},\n(17)\nwhere\nùîª\n\\mathbb{D}\nis the direction of movement that can be right, left, up, down, forward, or backward. In this approach, the AUV uses different bands (i.e., central frequencies) for AET and information uplink via two separate antennas, which allows simultaneous operation with different devices.\nSecond Approach: 2D Action Space (TDD)\nTo simplify decision-making and reduce computational and hardware demands, TDD reduces the action space to two decisions. The AUV selects a direction for movement and selects the same node for both AET and information uplink, with a portion of the time\nŒ≤\n‚Äã\nœÑ\n\\beta\\tau\ndedicated to charging and\n(\n1\n‚àí\nŒ≤\n)\n‚Äã\nœÑ\n(1-\\beta)\\tau\nto data collection. Thus, the TDD action space is defined as:\nùíú\n=\nùîª\n1\n‚èü\ndirection\n√ó\n{\n0\n,\n1\n}\nK\n‚èü\nsparse vector for node selection\n,\n\\mathcal{A}=\\underbrace{\\mathbb{D}^{1}}_{\\text{direction}}\\times\\underbrace{\\{0,1\\}^{K}}_{\\text{sparse vector for node selection}},\n(18)\nRemark 2\n.\nThe action space components were chosen to allow the agent to balance AoI reduction, energy replenishment, and efficient navigation. By independently selecting nodes for WET (\nW\n‚Äã\n(\nt\n)\nW(t)\n) and data collection (\nI\n‚Äã\n(\nt\n)\nI(t)\n) in the FDD approach, or combining them into a single node decision in the TDD approach, the framework enables efficient decision-making while accounting for the trade-offs between performance and complexity. Reducing the dimensionality of the action space in the FDD approach simplifies decision-making but compromises performance, as the agent loses the ability to independently optimize WET and data collection.\nwhere the sparse vector indicates the IoUT device selected for both AET and information, with the\nk\nk\n-th position in the vector being 1 if node\nk\nk\nis selected. In that case,\nw\nk\n‚Äã\n(\nt\n)\n=\ni\nk\n‚Äã\n(\nt\n)\n=\n1\nw_{k}(t)=i_{k}(t)=1\n.\nIV-A\n3\nTransition probability\nThe transition between states relies on the 3 components of the state space and the components of the action space. The AoI is updated as follows\nA\nk\n‚Äã\n(\nt\n+\n1\n)\n=\n{\n1\n,\nif\ni\nk\n‚Äã\n(\nt\n+\n1\n)\n=\n1\n,\nA\nk\n‚Äã\n(\nt\n)\n+\n1\n,\notherwise\n,\nA_{k}(t+1)=\\begin{cases}1,&\\quad\\text{if $i_{k}(t+1)=1$ },\\\\\nA_{k}(t)+1,&\\quad\\text{otherwise},\\end{cases}\n(19)\nwhere\ni\nk\n‚Äã\n(\nt\n+\n1\n)\ni_{k}(t+1)\nis the element of the sparse vector\nI\n‚Äã\n(\nt\n+\n1\n)\nI(t+1)\n.\nThe position of the AUV\nl\nauv\n‚Äã\n(\nt\n)\nl_{\\text{auv}}(t)\nis updated according to the selected action\nd\n‚Äã\n(\nt\n)\nd(t)\nl\nauv\n‚Äã\n(\nt\n+\n1\n)\n=\n{\nl\nauv\n‚Äã\n(\nt\n)\n+\n(\nd\ng\n,\n0\n,\n0\n)\n,\nd\n‚Äã\n(\nt\n)\n=\nright\n,\nl\nauv\n‚Äã\n(\nt\n)\n‚àí\n(\nd\ng\n,\n0\n,\n0\n)\n,\nd\n‚Äã\n(\nt\n)\n=\nleft\n,\nl\nauv\n‚Äã\n(\nt\n)\n+\n(\n0\n,\nd\ng\n,\n0\n)\n,\nd\n‚Äã\n(\nt\n)\n=\nup\n,\nl\nauv\n‚Äã\n(\nt\n)\n‚àí\n(\n0\n,\nd\ng\n,\n0\n)\n,\nd\n‚Äã\n(\nt\n)\n=\ndown\n,\nl\nauv\n‚Äã\n(\nt\n)\n+\n(\n0\n,\n0\n,\nd\ng\n)\n,\nd\n‚Äã\n(\nt\n)\n=\nforward\n,\nl\nauv\n‚Äã\n(\nt\n)\n‚àí\n(\n0\n,\n0\n,\nd\ng\n)\n,\nd\n‚Äã\n(\nt\n)\n=\nbackward\n,\nl_{\\text{auv}}(t+1)=\\begin{cases}l_{\\text{auv}}(t)+(d_{g},0,0),&\\quad d(t)=\\text{right},\\\\\nl_{\\text{auv}}(t)-(d_{g},0,0),&\\quad d(t)=\\text{left},\\\\\nl_{\\text{auv}}(t)+(0,d_{g},0),&\\quad d(t)=\\text{up},\\\\\nl_{\\text{auv}}(t)-(0,d_{g},0),&\\quad d(t)=\\text{down},\\\\\nl_{\\text{auv}}(t)+(0,0,d_{g}),&\\quad d(t)=\\text{forward},\\\\\nl_{\\text{auv}}(t)-(0,0,d_{g}),&\\quad d(t)=\\text{backward},\\\\\n\\end{cases}\n(20)\nwhere\nd\ng\nd_{g}\nis the unit distance between two squares in the grid.\nAs for the energy stored at each node, the update in a node\nk\nk\nis as follows\nùìî\nk\n‚Äã\n(\nt\n+\n1\n)\n=\n{\nùìî\nk\n‚Äã\n(\nt\n)\n+\ne\nr\n‚Äã\n(\nt\n)\n‚àí\ne\nc\n‚Äã\n(\nt\n)\n,\nif\nw\nk\n‚Äã\n(\nt\n+\n1\n)\n=\ni\nk\n‚Äã\n(\nt\n+\n1\n)\n=\n1\n,\nùìî\nk\n‚Äã\n(\nt\n)\n+\ne\nr\n‚Äã\n(\nt\n)\n,\nif only\n‚Äã\nw\nk\n‚Äã\n(\nt\n+\n1\n)\n=\n1\n,\nùìî\nk\n‚Äã\n(\nt\n)\n‚àí\ne\nc\n‚Äã\n(\nt\n)\n,\nif only\n‚Äã\ni\nk\n‚Äã\n(\nt\n+\n1\n)\n=\n1\n,\nùìî\nk\n‚Äã\n(\nt\n)\n,\notherwise\n,\n\\boldsymbol{\\mathcal{E}}_{k}(t+1)\\!=\\!\\begin{cases}\\boldsymbol{\\mathcal{E}}_{k}(t)+e_{r}(t)-e_{c}(t),&\\begin{aligned} \\text{if }&w_{k}(t+1)=\\\\\n&i_{k}(t+1)=1,\\end{aligned}\\\\\n\\boldsymbol{\\mathcal{E}}_{k}(t)+e_{r}(t),&\\text{if only }w_{k}(t+1)=1,\\\\\n\\boldsymbol{\\mathcal{E}}_{k}(t)-e_{c}(t),&\\text{if only }i_{k}(t+1)=1,\\\\\n\\boldsymbol{\\mathcal{E}}_{k}(t),&\\text{otherwise},\\end{cases}\n(21)\nwhere\ne\nr\n‚Äã\n(\nt\n)\ne_{r}(t)\nis the energy received by the node from the AUV at time slot\nt\nt\nand\ne\nc\n‚Äã\n(\nt\n)\ne_{c}(t)\nis the energy consumed for transmission of the data.\nIV-A\n4\nReward function\nThe reward system is defined to minimize the weighted sum of the AoI for all IoUT devices and to maximize Jain‚Äôs fairness index. For mathematical convenience, we consider the discrimination index instead of the fairness that is defined in (\n15\n)\nùíü\nT\n=\n1\n‚àí\nùí•\nT\n=\n1\n‚àí\n(\n‚àë\nk\n=\n1\nK\nD\nT\n‚Äã\n(\nk\n)\n)\n2\nK\n‚Äã\n‚àë\nk\n=\n1\nK\nD\nT\n‚Äã\n(\nk\n)\n2\n.\n\\mathscr{D}_{T}=1-\\mathcal{J}_{T}=1-\\frac{\\left(\\sum_{k=1}^{K}D_{T}(k)\\right)^{2}}{K\\sum_{k=1}^{K}D_{T}(k)^{2}}.\n(22)\nHerein, maximizing Jain‚Äôs fairness index is equivalent to minimizing Jain‚Äôs discrimination index.\nWe define the immediate reward\nr\nu\nr_{u}\nfor the AUV at time instant\nt\nt\nas\nr\nu\n‚Äã\n(\nt\n)\n=\n‚àí\n(\nùíü\nt\nK\n‚Äã\n‚àë\nk\n=\n1\nK\nŒ¥\nk\n‚Äã\nA\nk\n‚Äã\n(\nt\n)\n+\nœÅ\n‚Äã\n(\nt\n)\n)\n,\nr_{u}(t)=-\\left(\\frac{\\mathscr{D}_{t}}{K}\\sum_{k=1}^{K}\\delta_{k}A_{k}(t)+\\rho(t)\\right),\n(23)\nwith\nœÅ\n‚Äã\n(\nt\n)\n\\rho(t)\nbeing the penalty term that varies based on the action space as follows\nœÅ\n‚Äã\n(\nt\n)\n=\nœÅ\nlocation\n‚Äã\n(\nt\n)\n+\nœÅ\ninformation\n‚Äã\n(\nt\n)\n+\nœÅ\noccurrence\n‚Äã\n(\nt\n)\n,\n\\rho(t)=\\rho_{\\text{location}}(t)+\\rho_{\\text{information}}(t)+\\rho_{\\text{occurrence}}(t),\n(24)\nwhere\nœÅ\nlocation\n‚Äã\n(\nt\n)\n\\rho_{\\text{location}}(t)\nis a penalty applied if the AUV is outside the designated set of valid locations\nùí≥\n\\mathcal{X}\n. It is defined as\nœÅ\nlocation\n‚Äã\n(\nt\n)\n=\n{\nœÅ\nloc\n,\nif\n‚Äã\nl\nauv\n‚Äã\n(\nt\n)\n‚àâ\nùí≥\n,\n0\n,\notherwise\n.\n\\rho_{\\text{location}}(t)=\\begin{cases}\\rho_{\\text{loc}},&\\text{if }l_{\\text{auv}}(t)\\notin\\mathcal{X},\\\\\n0,&\\text{otherwise}.\\end{cases}\n(25)\nœÅ\noccurrence\n‚Äã\n(\nt\n)\n\\rho_{\\text{occurrence}}(t)\nis applied to avoid a scenario where a specific node\nk\nk\ncommunicates with the AUV more frequently than others. The number of times node\nk\nk\nhas been selected to transmit information to the AUV by timeslot\nt\nt\nis denoted by\nùí™\n‚Äã\nùíû\n‚Äã\nùíû\n‚Äã\n(\nk\n,\nt\n)\n\\mathcal{OCC}(k,t)\n. The penalty is incurred if, at timeslot\nt\nt\n, the occurrence\nùí™\n‚Äã\nùíû\n‚Äã\nùíû\n‚Äã\n(\nk\n,\nt\n)\n\\mathcal{OCC}(k,t)\nis higher than the average communication time per node. Since\nT\nT\nis the total navigation time of the AUV,\nT\nK\n\\frac{T}{K}\nrepresents the ideal number of times each node would send data to the AUV if all nodes were selected equally. The penalty is defined as\nœÅ\noccurrence\n‚Äã\n(\nt\n)\n=\n{\nœÅ\nocc\n,\nif\n‚Äã\nùí™\n‚Äã\nùíû\n‚Äã\nùíû\n‚Äã\n(\nk\n,\nt\n)\n>\nT\nK\n,\n0\n,\notherwise\n.\n\\rho_{\\text{occurrence}}(t)=\\begin{cases}\\rho_{\\text{occ}},&\\text{if }\\mathcal{OCC}(k,t)>\\frac{T}{K},\\\\\n0,&\\text{otherwise}.\\end{cases}\n(26)\nThe penalty terms\nœÅ\nlocation\n‚Äã\n(\nt\n)\n\\rho_{\\text{location}}(t)\nand\nœÅ\noccurrence\n‚Äã\n(\nt\n)\n\\rho_{\\text{occurrence}}(t)\nare the same for both FDD and TDD.\nPenalty Term\nœÅ\ninformation\n‚Äã\n(\nt\n)\n\\rho_{\\text{information}}(t)\nfor 3D Action Space (FDD)\nThis penalty is incurred when either no node is available to transmit data or the AUV makes an incorrect selection of a node for data collection. Let\n‚Ñê\n‚Äã\n(\nt\n)\n\\mathcal{I}(t)\ndenote the indices of the nodes that have sufficient energy to transmit data at timeslot\nt\nt\n. The penalty is defined as:\nœÅ\ninformation\n‚Äã\n(\nt\n)\n=\n{\nœÅ\nno_indices\n,\nif\n‚Äã\n‚Ñê\n‚Äã\n(\nt\n)\n=\n‚àÖ\n,\nœÅ\nwrong_indice\n,\nif\n‚Äã\nk\n‚àâ\n‚Ñê\n‚Äã\n(\nt\n)\n‚Äã\nand\n‚Äã\n‚Ñê\n‚Äã\n(\nt\n)\n‚â†\n‚àÖ\n,\n0\n,\notherwise\n.\n\\rho_{\\text{information}}(t)=\\begin{cases}\\rho_{\\text{no\\_indices}},&\\text{if }\\mathcal{I}(t)=\\varnothing,\\\\\n\\rho_{\\text{wrong\\_indice}},&\\text{if}\\ k\\notin\\mathcal{I}(t)\\text{ and }\\mathcal{I}(t)\\neq\\varnothing,\\\\\n0,&\\text{otherwise}.\\end{cases}\n(27)\nIf no nodes have sufficient energy to transmit data (\n‚Ñê\n‚Äã\n(\nt\n)\n=\n‚àÖ\n\\mathcal{I}(t)=\\varnothing\n), a penalty\nœÅ\nno_indices\n\\rho_{\\text{no\\_indices}}\nis applied. If there exist nodes with sufficient energy (\n‚Ñê\n‚Äã\n(\nt\n)\n‚â†\n‚àÖ\n\\mathcal{I}(t)\\neq\\varnothing\n), but the AUV selects a node that lacks energy for transmission, a penalty\nœÅ\nwrong_indice\n\\rho_{\\text{wrong\\_indice}}\nis applied.\nPenalty Term\nœÅ\ninformation\n‚Äã\n(\nt\n)\n\\rho_{\\text{information}}(t)\nfor 2D Action Space (TDD)\nThis penalty is introduced to account for situations where simultaneous AET and information uplink do not occur. That is, when the AUV is either only charging (i.e., IoUT node does not have enough energy to transmit data) or only collecting data (IoUT node has sufficient energy to transmit data without getting charged), rather than doing both. The penalty term is defined as\nœÅ\ninformation\n‚Äã\n(\nt\n)\n=\n{\nœÅ\nonly_charging\n,\nif\n‚Äã\nŒ≤\n=\n1\n,\nœÅ\nonly_transmitting\n,\nif\n‚Äã\nŒ≤\n=\n0\n,\n0\n,\notherwise\n.\n\\rho_{\\text{information}}(t)=\\begin{cases}\\rho_{\\text{only\\_charging}},&\\text{if }\\beta=1,\\\\\n\\rho_{\\text{only\\_transmitting}},&\\text{if }\\beta=0,\\\\\n0,&\\text{otherwise}.\\end{cases}\n(28)\nIV-B\nDRL Solution: Proximal Policy Optimization\nProximal Policy Optimization (PPO) is a mix of two methods: a gradient-based policy that aims to maximize the reward through gradient descent and an actor-critic approach frequently utilized in RL. PPO stands out for its insensitivity to perturbations, a trait it addresses by constraining updates to the neural network. This is achieved by performing updates based on the ratio of the probability of the new policy to the old one. Additionally, PPO considers an advantage function to evaluate the value of each state\n[\n24\n]\n. By prioritizing profitable states while controlling the loss function, PPO employs techniques like clipping and setting a lower bound using a minimum function. One distinguishing feature of PPO is its approach to memory management. Instead of storing and sampling from millions of transitions randomly, PPO maintains a fixed-length trajectory of memories, simplifying the process.\nThe actor is responsible for the actions of the agent based on a learned policy that aims to minimize the clipped loss function defined as\n[\n24\n]\nL\nC\n‚Äã\nL\n‚Äã\nI\n‚Äã\nP\n‚Äã\n(\nŒ∏\n)\n=\nùîº\n^\nt\n‚Äã\n[\nmin\n‚Å°\n(\nr\nt\n‚Äã\n(\nŒ∏\n)\n‚Äã\nA\n^\nt\n,\nclip\n‚Å°\n(\nr\nt\n‚Äã\n(\nŒ∏\n)\n,\n1\n‚àí\nœµ\n,\n1\n+\nœµ\n)\n‚Äã\nA\n^\nt\n)\n]\n,\nL^{CLIP}(\\theta)\\!=\\!\\hat{\\mathbb{E}}_{t}\\left[\\min\\left(r_{t}(\\theta)\\hat{A}_{t},\\operatorname{clip}\\left(r_{t}(\\theta),1\\!-\\!\\epsilon,1+\\epsilon\\right)\\!\\hat{A}_{t}\\!\\right)\\right],\n(29)\nwhere\nr\nt\n‚Äã\n(\nŒ∏\n)\nr_{t}(\\theta)\ndenotes the probability ratio\nr\nt\n‚Äã\n(\nŒ∏\n)\n=\nœÄ\nŒ∏\n‚Äã\n(\na\nt\n‚à£\ns\nt\n)\nœÄ\nŒ∏\nold\n‚Äã\n(\na\nt\n‚à£\ns\nt\n)\nr_{t}(\\theta)=\\frac{\\pi_{\\theta}\\left(a_{t}\\mid s_{t}\\right)}{\\pi_{\\theta_{\\text{old }}}\\left(a_{t}\\mid s_{t}\\right)}\n. Herein,\nœÄ\nŒ∏\n‚Äã\n(\na\nt\n|\ns\nt\n)\n\\pi_{\\theta}(a_{t}|s_{t})\nis the new policy‚Äôs probability of taking action\na\nt\na_{t}\nin state\ns\nt\ns_{t}\n, and\nœÄ\nŒ∏\nold\n‚Äã\n(\na\nt\n|\ns\nt\n)\n\\pi_{\\theta_{\\text{old}}}(a_{t}|s_{t})\nis the old policy‚Äôs probability of taking action\na\nt\na_{t}\nin state\ns\nt\ns_{t}\n. The term\nclip\n‚Å°\n(\nr\nt\n‚Äã\n(\nŒ∏\n)\n,\n1\n‚àí\nœµ\n,\n1\n+\nœµ\n)\n\\operatorname{clip}(r_{t}(\\theta),1-\\epsilon,1+\\epsilon)\nis used to clip the ratio\nr\nt\n‚Äã\n(\nŒ∏\n)\nr_{t}(\\theta)\nbetween the lower and upper bounds of\n1\n‚àí\nœµ\n1-\\epsilon\nand\n1\n+\nœµ\n1+\\epsilon\n, respectively. The hyperparameter\nœµ\n\\epsilon\ndetermines the extent of the clipping, and\nœµ\n‚âà\n0.2\n\\epsilon\\approx 0.2\nis the most common value selected in the literature.\nThe objective is to maximize the clipped advantage function, which is a surrogate for the true advantage function\nA\n^\nt\n\\hat{A}_{t}\n. The advantage function is defined as\nA\n^\nt\n=\n‚àí\nV\n‚Äã\n(\ns\nt\n)\n+\nr\nu\n‚Äã\n(\nt\n)\n+\nŒ≥\n‚Äã\nr\nu\n‚Äã\n(\nt\n+\n1\n)\n+\n‚ãØ\n+\nŒ≥\nT\n‚àí\nt\n+\n1\n‚Äã\nr\nu\n‚Äã\n(\nT\n‚àí\n1\n)\n+\nŒ≥\nT\n‚àí\nt\n‚Äã\nV\n‚Äã\n(\ns\nT\n)\n\\hat{A}_{t}=-V(s_{t})+r_{u}(t)+\\gamma r_{u}(t+1)+\\cdots\\\\\n+\\gamma^{T-t+1}r_{u}(T-1)+\\gamma^{T-t}V(s_{T})\n(30)\nwhere\nŒ≥\n\\gamma\nis the discount factor that determines the weight of future rewards,\nV\n‚Äã\n(\ns\nt\n)\nV(s_{t})\nis the state value function at state\ns\nt\ns_{t}\n, representing the expected return starting from state\ns\nt\ns_{t}\n.\nr\nu\n‚Äã\n(\nt\n)\nr_{u}(t)\nis the reward received at time step\nt\nt\n,\nT\nT\nis the final time step in the episode, and\ns\nT\ns_{T}\nis the state at the final time step\nT\nT\n. The Total loss is expressed as\nL\nt\n‚Äã\no\n‚Äã\nt\n‚Äã\na\n‚Äã\nl\n‚Äã\n(\nŒ∏\n)\n=\nùîº\n^\nt\n‚Äã\n[\nL\nt\nC\n‚Äã\nL\n‚Äã\nI\n‚Äã\nP\n‚Äã\n(\nŒ∏\n)\n‚àí\nc\n1\n‚Äã\nL\nt\nV\n‚Äã\nF\n‚Äã\n(\nŒ∏\n)\n+\nc\n2\n‚Äã\nS\n‚Äã\n[\nœÄ\nŒ∏\n]\n‚Äã\n(\ns\nt\n)\n]\nL_{total}(\\theta)=\\hat{\\mathbb{E}}_{t}\\left[L_{t}^{CLIP}(\\theta)-c_{1}L_{t}^{VF}(\\theta)+c_{2}S\\left[\\pi_{\\theta}\\right]\\left(s_{t}\\right)\\right]\n(31)\nwhere\nc\n1\n,\nc\n2\nc_{1},c_{2}\nare coefficients used for exploitation and exploration respectively, and\nS\nS\ndenotes an entropy bonus, and\nL\nt\nV\n‚Äã\nF\nL_{t}^{VF}\nis a squared-error loss\n(\nV\nŒ∏\n‚Äã\n(\ns\nt\n)\n‚àí\nV\nt\ntarg\n)\n2\n\\left(V_{\\theta}\\left(s_{t}\\right)-V_{t}^{\\mathrm{targ}}\\right)^{2}\n. Algorithm 1 illustrates the PPO approach for both TDD and FDD\n3\n3\n3\nFor simplicity, we present the two algorithms combined here. However, it is important to note that each algorithm is fundamentally different from the other. The key distinction lies in their action spaces, resulting in differing dimensions. Furthermore, each algorithm has its own set of penalty terms and requires separate hyperparameter tuning ( such as discount factor\nŒ≥\n\\gamma\nand learning rate\nŒ±\n\\alpha\n) to achieve optimal performance.\n.\nInput:\nEnvironment with locations of IoUT nodes\nc\nk\nc_{k}\n, AUV starting position\nl\na\n‚Äã\nu\n‚Äã\nv\n‚Äã\n(\n0\n)\nl_{auv}(0)\n, AoI for all nodes\nùë®\n‚Äã\n(\n0\n)\n\\boldsymbol{A}(0)\n, other parameters (i.e, operating frequencies, etc..)\n.\nOutput:\nTrained PPO agent\n1\nInitialization:\n2\nInitialize PPO agent\nœÄ\nŒ∏\n\\pi_{\\theta}\n, value network\nV\nŒ∏\nV_{\\theta}\n3\nSet training parameters:\nm\n‚Äã\na\n‚Äã\nx\n‚Äã\n_\n‚Äã\ne\n‚Äã\np\n‚Äã\ni\n‚Äã\ns\n‚Äã\no\n‚Äã\nd\n‚Äã\ne\n‚Äã\ns\nmax\\_episodes\n,\nm\n‚Äã\na\n‚Äã\nx\n‚Äã\n_\n‚Äã\ni\n‚Äã\nt\n‚Äã\ne\n‚Äã\nr\n‚Äã\na\n‚Äã\nt\n‚Äã\ni\n‚Äã\no\n‚Äã\nn\n‚Äã\ns\nmax\\_iterations\n‚Ä¶,\n4\n5\nProcedure of Training:\n6\nfor\neach episode\ni\n=\n1\ni=1\nto\nm\n‚Äã\na\n‚Äã\nx\n‚Äã\n_\n‚Äã\ne\n‚Äã\np\n‚Äã\ni\n‚Äã\ns\n‚Äã\no\n‚Äã\nd\n‚Äã\ne\n‚Äã\ns\nmax\\_episodes\ndo\n7\nt\n‚Üê\n0\nt\\leftarrow 0\n8\nReset environment:\nl\na\n‚Äã\nu\n‚Äã\nv\nl_{auv}\n,\nùë®\n‚Äã\n(\nt\n)\n\\boldsymbol{A}(t)\n,\nùìî\n‚Äã\n(\nt\n)\n\\boldsymbol{\\mathcal{E}}(t)\nand set\nm\n‚Äã\na\n‚Äã\nx\n‚Äã\n_\n‚Äã\ni\n‚Äã\nt\n‚Äã\ne\n‚Äã\nr\n‚Äã\na\n‚Äã\nt\n‚Äã\ni\n‚Äã\no\n‚Äã\nn\n‚Äã\ns\nmax\\_iterations\n9\nInitialize cumulative reward\nR\n‚Üê\n0\nR\\leftarrow 0\n10\nwhile\nm\n‚Äã\na\n‚Äã\nx\n‚Äã\n_\n‚Äã\ni\n‚Äã\nt\n‚Äã\ne\n‚Äã\nr\n‚Äã\na\n‚Äã\nt\n‚Äã\ni\n‚Äã\no\n‚Äã\nn\n‚Äã\ns\n>\n0\nmax\\_iterations>0\ndo\n11\nt\n‚Üê\nt\n+\n1\nt\\leftarrow t+1\n12\nm\n‚Äã\na\n‚Äã\nx\n‚Äã\n_\n‚Äã\ni\n‚Äã\nt\n‚Äã\ne\n‚Äã\nr\n‚Äã\na\n‚Äã\nt\n‚Äã\ni\n‚Äã\no\n‚Äã\nn\n‚Äã\ns\n‚Üê\nm\n‚Äã\na\n‚Äã\nx\n‚Äã\n_\n‚Äã\ni\n‚Äã\nt\n‚Äã\ne\n‚Äã\nr\n‚Äã\na\n‚Äã\nt\n‚Äã\ni\n‚Äã\no\n‚Äã\nn\n‚Äã\ns\n‚àí\n1\nmax\\_iterations\\leftarrow max\\_iterations-1\n13\nAction Selection:\n14\nObserve state\ns\n‚Äã\n(\nt\n)\ns(t)\n15\nif\nTDD\nthen\n16\nSample action\na\nt\n=\n{\nd\n‚Äã\n(\nt\n)\n,\nI\n‚Äã\n(\nt\n)\n=\nW\n‚Äã\n(\nt\n)\n}\na_{t}=\\left\\{d(t),I(t)=W(t)\\right\\}\n17\n18\nelse\n19\nSample action\na\nt\n=\n{\nd\n‚Äã\n(\nt\n)\n,\nI\n‚Äã\n(\nt\n)\n,\nW\n‚Äã\n(\nt\n)\n}\na_{t}=\\left\\{d(t),I(t),W(t)\\right\\}\n20\n21\nend if\n22\nEnvironment Interaction:\n23\nMove AUV according to the direction from\na\nœÑ\na_{\\tau}\n.\n24\nCompute harvested energy and update AoI for\n25\nthe selected node(s) using (\n20\n),(\n19\n),(\n21\n).\n26\n27\nReward Calculation:\n28\nCompute discrimination index using (\n22\n).\n29\nCompute reward\nr\nu\n‚Äã\n(\nt\n)\nr_{u}(t)\nand penalize unfair AoI distribution and wasted energy according to the mode selected (FDD or TDD) using equations (\n23\n), (\n25\n), (\n26\n), (\n27\n), and (\n28\n).\n30\n31\nLearning:\n32\nStore\n(\ns\nt\n,\na\nt\n,\nr\nt\n,\ns\nt\n+\n1\n)\n(s_{t},a_{t},r_{t},s_{t+1})\nin buffer\n33\nif\nbuffer full\nthen\n34\nUpdate PPO policy\nœÄ\nŒ∏\n\\pi_{\\theta}\nand value function\n35\nV\nŒ∏\nV_{\\theta}\n.\n36\nend if\n37\nUpdate cumulative reward\n38\n39\nend while\n40\n41\nend for\n42\nProcedure of Testing:\n43\nLoad trained policy\nœÄ\nŒ∏\n\\pi_{\\theta}\nand evaluate on the test\n44\nenvironment.\n45\nSimulate AUV operation and measure cumulative\nreward, fairness, AoI reduction.\nAlgorithm¬†1\nPPO for TDD and FDD\nV\nNumerical Results\nWe begin by outlining the assumptions and system configuration of our simulations, including the environment parameters and grid world setup. The problem is addressed using the PPO algorithm to evaluate the performance of both 3D-FDD and 2D-TDD approaches. We compare the results obtained from the proposed RL approaches with benchmark methods, such as RW, RR, and GA, to highlight the improvements and effectiveness of the proposed solutions.\nV-\n1\nSimulation parameters\nIn this study, we assumed a 3D grid for our simulations to better represent real-world underwater environments, which often involve a vertical dimension critical to communication and navigation. This choice adds complexity compared to the commonly used 2D grids, making the simulations more realistic. The grid size is set to\n1000\n‚Äã\nm\n√ó\n1000\n‚Äã\nm\n√ó\n400\n‚Äã\nm\n1000\\,\\text{m}\\times 1000\\,\\text{m}\\times 400\\,\\text{m}\n, reflecting a reasonable approximation.It is discretized by a cell size of\n100\n100\nm, resulting in 400 unique geometric positions. The AUV begins at the center of this grid and communicates with K sensor nodes, where K\n‚àà\n{\n3\n,\n5\n,\n7\n,\n10\n}\n\\in\\{3,5,7,10\\}\n.\nThe main simulation parameters are depicted in Table\nI\n.\nV-\n2\nAlgorithm architecture and hyperparameter settings\nFor training, we employed the PPO algorithm inspired by the one implemented in the Stable Baselines3 library. The neural network architecture consists of two fully connected layers with 64 neurons each, using Tanh activation functions.\nTo ensure consistency across varying network sizes (K\n‚àà\n{\n3\n,\n5\n,\n7\n,\n10\n}\n\\in\\{3,5,7,10\\}\n), we tuned the hyperparameters using grid search. Our goal was to identify a single set of hyperparameters for both algorithms (3D-FDD and 2D-TDD). The selected hyperparameters are summarized in Table\nII\n.\nAs illustrated in Algorithm 1, both techniques (TDD and FDD) share a similar RL environment in terms of the state space. However, they differ in the action space and reward function, as defined in equations (\n18\n),(\n17\n),(\n28\n) and (\n27\n). This distinction in the action space allows the agent to choose different actions (i.e., direction and node selection) depending on the duplexing technique adopted. The reward function is also adjusted accordingly to reflect the differences in energy transfer and AoI optimization.\nTABLE I:\nThe Simulation Parameters\nParameter\nValue\nNetwork size\n1000\n‚Äã\nm\n√ó\n1000\n‚Äã\nm\n√ó\n400\n‚Äã\nm\n1000\\,\\text{m}\\times 1000\\,\\text{m}\\times 400\\,\\text{m}\nElectrical power (\nP\nelec\nP_{\\text{elec}}\n)\n2000\n‚Äã\nWatts\n2000\\,\\text{Watts}\nFDD Mode Frequency:\nInf transmission:\n30\n‚Äã\nkHz\n30\\,\\text{kHz}\nEnergy harvesting:\n40\n‚Äã\nkHz\n40\\,\\text{kHz}\nTDD Mode Frequency:\n40\n‚Äã\nkHz\n40\\,\\text{kHz}\nElect-acoustic coefficient (\nŒ∑\n\\eta\n)\n0.5\n0.5\nDirectivity index\n(\nD\n‚Äã\nI\n)\n(DI)\n20\n‚Äã\ndB\n20\\,\\text{dB}\nSensitivity\n(\nR\n‚Äã\nV\n‚Äã\nS\n)\n(RVS)\n‚àí\n150\n‚Äã\ndB re V\n/\nŒº\n‚Äã\nPa\n-150\\,\\text{dB re V}/\\mu\\text{Pa}\nSpeed of AUV\n(\nV\n)\n(V)\n4\n‚Äã\nm/s\n4\\,\\text{m/s}\nSpreading factor (\nk\ns\nk_{s}\n)\n1.5\n1.5\nResistance\n(\nR\n‚Äã\np\n)\n(R\\textsubscript{p})\n125\n‚Äã\nŒ©\n125\\,\\Omega\nPacket size\n(\nL\n‚Äã\nt\n)\n(L\\textsubscript{t})\n100\n‚Äã\nbytes\n100\\,\\text{bytes}\nBandwidth\n(\nB\n)\n(B)\n3000\n‚Äã\nHz\n3000\\,\\text{Hz}\nTotal navigation time\n(\nT\n)\n(T)\n2500\n‚Äã\ns\n2500\\,\\text{s}\nNoise power\n(\nN\n‚Äã\nL\n)\n(NL)\n30\n‚Äã\ndB\n30\\,\\text{dB}\nMinimum Fairness (\nJ\nTmin\nJ_{\\text{Tmin}}\n)\n0.85\n0.85\nMaximum Age (\nA\nmax\nA_{\\text{max}}\n)\n50\n50\nTABLE II:\nHyperparameter settings for 2D-TDD and 3D-FDD\nHyperparameter\n2D-TDD\n3D-FDD\nDiscount factor (\nŒ≥\n\\gamma\n)\n0.93\n0.92\nLearning rate (\nŒ±\n\\alpha\n)\n0.0003\n0.0005\nEntropy coefficient (\nc\n2\n)\nc_{2})\n0.01\n0.01\nBatch size\n100\n100\nSteps per update (\nn\n‚Äã\n_\n‚Äã\ns\n‚Äã\nt\n‚Äã\ne\n‚Äã\np\n‚Äã\ns\nn\\_steps\n)\n100\n100\nV-\n3\nTDD mode configuration\nIn Fig.\n4\n, we analyze the TDD energy dynamics in the underwater communication system by examining the energy harvested and the energy required for information transmission across different values of\nŒ≤\n\\beta\nat a frequency of 40 KHz. The plot demonstrates that for\nŒ≤\n=\n0.1\n\\beta=0.1\n, the energy harvested is the lowest, as only a small portion of time is dedicated to energy harvesting. This configuration may lead to challenges in maintaining efficient long-distance transmission due to insufficient energy harvesting. As\nŒ≤\n\\beta\nincreases to 0.5 and 0.9, the energy harvested significantly rises, highlighting the direct impact of\nŒ≤\n\\beta\non energy allocation. In these scenarios, more time is dedicated to energy harvesting, allowing the AUV to sustain longer energy transmission effectively. Notably, the energy needed for transmission remains relatively unaffected by variations in\nŒ≤\n\\beta\n. The observation that\nE\ntrans\nE_{\\text{trans}}\nremains almost constant across different values of\nŒ≤\n\\beta\nis further explained in Appendix\nA\n.\nFigure 4:\nEnergy harvested and information uplink for different Values of\nŒ≤\n\\beta\nand for frequency\nf\n=\n40\nf=40\nKHz.\nEfficient simultaneous AET and information uplink operation is achieved when the energy harvested surpasses the energy required for transmission (i.e., the intersection points in Fig.\n4\n). This critical condition is more likely to occur when\nŒ≤\n\\beta\nis higher, and the distance between the AUV and the IoUT node is short. To further explore the optimization of\nŒ≤\n\\beta\n, Fig.\n5\npresents the relationship between\nŒ≤\n‚àó\n\\beta^{*}\nand the distance\nd\n‚àó\nd^{*}\nfor various communication frequencies which are the values of\nŒ≤\n\\beta\nand\nd\nd\nthat achieves the intersection in the Fig.\n4\n. Here, we observe that\nŒ≤\n‚àó\n\\beta^{*}\nvalues ranging from 0 to 1 are achieved over shorter distances as the communication frequency increases. For instance, at higher frequencies such as 60 KHz,\nŒ≤\n‚àó\n\\beta^{*}\nquickly approaches its maximum value, reflecting a rapid signal attenuation requiring more charging time for reliable signal transmission.\nFigure 5:\nPlot of\nŒ≤\n‚àó\n\\beta^{*}\nas a function of\nd\n‚àó\nd^{*}\nfor different frequencies\nConversely, for lower frequencies, such as 10 KHz,\nŒ≤\n‚àó\n\\beta^{*}\nincreases slowly with distance, supporting long-range AET and information uplink. This observation aligns with the goal of achieving a balanced configuration that supports both data transmission and energy harvesting, highlighting why a frequency of 40 KHz was selected in our next simulations. This medium frequency enables a practical compromise, optimizing the trajectory of the AUV by extending the range and reducing antenna size while maintaining adequate bandwidth for data and energy transfer.\nHerein, we choose to restrict\nŒ≤\n\\beta\nbetween 0.1 and 0.9 because practically, if the splitting factor is less than 0.1 (i.e., indicating that the charging time is less than 10%), there will not be enough time for AET, and only information uplink occurs. Conversely, if the splitting factor exceeds 0.9 (\nŒ≤\n>\n0.9\n\\beta>0.9\n), only charging occurs, with insufficient time for information uplink. In addition to the observations from Fig.\n5\n, we provide a rigorous mathematical treatment of how\nŒ≤\n\\beta\nis directly related to the distance\nd\nd\nthrough an inequality. This is required for simultaneous AET and information uplink to occur, ensuring that energy harvesting is sufficient for data transmission. The relationship between\nŒ≤\n\\beta\nand\nd\nd\nis formalized in Appendix\nB\n, where we analyze the sufficient condition\nE\nh\n‚Äã\na\n‚Äã\nr\n‚Äã\nv\n‚â•\nE\nr\n‚Äã\ne\n‚Äã\nq\n,\nk\n,\nE_{harv}\\geq E_{req,k},\n(32)\nwhich leads to\ng\n‚Äã\n(\nŒ≤\n)\n‚â•\nh\n‚Äã\n(\nd\n)\n,\ng(\\beta)\\geq h(d),\n(33)\nwhere\ng\n‚Äã\n(\nŒ≤\n)\ng(\\beta)\nand\nh\n‚Äã\n(\nd\n)\nh(d)\nare derived from energy harvesting and transmission models, as detailed in Appendix\nB\n.\nBy proving the function\ng\n‚Äã\n(\nŒ≤\n)\ng(\\beta)\nis bijective within the interval\nŒ≤\n1\n<\nŒ≤\n<\nŒ≤\n2\n\\beta_{1}<\\beta<\\beta_{2}\n, where\nŒ≤\n1\n\\beta_{1}\nis close to 0 and\nŒ≤\n2\n\\beta_{2}\nis close to 1 as shown in Appendix\nB\n, we demonstrate that\nŒ≤\n\\beta\nis strictly increasing with\nd\nd\n, implying a direct relationship. This bijection ensures that for any distance\nd\n‚àó\nd^{*}\n, there exists a unique\nŒ≤\n‚àó\n\\beta^{*}\n, supporting our selection of frequencies and configurations in the simultaneous AET and information uplink process in TDD.\nV-\n4\nPerformance Evaluation\nThe plot in Fig.\n6\nillustrates the average AoI for various number of IoUT nodes using different AUV trajectory optimization and scheduling methods. The RW method, represented by the blue dashed line, shows the highest AoI across all nodes, indicating its inefficiency in maintaining up-to-date information. The RR method performs better than RW, reducing the AoI by approximately 16% for small number of nodes and up to 25% for a higher number of nodes (i.e, 7 and 10). The GA further reduces the AoI compared to RR, especially for lower-number of nodes with a reduction of approximately 30%. This reflects that positioning the AUV near the center of gravity manages to solve the optimization problem more efficiently, but of course at the cost of fairness. In contrast, our RL based approaches, both 2D-TDD and 3D-TDD, demonstrate significant improvements over the GA and RR methods. The 2D-TDD achieves a lower AoI than GA, reducing it by about 15.5%, which highlights its effectiveness in optimizing the AUV‚Äôs path. The best performance is observed for the 3D-TDD, which maintains a consistently low AoI across all nodes to showcase its superior efficiency in terms of AoI reduction over all other methods.\nFigure 6:\nAverage AoI for different algorithms and network sizes.\nLooking at Fig.\n7\n, we notice that both RW and RR methods render similar and relatively low energy harvesting capabilities across all node counts (i.e, not exceeding 7 KJ). This indicates their inefficiency in energy management. The proposed RL approaches with 2D-TDD and 3D-FDD action spaces demonstrate significant improvements over the RW, RR, and GA methods. The RL with a 2D-TDD action space harvests an amount ranging from 8 KJ to 9.2 KJ. However, its performance is inferior to the 3D-TDD (green bars), which achieves the highest energy harvesting levels among all methods across all different network sizes, indicating its superiority as expected. The RL 3D-FDD method harvests more than 10.5 KJ in all cases and up to 11.7 KJ in the 7-node setup. This highlights the 3D-FDD approach‚Äôs effectiveness and superiority in energy harvesting by dynamically adjusting to the environment. We can further explore the efficiency of 3D-FDD in Fig.\n8\n, where it consistently maintains the highest fairness index outperforming 2D-TDD, which leads to a quasi-uniform distribution of resources across all nodes. In contrast, the benchmark methods exhibit increased randomness for a higher number of IoUT devices, resulting in lower fairness as shown in the figure.\nFigure 7:\nTotal energy harvested plot for different algorithms and network sizes.\nFigure 8:\nThe average Jain‚Äôs fairness index for different algorithms and network sizes\nV-\n5\nComplexity Evaluation\nThe environmental impact of training ML models has become a significant concern within the ML community due to their substantial energy consumption and carbon emissions. The eco2ai library introduced in\n[\n6\n]\naddresses this issue by providing a tool to track AI models‚Äô carbon footprint and energy consumption during both the training and inference phases, promoting sustainable practices in AI development. In our work, we adopt eco2ai to compare the 2D-TDD to 3D-FDD. Table.\nIII\nhighlights that models with more IoUT nodes generally require longer training times, leading to higher energy consumption and more CO2 emissions. The consistent use of the same hardware (i.e, CPU: AMD Ryzen 7 5800H with Radeon Graphics; GPU: NVIDIA GeForce GTX 1650 ) across all models ensures that these variations are primarily due to differences in model configurations and training times. Notably, the model that adopts 2D-TDD consistently consumes less energy and emits less CO2 compared to their 3D-FDD counterparts, indicating a lower environmental impact for simpler models.\nTABLE III:\nA Complexity Analysis and Environmental Impact for the Proposed Methods.\nPPO Model\nTrain Time\nEnergy (kWh)\nCO2 (kg)\n3\nnodes TDD\n58\nmin\n0.0173\n0.0099\n3\nnodes FDD\n1\nh 9 min\n0.0188\n0.0107\n5\nnodes TDD\n1\nh 24 min\n0.0231\n0.0132\n5\nnodes FDD\n2\nh 17 min\n0.0838\n0.0478\n7\nnodes TDD\n3\nh 34 min\n0.1382\n0.0788\n7\nnodes FDD\n6\nh 4 min\n0.2174\n0.1240\n10\nnodes TDD\n6\nh 47 min\n0.2246\n0.1260\n10\nnodes FDD\n8\nh 11 min\n0.2942\n0.1679\nWhile the current study is based on simulations, the proposed solutions can be tested in real-world scenarios to validate their applicability further. Specifically, the framework can be implemented in a controlled underwater testbed using AUVs equipped with acoustic modems for communication and energy transfer modules. Such an experimental setup would allow us to evaluate the practical feasibility of the FDD and TDD schemes under varying underwater conditions, including different water depths, noise levels, and environmental factors.\nVI\nConclusions\nThis paper proposed two RL schemes for simultaneous AET and information uplink in IoUT network via AUV. The first scheme is FDD, which shows high performance in terms of age minimization and energy harvesting at the cost of higher complexity and hardware cost. The second scheme is TDD which offers a sub-optimal performance at lower complexity, less Co2 emissions and hardware cost. The results demonstrated that both schemes significantly improved energy harvesting efficiency, data collection, and fairness in resource distribution compared to conventional RW, GA, RR benchmarks.\nFuture work may include accounting for the AUV navigation energy and the deployment of multiple AUVs to serve massive IoUT networks via multi-agent reinforcement learning and meta-learning for dynamic environments. Reconfigurable intelligent surfaces (RIS) could be also applied in underwater environments to boost the efficiency of AET and information uplink in the same way it is deployed in terrestrial and non-terrestrial networks\n[\n4\n]\n.\nAppendix A\nDemonstrating how\nE\nr\n‚Äã\ne\n‚Äã\nq\n,\nk\nE_{req,k}\nis almost constant\nIn this appendix, we provide a detailed explanation for why the energy needed for transmission,\nE\nr\n‚Äã\ne\n‚Äã\nq\n,\nk\nE_{req,k}\n, remains relatively unaffected by changes in\nŒ≤\n\\beta\n. We start with the expression for\nE\nr\n‚Äã\ne\n‚Äã\nq\n,\nk\nE_{req,k}\nE\nr\n‚Äã\ne\n‚Äã\nq\n,\nk\n=\nP\nt\n‚Äã\nr\n‚Äã\na\n‚Äã\nn\n‚Äã\ns\n,\nk\n‚ãÖ\n(\n1\n‚àí\nŒ≤\n)\n‚ãÖ\nœÑ\n.\nE_{req,k}=P_{trans,k}\\cdot(1-\\beta)\\cdot\\tau.\n(34)\nUsing (\n12\n)\nE\nr\n‚Äã\ne\n‚Äã\nq\n,\nk\n=\nŒ≥\nk\n‚ãÖ\n10\nA\n‚Äã\nL\n+\nN\n‚Äã\nL\n10\n‚ãÖ\n(\n1\n‚àí\nŒ≤\n)\n‚Äã\nœÑ\n.\nE_{req,k}=\\gamma_{\\mathrm{k}}\\cdot 10^{\\frac{AL+NL}{10}}\\cdot(1-\\beta)\\tau.\n(35)\nReferring to (\n11\n), we can write the throghput as\nùíÆ\n=\nL\nt\n(\n1\n‚àí\nŒ≤\n)\n‚ãÖ\nœÑ\n,\n\\mathcal{S}=\\frac{L_{t}}{(1-\\beta)\\cdot\\tau},\n(36)\nwhere\nL\nt\nL_{t}\nis the packet size, indicating the quantity of data per transmission\nHence,\nE\nr\n‚Äã\ne\n‚Äã\nq\n,\nk\n=\n(\n2\n(\nL\nt\n(\n1\n‚àí\nŒ≤\n)\n‚ãÖ\nœÑ\n‚ãÖ\nB\n)\n‚àí\n1\n)\n‚ãÖ\n10\nA\n‚Äã\nL\n+\nN\n‚Äã\nL\n10\n‚ãÖ\n(\n1\n‚àí\nŒ≤\n)\n‚Äã\nœÑ\n.\nE_{req,k}=\\left(2^{\\left(\\frac{L_{t}}{(1-\\beta)\\cdot\\tau\\cdot B}\\right)}-1\\right)\\cdot 10^{\\frac{AL+NL}{10}}\\cdot(1-\\beta)\\tau.\n(37)\nUsing the Taylor expansion, we can deduce that\n2\n(\nL\nt\n(\n1\n‚àí\nŒ≤\n)\n‚ãÖ\nœÑ\n‚ãÖ\nB\n)\n‚âà\n1\n+\nL\nt\n‚ãÖ\nlog\n‚Å°\n(\n2\n)\n(\n1\n‚àí\nŒ≤\n)\n‚Äã\nœÑ\n‚Äã\nB\n.\n2^{\\left(\\frac{L_{t}}{(1-\\beta)\\cdot\\tau\\cdot B}\\right)}\\approx 1+\\frac{L_{t}\\cdot\\log(2)}{(1-\\beta)\\tau B}.\n(38)\nTherefore,\nE\nr\n‚Äã\ne\n‚Äã\nq\n,\nk\n‚âà\nL\nt\n‚ãÖ\nlog\n‚Å°\n2\n(\n1\n‚àí\nŒ≤\n)\n‚ãÖ\nœÑ\n‚ãÖ\nB\n‚ãÖ\n10\nA\n‚Äã\nL\n+\nN\n‚Äã\nL\n10\n‚ãÖ\n(\n1\n‚àí\nŒ≤\n)\n‚Äã\nœÑ\nE_{req,k}\\approx\\frac{L_{t}\\cdot\\log 2}{(1-\\beta)\\cdot\\tau\\cdot B}\\cdot 10^{\\frac{AL+NL}{10}}\\cdot(1-\\beta)\\tau\n(39)\nSimplifying, we obtain\nE\nr\n‚Äã\ne\n‚Äã\nq\n,\nk\n‚Äã\n(\nŒ≤\n,\nd\n)\n‚âà\nE\nr\n‚Äã\ne\n‚Äã\nq\n,\nk\n‚Äã\n(\nd\n)\n=\nL\nt\n‚ãÖ\nlog\n‚Å°\n2\nB\n√ó\n10\nA\n‚Äã\nL\n‚Äã\n(\nd\n)\n+\nN\n‚Äã\nL\n10\n.\nE_{req,k}(\\beta,d)\\approx E_{req,k}(d)=\\frac{L_{t}\\cdot\\log 2}{B}\\times 10^{\\frac{AL(d)+NL}{10}}.\n(40)\nNow, let\nŒ∫\n=\nL\nt\n‚ãÖ\nlog\n‚Å°\n(\n2\n)\nB\n‚ãÖ\n10\nN\n‚Äã\nL\n10\n\\text{\\LARGE$\\kappa$}=\\frac{L_{t}\\cdot\\log(2)}{B}\\cdot 10^{\\frac{NL}{10}}\n. We attain\nE\nr\n‚Äã\ne\n‚Äã\nq\n,\nk\n‚Äã\n(\nd\n)\n‚âà\nŒ∫\n‚ãÖ\n10\nA\n‚Äã\nL\n‚Äã\n(\nd\n)\n10\n.\nE_{req,k}(d)\\approx\\text{\\LARGE$\\kappa$}\\cdot 10^{\\frac{AL(d)}{10}}.\n(41)\nPlugging the values indicated in TABLE II, we end up with\nE\nr\n‚Äã\ne\n‚Äã\nq\n,\nk\n‚Äã\n(\nd\n)\n‚âà\n23.105\n√ó\n10\nA\n‚Äã\nL\n‚Äã\n(\nd\n)\n10\n.\nE_{req,k}(d)\\approx 23.105\\times 10^{\\frac{AL(d)}{10}}.\n(42)\nThus, the energy required for transmission is approximately constant due to the significant effect of the constant term in the power calculation and the nearly linear dependency of the SNR on\n(\n1\n‚àí\nŒ≤\n)\n(1-\\beta)\n. From Table\nIV\n, we can observe the tightness of the proposed approximation, where the normalized mean square error is in the order of\n10\n‚àí\n5\n10^{-5}\nfor all values of\nŒ≤\n\\beta\nand\nd\nd\n.\nTABLE IV:\nA Comparison of True and Approximated Energy Values.\nDistance (d)\nApproximated\nTrue Energy (J)\n(\n37\n)\nEnergy (J) (\n42\n)\nŒ≤\n=\n0.1\n\\beta=0.1\nŒ≤\n=\n0.5\n\\beta=0.5\nŒ≤\n=\n0.9\n\\beta=0.9\n100\n62.0503\n62.0819\n62.1075\n62.3377\n200\n92.6695\n92.7167\n92.7548\n93.0986\n300\n132.5527\n132.6202\n132.6747\n133.1665\n700\n494.0117\n494.2635\n494.4666\n496.2996\n800\n678.3817\n678.7274\n679.0063\n681.5234\n900\n929.3624\n929.8360\n930.2181\n933.6665\nAppendix B\nEnergy Harvesting vs energy required for transmission\nWe explore the relationship between\nŒ≤\n\\beta\nand\nd\nd\n, ensuring that energy harvesting is sufficient for reliable data transmission.\nB-\n1\nEnergy harvested\nAssuming\nŒ≤\n\\beta\namount of time for energy harvesting and using (\n1\n) in (\n9\n), we obtain\nE\nh\n‚Äã\na\n‚Äã\nr\n‚Äã\nv\n=\nŒ≤\n‚ãÖ\nœÑ\n‚ãÖ\nP\nh\n‚Äã\na\n‚Äã\nr\n‚Äã\nv\n=\nŒ≤\n‚ãÖ\nœÑ\n‚ãÖ\nŒ∑\n4\n‚Äã\nR\np\n‚Äã\n10\nR\n‚Äã\nV\n‚Äã\nS\n+\nR\n‚Äã\nL\n10\n=\nŒ≤\n‚ãÖ\nœÑ\n‚ãÖ\nŒ∫\n2\n‚ãÖ\n10\n‚àí\nA\n‚Äã\nL\n10\n,\n\\begin{split}E_{harv}&=\\beta\\cdot\\tau\\cdot P_{harv}\\\\\n&=\\beta\\cdot\\tau\\cdot\\frac{\\eta}{4R_{p}}10^{\\frac{RVS+RL}{10}}\\\\\n&=\\beta\\cdot\\tau\\cdot\\text{\\large$\\kappa_{2}$ }\\cdot 10^{-\\frac{AL}{10}},\\end{split}\n(43)\nwhere\nŒ∫\n2\n\\kappa_{2}\n=\nŒ∑\n4\n‚Äã\nR\np\n‚Äã\n10\nR\n‚Äã\nV\n‚Äã\nS\n+\nS\n‚Äã\nL\n‚àí\nN\n‚Äã\nL\n10\n=\\frac{\\eta}{4R_{p}}10^{\\frac{RVS+SL-NL}{10}}\n.\nB-\n2\nEnergy required for transmission\nAssuming\n1\n‚àí\nŒ≤\n1-\\beta\nportion of time for information uplink, from (\n37\n) we have\nE\nr\n‚Äã\ne\n‚Äã\nq\n,\nk\n=\n(\n2\n(\nL\nt\n(\n1\n‚àí\nŒ≤\n)\n‚ãÖ\nœÑ\n‚ãÖ\nB\n)\n‚àí\n1\n)\n√ó\n10\nA\n‚Äã\nL\n+\nN\n‚Äã\nL\n10\n√ó\n(\n1\n‚àí\nŒ≤\n)\n‚ãÖ\nœÑ\n.\nE_{req,k}=\\left(2^{\\left(\\frac{L_{t}}{(1-\\beta)\\cdot\\tau\\cdot B}\\right)}-1\\right)\\times 10^{\\frac{AL+NL}{10}}\\times(1-\\beta)\\cdot\\tau.\n(44)\nB-\n3\nInequality Comparison\nIn order to perform successful transmission, the harvested energy must be greater than or equal to the amount of energy required for the information uplink. That is\nE\nh\n‚Äã\na\n‚Äã\nr\n‚Äã\nv\n\\displaystyle E_{harv}\n‚â•\nE\nr\n‚Äã\ne\n‚Äã\nq\n,\nk\n,\n\\displaystyle\\geq E_{req,k},\n(45)\nPlugging (\n44\n) and (\n45\n), the inequality gives\nŒ≤\n‚ãÖ\nŒ∫\n2\n‚ãÖ\n10\n‚àí\nA\n‚Äã\nL\n10\n‚â•\n(\n1\n‚àí\nŒ≤\n)\n‚ãÖ\n(\n2\nL\nt\n(\n1\n‚àí\nŒ≤\n)\n‚ãÖ\nœÑ\n‚ãÖ\nB\n‚àí\n1\n)\n‚ãÖ\n10\nA\n‚Äã\nL\n+\nN\n‚Äã\nL\n10\n\\beta\\cdot\\kappa_{2}\\cdot 10^{-\\frac{AL}{10}}\\geq(1-\\beta)\\cdot\\left(2^{\\smash{\\scriptstyle\\frac{L_{t}}{(1-\\beta)\\cdot\\tau\\cdot B}}}-1\\right)\\cdot 10^{\\smash{\\scriptstyle\\frac{AL+NL}{10}}}\n(46)\nleading to\nŒ≤\n‚ãÖ\nŒ∫\n3\n(\n1\n‚àí\nŒ≤\n)\n‚Äã\n(\n2\nL\nt\n(\n1\n‚àí\nŒ≤\n)\n‚ãÖ\nœÑ\n‚ãÖ\nB\n‚àí\n1\n)\n‚â•\n10\nA\n‚Äã\nL\n5\n,\nŒ∫\n3\n=\nŒ∫\n2\n‚ãÖ\n10\n‚àí\nN\n‚Äã\nL\n10\n\\frac{\\beta\\cdot\\kappa_{3}}{(1-\\beta)\\left(2^{\\smash{\\scriptstyle\\frac{L_{t}}{(1-\\beta)\\cdot\\tau\\cdot B}}}-1\\right)}\\geq 10^{\\smash{\\scriptstyle\\frac{AL}{5}}},\\quad\\kappa_{3}=\\kappa_{2}\\cdot 10^{\\smash{\\scriptstyle-\\frac{NL}{10}}}\n(47)\nTaking logarithm base 10 for both sides, we attain\nlog\n10\n‚Å°\n(\nŒ≤\n1\n‚àí\nŒ≤\n)\n‚àí\nlog\n10\n‚Å°\n(\n2\nL\nt\n(\n1\n‚àí\nŒ≤\n)\n‚ãÖ\nœÑ\n‚ãÖ\nB\n‚àí\n1\n)\n\\displaystyle\\log_{10}\\left(\\frac{\\beta}{1-\\beta}\\right)-\\log_{10}\\left(2^{\\smash{\\scriptstyle\\frac{L_{t}}{(1-\\beta)\\cdot\\tau\\cdot B}}}-1\\right)\n‚â•\nA\n‚Äã\nL\n5\n‚àí\nlog\n10\n‚Å°\nŒ∫\n3\n,\n\\displaystyle\\geq\\frac{AL}{5}-\\log_{10}\\kappa_{3},\n(48)\nwhere\nA\n‚Äã\nL\n‚Äã\n(\nd\n)\n\\displaystyle AL(d)\n=\nk\ns\n‚ãÖ\nlog\n10\n‚Å°\n(\nd\n)\n+\nŒ∫\n4\n‚ãÖ\nd\nwith\nŒ∫\n4\n=\nŒ±\n‚Äã\n(\nf\n)\n.\n\\displaystyle=k_{s}\\cdot\\log_{10}(d)+\\kappa_{4}\\cdot d\\quad\\text{with}\\quad\\kappa_{4}=\\alpha(f).\n(49)\nFinally,\nlog\n10\n‚Å°\n(\nŒ≤\n1\n‚àí\nŒ≤\n)\n‚àí\nlog\n10\n\\displaystyle\\log_{10}\\left(\\frac{\\beta}{1-\\beta}\\right)-\\log_{10}\n(\n2\nL\nt\n(\n1\n‚àí\nŒ≤\n)\n‚ãÖ\nœÑ\n‚ãÖ\nB\n‚àí\n1\n)\n‚â•\n\\displaystyle\\left(2^{\\smash{\\scriptstyle\\frac{L_{t}}{(1-\\beta)\\cdot\\tau\\cdot B}}}-1\\right)\\geq\n(50)\nk\ns\n‚Äã\nlog\n10\n‚Å°\n(\nd\n)\n5\n+\nŒ∫\n4\n‚Äã\nd\n5\n‚àí\nlog\n10\n‚Å°\nŒ∫\n3\n.\n\\displaystyle\\frac{k_{s}\\log_{10}(d)}{5}+\\frac{\\kappa_{4}d}{5}-\\log_{10}\\kappa_{3}.\nHence,\ng\n‚Äã\n(\nŒ≤\n)\n‚â•\nh\n‚Äã\n(\nd\n)\n,\ng(\\beta)\\geq h(d),\n(51)\nwhere\ng\n‚Äã\n(\nŒ≤\n)\n=\nlog\n10\n‚Å°\n(\nŒ≤\n1\n‚àí\nŒ≤\n)\n‚àí\nlog\n10\n‚Å°\n(\n2\nL\nt\n(\n1\n‚àí\nŒ≤\n)\n‚ãÖ\nœÑ\n‚ãÖ\nB\n‚àí\n1\n)\ng(\\beta)=\\log_{10}\\left(\\frac{\\beta}{1-\\beta}\\right)-\\log_{10}\\left(2^{\\frac{L_{t}}{(1-\\beta)\\cdot\\tau\\cdot B}}-1\\right)\n(52)\nh\n‚Äã\n(\nd\n)\n=\n1\n5\n‚Äã\n(\nk\ns\n‚Äã\nlog\n10\n‚Å°\n(\nd\n)\n+\nŒ∫\n4\n‚ãÖ\nd\n)\n‚àí\nlog\n10\n‚Å°\nŒ∫\n3\nh(d)=\\frac{1}{5}\\left(k_{s}\\log_{10}(d)+\\kappa_{4}\\cdot d\\right)-\\log_{10}\\kappa_{3}\n(53)\nB-\n4\nDerivative Calculation\nThe derivation of\ng\n‚Äã\n(\nŒ≤\n)\ng(\\beta)\nwith respect to\nŒ≤\n\\beta\ngives\n‚àÇ\ng\n‚àÇ\nŒ≤\n=\n1\nlog\n‚Å°\n10\n\\displaystyle\\frac{\\partial g}{\\partial\\beta}=\\frac{1}{\\log 10}\n(\n1\nŒ≤\n‚Äã\n(\n1\n‚àí\nŒ≤\n)\n\\displaystyle\\left(\\frac{1}{\\beta(1-\\beta)}\\right.\n(54)\n+\n2\nL\nt\n(\n1\n‚àí\nŒ≤\n)\n‚ãÖ\nœÑ\n‚ãÖ\nB\n‚Äã\nlog\n‚Å°\n2\n‚ãÖ\n(\nL\nt\n(\n1\n‚àí\nŒ≤\n)\n2\n‚ãÖ\nœÑ\n‚ãÖ\nB\n)\n2\nL\nt\n(\n1\n‚àí\nŒ≤\n)\n‚ãÖ\nœÑ\n‚ãÖ\nB\n‚àí\n1\n)\n.\n\\displaystyle\\quad+\\left.\\frac{2^{\\smash{\\scriptstyle\\frac{L_{t}}{(1-\\beta)\\cdot\\tau\\cdot B}}}\\log 2\\cdot\\left(\\frac{L_{t}}{(1-\\beta)^{2}\\cdot\\tau\\cdot B}\\right)}{2^{\\smash{\\scriptstyle\\frac{L_{t}}{(1-\\beta)\\cdot\\tau\\cdot B}}}-1}\\right).\nProof of Bijectivity\nTo prove the bijectivity of\ng\n‚Äã\n(\nŒ≤\n)\ng(\\beta)\n, we need to prove its injectivity and surjectivity within the domain\nŒ≤\n‚àà\n[\nŒ≤\n1\n,\nŒ≤\n2\n]\n\\beta\\in[\\beta_{1},\\beta_{2}]\nwhere\nŒ≤\n1\n\\beta_{1}\nis close to 0 and\nŒ≤\n2\n\\beta_{2}\nis close to 1. To prove injectivity, we examine the derivative of\ng\n‚Äã\n(\nŒ≤\n)\ng(\\beta)\n. Since\nŒ≤\n‚àà\n[\nŒ≤\n1\n,\nŒ≤\n2\n]\n\\beta\\in[\\beta_{1},\\beta_{2}]\n, both\nŒ≤\n\\beta\nand\n1\n‚àí\nŒ≤\n1-\\beta\nare positive, making\n1\nŒ≤\n‚Äã\n(\n1\n‚àí\nŒ≤\n)\n>\n0\n\\frac{1}{\\beta(1-\\beta)}>0\n. For the second term, the expression\nL\nt\n(\n1\n‚àí\nŒ≤\n)\n‚ãÖ\nœÑ\n‚ãÖ\nB\n>\n0\n\\frac{L_{t}}{(1-\\beta)\\cdot\\tau\\cdot B}>0\nsince\nL\nt\n,\nœÑ\n,\nL_{t},\\tau,\nand\nB\nB\nare all positive. Therefore,\n2\nL\nt\n(\n1\n‚àí\nŒ≤\n)\n‚ãÖ\nœÑ\n‚ãÖ\nB\n>\n1\n2^{\\frac{L_{t}}{(1-\\beta)\\cdot\\tau\\cdot B}}>1\n, which implies that both the numerator\n2\nL\nt\n(\n1\n‚àí\nŒ≤\n)\n‚ãÖ\nœÑ\n‚ãÖ\nB\n‚ãÖ\nlog\n‚Å°\n(\n2\n)\n‚ãÖ\n(\nL\nt\n(\n1\n‚àí\nŒ≤\n)\n2\n‚ãÖ\nœÑ\n‚ãÖ\nB\n)\n2^{\\frac{L_{t}}{(1-\\beta)\\cdot\\tau\\cdot B}}\\cdot\\log(2)\\cdot\\left(\\frac{L_{t}}{(1-\\beta)^{2}\\cdot\\tau\\cdot B}\\right)\nand the denominator\n2\nL\nt\n(\n1\n‚àí\nŒ≤\n)\n‚ãÖ\nœÑ\n‚ãÖ\nB\n‚àí\n1\n2^{\\frac{L_{t}}{(1-\\beta)\\cdot\\tau\\cdot B}}-1\nare positive. Hence, the overall derivative\n‚àÇ\ng\n‚àÇ\nŒ≤\n>\n0\n\\frac{\\partial g}{\\partial\\beta}>0\nin the interval\nŒ≤\n‚àà\n[\nŒ≤\n1\n,\nŒ≤\n2\n]\n\\beta\\in[\\beta_{1},\\beta_{2}]\n, confirming that\ng\ng\nis strictly increasing and injective in the interval\nŒ≤\n‚àà\n[\nŒ≤\n1\n,\nŒ≤\n2\n]\n\\beta\\in[\\beta_{1},\\beta_{2}]\n.\nProof of Surjectivity\nSince\ng\n‚Äã\n(\nŒ≤\n)\ng(\\beta)\nis continuous by definition of logarithmic function, and strictly increasing in the interval\nŒ≤\n‚àà\n[\nŒ≤\n1\n,\nŒ≤\n2\n]\n\\beta\\in[\\beta_{1},\\beta_{2}]\n, it will cover all values between its minimum and maximum,\ng\n‚Äã\n(\nŒ≤\n1\n)\ng(\\beta_{1})\nand\ng\n‚Äã\n(\nŒ≤\n2\n)\ng(\\beta_{2})\n. Therefore,\ng\ng\nis surjective onto its range.\nSince\ng\ng\nis both injective and surjective in the interval\nŒ≤\n‚àà\n[\nŒ≤\n1\n,\nŒ≤\n2\n]\n\\beta\\in[\\beta_{1},\\beta_{2}]\n, we conclude that\ng\n‚Äã\n(\nŒ≤\n)\ng(\\beta)\nis bijective in this interval.\nReferences\n[1]\nM. A. Abd-Elmagid, A. Ferdowsi, H. S. Dhillon, and W. Saad\n(2019)\nDeep Reinforcement Learning for Minimizing Age-of-Information in UAV-Assisted Networks\n.\nIn\n2019 IEEE Global Communications Conference (GLOBECOM)\n,\nVol.\n,\npp.¬†1‚Äì6\n.\nExternal Links:\nDocument\nCited by:\n¬ßI\n,\n¬ß\nIII-C\n.\n[2]\nT. Ahmad, X. J. Li, A. K. Cherukuri, and K. Kim\n(2023)\nHierarchical localization algorithm for sustainable ocean health in large-scale underwater wireless sensor networks\n.\nSustainable Computing: Informatics and Systems\n39\n,\npp.¬†100902\n.\nExternal Links:\nISSN 2210-5379\n,\nDocument\n,\nLink\nCited by:\n¬ßI\n.\n[3]\nA. Ahmadian and H. Park\n(2018)\nWireless Powered Communication Networks: TDD or FDD?\n.\nExternal Links:\n1807.05670\n,\nLink\nCited by:\n¬ß\nIII-B\n.\n[4]\nK. An, Y. Sun, Z. Lin, Y. Zhu, W. Ni, N. Al-Dhahir, K. Wong, and D. Niyato\n(2024)\nExploiting multi-layer refracting ris-assisted receiver for hap-swipt networks\n.\nIEEE Transactions on Wireless Communications\n23\n(\n10\n),\npp.¬†12638‚Äì12657\n.\nExternal Links:\nDocument\nCited by:\n¬ßVI\n.\n[5]\nA. Bereketli and S. Bilgen\n(2012)\nRemotely powered underwater acoustic sensor networks\n.\nIEEE Sensors Journal\n12\n(\n12\n),\npp.¬†3467‚Äì3472\n.\nExternal Links:\nDocument\nCited by:\n¬ß\nII-B\n,\n¬ß\nIII-A\n1\n,\n¬ß\nIII-A\n1\n.\n[6]\nS. A. Budennyy, V. D. Lazarev, N. N. Zakharenko, A. N. Korovin, O. Plosskaya, D. V. Dimitrov, V. Akhripkin, I. Pavlov, I. V. Oseledets, I. S. Barsola,\net al.\n(2022)\nEco2AI: carbon emissions tracking of machine learning models as the first step towards sustainable AI\n.\nIn\nDoklady Mathematics\n,\nVol.\n106\n,\npp.¬†S118‚ÄìS128\n.\nCited by:\n¬ß\nV-\n5\n.\n[7]\nD. Centelles, E. M. Rubino, J. Sales, J. V. Mart√≠, R. Mar√≠n, and P. J. Sanz\n(2015)\nWireless RF camera monitoring for underwater cooperative robotic archaeological applications\n.\nInstrumentation viewpoint\n(\n18\n),\npp.¬†51‚Äì52\n.\nCited by:\n¬ßI\n.\n[8]\nJ. Dai, X. Li, S. Han, J. Yu, and Z. Liu\n(2024)\nRelay selection and power control for mobile underwater acoustic communication networks: a dual-thread reinforcement learning approach\n.\nIEEE Transactions on Green Communications and Networking\n(\n),\npp.¬†1‚Äì1\n.\nExternal Links:\nDocument\nCited by:\n¬ßI\n.\n[9]\nA. Eid, J. Rademacher, W. Akbar, P. Wang, A. Allam, and F. Adib\n(2023)\nEnabling long-range underwater backscatter via van atta acoustic networks\n.\nIn\nProceedings of the ACM SIGCOMM 2023 Conference\n,\npp.¬†1‚Äì19\n.\nCited by:\n¬ßI\n.\n[10]\nE. Eldeeb, J. M. d. S. Sant‚ÄôAna, D. E. Perez, M. Shehab, N. H. Mahmood, and H. Alves\n(2023)\nMulti-uav path learning for age and power optimization in iot with uav battery recharge\n.\nIEEE Transactions on Vehicular Technology\n72\n(\n4\n),\npp.¬†5356‚Äì5360\n.\nExternal Links:\nDocument\nCited by:\n¬ßI\n.\n[11]\nE. Eldeeb, M. Shehab, and H. Alves\n(2023)\nAge minimization in massive iot via uav swarm: a multi-agent reinforcement learning approach\n.\nIn\n2023 IEEE 34th Annual International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC)\n,\nVol.\n,\npp.¬†1‚Äì6\n.\nExternal Links:\nDocument\nCited by:\n¬ßI\n,\n¬ß\nIII-C\n.\n[12]\nH. Farag, M. Gidlund, and C. Stefanovic\n(2021)\nA deep reinforcement learning approach for improving age of information in mission-critical iot\n.\nIn\n2021 IEEE Global Conference on Artificial Intelligence and Internet of Things (GCAIoT)\n,\nVol.\n,\npp.¬†14‚Äì18\n.\nExternal Links:\nDocument\nCited by:\n¬ß\nIII-C\n.\n[13]\nR. Guida, E. Demirors, N. Dave, and T. Melodia\n(2022)\nUnderwater ultrasonic wireless power transfer: a battery-less platform for the internet of underwater things\n.\nIEEE Transactions on Mobile Computing\n21\n(\n5\n),\npp.¬†1861‚Äì1873\n.\nExternal Links:\nDocument\nCited by:\n¬ßI\n,\n¬ß\nII-B\n.\n[14]\nH. Guo and A. A. Ofori\n(2021)\nThe internet of things in extreme environments using low-power long-range near field communication\n.\nIEEE Internet of Things Magazine\n4\n(\n1\n),\npp.¬†34‚Äì38\n.\nExternal Links:\nDocument\nCited by:\n¬ßI\n.\n[15]\nY. He, Y. Gan, H. Cui, and M. Guizani\n(2023)\nFairness-based 3-d multi-uav trajectory optimization in multi-uav-assisted mec system\n.\nIEEE Internet of Things Journal\n10\n(\n13\n),\npp.¬†11383‚Äì11395\n.\nExternal Links:\nDocument\nCited by:\n¬ß\nIII-C\n,\n¬ß\nIII-C\n.\n[16]\nM. Jouhari, K. Ibrahimi, H. Tembine, and J. Ben-Othman\n(2019)\nUnderwater wireless sensor networks: a survey on enabling technologies, localization protocols, and internet of underwater things\n.\nIEEE Access\n7\n(\n),\npp.¬†96879‚Äì96899\n.\nExternal Links:\nDocument\nCited by:\n¬ßI\n.\n[17]\nA. Kosta, N. Pappas, and V. Angelakis\n(2017)\nAge of information: a new concept, metric, and tool\n.\nFoundations and Trends in Networking, Now Publishers, Inc.\n.\nCited by:\n¬ßI\n.\n[18]\nY. Ma, R. Ma, Z. Lin, R. Zhang, Y. Cai, W. Wu, and J. Wang\n(2024)\nImproving age of information for covert communication with time-modulated arrays\n.\nIEEE Internet of Things Journal (early access)\n(\n),\npp.¬†1‚Äì1\n.\nExternal Links:\nDocument\nCited by:\n¬ßI\n.\n[19]\nK. G. Omeke, A. I. Abubakar, L. Zhang, Q. H. Abbasi, and M. A. Imran\n(2022)\nHow reinforcement learning is helping to solve internet-of-underwater-things problems\n.\nIEEE Internet of Things Magazine\n5\n(\n4\n),\npp.¬†24‚Äì29\n.\nExternal Links:\nDocument\nCited by:\n¬ßI\n.\n[20]\nK. G. Omeke, M. Mollel, S. T. Shah, L. Zhang, Q. H. Abbasi, and M. A. Imran\n(2024)\nToward a sustainable internet of underwater things based on auvs, swipt, and reinforcement learning\n.\nIEEE Internet of Things Journal\n11\n(\n5\n),\npp.¬†7640‚Äì7651\n.\nExternal Links:\nDocument\nCited by:\n¬ßI\n,\n¬ß\nIII-A\n2\n.\n[21]\nA. Pal, F. Campagnaro, K. Ashraf, M. R. Rahman, A. Ashok, and H. Guo\n(2022)\nCommunication for underwater sensor networks: a comprehensive summary\n.\nACM Transactions on Sensor Networks\n19\n(\n1\n),\npp.¬†1‚Äì44\n.\nCited by:\n¬ßI\n.\n[22]\nS. Reddy, R. Arya, and Prateek\n(2024-08)\nCompensation of coordinated attacks in underwater internet of sensor networks\n.\nIEEE Transactions on Consumer Electronics\nPP\n,\npp.¬†1‚Äì1\n.\nExternal Links:\nDocument\nCited by:\n¬ßI\n.\n[23]\nE. Safeer, S. Tahir, M. Shaheen, and M. S. Farooq\n(2024)\nFederated learning for internet of underwater drone things\n.\nIn\nArtificial Intelligence and Edge Computing for Sustainable Ocean Health\n,\nD. De, D. Sengupta, and T. A. Tran (Eds.)\n,\npp.¬†295‚Äì309\n.\nExternal Links:\nISBN 978-3-031-64642-3\n,\nDocument\n,\nLink\nCited by:\n¬ßI\n.\n[24]\nJ. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov\n(2017)\nProximal policy optimization algorithms\n.\nExternal Links:\n1707.06347\n,\nLink\nCited by:\n¬ß\nIV-B\n,\n¬ß\nIV-B\n.\n[25]\nB. Shihada, O. Amin, C. Bainbridge, S. Jardak, O. Alkhazragi, T. K. Ng, B. Ooi, M. Berumen, and M. Alouini\n(2020)\nAqua-fi: delivering internet underwater using wireless optical networks\n.\nIEEE Communications Magazine\n58\n(\n5\n),\npp.¬†84‚Äì89\n.\nCited by:\n¬ßI\n.\n[26]\nA. Wibisono, M. H. Alsharif, H. Song, and B. M. Lee\n(2024)\nA survey on underwater wireless power and data transfer system\n.\nIEEE Access\n12\n(\n),\npp.¬†34942‚Äì34957\n.\nExternal Links:\nDocument\nCited by:\n¬ßI\n.\n[27]\nY. Zhao, Y. Du, Z. Wang, J. Wang, and Y. Geng\n(2021)\nDesign of ultrasonic transducer structure for underwater wireless power transfer system\n.\nIn\n2021 IEEE Wireless Power Transfer Conference (WPTC)\n,\nVol.\n,\npp.¬†1‚Äì4\n.\nExternal Links:\nDocument\nCited by:\n¬ßI\n.\n[28]\nM. Y. I. Zia, J. Poncela, and P. Otero\n(2021)\nState-of-the-art underwater acoustic communication modems: classifications, analyses and design challenges\n.\nWireless personal communications\n116\n,\npp.¬†1325‚Äì1360\n.\nCited by:\n¬ßI\n.",
  "preview_text": "Internet of underwater things (IoUT) is increasingly gathering attention with the aim of monitoring sea life and deep ocean environment, underwater surveillance as well as maintenance of underwater installments. However, conventional IoUT devices, reliant on battery power, face limitations in lifespan and pose environmental hazards upon disposal. This paper introduces a sustainable approach for simultaneous information uplink from the IoUT devices and acoustic energy transfer (AET) to the devices via an autonomous underwater vehicle (AUV), potentially enabling them to operate indefinitely. To tackle the time-sensitivity, we adopt age of information (AoI), and Jain's fairness index. We develop two deep-reinforcement learning (DRL) algorithms, offering a high-complexity, high-performance frequency division duplex (FDD) solution and a low-complexity, medium-performance time division duplex (TDD) approach. The results elucidate that the proposed FDD and TDD solutions significantly reduce the average AoI and boost the harvested energy as well as data collection fairness compared to baseline approaches.\n\nAUV Trajectory Learning for Underwater Acoustic Energy Transfer and Age Minimization\nMohamed Afouene Melki, Mohammad Shehab, and Mohamed-Slim Alouini\nThis work is supported by the KAUST Office of Sponsored Research under Award ORA-CRG2021-4695.The authors are with CEMSE Division, King Abdullah University of Science and Technology (KAUST), Thuwal 23955-6900, Saudi Arabia (emails: mohamed.melki@kaust.edu.sa, mohammad.shehab@kaust.edu.sa, slim.alouini@kaust.edu.sa).\nAbstract\nInternet of underwater things (IoUT) is increasingly gathering attention with the aim of monitoring sea life and deep ocean environment, underwater surveillance as well as maintenance of underwater installments. However, conventional IoUT devices, reliant on battery power, face limitations in lifespan and pose environmental hazards upon disposal. This paper introduces a sustainable approach for simultane",
  "is_relevant": true,
  "relevance_score": 4.0,
  "extracted_keywords": [
    "Reinforcement Learning"
  ],
  "one_line_summary": "ËØ•ËÆ∫ÊñáÊèêÂá∫‰ΩøÁî®Ê∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†ÁÆóÊ≥ï‰ºòÂåñËá™‰∏ªÊ∞¥‰∏ãËΩ¶ËæÜÁöÑËΩ®ËøπÔºå‰ª•ÂêåÊó∂ÂÆûÁé∞Ê∞¥‰∏ãÂ£∞ËÉΩ‰º†ËæìÂíå‰ø°ÊÅØÂπ¥ÈæÑÊúÄÂ∞èÂåñ„ÄÇ",
  "detailed_summary": "",
  "qa_pairs": [],
  "is_hidden": false,
  "is_starred": false,
  "flag": "",
  "published_date": "2026-01-13T12:23:53Z",
  "created_at": "2026-01-20T17:49:44.466539",
  "updated_at": "2026-01-20T17:49:44.466547"
}