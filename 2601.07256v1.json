{
    "id": "2601.07256v1",
    "title": "Robust maximum hands-off optimal control: existence, maximum principle, and $L^{0}$-$L^1$ equivalence",
    "authors": [
        "Siddhartha Ganguly",
        "Kenji Kashima"
    ],
    "abstract": "æœ¬ç ”ç©¶é€šè¿‡ä¸ºå…·æœ‰å‚æ•°ä¸ç¡®å®šæ€§çš„çº¦æŸçº¿æ€§ç³»ç»Ÿå¼€å‘é²æ£’å¯¹åº”æ¨¡å‹ï¼Œæ¨è¿›äº†æœ€å¤§é›¶è¾“å…¥ç¨€ç–æ§åˆ¶æ¡†æ¶ã€‚æ‰€å¾—åˆ°çš„æœ€ä¼˜æ§åˆ¶é—®é¢˜åœ¨æ»¡è¶³ä¸€ä¸ªä¸å¯æ•°ã€ç´§è‡´çš„çº¦æŸæ—æ¡ä»¶ä¸‹æœ€å°åŒ–$L^{0}$ç›®æ ‡å‡½æ•°ï¼Œå› æ­¤å±äºéå‡¸ã€éå…‰æ»‘çš„é²æ£’ä¼˜åŒ–é—®é¢˜ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬é‡‡ç”¨å‡¸$L^{1}$ä»£ç†å‡½æ•°æ›¿ä»£$L^{0}$ç›®æ ‡ï¼Œå¹¶è¿ç”¨é²æ£’åºç‰¹é‡Œäºšé‡‘æœ€å¤§å€¼åŸç†çš„éå…‰æ»‘å˜ä½“ï¼Œè¯æ˜$L^{0}$ä¸$L^{1}$ä¸¤ç§å½¢å¼å…·æœ‰å®Œå…¨ç›¸åŒçš„æœ€ä¼˜è§£é›†â€”â€”æˆ‘ä»¬ç§°ä¹‹ä¸ºé²æ£’é›¶è¾“å…¥åŸç†ã€‚åŸºäºè¿™ä¸€ç­‰ä»·æ€§ï¼Œæˆ‘ä»¬æå‡ºä¸€ç§ç®—æ³•æ¡†æ¶â€”â€”å€Ÿé‰´åŠæ— é™é²æ£’ä¼˜åŒ–æ–‡çŒ®ä¸­æ•°å€¼å¯è¡Œçš„æŠ€æœ¯â€”â€”ä»¥æ±‚è§£æ‰€å¾—é—®é¢˜ã€‚æ–‡ä¸­é€šè¿‡ç¤ºä¾‹éªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚",
    "url": "https://arxiv.org/abs/2601.07256v1",
    "html_url": "https://arxiv.org/html/2601.07256v1",
    "html_content": "Robust maximum hands-off optimal control: existence, maximum principle, and\nL\n0\n{L}^{0}\n-\nL\n1\n{L}^{1}\nequivalence\nSiddhartha Ganguly\nand\nKenji Kashima\nAbstract.\nThis work advances the maximum hands-off sparse control framework by developing a robust counterpart for constrained linear systems with parametric uncertainties. The resulting optimal control problem minimizes an\nL\n0\n{L}^{0}\nobjective subject to an uncountable, compact family of constraints, and is therefore a nonconvex, nonsmooth robust optimization problem. To address this, we replace the\nL\n0\n{L}^{0}\nobjective with its convex\nL\n1\n{L}^{1}\nsurrogate and, using a nonsmooth variant of the robust Pontryagin maximum principle, show that the\nL\n0\n{L}^{0}\nand\nL\n1\n{L}^{1}\nformulations have identical sets of optimal solutions â€” we call this\nthe robust hands-off principle\n. Building on this equivalence, we propose an algorithmic framework â€” drawing on numerically viable techniques from the semi-infinite robust optimization literature â€” to solve the resulting problems. An illustrative example is provided to demonstrate the effectiveness of the approach.\nS. Ganguly and K. Kashima are with\n\\faGroup\nThe Applied Mathematics and Physics Department, Graduate School of Informatics,\nKyoto University,\nKyoto, Japan. S.G. gratefully acknowledges Takuya Ikedaâ€™s valuable suggestions, as well as the encouraging comments from Debasish Chatterjee and Masaaki Nagahara.\nContact Information: (SG)\nhttps://sites.google.com/view/siddhartha-ganguly\n,\nsiddhartha1123@gmail.com\n,\n(KK):\nkk@i.kyoto-u.ac.jp\n,\nhttps://www.bode.amp.i.kyoto-u.ac.jp/en/kk/\n.\n1.\nIntroduction\nSparsity, in broad strokes, is defined as the mathematical representation of\nsimplicity\n, capturing the principle of minimizing complexity in models or systems. Naturally, the study of sparsity and the associated numerical techniques to promote it have gained significant prominence across various scientific and technological fields, including signal processing, machine learning, and statistics, such as compressed sensing or sparse modeling\n[\nUT14\n,\nVid19\n]\n,\n[\nHTW15\n]\n,\n[\nDon06\n]\n.\nSparsity-driven techniques have been extensively utilized in the control literature to minimize control activity across a wide range of applications. These include networked control systems\n[\nNQÃ˜13\n]\n, feedback controller design\n[\nLFJ13\n,\nPKS14\n]\n, sensor placement and sensing strategies\n[\nBB11\n]\n, aerospace systems\n[\nHGM13\n]\n, control of partial differential equations\n[\nCHW12\n,\nCF14\n]\n, and infinite-dimensional systems\n[\nIN25\n]\n. From a theoretical perspective, the system-theoretic properties of sparse optimal controllers constitute a highly active and rapidly developing area of research\n[\nAK25\n,\nABM25\n,\nCJL25\n]\n. By promoting sparse control inputs, these approaches optimize resource efficiency and reduce actuator engagement while maintaining system performance. From the perspective of constrained optimal control theory, the use of sparsity-promoting cost functions was explored in\n[\nNQN15\n]\n. This approach underpins the well-established concept of the\nmaximum hands-off control\nin the sparse optimal control literature. Within the context of deterministic linear systems, this principle is formalized by minimizing the\nL\n0\n{L}^{0}\n-(semi)norm of the control input, which effectively reduces the duration over which the control is nonzero\n[\nNQN15\n]\n. By prioritizing sparsity, the maximum hands-off principle induces prolonged intervals of zero control input, thereby minimizing control effort by keeping actuators inactive for extended periods while ensuring that system constraints are satisfied. In practice, the nonconvex and nonsmooth\nL\n0\n{L}^{0}\nobjective is often replaced by its convex surrogate, the\nL\n1\n{L}^{1}\nnorm, a relaxation justified by theoretical results demonstrating their equivalence under mild assumptions on the problem data\n[\nNQN15\n]\n. This substitution facilitates computational tractability while preserving the sparsity-promoting properties central to the maximum hands-off control framework, ultimately enhancing efficiency by reducing the active engagement of control actuators.\nMotivation, theme, and contributions:\nGiven the preceding premise, sparse control is typically not robust to uncertainties, and ensuring resilience to alterations in system models is a critical task. Real-world dynamical models contain uncertainties, including unmodeled dynamics and disturbances, which can degrade system performance if not included in the control design. The theoretical equivalence between the\nL\n0\n{L}^{0}\nand the\nL\n1\n{L}^{1}\nsparse optimal controls and their numerical synthesis is well-established\n[\nNQN15\n]\nfor deterministic uncertainty-free systems. On the otherhand, a rigorous theoretical foundation for robust sparse control has remained an open challenge, along with a numerically viable technique for the synthesis of such control. To this end, we ask:\n{myOCP}\nâ€œIs it possible to establish an equivalence between\nL\n0\n{L}^{0}\n- and\nL\n1\n{L}^{1}\n-sparse controls for a class of parameter-dependent systems, and to develop a numerically viable method for synthesizing such control actions?â€\nThis article provides an affirmative answer to this question; specifically, our contributions are as follows:\n(1)\nWe consider a class of constrained linear uncertain systems with the objective of minimizing the control activity, i.e., minimizing the\nL\n0\n{L}^{0}\ncontrol cost, while satisfying an\nuncountable family\nof constraints. The ensuing optimization problem is a nonconvex and nonsmooth robust program which is both challenging to analyze and solve in a numerically tractable fashion.\n(2)\nFollowing the standard route\n[\nNQN15\n]\n, we analyze its convex relaxation, the robust\nL\n1\n{L}^{1}\nproblem. The main contribution of this work is a rigorous theoretical framework for this problem. By employing a nonsmooth version of the robust Pontryaginâ€™s Maximum Principle, we first derive the necessary conditions for optimality for the robust\nL\n1\n{L}^{1}\nproblem. Using these conditions, we prove that under standard assumptions, the optimal control exhibits a\nbang-off-bang\nstructure. Leveraging this structural result, we then present the central theoretical finding of this paper: a proof that the set of optimal solutions for the original robust\nL\n0\n{L}^{0}\nproblem is identical to that of its tractable\nL\n1\n{L}^{1}\nconvex relaxation.\n(3)\nFinally, in the numerical front we follow the suggestions of\n[\nVin05\n, Â§I, p. 941]\n: we parametrize the space of admissible controls employing piecewise constant functions to arrive at a finite dimensional semi-infinite optimization problem and then employ some recent algorithms to furnish a numerically tractable algorithmic architecture with guarantees of\nexact solutions\n. We validate our theoretical claims and demonstrate the performance of the numerical architecture on a benchmark control example.\nPlacement and potential applications of our results:\nFrom a\ntheoretical standpoint\n, our results should be viewed as an addition to the literature on sparse optimal control and equivalence principles, filling a gap in the setting of robust parameter-dependent systems. While the route to equivalence is similar to standard works the technical and methodological engines are\ncompletely novel\n. From an\nalgorithmic viewpoint\n, the proposed approach leverages existing robust optimization oracles; several such alternatives are available, including cutting-plane or cutting-surface methods\n[\nBF76\n]\nand the scenario approach\n[\nCG18\n]\n(see\n[\nZF22\n]\nfor an application). We adopt the technique in\n[\nDACC22\n]\nas a representative method because of its ability to generate numerically viable\nexact solutions\nin a computationally viable fashion, which is unique. Our results have potential applications in several areas, including attitude control of thrusters under uncertainty\n[\nKG23\n]\n, networked control over communication channels subject to packet drops\n[\nNQÃ˜13\n]\n, and energy-efficient control design under uncertainty\n[\nNag23\n]\n. These directions will be investigated in future work.\nThe article is structured as follows: the central problem is formulated in Â§\n2\n. The primary theoretical contributions are presented in Â§\n3.1\n, while the algorithmic developments are detailed in Â§\n3.2\n. Finally, Â§\n4\nprovides a numerical example to illustrate our results and the algorithmic architecture.\n2.\nThe central problem\nNotation\nWe employ standard notation in this article. We let\nâ„•\nâˆ—\nâ‰”\n{\n1\n,\n2\n,\nâ€¦\n}\n\\mathbb{N}^{*}\\coloneqq\\{1,2,\\ldots\\}\ndenote the set of positive integers, and let\nâ„¤\n\\mathbb{Z}\nbe the set of integers. Let\nd\nâˆˆ\nâ„•\nâˆ—\nd\\in\\mathbb{N}^{*}\n; we will denote the standard Euclidean vector space by\nâ„\nd\n\\mathbb{R}^{d}\nwhich is assumed to be equipped with standard norm\nâ„\nd\nâˆ‹\nx\nâ†¦\nâ€–\nx\nâ€–\n\\mathbb{R}^{d}\\ni x\\mapsto\\left\\lVert x\\right\\rVert\n. Let\nX\nX\nbe an arbitrary subset of\nâ„\nd\n\\mathbb{R}^{d}\n; by\nint\nâ¡\nX\n\\operatorname{int}{X}\nwe denote the interior of\nX\nX\n. Let\nT\n>\n0\nT>0\n; for any bounded measurable function\nf\n:\n[\n0\n,\nT\n]\nâŸ¶\nâ„\nf:[0,T]\\longrightarrow\\mathbb{R}\nwe employ the notation\nâ€–\nf\nâ€‹\n(\nâ‹…\n)\nâ€–\nâˆ\nâ‰”\nesssup\nt\nâˆˆ\n[\n0\n,\nT\n]\nâ€‹\n|\nf\nâ€‹\n(\nt\n)\n|\n\\left\\lVert f(\\cdot)\\right\\rVert_{\\infty}\\coloneqq\\text{esssup}_{t\\in[0,T]}\\left\\lvert{f(t)}\\right\\rvert\nfor the uniform norm, and when\nf\nâ€‹\n(\nâ‹…\n)\nf(\\cdot)\nis continuous then the essential supremum â€˜\nesssup\nâ€™ is replaced by the standard supremum â€˜\nsup\n\\sup\nâ€™ or the â€˜maxâ€™ operator. Let\nA\nA\nbe a subset of\nâ„\n\\mathbb{R}\n, then the indicator function of\nA\nA\nis the function\nğŸ™\nA\nâ€‹\n(\nâ‹…\n)\n\\mathds{1}_{A}(\\cdot)\ndefined by\nğŸ™\nA\nâ€‹\n(\nx\n)\n=\n1\n\\mathds{1}_{A}(x)=1\nif\nx\nâˆˆ\nA\nx\\in A\nand\nğŸ™\nA\nâ€‹\n(\nx\n)\n=\n0\n\\mathds{1}_{A}(x)=0\notherwise. For a fixed\nT\n>\n0\nT>0\nand fixed step\nh\n>\n0\nh>0\n, the space of\nâ„\n\\mathbb{R}\n-valued piecewise constant functions is given by\n((4))\nğ–¯ğ–¢\nh\n(\n[\n0\n,\nT\n]\n;\nâ„\n)\nâ‰”\n{\nÎ¾\n:\n[\n0\n,\nT\n]\nâ†’\nâ„\n|\n0\n=\nt\n0\n<\nt\n1\n<\nâ‹¯\n<\nt\nK\nâ©½\nT\n,\nÎ¾\ni\nâˆˆ\nâ„\n,\nt\ni\nâˆ’\nt\ni\nâˆ’\n1\n=\nh\nâ€‹\nfor\nâ€‹\ni\n=\n1\n,\nâ€¦\n,\nK\n,\nT\nâˆ’\nt\nK\nâ©½\nh\n,\nÎ¾\nâ€‹\n(\nâ‹…\n)\n=\nâˆ‘\ni\n=\n1\nK\nÎ¾\ni\nâˆ’\n1\nâ€‹\nğŸ™\n[\nt\ni\nâˆ’\n1\n,\nt\ni\n[\nâ€‹\n(\nâ‹…\n)\n+\nÎ¾\nK\nâ€‹\nğŸ™\n[\nt\nK\n,\nT\n]\nâ€‹\n(\nâ‹…\n)\n}\n.\n\\displaystyle\\mathsf{PC}_{h}([0,T];\\mathbb{R})\\coloneqq\\left\\{\\xi:[0,T]\\to\\mathbb{R}\\;\\middle|\\;\\begin{array}[]{@{}l@{}}0=t_{0}<t_{1}<\\cdots<t_{K}\\leqslant T,\\;\\xi_{i}\\in\\mathbb{R},\\\\\n\\,t_{i}-t_{i-1}=h\\text{ for }i=1,\\ldots,K,T-t_{K}\\leqslant h,\\\\\n\\xi(\\cdot)=\\sum_{i=1}^{K}\\xi_{i-1}\\mathds{1}_{[t_{i-1},t_{i}[}(\\cdot)+\\xi_{K}\\mathds{1}_{[t_{K},T]}(\\cdot)\\end{array}\\right\\}.\nLet\nd\n1\n,\nd\n2\nâˆˆ\nâ„•\nâˆ—\nd_{1},d_{2}\\in\\mathbb{N}^{*}\n; for\nX\nâŠ‚\nâ„\nd\n1\nX\\subset\\mathbb{R}^{d_{1}}\nand\nY\nâŠ‚\nâ„\nd\n2\nY\\subset\\mathbb{R}^{d_{2}}\nopen subsets, the set of\nr\nr\n-times continuously differentiable functions from\nX\nX\nto\nY\nY\nis denoted by\nğ’\nr\nâ€‹\n(\nX\n;\nY\n)\n\\mathcal{C}^{r}(X;Y)\nand for\n1\nâ©½\np\n<\n+\nâˆ\n1\\leqslant p<+\\infty\nthe space of Lebesgue measurable functions\nL\np\nâ€‹\n(\nX\n;\nY\n)\n{L}^{p}(X;Y)\nis defined by\nL\np\n(\nX\n;\nY\n)\nâ‰”\n{\nu\n:\nX\nâŸ¶\nY\n|\nu\n(\nâ‹…\n)\nis measurable and\nâˆ«\nX\nâˆ¥\nu\n(\nx\n)\nâˆ¥\np\nd\nx\n<\n+\nâˆ\n}\n.\n{L}^{p}(X;Y)\\coloneqq\\bigg\\{u:X\\longrightarrow Y\\;\\bigg|\\;u(\\cdot)\\text{ is measurable and}\\int_{X}\\left\\lVert u(x)\\right\\rVert^{p}\\mathop{}\\!\\mathrm{d}x<+\\infty\\bigg\\}.\nThe set of measurable and essentially bounded functions\nL\nâˆ\nâ€‹\n(\nX\n;\nY\n)\n{L}^{\\infty}(X;Y)\nis defined by\nL\nâˆ\n(\nX\n;\nY\n)\nâ‰”\n{\nu\n:\nX\nâŸ¶\nY\n|\nu\n(\nâ‹…\n)\nis measurable and\nesssup\nx\nâˆˆ\nX\nâˆ¥\nu\n(\nx\n)\nâˆ¥\n<\n+\nâˆ\n}\n.\n{L}^{\\infty}(X;Y)\\coloneqq\\bigg\\{u:X\\longrightarrow Y\\;\\bigg|\\;u(\\cdot)\\text{ is measurable and}\\text{ esssup}_{x\\in X}\\left\\lVert u(x)\\right\\rVert<+\\infty\\bigg\\}.\nThe space of absolutely continuous functions is defined by\nW\n1\n,\n1\n(\nX\n;\nY\n)\nâ‰”\n{\nu\n:\nX\nâŸ¶\nY\n|\nu\nâ€‹\n(\nâ‹…\n)\nâˆˆ\nL\n1\nâ€‹\n(\nX\n;\nY\n)\nâ€‹\nand\nâ€‹\nâˆ‚\nj\nu\ni\nâ€‹\n(\nâ‹…\n)\nâˆˆ\nL\n1\nâ€‹\n(\nX\n)\nfor all\nâ€‹\ni\n=\n1\n,\nâ€¦\n,\nd\n2\n,\nand\nâ€‹\nj\n=\n1\n,\nâ€¦\n,\nd\n1\n}\nW^{1,1}(X;Y)\\coloneqq\\bigg\\{u:X\\longrightarrow Y\\;\\bigg|\\;\\begin{array}[]{l}u(\\cdot)\\in{L}^{1}(X;Y)\\text{ and }\\partial_{j}u_{i}(\\cdot)\\in{L}^{1}(X)\\\\\n\\text{for all }i=1,\\ldots,d_{2},\\text{ and }j=1,\\ldots,d_{1}\\end{array}\\bigg\\}\nWe assume that all these spaces are equipped with their standard norms\n[\nAF03\n]\n. Finally, the normal cone to a given convex set\nC\nC\nat a point\nx\nâˆˆ\nC\nx\\in C\n, denoted\nN\nC\nâ€‹\n(\nx\n)\nN_{C}(x)\n, is defined by\n[\nCla13\n, Â§1.4]\nN\nC\nâ€‹\n(\nx\n)\nâ‰”\n{\nv\nâˆˆ\nâ„\nd\n|\nâŸ¨\nv\n,\ny\nâˆ’\nx\nâŸ©\nâ©½\n0\nâ€‹\nfor all\nâ€‹\ny\nâˆˆ\nC\n}\n.\n\\displaystyle N_{C}(x)\\coloneqq\\big\\{v\\in\\mathbb{R}^{d}\\;\\big|\\;\\left\\langle{v},\\,{y-x}\\right\\rangle\\leqslant 0\\text{ for all }y\\in C\\big\\}.\nWe present the central problem of this manuscript. Let\nd\n,\nÎ½\nâˆˆ\nâ„•\nâˆ—\nd,\\nu\\in\\mathbb{N}^{*}\nand fix a time horizon\nT\n>\n0\nT>0\n. Let us consider an uncertain linear time-invariant controlled dynamical system modeled by the ordinary differential equation\n((5))\nË™\nâ€‹\nx\nâ€‹\n(\nt\n;\nÎ±\n)\n=\nA\nâ€‹\n(\nÎ±\n)\nâ€‹\nx\nâ€‹\n(\nt\n;\nÎ±\n)\n+\nb\nâ€‹\n(\nÎ±\n)\nâ€‹\nu\nâ€‹\n(\nt\n)\nâ€‹\nfor a.e.\nâ€‹\nt\nâˆˆ\n[\n0\n,\nT\n]\n,\nx\nâ€‹\n(\n0\n;\nÎ±\n)\nâ‰”\nx\nÂ¯\nâ€‹\ngiven\n\\dot{}x(t;\\alpha)=A(\\alpha)x(t;\\alpha)+b(\\alpha)u(t)\\,\\text{for a.e.\\, }t\\in[0,T],\\,\\,x(0;\\alpha)\\coloneqq\\overline{x}\\text{ given}\nwith the data:\n((\n(5)\n)-a)\nThe uncertain parameter\nÎ±\nâˆˆ\nğ–¯\n\\alpha\\in\\mathsf{P}\nwhere\nğ–¯\nâŠ‚\nâ„\nÎ½\n\\mathsf{P}\\subset\\mathbb{R}^{\\nu}\nis a nonempty, compact and convex set of\nuncertain parameters\n. A commonly occurring example of such uncertainty set\nğ–¯\n\\mathsf{P}\nis a polytope, and it is widely found in the robust control literature\n[\nBGFB94\n, Chapter 4]\n,\n[\nDP13\n, Chapter 8]\n.\n((\n(5)\n)-b)\nthe control trajectory\nt\nâ†¦\nu\nâ€‹\n(\nt\n)\nâˆˆ\nâ„\nt\\mapsto u(t)\\in\\mathbb{R}\nis a bounded measurable function satisfying\nu\nâ€‹\n(\nt\n)\nâˆˆ\nğ•Œ\nâ‰”\n[\nâˆ’\n1\n,\n1\n]\nâŠ‚\nâ„\nfor a.e.\nâ€‹\nt\nâˆˆ\n[\n0\n,\nT\n]\n,\nu(t)\\in\\mathbb{U}\\coloneqq[-1,1]\\subset\\mathbb{R}\\quad\\text{ for a.e. }t\\in[0,T],\nand consequently, the admissible set of control actions is defined by\nğ’°\nâ‰”\n{\nu\nâ€‹\n(\nâ‹…\n)\nâˆˆ\nL\nâˆ\nâ€‹\n(\n[\n0\n,\nT\n]\n;\nâ„\n)\n|\nu\nâ€‹\n(\nt\n)\nâˆˆ\nğ•Œ\nâ€‹\nfor a.e.\nâ€‹\nt\nâˆˆ\n[\n0\n,\nT\n]\n}\n.\n\\displaystyle\\mathcal{U}\\coloneqq\\big\\{u(\\cdot)\\in{L}^{\\infty}([0,T];\\mathbb{R})\\;|\\;u(t)\\in\\mathbb{U}\\text{ for a.e. }t\\in[0,T]\\big\\}.\nFor every\nÎ±\nâˆˆ\nğ–¯\n\\alpha\\in\\mathsf{P}\n, the state trajectory\nx\nâ€‹\n(\nâ‹…\n;\nÎ±\n)\nâˆˆ\nW\n1\n,\n1\nâ€‹\n(\n[\n0\n,\nT\n]\n;\nâ„\nd\n)\nx(\\cdot;\\alpha)\\in W^{1,1}([0,T];\\mathbb{R}^{d})\nis an absolutely continuous function of time. We assume that the mappings\nğ–¯\nâˆ‹\nÎ±\nâ†¦\nA\nâ€‹\n(\nÎ±\n)\nâˆˆ\nâ„\nd\nÃ—\nd\n\\mathsf{P}\\ni\\alpha\\mapsto A(\\alpha)\\in\\mathbb{R}^{d\\times d}\nand\nğ–¯\nâˆ‹\nÎ±\nâ†¦\nb\nâ€‹\n(\nÎ±\n)\nâˆˆ\nâ„\nd\n\\mathsf{P}\\ni\\alpha\\mapsto b(\\alpha)\\in\\mathbb{R}^{d}\nare continuously differentiable on an open neighbourhood of\nğ–¯\n\\mathsf{P}\n. We will call the pair\n(\nu\nâ€‹\n(\nâ‹…\n)\n,\n{\nx\nâ€‹\n(\nâ‹…\n;\nÎ±\n)\n|\nÎ±\nâˆˆ\nğ–¯\n}\n)\n\\bigl(u(\\cdot),\\{x(\\cdot;\\alpha)\\;|\\;\\alpha\\in\\mathsf{P}\\}\\bigr)\na\nprocess\nsatisfying the dynamics (\n(5)\n) with\nx\nâ€‹\n(\n0\n;\nÎ±\n)\nâ‰”\nx\nÂ¯\nx(0;\\alpha)\\coloneqq\\overline{x}\ngiven.\n((\n(5)\n)-c)\nThe final state takes values in the compact and convex set\nC\nC\ngiven by\nC\nâ‰”\n{\nÎ¾\nâˆˆ\nâ„\nd\n|\nÏˆ\nâ€‹\n(\nÎ¾\n)\nâ©½\n0\n}\n,\n\\displaystyle C\\coloneqq\\{\\xi\\in\\mathbb{R}^{d}\\;|\\;\\psi(\\xi)\\leqslant 0\\},\ni.e,\nÏˆ\nâ€‹\n(\nx\nâ€‹\n(\nT\n;\nÎ±\n)\n)\nâ©½\n0\n\\psi\\bigl(x(T;\\alpha)\\bigr)\\leqslant 0\nfor all\nÎ±\nâˆˆ\nğ–¯\n\\alpha\\in\\mathsf{P}\n, where\nÏˆ\n:\nâ„\nd\nâŸ¶\nâ„\n\\psi:\\mathbb{R}^{d}\\longrightarrow\\mathbb{R}\nis continuously differentiable and convex function.\nThe process\n(\nu\nâ€‹\n(\nâ‹…\n)\n,\n{\nx\nâ€‹\n(\nâ‹…\n;\nÎ±\n)\n|\nÎ±\nâˆˆ\nğ–¯\n}\n)\n\\bigl(u(\\cdot),\\{x(\\cdot;\\alpha)\\;|\\;\\alpha\\in\\mathsf{P}\\}\\bigr)\nis\nfeasible\nif\nt\nâ†¦\nu\nâ€‹\n(\nt\n)\nâˆˆ\nğ•Œ\nt\\mapsto u(t)\\in\\mathbb{U}\nand\nx\nâ€‹\n(\nT\n;\nÎ±\n)\nâˆˆ\nC\nx(T;\\alpha)\\in C\nfor all\nÎ±\nâˆˆ\nğ–¯\n\\alpha\\in\\mathsf{P}\n. Define the support for the control trajectory by\nsupp\nâ€‹\n(\nu\n)\nâ‰”\n{\nt\nâˆˆ\n[\n0\n,\nT\n]\n|\nu\nâ€‹\n(\nt\n)\nâ‰ \n0\n}\n.\n\\displaystyle\\text{supp}(u)\\coloneqq\\big\\{t\\in[0,T]\\;|\\;u(t)\\neq 0\\big\\}.\nThen the\nL\n0\n{L}^{0}\n-norm of\nu\nâ€‹\n(\nâ‹…\n)\nu(\\cdot)\nis given by\n((6))\nâ€–\nu\nâ€‹\n(\nâ‹…\n)\nâ€–\n0\nâ‰”\nÎ¼\nâ€‹\n(\nsupp\nâ€‹\n(\nu\n)\n)\n=\nâˆ«\n0\nT\n|\nu\nâ€‹\n(\nt\n)\n|\n0\nâ€‹\nd\nâ€‹\nt\n,\n\\displaystyle\\|u(\\cdot)\\|_{0}\\coloneqq\\mu\\bigl(\\text{supp}(u)\\bigr)=\\int_{0}^{T}\\left\\lvert{u(t)}\\right\\rvert^{0}\\mathop{}\\!\\mathrm{d}t,\nwhere the zero exponent is defined by\nz\n0\nâ‰”\n1\nz^{0}\\coloneqq 1\nif\nz\nâ‰ \n0\nz\\neq 0\nand\n0\nif\nz\n=\n0\nz=0\n.\n1\n1\n1\nNote that\nâ€–\nu\nâ€‹\n(\nâ‹…\n)\nâ€–\n0\n\\left\\lVert u(\\cdot)\\right\\rVert_{0}\ndoes not satisfy the absolute homogeneous property and thus, technically, its a semi-norm.\nThus\nâ€–\nu\nâ€‹\n(\nâ‹…\n)\nâ€–\n0\n\\left\\lVert u(\\cdot)\\right\\rVert_{0}\nis the time length over which the function\nu\nâ€‹\n(\nâ‹…\n)\nu(\\cdot)\nadmits nonzero values. Over the set of feasible controls, we consider the\nL\n0\n{L}^{0}\nrobust optimal control problem\nwhich is the central object of this article:\n{myOCP}\n((7))\ninf\nu\nâ€‹\n(\nâ‹…\n)\n\\displaystyle\\inf_{u(\\cdot)}\nğ’¥\n0\nâ€‹\n(\nu\nâ€‹\n(\nâ‹…\n)\n)\nâ‰”\nâ€–\nu\nâ€–\n0\n=\nâˆ«\n0\nT\n|\nu\nâ€‹\n(\nt\n)\n|\n0\nâ€‹\nd\nâ€‹\nt\n\\displaystyle\\mathcal{J}_{0}\\bigl(u(\\cdot)\\bigr)\\coloneqq\\left\\lVert u\\right\\rVert_{0}=\\int_{0}^{T}\\left\\lvert{u(t)}\\right\\rvert^{0}\\mathop{}\\!\\mathrm{d}t\nsubject\nâ€‹\nto\n\\displaystyle\\operatorname{subject\\ to}\n{\ndynamics\nâ€‹\n(\n(5)\n)\n,\nx\nâ€‹\n(\n0\n;\nÎ±\n)\n=\nx\nÂ¯\n,\nu\nâ€‹\n(\nt\n)\nâˆˆ\nğ•Œ\nâ€‹\nfor a.e\nâ€‹\nt\nâˆˆ\n[\n0\n,\nT\n]\n,\nx\nâ€‹\n(\nT\n;\nÎ±\n)\nâˆˆ\nC\nâ€‹\nfor all\nâ€‹\nÎ±\nâˆˆ\nğ–¯\n.\n\\displaystyle\nThis is the robust version of the typical setting of the maximum hands-off control paradigm in the nominal noiseless/uncertainty-free scenario, where the final objective is to obtain a\nsparse\noptimal control that drives the final state to zero, satisfying all the constraints. Our setting is more challenging: in the presence of uncertainties, and a possible uncountable family of constraints, steering the final state to zero is not practical and thus the OCP (\n(7)\n) considers steering\nx\nâ€‹\n(\nT\n;\nÎ±\n)\nx(T;\\alpha)\nto a prespecified set for all possible realizations of the uncertainty\nÎ±\nâˆˆ\nğ–¯\n\\alpha\\in\\mathsf{P}\n.\n2.1.\nRelaxation\nThe optimization problem (\n(7)\n) is an infinite-dimensional, nonsmooth, and nonconvex robust optimization problem with an uncountable family of constraints, rendering it extremely challenging to solve numerically.\nFollowing the standard approach of the literature on nominal maximum hands-off control\n[\nNag20\n,\nNQN15\n,\nNag23\n,\nIK19\n]\n, we relax the problem (\n(7)\n) into an\nL\n1\n{L}^{1}\nrobust optimal control problem to enable further analysis. This approach also facilitates the use of a broad spectrum of techniques from robust and semi-infinite optimization. With this motivation, consider the relaxed\nL\n1\n{L}^{1}\nrobust optimal control problem\n:\n{myOCP}\n((8))\ninf\nu\nâ€‹\n(\nâ‹…\n)\n\\displaystyle\\inf_{u(\\cdot)}\nğ’¥\n1\nâ€‹\n(\nu\nâ€‹\n(\nâ‹…\n)\n)\nâ‰”\nâ€–\nu\nâ€‹\n(\nâ‹…\n)\nâ€–\nL\n1\n=\nâˆ«\n0\nT\n|\nu\nâ€‹\n(\nt\n)\n|\nâ€‹\nd\nâ€‹\nt\n\\displaystyle\\mathcal{J}_{1}\\bigl(u(\\cdot)\\bigr)\\coloneqq\\left\\lVert u(\\cdot)\\right\\rVert_{{L}^{1}}=\\int_{0}^{T}\\left\\lvert{u(t)}\\right\\rvert\\mathop{}\\!\\mathrm{d}t\nsubject\nâ€‹\nto\n\\displaystyle\\operatorname{subject\\ to}\n{\ndynamics\nâ€‹\n(\n(5)\n)\n,\nx\nâ€‹\n(\n0\n;\nÎ±\n)\n=\nx\nÂ¯\n,\nu\nâ€‹\n(\nt\n)\nâˆˆ\nğ•Œ\nâ€‹\nfor a.e\nâ€‹\nt\nâˆˆ\n[\n0\n,\nT\n]\n,\nx\nâ€‹\n(\nT\n;\nÎ±\n)\nâˆˆ\nC\nâ€‹\nfor all\nâ€‹\nÎ±\nâˆˆ\nğ–¯\n.\n\\displaystyle\nThe optimal control problem (\n(8)\n) is an infinite-dimensional robust optimization problem. In our main results in Â§\n3\n, we present a series of theoretical results addressing the existence of solutions, necessary optimality conditions, equivalence properties, and an algorithmic framework designed to compute sparse control actions efficiently and with numerical viability.\n3.\nMain results\nOur main results are divided into two major parts: (a)\nTheoretical developments\nand (b)\nAlgorithmic developments\n.\nâˆ˜\n\\circ\nOn the theoretical front, we show the existence of optimal solutions to the OCP (\n(8)\n) and consequently we derive a robust (minmax) Pontryagin-type Maximum Principle. We demonstrate that under standard assumptions, the optimal control exhibits a bang-off-bang structure. Subsequently, we prove that the set of optimal solutions for the OCP (\n(8)\n) is equivalent to that of the OCP (\n(7)\n), establishing the equivalence of the two problems.\nâˆ˜\n\\circ\nOn the algorithmic front, by exploiting the established equivalence and demonstrating that (\n(8)\n) is a convex semi-infinite program, we establish an algorithmic framework to solve (\n(8)\n) (and, consequently, (\n(7)\n)) in an\nexact fashion\n.\n3.1.\nTheoretical development: maximum principle and equivalence\nWe present our main results in the following sequence:\nâˆ˜\n\\circ\nWe begin by showing an existence result for the\nL\n1\n{L}^{1}\nrobust OCP (\n(8)\n); this is documented in Theorem\n3.1\n.\nâˆ˜\n\\circ\nWe establish a robust Pontryagin-type maximum principle for the\nL\n1\n{L}^{1}\nrobust OCP (\n(8)\n). Our primary tool relies on a nonsmooth robust maximum principle from\n[\nVin05\n]\n. This is documented in Theorem\n3.2\n.\nâˆ˜\n\\circ\nUsing the structure of the control obtained from Theorem\n3.2\n, we show that under some additional hypothesis on the problem data\nL\n1\n{L}^{1}\noptimal controls admit a bang-off-bang-type representation. This is documented in Corollary\n3.4\n.\nâˆ˜\n\\circ\nFinally, leveraging these results, we establish that the OCPs (\n(7)\n) and (\n(8)\n) are equivalent in the sense that the set of optimal solutions of the\nL\n0\n{L}^{0}\nproblem and the\nL\n1\n{L}^{1}\nproblem are identical. The result is given in Theorem\n3.6\n.\n\\lxSVG@picture\nThe Robust\nL\n0\n{L}^{0}\nProblem\nThe Robust\nL\n1\n{L}^{1}\nProblem\nRobust PMP\n(Theorem\n3.2\n)\nExistence of\nL\n1\n{L}^{1}\nSolutions\n(Theorem\n3.1\n)\nBang-Off-Bang\nStructure\n(Corollary\n3.4\n)\nL\n0\n/\nL\n1\n{L}^{0}/{L}^{1}\nEquivalence\n(Theorem\n3.6\n)\nRelaxation\n\\endlxSVG@picture\nFigure 1\n.\nRoadmap of the robust hands-off synthesis. The original OCPÂ (\n(7)\n), featuring an\nL\n0\n{L}^{0}\nobjective and semi-infinite uncertainty constraints, is reduced â€” via the\nL\n0\n{L}^{0}\nâ€“\nL\n1\n{L}^{1}\nequivalence (Theorem\n3.2\nand Theorem\n3.6\n, under the conditions of Corollary\n3.4\n) â€” to a convex robust\nL\n1\n{L}^{1}\nformulation. For practical implementation, in Â§\n3.2\n, after performing piecewise constant control parametrization, the problem is further transformed into a finite-dimensional convex semi-infinite programÂ (\n(54)\n), which is then addressed using tools from robust optimization.\nWe begin with the existence theorem.\n{myOCP}\nTheorem 3.1\n.\nConsider the optimal control problems (\n(7)\n)â€“(\n(8)\n) along with their data\n((\n(5)\n)-a)\nâ€“\n((\n(5)\n)-c)\n. Define the set of admissible control actions\n((11))\nğ’°\nad\nâ‰”\n{\nu\n(\nâ‹…\n)\nâˆˆ\nL\nâˆ\n(\n[\n0\n,\nT\n]\n;\nâ„\n)\n|\nu\nâ€‹\n(\nt\n)\nâˆˆ\nğ•Œ\nâ€‹\nfor a.e.\nâ€‹\nt\nâˆˆ\n[\n0\n,\nT\n]\nâ€‹\nand\nÏˆ\nâ€‹\n(\nx\nâ€‹\n(\nT\n;\nÎ±\n)\n)\nâ©½\n0\nâ€‹\nfor all\nâ€‹\nÎ±\nâˆˆ\nğ–¯\n}\n.\n\\displaystyle\\mathcal{U}_{\\text{ad}}\\coloneqq\\left\\{u(\\cdot)\\in{L}^{\\infty}([0,T];\\mathbb{R})\\;\\middle|\\;\\begin{array}[]{@{}l@{}}u(t)\\in\\mathbb{U}\\text{ for a.e. }t\\in[0,T]\\text{ and }\\\\\n\\psi\\bigl(x(T;\\alpha)\\bigr)\\leqslant 0\\text{ for all }\\alpha\\in\\mathsf{P}\\end{array}\\right\\}.\nNote that for a given\nÎ±\nâˆˆ\nğ–¯\n\\alpha\\in\\mathsf{P}\nand\nx\nâ€‹\n(\n0\n;\nÎ±\n)\n=\nx\nÂ¯\nx(0;\\alpha)=\\overline{x}\n, by\nx\nu\nâ€‹\n(\nT\n;\nÎ±\n)\nx_{u}(T;\\alpha)\nwe denote the state trajectory of the ODE (\n(5)\n), under the control action\nu\nâ€‹\n(\nâ‹…\n)\nu(\\cdot)\n, evaluated at time\nT\nT\n.\n2\n2\n2\nThe state trajectory at\nt\n=\nT\nt=T\nis given by (employing Duhamelâ€™s formula)\n((12))\nx\nu\nâ€‹\n(\nT\n,\nÎ±\n)\nâ‰”\ne\nA\nâ€‹\n(\nÎ±\n)\nâ€‹\nT\nâ€‹\nx\nÂ¯\n+\nâˆ«\n0\nT\ne\nA\nâ€‹\n(\nÎ±\n)\nâ€‹\n(\ns\nâˆ’\nT\n)\nâ€‹\nb\nâ€‹\n(\nÎ±\n)\nâ€‹\nu\nâ€‹\n(\ns\n)\nâ€‹\nd\nâ€‹\ns\nâ‰•\nğ–¤\nx\nÂ¯\n,\nT\n,\nÎ±\nâ€‹\n(\nu\nâ€‹\n(\nâ‹…\n)\n)\n,\n\\displaystyle x_{u}(T,\\alpha)\\coloneqq\\mathrm{e}^{A(\\alpha)T}\\overline{x}+\\int_{0}^{T}\\mathrm{e}^{A(\\alpha)(s-T)}b(\\alpha)u(s)\\mathop{}\\!\\mathrm{d}s\\eqqcolon\\mathsf{E}_{\\overline{x},T,\\alpha}(u(\\cdot)),\nwhere the quantity\nğ–¤\nx\nÂ¯\n,\nT\n,\nÎ±\nâ€‹\n(\nu\nâ€‹\n(\nâ‹…\n)\n)\n\\mathsf{E}_{\\overline{x},T,\\alpha}(u(\\cdot))\nis the\nend-point mapping\n; see\n[\nTrÃ©24\n, Definition 1.1]\n.\nLet\nğ’°\nad\n\\mathcal{U}_{\\text{ad}}\nbe nonempty, then the OCP (\n(8)\n) admits a solution.\nProof.\nWe provide a proof using the direct method in the calculus of variations\n[\nSan23\n, Chapter 3]\n. Define\n((13))\nğ–©\nâˆ—\nâ‰”\ninf\nu\nâ€‹\n(\nâ‹…\n)\nâˆˆ\nğ’°\nad\nğ’¥\n1\nâ€‹\n(\nu\nâ€‹\n(\nâ‹…\n)\n)\n,\n\\displaystyle{\\mathsf{J}}^{\\ast}\\coloneqq\\inf_{u(\\cdot)\\in\\mathcal{U}_{\\text{ad}}}\\mathcal{J}_{1}\\bigl(u(\\cdot)\\bigr),\nand note that since the admissible set\nğ’°\nad\n\\mathcal{U}_{\\text{ad}}\nis nonempty\nğ–©\nâˆ—\n<\n+\nâˆ\n.\n{\\mathsf{J}}^{\\ast}<+\\infty.\nThen, by definition of the infimum there exists a\nminimizing sequence\n(\nu\nk\nâ€‹\n(\nâ‹…\n)\n)\nk\nâˆˆ\nâ„•\nâˆ—\nâŠ‚\nğ’°\nad\n\\bigl(u_{k}(\\cdot)\\bigr)_{k\\in\\mathbb{N}^{*}}\\subset\\mathcal{U}_{\\text{ad}}\nsuch that\nlim\nk\nâŸ¶\n+\nâˆ\nğ’¥\n1\nâ€‹\n(\nu\nk\nâ€‹\n(\nâ‹…\n)\n)\n=\nğ–©\nâˆ—\n\\lim_{k\\longrightarrow+\\infty}\\mathcal{J}_{1}\\bigl(u_{k}(\\cdot)\\bigr)={\\mathsf{J}}^{\\ast}\n. Moreover, by definition\n(\nu\nk\nâ€‹\n(\nâ‹…\n)\n)\nk\nâˆˆ\nâ„•\nâˆ—\nâŠ‚\nğ–¡\nâˆ\nâ‰”\n{\nÎ¼\nâ€‹\n(\nâ‹…\n)\nâˆˆ\nL\nâˆ\nâ€‹\n(\n[\n0\n,\nT\n]\n;\nâ„\n)\n|\nâ€–\nÎ¼\nâ€‹\n(\nâ‹…\n)\nâ€–\nâˆ\nâ©½\n1\n}\n.\n\\bigl(u_{k}(\\cdot)\\bigr)_{k\\in\\mathbb{N}^{*}}\\subset\\mathsf{B}_{\\infty}\\coloneqq\\big\\{\\mu(\\cdot)\\in{L}^{\\infty}\\bigl([0,T];\\mathbb{R}\\bigr)\\;|\\;\\left\\lVert\\mu(\\cdot)\\right\\rVert_{\\infty}\\leqslant 1\\big\\}.\nThe celebrated Banach-Alaoglu theorem\n[\nCla13\n, Theorem 3.14]\nstates that the closed unit ball of the dual of a given Banach space is sequentially compact in the weak\nâˆ—\ntopology\n[\nCla13\n, Â§3.3]\n. Since\nL\nâˆ\nâ€‹\n(\n[\n0\n,\nT\n]\n;\nâ„\n)\n{L}^{\\infty}\\bigl([0,T];\\mathbb{R}\\bigr)\nis the dual of the separable space\nL\n1\nâ€‹\n(\n[\n0\n,\nT\n]\n;\nâ„\n)\n{L}^{1}\\bigl([0,T];\\mathbb{R}\\bigr)\n, this theorem applies. Therefore, there exists a subsequence (which we do not relabel for simplicity) and a mapping\nu\n^\nâ€‹\n(\nâ‹…\n)\nâˆˆ\nL\nâˆ\nâ€‹\n(\n[\n0\n,\nT\n]\n;\nâ„\n)\n\\widehat{u}(\\cdot)\\in{L}^{\\infty}\\bigl([0,T];\\mathbb{R}\\bigr)\nwith\nâ€–\nu\n^\nâ€‹\n(\nâ‹…\n)\nâ€–\nâˆ\nâ©½\n1\n\\left\\lVert\\widehat{u}(\\cdot)\\right\\rVert_{\\infty}\\leqslant 1\nsuch that\n3\n3\n3\nIn our setting, admissible controls satisfy\nu\nâ€‹\n(\nâ‹…\n)\nâˆˆ\nL\nâˆ\nâ€‹\n(\n[\n0\n,\nT\n]\n;\nâ„\n)\nwith\nâ€‹\nu\nâ€‹\n(\nt\n)\nâˆˆ\nğ•Œ\nâ€‹\nfor a.e.\nâ€‹\nt\nâˆˆ\n[\n0\n,\nT\n]\n.\nu(\\cdot)\\in{L}^{\\infty}([0,T];\\mathbb{R})\\quad\\text{with }\\,u(t)\\in\\mathbb{U}\\text{ for a.e. }t\\in[0,T].\nThe key functional-analytic facts we use are:\nâˆ˜\n\\circ\nL\nâˆ\nâ€‹\n(\n[\n0\n,\nT\n]\n;\nâ„\n)\n{L}^{\\infty}([0,T];\\mathbb{R})\nis (isometrically) the dual of the separable Banach space\nL\n1\nâ€‹\n(\n[\n0\n,\nT\n]\n;\nâ„\n)\n{L}^{1}([0,T];\\mathbb{R})\n[\nCla13\n, Chapter 5 and Chapter 6, Theorem 6.10]\n;\nâˆ˜\n\\circ\nthe closed unit ball in\nL\nâˆ\nâ€‹\n(\n[\n0\n,\nT\n]\n;\nâ„\n)\n{L}^{\\infty}([0,T];\\mathbb{R})\nis therefore sequentially weak\nâˆ—\n-compact by the Banachâ€“Alaoglu theorem\n[\nCla13\n, Chapter 3, Theorem 3.14 and Chapter 6]\n.\nWe provide the definition of weak\nâˆ—\nconvergence in\nL\nâˆ\nâ€‹\n(\n[\n0\n,\nT\n]\n;\nâ„\n)\n{L}^{\\infty}([0,T];\\mathbb{R})\n[\nCla13\n, Chapter 3]\n): A sequence\n(\nu\nk\nâ€‹\n(\nâ‹…\n)\n)\nk\nâˆˆ\nâ„•\nâˆ—\nâŠ‚\nL\nâˆ\nâ€‹\n(\n[\n0\n,\nT\n]\n;\nâ„\n)\n\\bigl(u_{k}(\\cdot)\\bigr)_{k\\in\\mathbb{N}^{*}}\\subset{L}^{\\infty}([0,T];\\mathbb{R})\nconverges to\nu\nÂ¯\nâ€‹\n(\nâ‹…\n)\nâˆˆ\nL\nâˆ\nâ€‹\n(\n[\n0\n,\nT\n]\n;\nâ„\n)\n\\bar{u}(\\cdot)\\in{L}^{\\infty}([0,T];\\mathbb{R})\nin the\nweak\nâˆ—\n-sense\nif\nâˆ«\n0\nT\nu\nk\nâ€‹\n(\nt\n)\nâ€‹\nf\nâ€‹\n(\nt\n)\nâ€‹\nğ‘‘\nt\nâŸ¶\nâˆ«\n0\nT\nu\nÂ¯\nâ€‹\n(\nt\n)\nâ€‹\nf\nâ€‹\n(\nt\n)\nâ€‹\nğ‘‘\nt\nfor every\nâ€‹\nf\nâ€‹\n(\nâ‹…\n)\nâˆˆ\nL\n1\nâ€‹\n(\n[\n0\n,\nT\n]\n;\nâ„\n)\nâ€‹\nas\nâ€‹\nk\nâŸ¶\n+\nâˆ\n.\n\\int_{0}^{T}u_{k}(t)f(t)\\,dt\\;\\longrightarrow\\;\\int_{0}^{T}\\bar{u}(t)f(t)\\,dt\\quad\\text{for every }f(\\cdot)\\in L^{1}([0,T];\\mathbb{R})\\text{ as }k\\longrightarrow+\\infty.\nu\nk\nâ€‹\n(\nâ‹…\n)\nâ†’\nweak\nâˆ—\nu\n^\nâ€‹\n(\nâ‹…\n)\nin\nâ€‹\nL\nâˆ\nâ€‹\n(\n[\n0\n,\nT\n]\n;\nâ„\n)\n,\nu_{k}(\\cdot)\\xrightarrow{\\text{weak}^{*}}\\widehat{u}(\\cdot)\\quad\\text{in }{L}^{\\infty}\\bigl([0,T];\\mathbb{R}\\bigr),\nwhich implies that for any\nf\nâ€‹\n(\nâ‹…\n)\nâˆˆ\nL\n1\nâ€‹\n(\n[\n0\n,\nT\n]\n;\nâ„\n)\nf(\\cdot)\\in{L}^{1}\\bigl([0,T];\\mathbb{R}\\bigr)\n, we have\n((14))\nâˆ«\n0\nT\nu\nk\nâ€‹\n(\nt\n)\nâ€‹\nf\nâ€‹\n(\nt\n)\nâ€‹\nd\nâ€‹\nt\nâ†’\nk\nâŸ¶\n+\nâˆ\nâˆ«\n0\nT\nu\n^\nâ€‹\n(\nt\n)\nâ€‹\nf\nâ€‹\n(\nt\n)\nâ€‹\nd\nâ€‹\nt\n.\n\\displaystyle\\int_{0}^{T}u_{k}(t)f(t)\\mathop{}\\!\\mathrm{d}t\\xrightarrow{k\\longrightarrow+\\infty}\\int_{0}^{T}\\widehat{u}(t)f(t)\\mathop{}\\!\\mathrm{d}t.\nWe show convergence of the state trajectories. Fix\nÎ±\nâˆˆ\nğ–¯\n\\alpha\\in\\mathsf{P}\nand define\n((15))\nf\nk\nâ€‹\n(\nÎ±\n)\nâ‰”\nx\nu\nk\nâ€‹\n(\nT\n;\nÎ±\n)\n=\ne\nA\nâ€‹\n(\nÎ±\n)\nâ€‹\nT\nâ€‹\nx\nÂ¯\n+\nâˆ«\n0\nT\ne\nA\nâ€‹\n(\nÎ±\n)\nâ€‹\n(\nT\nâˆ’\ns\n)\nâ€‹\nb\nâ€‹\n(\nÎ±\n)\nâ€‹\nu\nk\nâ€‹\n(\ns\n)\nâ€‹\nd\nâ€‹\ns\n.\n\\displaystyle f_{k}(\\alpha)\\coloneqq x_{u_{k}}(T;\\alpha)=\\mathrm{e}^{A(\\alpha)T}\\overline{x}+\\int_{0}^{T}\\mathrm{e}^{A(\\alpha)(T-s)}b(\\alpha)u_{k}(s)\\mathop{}\\!\\mathrm{d}s.\nPointwise convergence for fixed\nÎ±\nâˆˆ\nğ–¯\n\\alpha\\in\\mathsf{P}\nfollows easily; indeed: the function\ns\nâ†¦\ne\nA\nâ€‹\n(\nÎ±\n)\nâ€‹\n(\nT\nâˆ’\ns\n)\nâ€‹\nb\nâ€‹\n(\nÎ±\n)\ns\\mapsto\\mathrm{e}^{A(\\alpha)(T-s)}b(\\alpha)\nis a continuous function defined on a compact interval\n[\n0\n,\nT\n]\n[0,T]\nand thus it is integrable. By the definition of weak\nâˆ—\nconvergence we see that\n((16))\nlim\nk\nâŸ¶\n+\nâˆ\nâˆ«\n0\nT\ne\nA\nâ€‹\n(\nÎ±\n)\nâ€‹\n(\nT\nâˆ’\ns\n)\nâ€‹\nb\nâ€‹\n(\nÎ±\n)\nâ€‹\nu\nk\nâ€‹\n(\ns\n)\nâ€‹\nd\nâ€‹\ns\n=\nâˆ«\n0\nT\ne\nA\nâ€‹\n(\nÎ±\n)\nâ€‹\n(\nT\nâˆ’\ns\n)\nâ€‹\nb\nâ€‹\n(\nÎ±\n)\nâ€‹\nu\n^\nâ€‹\n(\ns\n)\nâ€‹\nd\nâ€‹\ns\n.\n\\displaystyle\\lim_{k\\longrightarrow+\\infty}\\int_{0}^{T}\\mathrm{e}^{A(\\alpha)(T-s)}b(\\alpha)u_{k}(s)\\mathop{}\\!\\mathrm{d}s=\\int_{0}^{T}\\mathrm{e}^{A(\\alpha)(T-s)}b(\\alpha)\\widehat{u}(s)\\mathop{}\\!\\mathrm{d}s.\nThus, for fixed\nÎ±\nâˆˆ\nğ–¯\n\\alpha\\in\\mathsf{P}\nwe have\n((17))\nf\nk\nâ€‹\n(\nÎ±\n)\n=\nx\nu\nk\nâ€‹\n(\nT\n;\nÎ±\n)\nâ†’\nk\nâŸ¶\n+\nâˆ\nx\nu\n^\nâ€‹\n(\nT\n;\nÎ±\n)\nâ‰•\nf\n^\nâ€‹\n(\nÎ±\n)\n.\n\\displaystyle f_{k}(\\alpha)=x_{u_{k}}(T;\\alpha)\\xrightarrow{k\\longrightarrow+\\infty}x_{\\widehat{u}}(T;\\alpha)\\eqqcolon\\widehat{f}(\\alpha).\nTo show this convergence is\nuniform\non\nğ–¯\n\\mathsf{P}\n, we need to invoke the Arzela-Ascoli theorem, and to this end, we check if the family\n(\nf\nk\n)\nk\nâˆˆ\nâ„•\nâˆ—\n(f_{k})_{k\\in\\mathbb{N}^{*}}\nis uniformly bounded and equicontinuous. Uniform boundedness follows immediately because\nğ–¯\nâˆ‹\nÎ±\nâ†¦\nA\nâ€‹\n(\nÎ±\n)\n\\mathsf{P}\\ni\\alpha\\mapsto A(\\alpha)\nand\nğ–¯\nâˆ‹\nÎ±\nâ†¦\nb\nâ€‹\n(\nÎ±\n)\n\\mathsf{P}\\ni\\alpha\\mapsto b(\\alpha)\nare continuous on the compact set\nğ–¯\n\\mathsf{P}\nand\nâ€–\nu\nk\nâ€‹\n(\nâ‹…\n)\nâ€–\nâˆ\nâ©½\n1\n\\left\\lVert u_{k}(\\cdot)\\right\\rVert_{\\infty}\\leqslant 1\n. To show equicontinuity, we show\n[\nRud87\n, Chapter 11, Definition 11.27]\nthat for all\nÎµ\n>\n0\n\\varepsilon>0\n, there exists\nÎ´\n>\n0\n\\delta>0\n, for any\nÎ±\n1\n,\nÎ±\n2\nâˆˆ\nğ–¯\n\\alpha_{1},\\alpha_{2}\\in\\mathsf{P}\nwith\nâ€–\nÎ±\n1\nâˆ’\nÎ±\n2\nâ€–\n<\nÎµ\n\\left\\lVert\\alpha_{1}-\\alpha_{2}\\right\\rVert<\\varepsilon\n,\nâ€–\nf\nk\nâ€‹\n(\nÎ±\n1\n)\nâˆ’\nf\nk\nâ€‹\n(\nÎ±\n2\n)\nâ€–\n<\nÎµ\n\\left\\lVert f_{k}(\\alpha_{1})-f_{k}(\\alpha_{2})\\right\\rVert<\\varepsilon\n. Observe that\nâ€–\nf\nk\nâ€‹\n(\nÎ±\n1\n)\nâˆ’\nf\nk\nâ€‹\n(\nÎ±\n2\n)\nâ€–\n\\displaystyle\\left\\lVert f_{k}(\\alpha_{1})-f_{k}(\\alpha_{2})\\right\\rVert\nâ©½\nâ€–\ne\nA\nâ€‹\n(\nÎ±\n1\n)\nâ€‹\nT\nâˆ’\ne\nA\nâ€‹\n(\nÎ±\n2\n)\nâ€‹\nT\nâ€–\nâ€‹\nâ€–\nx\nÂ¯\nâ€–\n\\displaystyle\\leqslant\\left\\lVert\\mathrm{e}^{A(\\alpha_{1})T}-\\mathrm{e}^{A(\\alpha_{2})T}\\right\\rVert\\left\\lVert\\overline{x}\\right\\rVert\n((18))\n+\nâˆ«\n0\nT\nâ€–\ne\nA\nâ€‹\n(\nÎ±\n1\n)\nâ€‹\n(\nT\nâˆ’\ns\n)\nâ€‹\nb\nâ€‹\n(\nÎ±\n1\n)\nâˆ’\ne\nA\nâ€‹\n(\nÎ±\n2\n)\nâ€‹\n(\nT\nâˆ’\ns\n)\nâ€‹\nb\nâ€‹\n(\nÎ±\n2\n)\nâ€–\nâ€‹\nd\nâ€‹\ns\n\\displaystyle+\\int_{0}^{T}\\left\\lVert\\mathrm{e}^{A(\\alpha_{1})(T-s)}b(\\alpha_{1})-\\mathrm{e}^{A(\\alpha_{2})(T-s)}b(\\alpha_{2})\\right\\rVert\\mathop{}\\!\\mathrm{d}s\nfor\ns\nâˆˆ\n[\n0\n,\nT\n]\ns\\in[0,T]\n. Since\nÎ±\nâ†¦\ne\nA\nâ€‹\n(\nÎ±\n)\nâ€‹\nT\n\\alpha\\mapsto\\mathrm{e}^{A(\\alpha)T}\nand\nÎ±\nâ†¦\ne\nA\nâ€‹\n(\nÎ±\n)\nâ€‹\n(\nT\nâˆ’\ns\n)\nâ€‹\nb\nâ€‹\n(\nÎ±\n)\n\\alpha\\mapsto\\mathrm{e}^{A(\\alpha)(T-s)}b(\\alpha)\nare uniformly continuous on\nğ–¯\n\\mathsf{P}\n, for any\n0\n<\nÎµ\nâ€²\nâ‰”\nÎµ\nâ€–\nx\nÂ¯\nâ€–\n+\nT\n0<\\varepsilon^{\\prime}\\coloneqq\\frac{\\varepsilon}{\\left\\lVert\\overline{x}\\right\\rVert+T}\n, there exists a\nÎ´\n>\n0\n\\delta>0\nsuch that with\nâ€–\nÎ±\n1\nâˆ’\nÎ±\n2\nâ€–\n<\nÎ´\n\\left\\lVert\\alpha_{1}-\\alpha_{2}\\right\\rVert<\\delta\nwe have\nâ€–\ne\nA\nâ€‹\n(\nÎ±\n1\n)\nâ€‹\nT\nâˆ’\ne\nA\nâ€‹\n(\nÎ±\n2\n)\nâ€‹\nT\nâ€–\n<\nÎµ\nâ€²\n\\left\\lVert\\mathrm{e}^{A(\\alpha_{1})T}-\\mathrm{e}^{A(\\alpha_{2})T}\\right\\rVert<\\varepsilon^{\\prime}\nand\nâ€–\ne\nA\nâ€‹\n(\nÎ±\n1\n)\nâ€‹\n(\nT\nâˆ’\ns\n)\nâ€‹\nb\nâ€‹\n(\nÎ±\n1\n)\nâˆ’\ne\nA\nâ€‹\n(\nÎ±\n2\n)\nâ€‹\n(\nT\nâˆ’\ns\n)\nâ€‹\nb\nâ€‹\n(\nÎ±\n2\n)\nâ€–\n<\nÎµ\nâ€²\n\\left\\lVert\\mathrm{e}^{A(\\alpha_{1})(T-s)}b(\\alpha_{1})-\\mathrm{e}^{A(\\alpha_{2})(T-s)}b(\\alpha_{2})\\right\\rVert<\\varepsilon^{\\prime}\nfor all\ns\nâˆˆ\n[\n0\n,\nT\n]\ns\\in[0,T]\n. Consequently,\n((19))\nâ€–\nf\nk\nâ€‹\n(\nÎ±\n1\n)\nâˆ’\nf\nk\nâ€‹\n(\nÎ±\n2\n)\nâ€–\nâ©½\nÎµ\nâ€²\nâ€‹\n(\nâ€–\nx\nÂ¯\nâ€–\n+\nT\n)\n=\nÎµ\n.\n\\displaystyle\\left\\lVert f_{k}(\\alpha_{1})-f_{k}(\\alpha_{2})\\right\\rVert\\leqslant\\varepsilon^{\\prime}\\bigl(\\left\\lVert\\overline{x}\\right\\rVert+T\\bigr)=\\varepsilon.\nThus, the family\n(\nf\nk\n)\nk\nâˆˆ\nâ„•\nâˆ—\n(f_{k})_{k\\in\\mathbb{N}^{*}}\nis uniformly bounded and equicontinuous on\nğ–¯\n\\mathsf{P}\n; and consequently, by Arzela-Ascoli theorem\n[\nRud87\n, Chapter 11, Theorem 11.28]\nthere exists a subsequence (not relabeled) such that\nf\nk\nâ†’\nf\n^\nf_{k}\\to\\widehat{f}\nuniformly on\nğ–¯\n\\mathsf{P}\n, where the limit\nf\n^\nâ€‹\n(\nÎ±\n)\n=\nx\nu\n^\nâ€‹\n(\nT\n;\nÎ±\n)\n\\widehat{f}(\\alpha)=x_{\\widehat{u}}(T;\\alpha)\nis the pointwise limit given by (\n(17)\n).\nWe are now ready to show that\nu\n^\nâ€‹\n(\nâ‹…\n)\nâˆˆ\nğ’°\nad\n\\widehat{u}(\\cdot)\\in\\mathcal{U}_{\\text{ad}}\n. By definition of the admissible set in (\n(11)\n), for every\nu\nk\nâ€‹\n(\nâ‹…\n)\nâˆˆ\nğ’°\nad\nu_{k}(\\cdot)\\in\\mathcal{U}_{\\text{ad}}\nfor\nk\nâˆˆ\nâ„•\nâˆ—\nk\\in\\mathbb{N}^{*}\n, we have\nÏˆ\nâ€‹\n(\nx\nu\nk\nâ€‹\n(\nT\n;\nÎ±\n)\n)\nâ©½\n0\n\\psi\\bigl(x_{u_{k}}(T;\\alpha)\\bigr)\\leqslant 0\nfor all\nÎ±\nâˆˆ\nğ–¯\n\\alpha\\in\\mathsf{P}\n. We just demonstrated the uniform convergence\nx\nu\nk\nâ€‹\n(\nT\n;\nÎ±\n)\nâ†’\nâˆ¥\nâ‹…\nâˆ¥\nâˆ\nx\nu\n^\nâ€‹\n(\nT\n;\nÎ±\n)\nas\nâ€‹\nk\nâŸ¶\n+\nâˆ\n,\nx_{u_{k}}\\bigl(T;\\alpha\\bigr)\\xrightarrow{\\left\\lVert\\cdot\\right\\rVert_{\\infty}}x_{\\widehat{u}}\\bigl(T;\\alpha\\bigr)\\quad\\text{ as }k\\longrightarrow+\\infty,\nand by design\nÏˆ\nâ€‹\n(\nâ‹…\n)\n\\psi(\\cdot)\nis continuous. Passing to the limit, we get\n((20))\nlim\nk\nâŸ¶\n+\nâˆ\nÏˆ\nâ€‹\n(\nx\nu\nk\nâ€‹\n(\nT\n;\nÎ±\n)\n)\n=\nÏˆ\nâ€‹\n(\nlim\nk\nâŸ¶\n+\nâˆ\nx\nu\nk\nâ€‹\n(\nT\n;\nÎ±\n)\n)\n=\nÏˆ\nâ€‹\n(\nx\nu\n^\nâ€‹\n(\nT\n;\nÎ±\n)\n)\n,\n\\displaystyle\\lim_{k\\longrightarrow+\\infty}\\psi\\bigl(x_{u_{k}}(T;\\alpha)\\bigr)=\\psi\\biggl(\\lim_{k\\longrightarrow+\\infty}x_{u_{k}}(T;\\alpha)\\biggr)=\\psi\\bigl(x_{\\widehat{u}}(T;\\alpha)\\bigr),\nand\nÏˆ\nâ€‹\n(\nx\nu\n^\nâ€‹\n(\nT\n;\nÎ±\n)\n)\nâ©½\n0\n\\psi\\bigl(x_{\\widehat{u}}(T;\\alpha)\\bigr)\\leqslant 0\nfor all\nÎ±\nâˆˆ\nğ–¯\n\\alpha\\in\\mathsf{P}\n. Thus\nu\n^\nâ€‹\n(\nâ‹…\n)\nâˆˆ\nğ’°\nad\n\\widehat{u}(\\cdot)\\in\\mathcal{U}_{\\text{ad}}\n.\nFinally, we show that\nu\n^\nâ€‹\n(\nâ‹…\n)\n\\widehat{u}(\\cdot)\nis an optimal choice. To this end, note that\nu\nâ€‹\n(\nâ‹…\n)\nâ†¦\nğ’¥\n1\nâ€‹\n(\nu\nâ€‹\n(\nâ‹…\n)\n)\nâ‰”\nâˆ«\n0\nT\n|\nu\nâ€‹\n(\nt\n)\n|\nâ€‹\nd\nâ€‹\nt\nu(\\cdot)\\mapsto\\mathcal{J}_{1}\\bigl(u(\\cdot)\\bigr)\\coloneqq\\int_{0}^{T}\\left\\lvert{u(t)}\\right\\rvert\\mathop{}\\!\\mathrm{d}t\nis convex and continuous and thus it is weak\nâˆ—\nlower semicontinuous\n[\nTrÃ¶10\n, Theorem 2.12]\n. Then\n((21))\nğ’¥\n1\nâ€‹\n(\nu\n^\nâ€‹\n(\nâ‹…\n)\n)\nâ©½\nlim inf\nk\nâŸ¶\n+\nâˆ\nğ’¥\n1\nâ€‹\n(\nu\nk\nâ€‹\n(\nâ‹…\n)\n)\n=\nğ–©\nâˆ—\n.\n\\displaystyle\\mathcal{J}_{1}\\bigl(\\widehat{u}(\\cdot))\\leqslant\\liminf_{k\\longrightarrow+\\infty}\\mathcal{J}_{1}\\bigl(u_{k}(\\cdot)\\bigr)={\\mathsf{J}}^{\\ast}.\nHowever,\nu\n^\nâ€‹\n(\nâ‹…\n)\nâˆˆ\nğ’°\nad\n\\widehat{u}(\\cdot)\\in\\mathcal{U}_{\\text{ad}}\nis a feasible control and thus\nğ’¥\n1\nâ€‹\n(\nu\n^\nâ€‹\n(\nâ‹…\n)\n)\nâ©¾\nğ–©\nâˆ—\n\\mathcal{J}_{1}\\bigl(\\widehat{u}(\\cdot)\\bigr)\\geqslant{\\mathsf{J}}^{\\ast}\nwhich implies, together with (\n(21)\n), that\nğ’¥\n1\nâ€‹\n(\nu\n^\nâ€‹\n(\nâ‹…\n)\n)\n=\nğ–©\nâˆ—\n\\mathcal{J}_{1}\\bigl(\\widehat{u}(\\cdot)\\bigr)={\\mathsf{J}}^{\\ast}\n. Thus,\nu\n^\nâ€‹\n(\nâ‹…\n)\n\\widehat{u}(\\cdot)\nis an\nL\n1\n{L}^{1}\noptimal control and the proof is complete.\nâˆ\nWe now establish a robust maximum principle for the OCP (\n(8)\n).\n{myOCP}\nTheorem 3.2\n.\nConsider the optimal control problem (\n(8)\n) along with its data\n((\n(5)\n)-a)\nâ€“\n((\n(5)\n)-c)\n. Let the optimal trajectory-pair\n(\nu\nâˆ—\nâ€‹\n(\nâ‹…\n)\n,\n{\nx\nâˆ—\nâ€‹\n(\nâ‹…\n;\nÎ±\n)\n|\nÎ±\nâˆˆ\nğ–¯\n}\n)\n\\bigl(u^{\\ast}(\\cdot),\\{x^{\\ast}(\\cdot;\\alpha)\\;|\\;\\alpha\\in\\mathsf{P}\\}\\bigr)\nbe a strong local minimizer of (\n(8)\n) and let the hypothesis of Theorem\n3.1\nholds. Then there exists:\n(1)\nA scalar\nÎ·\nâˆˆ\n[\n0\n,\n1\n]\n\\eta\\in[0,1]\n;\n(2)\nA non-negative Radon measure\nÎ›\n\\Lambda\non the compact set\nğ–¯\n\\mathsf{P}\n;\n(3)\nA family of absolutely continuous functions called the costate or adjoint arcs\np\nâ€‹\n(\nâ‹…\n;\nÎ±\n)\nâˆˆ\nW\n1\n,\n1\nâ€‹\n(\n[\n0\n,\nT\n]\n;\nâ„\nd\n)\np(\\cdot;\\alpha)\\in W^{1,1}\\bigl([0,T];\\mathbb{R}^{d}\\bigr)\n, defined for\nÎ›\n\\Lambda\n-a.e.\nÎ±\nâˆˆ\nsupp\nâ€‹\n(\nÎ›\n)\n\\alpha\\in\\mathrm{supp}(\\Lambda)\n,\nsatisfying the following conditions:\n(\n3.2\n-a)\n(Nontriviality) The multipliers are not simultaneously zero and are normalized such that:\nÎ·\n+\nÎ›\nâ€‹\n(\nğ–¯\n)\n=\n1\n.\n\\displaystyle\\eta+\\Lambda(\\mathsf{P})=1.\n(\n3.2\n-b)\n(Adjoint dynamics) For\nÎ›\n\\Lambda\n-a.e.\nÎ±\nâˆˆ\nğ–¯\n\\alpha\\in\\mathsf{P}\n, the costate arc\np\nâ€‹\n(\nâ‹…\n;\nÎ±\n)\np(\\cdot;\\alpha)\nis a solution to the adjoint equation:\nâˆ’\np\nË™\nâ€‹\n(\nt\n;\nÎ±\n)\n=\nA\nâ€‹\n(\nÎ±\n)\nâŠ¤\nâ€‹\np\nâ€‹\n(\nt\n;\nÎ±\n)\nfor a.e.\nâ€‹\nt\nâˆˆ\n[\n0\n,\nT\n]\n.\n\\displaystyle-\\dot{p}(t;\\alpha)=A(\\alpha)^{\\top}p(t;\\alpha)\\quad\\text{for a.e. }t\\in[0,T].\n(\n3.2\n-c)\n(Transversality condition) For\nÎ›\n\\Lambda\n-a.e.\nÎ±\nâˆˆ\nğ–¯\n\\alpha\\in\\mathsf{P}\n, there exists a scalar\nÎ¼\nâ€‹\n(\nÎ±\n)\nâ©¾\n0\n\\mu(\\alpha)\\geqslant 0\nsuch that the final value of the costate is given by:\nâˆ’\np\nâ€‹\n(\nT\n;\nÎ±\n)\n=\nÎ¼\nâ€‹\n(\nÎ±\n)\nâ€‹\nâˆ‡\nÏˆ\nâ€‹\n(\nx\nâˆ—\nâ€‹\n(\nT\n;\nÎ±\n)\n)\n.\n\\displaystyle-p(T;\\alpha)=\\mu(\\alpha)\\nabla\\psi\\bigl(x^{\\ast}(T;\\alpha)\\bigr).\n(\n3.2\n-d)\n(Support and complementarity condition) The measure\nÎ›\n\\Lambda\nis supported on the set of \"worst-case\" parameters for which the terminal constraint is active:\nsupp\nâ€‹\n(\nÎ›\n)\nâŠ‚\n{\nÎ±\nâˆˆ\nğ–¯\n|\nÏˆ\nâ€‹\n(\nx\nâˆ—\nâ€‹\n(\nT\n;\nÎ±\n)\n)\n=\n0\n}\n.\n\\displaystyle\\mathrm{supp}(\\Lambda)\\subset\\big\\{\\alpha\\in\\mathsf{P}\\;\\big|\\;\\psi\\bigl(x^{\\ast}(T;\\alpha)\\bigr)=0\\big\\}.\nMoreover, for every\nÎ±\nâˆˆ\nsupp\nâ€‹\n(\nÎ›\n)\n\\alpha\\in\\mathrm{supp}(\\Lambda)\n,\nÎ¼\nâ€‹\n(\nÎ±\n)\n>\n0\n\\mu(\\alpha)>0\nonly if\nÏˆ\nâ€‹\n(\nx\nâˆ—\nâ€‹\n(\nT\n;\nÎ±\n)\n)\n=\n0\n\\psi\\bigl(x^{\\ast}(T;\\alpha)\\bigr)=0\n.\n(\n3.2\n-e)\n(Hamiltonian maximization condition) For almost every\nt\nâˆˆ\n[\n0\n,\nT\n]\nt\\in[0,T]\n, the optimal control\nu\nâˆ—\nâ€‹\n(\nâ‹…\n)\nu^{\\ast}(\\cdot)\nis a solution to the maximization problem\nu\nâˆ—\nâ€‹\n(\nt\n)\n\\displaystyle u^{\\ast}(t)\nâˆˆ\narg\nâ€‹\nmax\nv\nâˆˆ\nğ•Œ\nâ¡\n(\nâˆ«\nğ–¯\np\nâ€‹\n(\nt\n;\nÎ±\n)\nâŠ¤\nâ€‹\n(\nA\nâ€‹\n(\nÎ±\n)\nâ€‹\nx\nâˆ—\nâ€‹\n(\nt\n;\nÎ±\n)\n+\nb\nâ€‹\n(\nÎ±\n)\nâ€‹\nv\n)\nâ€‹\nÎ›\nâ€‹\n(\nd\nâ€‹\nÎ±\n)\nâˆ’\nÎ·\nâ€‹\n|\nv\n|\n)\n\\displaystyle\\in\\operatorname*{arg\\,max}_{v\\in\\mathbb{U}}\\biggl(\\int_{\\mathsf{P}}p(t;\\alpha)^{\\top}\\bigl(A(\\alpha)x^{\\ast}(t;\\alpha)+b(\\alpha)v\\bigr)\\Lambda(\\mathop{}\\!\\mathrm{d}\\alpha)-\\eta\\left\\lvert{v}\\right\\rvert\\biggr)\n=\narg\nâ€‹\nmax\nv\nâˆˆ\nğ•Œ\nâ¡\n{\nğ’®\nâ€‹\n(\nt\n)\nâ€‹\nv\nâˆ’\nÎ·\nâ€‹\n|\nv\n|\n}\n\\displaystyle=\\operatorname*{arg\\,max}_{v\\in\\mathbb{U}}\\big\\{\\mathcal{S}(t)v-\\eta\\left\\lvert{v}\\right\\rvert\\big\\}\nwhere the averaged switching function\nt\nâ†¦\nğ’®\nâ€‹\n(\nt\n)\nâˆˆ\nâ„\nt\\mapsto\\mathcal{S}(t)\\in\\mathbb{R}\nis defined by\n[\n0\n,\nT\n]\nâˆ‹\nt\nâ†¦\nğ’®\nâ€‹\n(\nt\n)\nâ‰”\nâˆ«\nğ–¯\np\nâ€‹\n(\nt\n;\nÎ±\n)\nâŠ¤\nâ€‹\nb\nâ€‹\n(\nÎ±\n)\nâ€‹\nÎ›\nâ€‹\n(\nd\nâ€‹\nÎ±\n)\nâˆˆ\nâ„\n.\n[0,T]\\ni t\\mapsto\\mathcal{S}(t)\\coloneqq\\int_{\\mathsf{P}}p(t;\\alpha)^{\\top}b(\\alpha)\\Lambda(\\mathop{}\\!\\mathrm{d}\\alpha)\\in\\mathbb{R}.\nThe proof proceeds through four key steps. First, the\nL\n1\n{L}^{1}\nOCP (\n(8)\n) is reformulated to the standard Mayer form. Next, by introducing an artificial parameter, an equivalent minmax formulation is derived. This formulation leverages results from\n[\nVin05\n]\nto establish a set of necessary conditions. Finally, these conditions are refined to obtain the necessary conditions for the OCP given in (\n(8)\n).\nProof.\nWe reformulate the OCP (\n(8)\n), which is in the standard Bolza form, to the Mayer form. Towards this end, we augment the trajectory\nt\nâ†¦\nx\nâ€‹\n(\nt\n)\nâˆˆ\nâ„\nd\nt\\mapsto x(t)\\in\\mathbb{R}^{d}\nwith\nt\nâ†¦\nx\nd\n+\n1\nâ€‹\n(\nt\n)\nâˆˆ\nâ„\nt\\mapsto x_{d+1}(t)\\in\\mathbb{R}\nwhere\nx\nË™\nd\n+\n1\nâ€‹\n(\nt\n)\n=\n|\nu\nâ€‹\n(\nt\n)\n|\n,\nx\nd\n+\n1\nâ€‹\n(\n0\n)\n=\n0\nâ€‹\nfor all\nâ€‹\nt\nâˆˆ\n[\n0\n,\nT\n]\n.\n\\displaystyle\\dot{x}_{d+1}(t)=\\left\\lvert{u(t)}\\right\\rvert,\\quad x_{d+1}(0)=0\\text{ for all }t\\in[0,T].\nWe will denote the augmented state trajectory by\nt\nâ†¦\ny\nâ€‹\n(\nt\n)\nâ‰”\n[\nx\nâ€‹\n(\nt\n)\nâŠ¤\n,\nx\nd\n+\n1\nâ€‹\n(\nt\n)\n]\nâŠ¤\nâˆˆ\nâ„\nd\n+\n1\nt\\mapsto y(t)\\coloneqq[x(t)^{\\top},x_{d+1}(t)]^{\\top}\\in\\mathbb{R}^{d+1}\n. Thus OCP (\n(8)\n) is now equivalent to an OCP where the objective function consists of only the terminal cost\nx\nd\n+\n1\nâ€‹\n(\nT\n)\nx_{d+1}(T)\nwith the augmented dynamics given by\n((22))\ny\nË™\nâ€‹\n(\nt\n;\nÎ±\n)\n=\nF\nâ€‹\n(\ny\nâ€‹\n(\nt\n;\nÎ±\n)\n,\nu\nâ€‹\n(\nt\n)\n)\nâ‰”\n(\nA\nâ€‹\n(\nÎ±\n)\nâ€‹\nx\nâ€‹\n(\nt\n)\n+\nb\nâ€‹\n(\nÎ±\n)\nâ€‹\nu\nâ€‹\n(\nt\n)\n|\nu\nâ€‹\n(\nt\n)\n|\n)\n,\ny\nâ€‹\n(\n0\n;\nÎ±\n)\nâ‰”\n(\nx\nÂ¯\n0\n)\n.\n\\displaystyle\\dot{y}(t;\\alpha)=F(y(t;\\alpha),u(t))\\coloneqq\\begin{pmatrix}A(\\alpha)x(t)+b(\\alpha)u(t)\\\\\n\\left\\lvert{u(t)}\\right\\rvert\\end{pmatrix},\\quad y(0;\\alpha)\\coloneqq\\begin{pmatrix}\\overline{x}\\\\\n0\\end{pmatrix}.\nThe OCP (\n(8)\n) becomes\n((23))\ninf\nu\nâ€‹\n(\nâ‹…\n)\n\\displaystyle\\inf_{u(\\cdot)}\ng\nâ€‹\n(\ny\nâ€‹\n(\nT\n;\nÎ±\n)\n,\nÎ±\n)\nâ‰”\nx\nd\n+\n1\nâ€‹\n(\nT\n)\n\\displaystyle g\\bigl(y(T;\\alpha),\\alpha\\bigr)\\coloneqq x_{d+1}(T)\nsubject\nâ€‹\nto\n\\displaystyle\\operatorname{subject\\ to}\n{\ndynamics\nâ€‹\n(\n(22)\n)\n,\ny\nâ€‹\n(\n0\n;\nÎ±\n)\n=\n(\nx\nÂ¯\n,\n0\n)\nâŠ¤\n,\nu\nâ€‹\n(\nt\n)\nâˆˆ\nğ•Œ\nâ€‹\nfor a.e\nâ€‹\nt\nâˆˆ\n[\n0\n,\nT\n]\n,\ny\nâ€‹\n(\nT\n;\nÎ±\n)\nâˆˆ\nC\nâ‰”\n{\n(\nÎ¾\n1\n,\nÎ¾\n2\n)\nâˆˆ\nâ„\nd\nÃ—\nâ„\n|\nÏˆ\nâ€‹\n(\nÎ¾\n1\n)\nâ©½\n0\n}\nâ€‹\nfor all\nâ€‹\nÎ±\nâˆˆ\nğ–¯\n.\n\\displaystyle\nWe recast the Mayer-form OCP (\n(23)\n) into an equivalent minmax problem by extending the uncertainty set via augmenting an artificial parameter\nÎ±\nâˆ—\n\\alpha^{\\ast}\n. Define\nğ–¯\n^\nâ‰”\nğ–¯\nâˆª\n{\nÎ±\nâˆ—\n}\n\\widehat{\\mathsf{P}}\\coloneqq\\mathsf{P}\\cup\\{\\alpha^{\\ast}\\}\n; consider the objective function\ng\nâ€‹\n(\ny\n,\nÎ±\n~\n)\ng(y,\\widetilde{\\alpha})\ndefined by\ng\nâ€‹\n(\ny\n,\nÎ±\n~\n)\nâ‰”\n{\nx\nd\n+\n1\nif\nâ€‹\nÎ±\n~\n=\nÎ±\nâˆ—\n0\nif\nâ€‹\nÎ±\n~\nâˆˆ\nğ–¯\n,\n\\displaystyle g(y,\\widetilde{\\alpha})\\coloneqq\\begin{cases}x_{d+1}&\\text{if }\\widetilde{\\alpha}=\\alpha^{\\ast}\\\\\n0&\\text{if }\\widetilde{\\alpha}\\in\\mathsf{P},\\end{cases}\nand a new terminal constraint,\nC\nâ€‹\n(\nÎ±\n~\n)\nC(\\widetilde{\\alpha})\nby\nC\nâ€‹\n(\nÎ±\n~\n)\nâ‰”\n{\n{\ny\n=\n(\nx\n,\nx\nd\n+\n1\n)\nâˆˆ\nâ„\nd\n+\n1\n|\nÏˆ\nâ€‹\n(\nx\n)\nâ©½\n0\n}\nif\nâ€‹\nÎ±\n~\nâˆˆ\nğ–¯\nâ„\nd\n+\n1\nif\nâ€‹\nÎ±\n~\n=\nÎ±\nâˆ—\n.\n\\displaystyle C(\\widetilde{\\alpha})\\coloneqq\\begin{cases}\\big\\{y=(x,x_{d+1})\\in\\mathbb{R}^{d+1}\\;\\big|\\;\\psi(x)\\leqslant 0\\big\\}&\\text{if }\\widetilde{\\alpha}\\in\\mathsf{P}\\\\\n\\mathbb{R}^{d+1}&\\text{if }\\widetilde{\\alpha}=\\alpha^{\\ast}.\\end{cases}\nThus, the equivalent minmax reformulation of (\n(23)\n) is\n((24))\ninf\nu\nâ€‹\n(\nâ‹…\n)\nâˆˆ\nğ’°\nsup\nÎ±\n~\nâˆˆ\nğ–¯\n^\n\\displaystyle\\inf_{u(\\cdot)\\in\\mathcal{U}}\\sup_{\\widetilde{\\alpha}\\in\\widehat{\\mathsf{P}}}\ng\nâ€‹\n(\ny\nâ€‹\n(\nT\n;\nÎ±\n~\n)\n,\nÎ±\n~\n)\n\\displaystyle g\\bigl(y(T;\\widetilde{\\alpha}),\\widetilde{\\alpha}\\bigr)\nsubject\nâ€‹\nto\n\\displaystyle\\operatorname{subject\\ to}\n{\ny\nâ€‹\n(\nT\n;\nÎ±\n~\n)\nâˆˆ\nC\nâ€‹\n(\nÎ±\n~\n)\nâ€‹\nfor all\nâ€‹\nÎ±\n~\nâˆˆ\nğ–¯\n^\n.\n\\displaystyle\nDefine\nğ–¯\n1\nâ‰”\nğ–¯\n\\mathsf{P}_{1}\\coloneqq\\mathsf{P}\nand\nğ–¯\n2\nâ‰”\nÎ±\nâˆ—\n\\mathsf{P}_{2}\\coloneqq\\alpha^{\\ast}\n; and thus\nğ–¯\n^\n=\nğ–¯\n1\nâˆª\nğ–¯\n2\n\\widehat{\\mathsf{P}}=\\mathsf{P}_{1}\\cup\\mathsf{P}_{2}\n. Our next step involves application of the robust PMP in\n[\nVin05\n]\n. To this end, first, we need to verify the conditions\n[\nVin05\n, S1-S5, pp.946-947]\n. Observe that\nâ€¢\nThe vector field\n(\ny\n,\nu\n,\nÎ±\n)\nâ†¦\nF\nâ€‹\n(\ny\n,\nu\n)\n(y,u,\\alpha)\\mapsto F(y,u)\nis measurable for each\ny\nâˆˆ\nâ„\nd\n+\n1\ny\\in\\mathbb{R}^{d+1}\n, Thus, (S1) holds.\nâ€¢\nthe Jacobian of\nF\nâ€‹\n(\nâ‹…\n)\nF(\\cdot)\nwith respect to\ny\ny\nis\nâˆ‡\ny\nF\n=\n(\nA\nâ€‹\n(\nÎ±\n)\n0\n0\n0\n)\n\\nabla_{y}F=\\begin{pmatrix}A(\\alpha)&0\\\\\n0&0\\end{pmatrix}\nand recall that\nÎ±\nâ†¦\nA\nâ€‹\n(\nÎ±\n)\n\\alpha\\mapsto A(\\alpha)\nis continuous on the compact set\nğ–¯\n\\mathsf{P}\n. Thus\ny\nâ†¦\nF\nâ€‹\n(\ny\n,\nu\n)\ny\\mapsto F(y,u)\nis Lipschitz for all\nÎ±\nâˆˆ\nğ–¯\n\\alpha\\in\\mathsf{P}\n. Furthermore, since all problem data and the control set\nğ•Œ\n\\mathbb{U}\nare bounded,\nF\nâ€‹\n(\nâ‹…\n)\nF(\\cdot)\nis also bounded, and (S2) holds.\nâ€¢\nRecall that, for any\nÎ±\nâˆˆ\nğ–¯\n\\alpha\\in\\mathsf{P}\nthe function\ng\nâ€‹\n(\ny\n,\nÎ±\n)\ng(y,\\alpha)\nis identically zero, and thus (S3) is satisfied.\nâ€¢\n(S4) holds because\nğ–¯\nâˆ‹\nÎ±\nâ†¦\nA\nâ€‹\n(\nÎ±\n)\n\\mathsf{P}\\ni\\alpha\\mapsto A(\\alpha)\nand\nğ–¯\nâˆ‹\nÎ±\nâ†¦\nb\nâ€‹\n(\nÎ±\n)\n\\mathsf{P}\\ni\\alpha\\mapsto b(\\alpha)\nare continuous and (S5) holds trivially.\nAn application of\n[\nVin05\n, Theorem 3.2]\nguarantees the existence of a Radon probability measure\nÎ›\n~\n\\widetilde{\\Lambda}\non the set\nğ–¯\n^\n\\widehat{\\mathsf{P}}\n, and a family of arcs\n((25))\nq\n(\nâ‹…\n;\nÎ±\n~\n)\nâ‰”\n(\np\n(\nâ‹…\n;\nÎ±\n~\n)\n,\np\nd\n+\n1\n(\nâ‹…\n;\nÎ±\n~\n)\nâˆˆ\nW\n1\n,\n1\n(\n[\n0\n,\nT\n]\n;\nâ„\nd\n+\n1\n)\nfor\nÎ›\n~\n-a.e.\nÎ±\n~\n.\n\\displaystyle q(\\cdot;\\widetilde{\\alpha})\\coloneqq\\bigl(p(\\cdot;\\widetilde{\\alpha}),p_{d+1}(\\cdot;\\widetilde{\\alpha}\\bigr)\\in W^{1,1}\\bigl([0,T];\\mathbb{R}^{d+1}\\bigr)\\text{ for }\\widetilde{\\Lambda}\\text{-a.e. }\\widetilde{\\alpha}.\nFor the OCP (\n(24)\n) let the pair\n(\ny\nâˆ—\nâ€‹\n(\nâ‹…\n;\nÎ±\n)\n,\nu\nâ€‹\n(\nâ‹…\n)\n)\n\\bigl(y^{\\ast}(\\cdot;\\alpha),u(\\cdot)\\bigr)\ndenote the optimal state-action trajectory. Define the Hamiltonian\nâ„\nd\n+\n1\nÃ—\nâ„\nd\n+\n1\nÃ—\nâ„\nâˆ‹\n(\ny\n,\nq\n,\nu\n)\n\\displaystyle\\mathbb{R}^{d+1}\\times\\mathbb{R}^{d+1}\\times\\mathbb{R}\\ni(y,q,u)\nâ†¦\nH\n^\nÎ±\nâ€‹\n(\ny\n,\nq\n,\nu\n)\nâ‰”\nâŸ¨\nq\n,\nF\nâ€‹\n(\ny\n,\nu\n)\nâŸ©\n\\displaystyle\\mapsto\\widehat{H}_{\\alpha}(y,q,u)\\coloneqq\\left\\langle{q},\\,{F(y,u)}\\right\\rangle\n=\nâŸ¨\np\n,\nA\nâ€‹\n(\nÎ±\n)\nâ€‹\nx\n+\nb\nâ€‹\n(\nÎ±\n)\nâ€‹\nu\nâŸ©\n+\np\nd\n+\n1\nâ€‹\n|\nu\n|\nâˆˆ\nâ„\n,\n\\displaystyle=\\left\\langle{p},\\,{A(\\alpha)x+b(\\alpha)u}\\right\\rangle+p_{d+1}\\left\\lvert{u}\\right\\rvert\\in\\mathbb{R},\nwhere\nt\nâ†¦\nq\nâ€‹\n(\nt\n;\nÎ±\n)\nâ‰”\n(\np\nâ€‹\n(\nt\n;\nÎ±\n)\nâŠ¤\n,\np\nd\n+\n1\nâ€‹\n(\nt\n;\nÎ±\n)\n)\nâŠ¤\nâˆˆ\nâ„\nd\n+\n1\nt\\mapsto q(t;\\alpha)\\coloneqq(p(t;\\alpha)^{\\top},p_{d+1}(t;\\alpha))^{\\top}\\in\\mathbb{R}^{d+1}\nfor all\nt\nâˆˆ\n[\n0\n,\nT\n]\nt\\in[0,T]\nis the augmented costate/adjoint defined in (\n(25)\n). Now we will distil the conditions\n(\n3.2\n-b)\nâ€“\n(\n3.2\n-e)\nfrom the necessary conditions for the OCP (\n(24)\n).\nWe have, by definition,\nÎ›\n~\nâ€‹\n(\nğ–¯\n^\n)\n=\n1\n\\widetilde{\\Lambda}(\\widehat{\\mathsf{P}})=1\n; we split\nÎ›\n~\n\\widetilde{\\Lambda}\ninto its restriction on the set\nğ–¯\n\\mathsf{P}\nand on the point mass\n{\nÎ±\nâˆ—\n}\n\\{\\alpha^{\\ast}\\}\n. We define our multipliers as:\nÎ·\nâ‰”\nÎ›\n~\nâ€‹\n(\n{\nÎ±\nâˆ—\n}\n)\n\\eta\\coloneqq\\tilde{\\Lambda}(\\{\\alpha^{\\ast}\\})\n(the mass of the measure on the artificial point) and\nÎ›\n\\Lambda\nis the restriction of\nÎ›\n~\n\\tilde{\\Lambda}\nto the set\nğ–¯\n\\mathsf{P}\n. Since\nğ–¯\n^\n\\widehat{\\mathsf{P}}\nis a disjoint union of\nğ–¯\n\\mathsf{P}\nand\n{\nÎ±\nâˆ—\n}\n\\{\\alpha^{\\ast}\\}\n, we can split the measureâ€™s mass and write\nÎ›\n~\nâ€‹\n(\nğ–¯\n)\n+\nÎ›\n~\nâ€‹\n(\n{\nÎ±\nâˆ—\n}\n)\n=\n1\n\\tilde{\\Lambda}(\\mathsf{P})+\\tilde{\\Lambda}(\\{\\alpha^{\\ast}\\})=1\n, giving us the nontriviality condition\nÎ›\nâ€‹\n(\nğ–¯\n)\n+\nÎ·\n=\n1\n\\Lambda(\\mathsf{P})+\\eta=1\n.\nLet us derive the condition\n(\n3.2\n-b)\nâ€“\n(\n3.2\n-d)\n. For the OCP (\n(24)\n), corresponding to the pair\n(\ny\nâˆ—\nâ€‹\n(\nâ‹…\n;\nÎ±\n)\n,\nu\nâ€‹\n(\nâ‹…\n)\n)\n\\bigl(y^{\\ast}(\\cdot;\\alpha),u(\\cdot)\\bigr)\n, and the function\nH\n^\nÎ±\nâ€‹\n(\nâ‹…\n)\n\\widehat{H}_{\\alpha}(\\cdot)\n, we have the adjoint equation:\nâˆ’\nq\nË™\n=\nâˆ‡\ny\nH\n^\nÎ±\n-\\dot{q}=\\nabla_{y}\\widehat{H}_{\\alpha}\n, from which, computing the gradients\nâˆ‡\ny\nH\n^\nÎ±\n=\n(\nâˆ‡\nx\nH\n^\nÎ±\nâˆ‡\nx\nd\n+\n1\nH\n^\nÎ±\n)\n=\n(\nA\nâ€‹\n(\nÎ±\n)\nâŠ¤\nâ€‹\np\n0\n)\n,\n\\displaystyle\\nabla_{y}\\widehat{H}_{\\alpha}=\\begin{pmatrix}\\nabla_{x}\\widehat{H}_{\\alpha}\\\\\n\\nabla_{x_{d+1}}\\widehat{H}_{\\alpha}\\end{pmatrix}=\\begin{pmatrix}A(\\alpha)^{\\top}p\\\\\n0\\end{pmatrix},\nwe immediately obtain the adjoint equations\nâˆ’\np\nË™\nâ€‹\n(\nt\n;\nÎ±\n)\n\\displaystyle-\\dot{p}(t;\\alpha)\n=\nA\nâ€‹\n(\nÎ±\n)\nâŠ¤\nâ€‹\np\nâ€‹\n(\nt\n;\nÎ±\n)\n,\n\\displaystyle=A(\\alpha)^{\\top}p(t;\\alpha),\n((26))\nâˆ’\np\nË™\nd\n+\n1\nâ€‹\n(\nt\n;\nÎ±\n)\n\\displaystyle-\\dot{p}_{d+1}(t;\\alpha)\n=\n0\n,\nwhich implies\nâ€‹\np\nd\n+\n1\nâ€‹\n(\nt\n;\nÎ±\n)\nâ€‹\nis constant in time.\n\\displaystyle=0,\\text{ which implies }p_{d+1}(t;\\alpha)\\text{ is constant in time.}\nThe support and the transversality conditions follow directly from the more general conditions in\n[\nVin05\n, Theorem 3.2]\n. We have\n((27))\nâˆ’\nq\nâ€‹\n(\nT\n;\nÎ±\n~\n)\nâˆˆ\nN\nC\nâ€‹\n(\nÎ±\n~\n)\nâ€‹\n(\ny\nâˆ—\nâ€‹\n(\nT\n;\nÎ±\n~\n)\n)\n+\nâˆ‚\ny\ng\nâ€‹\n(\ny\nâˆ—\nâ€‹\n(\nT\n;\nÎ±\n~\n)\n,\nÎ±\n~\n)\n.\n\\displaystyle-q(T;\\widetilde{\\alpha})\\in N_{C(\\widetilde{\\alpha})}\\bigl(y^{\\ast}(T;\\widetilde{\\alpha})\\bigr)+\\partial_{y}g\\bigl(y^{\\ast}(T;\\widetilde{\\alpha}),\\widetilde{\\alpha}\\bigr).\nObserve that, when\nÎ±\nâˆˆ\nğ–¯\n\\alpha\\in\\mathsf{P}\n,\ng\nâ€‹\n(\ny\n,\nÎ±\n)\n=\n0\ng(y,\\alpha)=0\n, and thus (\n(27)\n) reduces to\n((28))\nâˆ’\nq\nâ€‹\n(\nT\n;\nÎ±\n)\nâˆˆ\nN\n{\ny\n|\nÏˆ\nâ€‹\n(\nx\n)\nâ©½\n0\n}\nâ€‹\n(\ny\nâˆ—\nâ€‹\n(\nT\n;\nÎ±\n)\n)\n\\displaystyle-q(T;\\alpha)\\in N_{\\{y\\;|\\;\\psi(x)\\leqslant 0\\}}\\bigl(y^{\\ast}(T;\\alpha)\\bigr)\nThe normal cone to this sublevel set is non-zero only if the point is on the boundary, i.e.,\nÏˆ\nâ€‹\n(\nx\nâˆ—\nâ€‹\n(\nT\n;\nÎ±\n)\n)\n=\n0\n\\psi\\bigl(x^{\\ast}(T;\\alpha)\\bigr)=0\n. Since the measure\nÎ›\n\\Lambda\ncan only be supported where the conditions are active, this directly proves the condition\n(\n3.2\n-d)\n.\nFrom the adjoint equations and the preceding arguments, it follows that there exists a scalar multiplier\nÎ¼\nâ€‹\n(\nÎ±\n)\nâ©¾\n0\n\\mu(\\alpha)\\geqslant 0\nsuch that\nâˆ’\nq\nâ€‹\n(\nT\n;\nÎ±\n)\n=\nâˆ’\n(\np\nâ€‹\n(\nT\n;\nÎ±\n)\np\nd\n+\n1\nâ€‹\n(\nT\n;\nÎ±\n)\n)\n=\nÎ¼\nâ€‹\n(\nÎ±\n)\nâ€‹\n(\nâˆ‡\nx\nÏˆ\nâ€‹\n(\nx\nâˆ—\nâ€‹\n(\nT\n;\nÎ±\n)\n)\n0\n)\n,\n\\displaystyle-q(T;\\alpha)=-\\begin{pmatrix}p(T;\\alpha)\\\\\np_{d+1}(T;\\alpha)\\end{pmatrix}=\\mu(\\alpha)\\begin{pmatrix}\\nabla_{x}\\psi\\bigl(x^{\\ast}(T;\\alpha)\\bigr)\\\\\n0\\end{pmatrix},\nwhere the first equation is the transversality condition in (\n(\n3.2\n-c)\n) and the second equation implies that\np\nd\n+\n1\nâ€‹\n(\nT\n;\nÎ±\n)\n=\n0\np_{d+1}(T;\\alpha)=0\n, and this implies. from (\n3.1\n), that\np\nd\n+\n1\nâ€‹\n(\nt\n;\nÎ±\n)\np_{d+1}(t;\\alpha)\nis identically zero for all\nt\nâˆˆ\n[\n0\n,\nT\n]\nt\\in[0,T]\n, when\nÎ±\nâˆˆ\nğ–¯\n\\alpha\\in\\mathsf{P}\n.\nWhen\nÎ±\n~\n=\nÎ±\nâˆ—\n\\widetilde{\\alpha}=\\alpha^{\\ast}\n, the constraint set is\nC\nâ€‹\n(\nÎ±\nâˆ—\n)\n=\nâ„\nd\n+\n1\nC(\\alpha^{\\ast})=\\mathbb{R}^{d+1}\n, and thus\nN\nC\nâ€‹\n(\nÎ±\nâˆ—\n)\n=\n{\n0\n}\nN_{C(\\alpha^{\\ast})}=\\{0\\}\n. The cost is\ng\nâ€‹\n(\ny\n,\nÎ±\nâˆ—\n)\n=\nx\nd\n+\n1\ng(y,\\alpha^{\\ast})=x_{d+1}\nand thus (\n(27)\n) reduces to\n((29))\nâˆ’\nq\nâ€‹\n(\nT\n;\nÎ±\nâˆ—\n)\nâˆˆ\n{\n0\n}\n+\n{\n[\n0\n,\nâ€¦\n,\n0\n,\n1\n]\nâŠ¤\n}\n\\displaystyle-q(T;\\alpha^{\\ast})\\in\\{0\\}+\\big\\{[0,\\ldots,0,1]^{\\top}\\big\\}\nwhich implies\nâˆ’\np\nâ€‹\n(\nT\n;\nÎ±\nâˆ—\n)\n=\n0\n-p(T;\\alpha^{\\ast})=0\nand\nâˆ’\np\nd\n+\n1\nâ€‹\n(\nT\n;\nÎ±\nâˆ—\n)\n=\n1\n-p_{d+1}(T;\\alpha^{\\ast})=1\n. From the adjoint dynamics (\n3.1\n) we have\np\nâ€‹\n(\nt\n;\nÎ±\nâˆ—\n)\n=\n0\np(t;\\alpha^{\\ast})=0\nand\np\nd\n+\n1\nâ€‹\n(\nt\n;\nÎ±\n)\n=\nâˆ’\n1\np_{d+1}(t;\\alpha)=-1\nfor all\nt\nâˆˆ\n[\n0\n,\nT\n]\nt\\in[0,T]\n.\nFinally, the minmax PMP states that the control trajectory\nu\nâˆ—\nâ€‹\n(\nâ‹…\n)\nu^{\\ast}(\\cdot)\nmust solve the variational problem\nmax\nu\nâˆˆ\nğ•Œ\nâ€‹\nâˆ«\nğ–¯\n^\nH\n^\nÎ±\n~\nâ€‹\n(\ny\nâˆ—\nâ€‹\n(\nt\n;\nÎ±\n~\n)\n,\nq\nâ€‹\n(\nt\n;\nÎ±\n~\n)\n,\nu\n)\nâ€‹\nÎ›\n~\nâ€‹\n(\nd\nâ€‹\nÎ±\n~\n)\n.\n\\max_{u\\in\\mathbb{U}}\\int_{\\widehat{\\mathsf{P}}}\\widehat{H}_{\\widetilde{\\alpha}}\\bigl(y^{\\ast}(t;\\widetilde{\\alpha}),q(t;\\widetilde{\\alpha}),u\\bigr)\\widetilde{\\Lambda}(\\mathop{}\\!\\mathrm{d}\\widetilde{\\alpha}).\nExpanding upon the integral, we obtain\nmax\nv\nâˆˆ\nğ•Œ\nâ€‹\nâˆ«\nğ–¯\nH\n^\nÎ±\nâ€‹\n(\ny\nâˆ—\nâ€‹\n(\nt\n;\nÎ±\n)\n,\nq\nâ€‹\n(\nt\n;\nÎ±\n)\n,\nu\n)\nâ€‹\nÎ›\nâ€‹\n(\nd\nâ€‹\nÎ±\n)\n+\nÎ·\nâ€‹\nH\n^\nÎ±\nâˆ—\nâ€‹\n(\ny\nâˆ—\nâ€‹\n(\nt\n;\nÎ±\nâˆ—\n)\n,\nq\nâ€‹\n(\nt\n;\nÎ±\nâˆ—\n)\n,\nu\n)\n\\displaystyle\\max_{v\\in\\mathbb{U}}\\int_{\\mathsf{P}}\\widehat{H}_{{\\alpha}}\\bigl(y^{\\ast}(t;{\\alpha}),q(t;{\\alpha}),u\\bigr)\\Lambda(\\mathop{}\\!\\mathrm{d}\\alpha)+\\eta\\widehat{H}_{\\alpha^{\\ast}}\\bigl(y^{\\ast}(t;{\\alpha}^{\\ast}),q(t;{\\alpha}^{\\ast}),u\\bigr)\n=\n(\nâ€ \n)\nmax\nv\nâˆˆ\nğ•Œ\nâ€‹\nâˆ«\nğ–¯\n(\np\nâ€‹\n(\nt\n;\nÎ±\n)\nâ€‹\n(\nA\nâ€‹\n(\nÎ±\n)\nâ€‹\nx\nâˆ—\nâ€‹\n(\nt\n;\nÎ±\n)\n+\nb\nâ€‹\n(\nÎ±\n)\nâ€‹\nv\n)\n+\np\nd\n+\n1\nâ€‹\n(\nt\n;\nÎ±\n)\nâ€‹\n|\nv\n|\n)\nâ€‹\nÎ›\nâ€‹\n(\nd\nâ€‹\nÎ±\n)\n+\n\\displaystyle\\stackrel{{\\scriptstyle\\mathclap{({\\dagger})}}}{{=}}\\max_{v\\in\\mathbb{U}}\\int_{\\mathsf{P}}\\bigl(p(t;\\alpha)(A(\\alpha)x^{\\ast}(t;\\alpha)+b(\\alpha)v)+p_{d+1}(t;\\alpha)\\left\\lvert{v}\\right\\rvert\\bigr)\\Lambda(\\mathop{}\\!\\mathrm{d}\\alpha)+\nÎ·\nâ€‹\n(\np\nâ€‹\n(\nt\n;\nÎ±\nâˆ—\n)\nâŠ¤\nâ€‹\n(\nA\nâ€‹\n(\nÎ±\nâˆ—\n)\nâ€‹\nx\nâ€‹\n(\nt\n;\nÎ±\nâˆ—\n)\n+\nb\nâ€‹\n(\nÎ±\nâˆ—\n)\nâ€‹\nv\n)\n+\np\nd\n+\n1\nâ€‹\n(\nt\n;\nÎ±\nâˆ—\n)\nâ€‹\n|\nv\n|\n)\n\\displaystyle\\hskip 56.9055pt\\eta\\bigl(p(t;\\alpha^{\\ast})^{\\top}(A(\\alpha^{\\ast})x(t;\\alpha^{\\ast})+b(\\alpha^{\\ast})v)+p_{d+1}(t;\\alpha^{\\ast})\\left\\lvert{v}\\right\\rvert\\bigr)\n=\n(\nâ€¡\n)\nmax\nv\nâˆˆ\nğ•Œ\n{\nâˆ«\nğ–¯\n(\np\n(\nt\n;\nÎ±\n)\nâŠ¤\n(\nA\n(\nÎ±\n)\nx\nâˆ—\n(\nt\n;\nÎ±\n)\n+\nb\n(\nÎ±\n)\nv\n)\n+\n0\nÃ—\n|\nv\n|\n)\nÎ›\n(\nd\nÎ±\n)\n+\n\\displaystyle\\stackrel{{\\scriptstyle\\mathclap{({\\ddagger})}}}{{=}}\\max_{v\\in\\mathbb{U}}\\bigg\\{\\int_{\\mathsf{P}}\\bigl(p(t;\\alpha)^{\\top}(A(\\alpha)x^{\\ast}(t;\\alpha)+b(\\alpha)v)+0\\times\\left\\lvert{v}\\right\\rvert\\bigr)\\Lambda(\\mathop{}\\!\\mathrm{d}\\alpha)+\nÎ·\n(\n0\nÃ—\n(\nA\n(\nÎ±\nâˆ—\n)\nx\nâˆ—\n(\nt\n;\nÎ±\nâˆ—\n)\n+\nb\n(\nÎ±\nâˆ—\n)\nv\n)\n+\n(\nâˆ’\n1\n)\n|\nv\n|\n)\n}\n,\n\\displaystyle\\hskip 56.9055pt\\eta\\big(0\\times(A(\\alpha^{\\ast})x^{\\ast}(t;\\alpha^{\\ast})+b(\\alpha^{\\ast})v)+(-1)\\left\\lvert{v}\\right\\rvert\\bigr)\\bigg\\},\nwhere:\nâˆ˜\n\\circ\nIn step\n(\nâ€ \n)\n({\\dagger})\n: we split the integral over\nğ–¯\n^\n\\widehat{\\mathsf{P}}\ninto integrals over\nğ–¯\n\\mathsf{P}\nand\n{\nÎ±\nâˆ—\n}\n\\{\\alpha^{\\ast}\\}\n. Recall that\nÎ·\nâ‰”\nÎ›\n~\nâ€‹\n(\n{\nÎ±\nâˆ—\n}\n)\n\\eta\\coloneqq\\widetilde{\\Lambda}(\\{\\alpha^{\\ast}\\})\nand\nÎ›\n\\Lambda\nis the restriction of the measure\nÎ›\n~\n\\widetilde{\\Lambda}\nto\nğ–¯\n\\mathsf{P}\n.\nâˆ˜\n\\circ\nIn step\n(\nâ€¡\n)\n({\\ddagger})\n: recall that, when\nÎ±\nâˆˆ\nğ–¯\n\\alpha\\in\\mathsf{P}\n, we showed that\np\nd\n+\n1\nâ€‹\n(\nt\n;\nÎ±\n)\nâ‰¡\n0\np_{d+1}(t;\\alpha)\\equiv 0\nand for\nÎ±\nâˆ—\n\\alpha^{\\ast}\nwe showed that\np\nâ€‹\n(\nt\n;\nÎ±\nâˆ—\n)\nâ‰¡\n0\np(t;\\alpha^{\\ast})\\equiv 0\nand\np\nd\n+\n1\nâ€‹\n(\nt\n;\nÎ±\nâˆ—\n)\nâ‰¡\nâˆ’\n1\np_{d+1}(t;\\alpha^{\\ast})\\equiv-1\nfor all\nt\nâˆˆ\n[\n0\n,\nT\n]\nt\\in[0,T]\n.\nWith all these ingredients, the variational problem reduces to\n((30))\nmax\nv\nâˆˆ\nğ•Œ\nâ¡\n{\nâˆ«\nğ–¯\np\nâ€‹\n(\nt\n;\nÎ±\n)\nâŠ¤\nâ€‹\n(\nA\nâ€‹\n(\nÎ±\n)\nâ€‹\nx\nâˆ—\nâ€‹\n(\nt\n;\nÎ±\n)\n+\nb\nâ€‹\n(\nÎ±\n)\nâ€‹\nv\n)\nâ€‹\nÎ›\nâ€‹\n(\nd\nâ€‹\nÎ±\n)\nâˆ’\nÎ·\nâ€‹\n|\nv\n|\n}\n.\n\\displaystyle\\max_{v\\in\\mathbb{U}}\\bigg\\{\\int_{\\mathsf{P}}p(t;\\alpha)^{\\top}(A(\\alpha){x}^{\\ast}(t;\\alpha)+b(\\alpha)v)\\Lambda(\\mathop{}\\!\\mathrm{d}\\alpha)-\\eta\\left\\lvert{v}\\right\\rvert\\bigg\\}.\nSince the first term inside the integral in (\n(30)\n) does not depend on\nv\nâˆˆ\nğ•Œ\nv\\in\\mathbb{U}\n, it does not play any role in the maximization, as thus, defining the averaged switching function\nt\nâ†¦\nğ’®\nâ€‹\n(\nt\n)\nâˆˆ\nâ„\nt\\mapsto\\mathcal{S}(t)\\in\\mathbb{R}\n[\n0\n,\nT\n]\nâˆ‹\nt\nâ†¦\nğ’®\nâ€‹\n(\nt\n)\nâ‰”\nâˆ«\nğ–¯\np\nâ€‹\n(\nt\n;\nÎ±\n)\nâŠ¤\nâ€‹\nb\nâ€‹\n(\nÎ±\n)\nâ€‹\nÎ›\nâ€‹\n(\nd\nâ€‹\nÎ±\n)\nâˆˆ\nâ„\n,\n[0,T]\\ni t\\mapsto\\mathcal{S}(t)\\coloneqq\\int_{\\mathsf{P}}p(t;\\alpha)^{\\top}b(\\alpha)\\Lambda(\\mathop{}\\!\\mathrm{d}\\alpha)\\in\\mathbb{R},\nwe obtain\n((31))\nu\nâˆ—\nâ€‹\n(\nt\n)\nâˆˆ\narg\nâ€‹\nmax\nv\nâˆˆ\nğ•Œ\nâ¡\n{\n(\nâˆ«\nğ–¯\np\nâ€‹\n(\nt\n;\nÎ±\n)\nâŠ¤\nâ€‹\nb\nâ€‹\n(\nÎ±\n)\nâ€‹\nÎ›\nâ€‹\n(\nd\nâ€‹\nÎ±\n)\n)\nâ€‹\nv\nâˆ’\nÎ·\nâ€‹\n|\nv\n|\n}\n=\narg\nâ€‹\nmax\nv\nâˆˆ\nğ•Œ\nâ¡\n{\nğ’®\nâ€‹\n(\nt\n)\nâ€‹\nv\nâˆ’\nÎ·\nâ€‹\n|\nv\n|\n}\n.\n\\displaystyle u^{\\ast}(t)\\in\\operatorname*{arg\\,max}_{v\\in\\mathbb{U}}\\bigg\\{\\left(\\int_{\\mathsf{P}}p(t;\\alpha)^{\\top}b(\\alpha)\\Lambda(\\mathop{}\\!\\mathrm{d}\\alpha)\\right)v-\\eta\\left\\lvert{v}\\right\\rvert\\bigg\\}=\\operatorname*{arg\\,max}_{v\\in\\mathbb{U}}\\big\\{\\mathcal{S}(t)v-\\eta\\left\\lvert{v}\\right\\rvert\\big\\}.\nThe proof is complete.\nâˆ\nRemark 3.3\n.\nTheorem\n3.2\nis a robust and nonsmooth analogue of Pontryaginâ€™s maximum principle for OCP (\n(8)\n) with an\nuncountable family of constraints indexed by\nÎ±\nâˆˆ\nğ–¯\n\\alpha\\in\\mathsf{P}\n. Under the hypotheses\n((\n(5)\n)-a)\nâ€“\n((\n(5)\n)-c)\n, the robust PMP yields the existence of (a) a scalar multiplier\nÎ·\nâ©¾\n0\n\\eta\\geqslant 0\n,\n(b) a nonnegative Radon measure\nÎ›\n\\Lambda\n(which can be interpreted as a continuous analogue of KKT multipliers over scenarios) supported on the\nactive uncertainty realizations\n, and\n(c) a family of adjoint variables\np\nâ€‹\n(\nâ‹…\n;\nÎ±\n)\np(\\cdot;\\alpha)\ndefined\nÎ›\n\\Lambda\n-a.e., such that the optimal control maximizes an averaged Hamiltonian. Finally, the averaged switching function\nğ’®\nâ€‹\n(\nâ‹…\n)\n\\mathcal{S}(\\cdot)\nrepresents an aggregate sensitivity of the robust terminal feasibility margin with respect to the control input at time\nt\nt\n.\nUnder some additional assumptions on the problem data, we have the immediate consequence that the\nL\n1\n{L}^{1}\noptimal control is bang-off-bang-type.\n{myOCP}\nCorollary 3.4\n.\nConsider the optimal control problem (\n(7)\n)â€“(\n(8)\n) along with their data\n((\n(5)\n)-a)\nâ€“\n((\n(5)\n)-c)\nand let the hypothesis of Theorem\n3.1\nhold. We define the\nactive set\nby\n((32))\nğ–¯\nact\nâ‰”\n{\nÎ±\nâˆˆ\nğ–¯\n|\nÏˆ\nâ€‹\n(\nx\nâˆ—\nâ€‹\n(\nT\n;\nÎ±\n)\n)\n=\n0\n}\n.\n\\displaystyle\\mathsf{P}_{\\mathrm{act}}\\coloneqq\\{\\alpha\\in\\mathsf{P}\\;|\\;\\psi\\bigl(x^{\\ast}(T;\\alpha)\\bigr)=0\\}.\ndenote\nÎ›\nact\nâ‰”\nÎ›\n|\nğ–¯\nact\n\\Lambda_{\\mathrm{act}}\\coloneqq\\Lambda|_{\\mathsf{P}_{\\mathrm{act}}}\n. Suppose that\n(\n3.2\n-a)\n(Normality condition) The problem (\n(7)\n)â€“(\n(8)\n) is normal, i.e.,\nÎ·\n>\n0\n\\eta>0\n.\n(\n3.2\n-b)\n(Average controllability-like condition) For every measurable\nÎ±\nâ†¦\nv\nâ€‹\n(\nÎ±\n)\nâˆˆ\nâ„\nd\n\\alpha\\mapsto v(\\alpha)\\in\\mathbb{R}^{d}\nwith\nv\nâ€‹\n(\nÎ±\n)\nâˆˆ\nN\nC\nâ€‹\n(\nx\nâˆ—\nâ€‹\n(\nT\n;\nÎ±\n)\n)\nv(\\alpha)\\in N_{C}\\bigl(x^{\\ast}(T;\\alpha)\\bigr)\nthat is not a.e. zero with respect to\nÎ›\nact\n\\Lambda_{\\mathrm{act}}\n, there exists\nm\nâˆˆ\n{\n1\n,\nâ€¦\n,\nd\nâˆ’\n1\n}\nm\\in\\{1,\\ldots,d-1\\}\nsuch that\nâˆ«\nğ–¯\nact\nâŸ¨\nA\nâ€‹\n(\nÎ±\n)\nm\nâ€‹\nb\nâ€‹\n(\nÎ±\n)\n,\nv\nâ€‹\n(\nÎ±\n)\nâŸ©\nâ€‹\nÎ›\nact\nâ€‹\n(\nd\nâ€‹\nÎ±\n)\nâ‰ \n0\n.\n\\displaystyle\\int_{\\mathsf{P}_{\\mathrm{act}}}\\left\\langle{A(\\alpha)^{m}b(\\alpha)},\\,{v(\\alpha)}\\right\\rangle\\Lambda_{\\mathrm{act}}(\\mathop{}\\!\\mathrm{d}\\alpha)\\neq\\ 0.\nThen the optimal control\nt\nâ†¦\nu\nâˆ—\nâ€‹\n(\nt\n)\nt\\mapsto u^{\\ast}(t)\nadmits a bang-off-bang representation for a.e.\nt\nâˆˆ\n[\n0\n,\nT\n]\nt\\in[0,T]\nand it is given by\n[\n0\n,\nT\n]\nâˆ‹\nt\nâ†¦\nu\nâˆ—\nâ€‹\n(\nt\n)\nâ‰”\n{\n1\nif\nâ€‹\nğ’®\nâ€‹\n(\nt\n)\n>\nÎ·\n0\nif\nâ€‹\n|\nğ’®\nâ€‹\n(\nt\n)\n|\n<\nÎ·\nâˆ’\n1\nif\nâ€‹\nğ’®\nâ€‹\n(\nt\n)\n<\nâˆ’\nÎ·\n.\n\\displaystyle[0,T]\\ni t\\mapsto u^{\\ast}(t)\\coloneqq\\begin{cases}1&\\text{if }\\mathcal{S}(t)>\\eta\\\\\n0&\\text{if }\\left\\lvert{\\mathcal{S}(t)}\\right\\rvert<\\eta\\\\\n-1&\\text{if }\\mathcal{S}(t)<-\\eta.\\end{cases}\nRemark 3.5\n.\nNote that, from the transversality condition in Theorem\n3.2\nwe have\nâˆ’\np\nâ€‹\n(\nT\n;\nÎ±\n)\nâˆˆ\nN\nC\nâ€‹\n(\nx\nâˆ—\nâ€‹\n(\nT\n;\nÎ±\n)\n)\n.\n-p(T;\\alpha)\\in N_{C}\\bigl(x^{\\ast}(T;\\alpha)\\bigr).\nIn particular, if\nÎ±\n\\alpha\nis\ninactive\n, i.e.,\nÏˆ\nâ€‹\n(\nx\nâˆ—\nâ€‹\n(\nT\n;\nÎ±\n)\n)\n<\n0\n\\psi\\bigl(x^{\\ast}(T;\\alpha)\\bigr)<0\n, then\nN\nC\nâ€‹\n(\nÎ±\n)\nâ€‹\n(\nx\nâˆ—\nâ€‹\n(\nT\n;\nÎ±\n)\n)\n=\n{\n0\n}\nN_{C(\\alpha)}(x^{*}(T;\\alpha))=\\{0\\}\nand hence\np\nâ€‹\n(\nT\n;\nÎ±\n)\n=\n0\np(T;\\alpha)=0\nfor all inactive\nÎ±\n\\alpha\n. Thus, without loss of generality, we specialized Corollary\n3.4\non\nğ–¯\nact\n\\mathsf{P}_{\\mathrm{act}}\n. The normality assumption is standard\n[\nNQN15\n]\nwhich ensures that the running cost is active in the first-order conditions and induces a nontrivial threshold in the Hamiltonian maximization. This creates a\noff\nregion in which actuation is not worthwhile. Abnormal extremals with\nÎ·\n=\n0\n\\eta=0\neliminate this threshold and may destroy sparsity. Assumption\n(\n3.2\n-b)\nis a sufficient\nnondegeneracy\nrequirement for the ensemble\n{\nA\nâ€‹\n(\nÎ±\n)\nk\n,\nb\nâ€‹\n(\nÎ±\n)\n}\nk\nâ©¾\n1\n\\{A(\\alpha)^{k},b(\\alpha)\\}_{k\\geqslant 1}\n: after averaging over\nÎ±\n\\alpha\n, the contributions from different parameter values cannot cancel in such a way that a nonzero terminal multiplier becomes invisible. In practical terms, any nontrivial multiplier inevitably produces a discernible change in the averaged switching signal, so the switching function cannot remain flat on a time interval. This rules out singular arcs and yields the bangâ€“offâ€“bang structure of the optimal control\nu\nâˆ—\nâ€‹\n(\nâ‹…\n)\nu^{\\ast}(\\cdot)\n. The assumption is, in broad strokes, an ensemble-like counterpart of the usual controllability\n[\nSH16\n,\nHS14\n,\nDMS25\n]\nand without some form of it, averaging across parameters can mask the influence of the input â€” even if each individual system is controllable â€” so bangâ€“offâ€“bang cannot be guaranteed. The condition\n(\n3.2\n-b)\nis verifiable and we refer the readers to Â§\n4\nfor more details.\nProof.\nRecall the switching function\n[\n0\n,\nT\n]\nâˆ‹\nt\nâ†¦\nğ’®\nâ€‹\n(\nt\n)\nâ‰”\nâˆ«\nğ–¯\np\nâ€‹\n(\nt\n;\nÎ±\n)\nâŠ¤\nâ€‹\nb\nâ€‹\n(\nÎ±\n)\nâ€‹\nÎ›\nâ€‹\n(\nd\nâ€‹\nÎ±\n)\nâˆˆ\nâ„\n,\n[0,T]\\ni t\\mapsto\\mathcal{S}(t)\\coloneqq\\int_{\\mathsf{P}}p(t;\\alpha)^{\\top}b(\\alpha)\\Lambda(\\mathop{}\\!\\mathrm{d}\\alpha)\\in\\mathbb{R},\nand the maximization condition\nu\nâˆ—\nâ€‹\n(\nt\n)\nâˆˆ\narg\nâ€‹\nmax\nv\nâˆˆ\nğ•Œ\nâ¡\n{\nğ’®\nâ€‹\n(\nt\n)\nâ€‹\nv\nâˆ’\nÎ·\nâ€‹\n|\nv\n|\n}\n,\n\\displaystyle u^{\\ast}(t)\\in\\operatorname*{arg\\,max}_{v\\in\\mathbb{U}}\\big\\{\\mathcal{S}(t)v-\\eta\\left\\lvert{v}\\right\\rvert\\big\\},\nfrom which we see that we see that\n[\n0\n,\nT\n]\nâˆ‹\nt\nâ†¦\nu\nâˆ—\nâ€‹\n(\nt\n)\nâˆˆ\n{\n{\nâˆ’\n1\n}\nif\nâ€‹\nğ’®\nâ€‹\n(\nt\n)\n<\nâˆ’\nÎ·\n[\nâˆ’\n1\n,\n0\n]\nif\nâ€‹\nğ’®\nâ€‹\n(\nt\n)\n=\nâˆ’\nÎ·\n{\n0\n}\nif\nâ€‹\n|\nğ’®\nâ€‹\n(\nt\n)\n|\n<\nÎ·\n[\n0\n,\n1\n]\nif\nâ€‹\nğ’®\nâ€‹\n(\nt\n)\n=\nÎ·\n{\n1\n}\nif\nâ€‹\nğ’®\nâ€‹\n(\nt\n)\n>\nÎ·\n.\n\\displaystyle[0,T]\\ni t\\mapsto u^{\\ast}(t)\\in\\begin{cases}\\{-1\\}&\\text{if }\\mathcal{S}(t)<-\\eta\\\\\n[-1,0]&\\text{if }\\mathcal{S}(t)=-\\eta\\\\\n\\{0\\}&\\text{if }\\left\\lvert{\\mathcal{S}(t)}\\right\\rvert<\\eta\\\\\n[0,1]&\\text{if }\\mathcal{S}(t)=\\eta\\\\\n\\{1\\}&\\text{if }\\mathcal{S}(t)>\\eta.\\end{cases}\nRecall that\nÎ¼\nâ€‹\n(\nâ‹…\n)\n\\mu(\\cdot)\nis the standard Eucledian Lebesgue measure; to show that\nu\nâˆ—\nâ€‹\n(\nâ‹…\n)\nu^{\\ast}(\\cdot)\nis bang-off-bang, i.e.,\nu\nâˆ—\nâ€‹\n(\nt\n)\nâˆˆ\n{\nâˆ’\n1\n,\n0\n,\n+\n1\n}\nu^{\\ast}(t)\\in\\{-1,0,+1\\}\nfor a.e.\nt\nâˆˆ\n[\n0\n,\nT\n]\nt\\in[0,T]\nwe show that\nÎ¼\nâ€‹\n(\n{\nt\nâˆˆ\n[\n0\n,\nT\n]\n|\n|\nğ’®\nâ€‹\n(\nt\n)\n|\n=\nÎ·\n}\n)\n=\n0\n,\n\\displaystyle\\mu\\bigl(\\{t\\in[0,T]\\;|\\;\\left\\lvert{\\mathcal{S}(t)}\\right\\rvert=\\eta\\}\\bigr)=0,\ni.e., no singular arcs can exist.\nTowards that end, we first establish that\nt\nâ†¦\nğ’®\nâ€‹\n(\nt\n)\nt\\mapsto\\mathcal{S}(t)\nis an analytic function. Recall that, from (\n3.1\n), the adjoint dynamics is given by\nâˆ’\np\nË™\nâ€‹\n(\nt\n;\nÎ±\n)\n=\nA\nâ€‹\n(\nÎ±\n)\nâŠ¤\nâ€‹\np\nâ€‹\n(\nT\n;\nÎ±\n)\n-\\dot{p}(t;\\alpha)=A(\\alpha)^{\\top}p(T;\\alpha)\n, and thus, for any fixed\nÎ±\nâˆˆ\nğ–¯\n\\alpha\\in\\mathsf{P}\n, we have\np\nâ€‹\n(\nt\n;\nÎ±\n)\n=\ne\nA\nâ€‹\n(\nÎ±\n)\nâŠ¤\nâ€‹\n(\nT\nâˆ’\nt\n)\nâ€‹\np\nâ€‹\n(\nT\n;\nÎ±\n)\np(t;\\alpha)=\\mathrm{e}^{A(\\alpha)^{\\top}(T-t)}p(T;\\alpha)\n. Because\nğ–¯\n\\mathsf{P}\nis compact and\nÎ±\nâ†¦\n(\nA\nâ€‹\n(\nÎ±\n)\n,\nb\nâ€‹\n(\nÎ±\n)\n)\n\\alpha\\mapsto(A(\\alpha),b(\\alpha))\nare continuous, one can find finite number\nM\nA\nM_{A}\nand\nM\nb\nM_{b}\nsuch that\nâ€–\nA\nâ€‹\n(\nÎ±\n)\nâ€–\nâ©½\nM\nA\n\\left\\lVert A(\\alpha)\\right\\rVert\\leqslant M_{A}\nand\nâˆ¥\nb\n(\nÎ±\nâˆ¥\nâ©½\nM\nb\n\\left\\lVert b(\\alpha\\right\\rVert\\leqslant M_{b}\nfor all\nÎ±\nâˆˆ\nğ–¯\nact\n\\alpha\\in\\mathsf{P}_{\\mathrm{act}}\n. Consequently,\nsup\nÎ±\n,\nt\nâ€–\ne\nA\nâ€‹\n(\nÎ±\n)\nâŠ¤\nâ€‹\n(\nT\nâˆ’\nt\n)\nâ€–\n<\n+\nâˆ\n\\sup_{\\alpha,t}\\left\\lVert\\mathrm{e}^{A(\\alpha)^{\\top}(T-t)}\\right\\rVert<+\\infty\n, uniformly for all\n(\nÎ±\n,\nt\n)\nâˆˆ\nğ–¯\nact\nÃ—\n[\n0\n,\nT\n]\n(\\alpha,t)\\in\\mathsf{P}_{\\mathrm{act}}\\times[0,T]\n. Using the power series expansion of the exponential, around some\nt\n^\nâˆˆ\n[\n0\n,\nT\n]\n\\hat{t}\\in[0,T]\n, we have\nğ’®\nâ€‹\n(\nt\n)\n=\nâˆ‘\nk\n=\n0\n+\nâˆ\n(\nâˆ’\n1\n)\nk\nk\n!\nâ€‹\n(\nt\nâˆ’\nt\n^\n)\nk\nâ€‹\nâˆ«\nğ–¯\nact\nâŸ¨\nA\nâ€‹\n(\nÎ±\n)\nk\nâ€‹\nb\nâ€‹\n(\nÎ±\n)\n,\ne\nA\nâ€‹\n(\nÎ±\n)\nâŠ¤\nâ€‹\n(\nT\nâˆ’\nt\n^\n)\nâ€‹\np\nâ€‹\n(\nT\n;\nÎ±\n)\nâŸ©\nâ€‹\nÎ›\nact\nâ€‹\n(\nd\nâ€‹\nÎ±\n)\n.\n\\displaystyle\\mathcal{S}(t)=\\sum_{k=0}^{+\\infty}\\frac{(-1)^{k}}{k!}(t-\\hat{t})^{k}\\int_{\\mathsf{P}_{\\mathrm{act}}}\\left\\langle{A(\\alpha)^{k}b(\\alpha)},\\,{\\mathrm{e}^{A(\\alpha)^{\\top}(T-\\hat{t})}p(T;\\alpha)}\\right\\rangle\\Lambda_{\\mathrm{act}}(\\mathop{}\\!\\mathrm{d}\\alpha).\nAs the term inside the above integral is uniformly bounded and integrable,\np\nâ€‹\n(\nT\n;\nâ‹…\n)\np(T;\\cdot)\nis integrable (which follows from the transversality condition in the PMP),\nğ–¯\nact\n\\mathsf{P}_{\\mathrm{act}}\nis compact, and\nÎ›\nact\n\\Lambda_{\\mathrm{act}}\nis finite, the series converges absolutely and uniformly and thus\nt\nâ†¦\nğ’®\nâ€‹\n(\nt\n)\n=\nâˆ«\nğ–¯\nact\nâŸ¨\nb\nâ€‹\n(\nÎ±\n)\n,\ne\nA\nâ€‹\n(\nÎ±\n)\nâ€‹\n(\nT\nâˆ’\nt\n)\nâ€‹\np\nâ€‹\n(\nT\n;\nÎ±\n)\nâŸ©\nâ€‹\nÎ›\nact\nâ€‹\n(\nd\nâ€‹\nÎ±\n)\n,\nt\\mapsto\\mathcal{S}(t)=\\int_{\\mathsf{P}_{\\mathrm{act}}}\\left\\langle{b(\\alpha)},\\,{\\mathrm{e}^{A(\\alpha)(T-t)}p(T;\\alpha)}\\right\\rangle\\Lambda_{\\mathrm{act}}(\\mathop{}\\!\\mathrm{d}\\alpha),\nis real-analytic.\nWe are now ready to show the nonexistence of singular arcs. We proceed via contradiction: take a nonempty open interval\nJ\nâŠ‚\n[\n0\n,\nT\n]\nJ\\subset[0,T]\nsuch that\n|\nğ’®\nâ€‹\n(\nt\n)\n|\n=\nÎ·\n\\left\\lvert{\\mathcal{S}(t)}\\right\\rvert=\\eta\nfor all\nt\nâˆˆ\nJ\nt\\in J\n. Without loss of generality we consider the case\nğ’®\nâ€‹\n(\nt\n)\n=\nÎ·\n\\mathcal{S}(t)=\\eta\non\nJ\nJ\n; the second case is identical with\nÎ·\nâ†¦\nâˆ’\nÎ·\n\\eta\\mapsto-\\eta\n. Real analyticity of\nğ’®\nâ€‹\n(\nâ‹…\n)\n\\mathcal{S}(\\cdot)\nimplies that it must be constant for all\nt\nâˆˆ\n[\n0\n,\nT\n]\nt\\in[0,T]\n[\nRud87\n, Chapter 15]\n. Therefore for every\nk\nâ©¾\n1\nk\\geqslant 1\n, the\nk\nk\n-th derivative\nğ’®\n(\nk\n)\nâ€‹\n(\nt\n)\n=\n0\n\\mathcal{S}^{(k)}(t)=0\nfor all\nt\nâˆˆ\nJ\nt\\in J\n. To wit:\n((33))\nğ’®\n(\nk\n)\nâ€‹\n(\nt\n)\n\\displaystyle\\mathcal{S}^{(k)}(t)\n=\n(\nâˆ’\n1\n)\nk\nâ€‹\nâˆ«\nğ–¯\nact\nâŸ¨\nA\nâ€‹\n(\nÎ±\n)\nk\nâ€‹\nb\nâ€‹\n(\nÎ±\n)\n,\ne\nA\nâ€‹\n(\nÎ±\n)\nâŠ¤\nâ€‹\n(\nT\nâˆ’\nt\n)\nâ€‹\np\nâ€‹\n(\nT\n;\nÎ±\n)\nâŸ©\nâ€‹\nÎ›\nact\nâ€‹\n(\nd\nâ€‹\nÎ±\n)\n.\n\\displaystyle=(-1)^{k}\\int_{\\mathsf{P}_{\\mathrm{act}}}\\left\\langle{A(\\alpha)^{k}b(\\alpha)},\\,{\\mathrm{e}^{A(\\alpha)^{\\top}(T-t)}p(T;\\alpha)}\\right\\rangle\\Lambda_{\\mathrm{act}}(\\mathop{}\\!\\mathrm{d}\\alpha).\nNow, fix\nk\nâ©¾\n1\nk\\geqslant 1\nand choose any sequence\nt\nn\nâ†‘\nT\nt_{n}\\uparrow T\nas\nn\nâŸ¶\n+\nâˆ\nn\\longrightarrow+\\infty\n. For\nÎ±\nâˆˆ\nğ–¯\nact\n\\alpha\\in\\mathsf{P}_{\\mathrm{act}}\nwe have\nâŸ¨\nA\n(\nÎ±\n)\nk\nb\n(\nÎ±\n)\n,\ne\nA\nâ€‹\n(\nÎ±\n)\nâŠ¤\nâ€‹\n(\nT\nâˆ’\nt\nn\n)\np\n(\nT\n;\nÎ±\n)\nâŸ©\nâ†’\nâŸ¨\nA\n(\nÎ±\n)\n)\nk\nb\n(\nÎ±\n)\n,\np\n(\nT\n;\nÎ±\n)\nâŸ©\n\\left\\langle{A(\\alpha)^{k}b(\\alpha)},\\,{\\mathrm{e}^{A(\\alpha)^{\\top}(T-t_{n})}p(T;\\alpha)}\\right\\rangle\\to\\left\\langle{A(\\alpha))^{k}b(\\alpha)},\\,{p(T;\\alpha)}\\right\\rangle\nas\nn\nâŸ¶\n+\nâˆ\nn\\longrightarrow+\\infty\n, because\ne\nA\nâ€‹\n(\nÎ±\n)\nâŠ¤\nâ€‹\n(\nT\nâˆ’\nt\nn\n)\nâ†’\nI\n\\mathrm{e}^{A(\\alpha)^{\\top}(T-t_{n})}\\to I\nand thus using the dominated convergence theorem\nlim\nn\nâ†’\n+\nâˆ\nâˆ«\nğ–¯\nact\nâŸ¨\nA\nâ€‹\n(\nÎ±\n)\nk\nâ€‹\nb\nâ€‹\n(\nÎ±\n)\n,\ne\nA\nâ€‹\n(\nÎ±\n)\nâŠ¤\nâ€‹\n(\nT\nâˆ’\nt\nn\n)\nâ€‹\np\nâ€‹\n(\nT\n;\nÎ±\n)\nâŸ©\nâ€‹\nÎ›\nact\nâ€‹\n(\nd\nâ€‹\nÎ±\n)\n\\displaystyle\\lim_{n\\to+\\infty}\\int_{\\mathsf{P}_{\\mathrm{act}}}\\left\\langle{A(\\alpha)^{k}b(\\alpha)},\\,{\\mathrm{e}^{A(\\alpha)^{\\top}(T-t_{n})}p(T;\\alpha)}\\right\\rangle\\Lambda_{\\mathrm{act}}(\\mathop{}\\!\\mathrm{d}\\alpha)\n((34))\n=\nâˆ«\nğ–¯\nact\nâŸ¨\nA\n(\nÎ±\n)\n)\nk\nb\n(\nÎ±\n)\n,\np\n(\nT\n;\nÎ±\n)\nâŸ©\nâ‰•\nâ„³\nk\n.\n\\displaystyle=\\int_{\\mathsf{P}_{\\mathrm{act}}}\\left\\langle{A(\\alpha))^{k}b(\\alpha)},\\,{p(T;\\alpha)}\\right\\rangle\\eqqcolon\\mathcal{M}_{k}.\nCombining with (\n(33)\n) we get\n((35))\nlim\nt\nâ†‘\nT\nğ’®\nk\nâ€‹\n(\nt\n)\n=\n(\nâˆ’\n1\n)\nk\nâ€‹\nâ„³\nk\n.\n\\displaystyle\\lim_{t\\uparrow T}\\mathcal{S}^{k}(t)=(-1)^{k}\\mathcal{M}_{k}.\nFrom Assumption\n(\n3.2\n-b)\n, we have for any nonzero measurable\nv\nâ€‹\n(\nâ‹…\n)\nv(\\cdot)\nin the terminal normal cone, at least one\nM\nk\nM_{k}\n(with\nk\nâ©¾\n1\nk\\geqslant 1\n) is nonzero. But from (\n(35)\n) we see that the singular interval enforces\nâ„³\n1\n=\nâ„³\n2\n=\nâ€¦\n=\nâ„³\nd\nâˆ’\n1\n=\n0\n\\mathcal{M}_{1}=\\mathcal{M}_{2}=\\ldots=\\mathcal{M}_{d-1}=0\n, hence\nv\nâ€‹\n(\nâ‹…\n)\nâ‰”\np\nâ€‹\n(\nT\n;\nâ‹…\n)\nâ‰¡\n0\nv(\\cdot)\\coloneqq p(T;\\cdot)\\equiv 0\nÎ›\nact\n\\Lambda_{\\mathrm{act}}\n-a.e., and this gives us and\nğ’®\nâ€‹\n(\nt\n)\nâ‰¡\n0\n\\mathcal{S}(t)\\equiv 0\non\n]\n0\n,\nT\n[\n]0,T[\nâ€” a contradiction. Hence no singular interval\nJ\nJ\nexists. Thus,\nu\nâˆ—\nâ€‹\n(\nâ‹…\n)\nu^{\\ast}(\\cdot)\nis bang-off-bang a.e., completing our proof.\nâˆ\nWe are ready to show the equivalence between the\nL\n0\n{L}^{0}\nproblem (\n(7)\n) and the\nL\n1\n{L}^{1}\nproblem (\n(8)\n). We recall and introduce some notations first. Recall that the set of admissible controls is given by\n((38))\nğ’°\nad\nâ‰”\n{\nu\n(\nâ‹…\n)\nâˆˆ\nL\nâˆ\n(\n[\n0\n,\nT\n]\n;\nâ„\n)\n|\nu\nâ€‹\n(\nt\n)\nâˆˆ\nğ•Œ\nâ€‹\nfor a.e.\nâ€‹\nt\nâˆˆ\n[\n0\n,\nT\n]\nâ€‹\nand\nÏˆ\nâ€‹\n(\nx\nâ€‹\n(\nT\n;\nÎ±\n)\n)\nâ©½\n0\nâ€‹\nfor all\nâ€‹\nÎ±\nâˆˆ\nğ–¯\n}\n,\n\\displaystyle\\mathcal{U}_{\\text{ad}}\\coloneqq\\left\\{u(\\cdot)\\in{L}^{\\infty}([0,T];\\mathbb{R})\\;\\middle|\\;\\begin{array}[]{@{}l@{}}u(t)\\in\\mathbb{U}\\text{ for a.e. }t\\in[0,T]\\text{ and }\\\\\n\\psi\\bigl(x(T;\\alpha)\\bigr)\\leqslant 0\\text{ for all }\\alpha\\in\\mathsf{P}\\end{array}\\right\\},\nwhich is, by assumption, nonempty. Also recall the expression of\nL\n0\n{L}^{0}\nobjective function\n((39))\nu\nâ€‹\n(\nâ‹…\n)\nâ†¦\nğ’¥\n0\nâ€‹\n(\nu\nâ€‹\n(\nâ‹…\n)\n)\nâ‰”\nÎ¼\nâ€‹\n(\n{\nt\nâˆˆ\n[\n0\n,\nT\n]\n|\n|\nu\nâ€‹\n(\nt\n)\n|\nâ‰ \n0\n}\n)\n,\n\\displaystyle\\ u(\\cdot)\\mapsto\\mathcal{J}_{0}\\bigl(u(\\cdot)\\bigr)\\coloneqq\\mu\\bigl(\\big\\{t\\in[0,T]\\;|\\;\\left\\lvert{u(t)}\\right\\rvert\\neq 0\\big\\}\\bigr),\nand the\nL\n1\n{L}^{1}\nobjective function\n((40))\nu\nâ€‹\n(\nâ‹…\n)\nâ†¦\nğ’¥\n1\nâ€‹\n(\nu\nâ€‹\n(\nâ‹…\n)\n)\nâ‰”\nâˆ«\n0\nT\n|\nu\nâ€‹\n(\nt\n)\n|\nâ€‹\nd\nâ€‹\nt\n.\n\\displaystyle u(\\cdot)\\mapsto\\mathcal{J}_{1}\\bigl(u(\\cdot)\\bigr)\\coloneqq\\int_{0}^{T}\\left\\lvert{u(t)}\\right\\rvert\\mathop{}\\!\\mathrm{d}t.\nWe are ready to state our equivalence result.\n{myOCP}\nTheorem 3.6\n.\nConsider the OCP (\n(7)\n) and (\n(8)\n) along with their associated data\n((\n(5)\n)-a)\nâ€“\n((\n(5)\n)-c)\n. Recall the definition of the admissible set (\n(11)\n) and objectives (\n(39)\n)â€“(\n(40)\n). Suppose that the hypotheses of Theorem\n3.1\n, Theorem\n3.2\n, and Corollary\n3.4\nhold. Define the optimal control set for the\nL\n0\n{L}^{0}\nproblem by\n((41))\nğ’°\n0\nâˆ—\nâ‰”\n{\nu\n0\nâˆ—\nâ€‹\n(\nâ‹…\n)\nâˆˆ\nğ’°\nad\n|\nğ’¥\n0\nâ€‹\n(\nu\n0\nâˆ—\nâ€‹\n(\nâ‹…\n)\n)\nâ©½\nğ’¥\n0\nâ€‹\n(\nu\nâ€‹\n(\nâ‹…\n)\n)\nâ€‹\nfor all\nâ€‹\nu\nâ€‹\n(\nâ‹…\n)\nâˆˆ\nğ’°\nad\n}\n,\n\\displaystyle\\mathcal{U}_{0}^{\\ast}\\coloneqq\\bigg\\{u_{0}^{\\ast}(\\cdot)\\in\\mathcal{U}_{\\text{ad}}\\;\\bigg|\\;\\mathcal{J}_{0}\\bigl(u_{0}^{\\ast}(\\cdot)\\bigr)\\leqslant\\mathcal{J}_{0}\\bigl(u(\\cdot)\\bigr)\\text{ for all }u(\\cdot)\\in\\mathcal{U}_{\\text{ad}}\\bigg\\},\nand the\nL\n1\n{L}^{1}\nproblem by\n((42))\nğ’°\n1\nâˆ—\nâ‰”\n{\nu\n1\nâˆ—\nâ€‹\n(\nâ‹…\n)\nâˆˆ\nğ’°\nad\n|\nğ’¥\n1\nâ€‹\n(\nu\n1\nâˆ—\nâ€‹\n(\nâ‹…\n)\n)\nâ©½\nğ’¥\n1\nâ€‹\n(\nu\nâ€‹\n(\nâ‹…\n)\n)\nâ€‹\nfor all\nâ€‹\nu\nâ€‹\n(\nâ‹…\n)\nâˆˆ\nğ’°\nad\n}\n.\n\\displaystyle\\mathcal{U}_{1}^{\\ast}\\coloneqq\\bigg\\{u_{1}^{\\ast}(\\cdot)\\in\\mathcal{U}_{\\text{ad}}\\;\\bigg|\\;\\mathcal{J}_{1}\\bigl(u_{1}^{\\ast}(\\cdot)\\bigr)\\leqslant\\mathcal{J}_{1}\\bigl(u(\\cdot)\\bigr)\\text{ for all }u(\\cdot)\\in\\mathcal{U}_{\\text{ad}}\\bigg\\}.\nThen the set of\nL\n0\n{L}^{0}\noptimal controls is equivalent to the set of\nL\n1\n{L}^{1}\noptimal controls, i.e.,\nğ’°\n0\nâˆ—\n=\nğ’°\n1\nâˆ—\n\\mathcal{U}_{0}^{\\ast}=\\mathcal{U}_{1}^{\\ast}\n.\nProof.\nWe first show\nğ’°\n1\nâˆ—\nâŠ‚\nğ’°\n0\nâˆ—\n\\mathcal{U}_{1}^{\\ast}\\subset\\mathcal{U}_{0}^{\\ast}\n. Towards this end, let\nu\n1\nâˆ—\nâ€‹\n(\nâ‹…\n)\nâˆˆ\nğ’°\n1\nâˆ—\nu_{1}^{\\ast}(\\cdot)\\in\\mathcal{U}_{1}^{\\ast}\n; such\nu\n1\nâˆ—\nâ€‹\n(\nâ‹…\n)\nu_{1}^{\\ast}(\\cdot)\nexists because due to Theorem\n3.1\n. From Corollary\n3.4\nwe know that\nt\nâ†¦\nu\n1\nâˆ—\nâ€‹\n(\nt\n)\nt\\mapsto u_{1}^{\\ast}(t)\nmust be a bang-off-bang, i.e., for a.e.\nt\nâˆˆ\n[\n0\n,\nT\n]\nt\\in[0,T]\n,\nu\n1\nâˆ—\nâ€‹\n(\nt\n)\nâˆˆ\n{\nâˆ’\n1\n,\n0\n,\n1\n}\nu_{1}^{\\ast}(t)\\in\\{-1,0,1\\}\n, which implies\n|\nu\n1\nâˆ—\nâ€‹\n(\nt\n)\n|\n\\left\\lvert{u_{1}^{\\ast}(t)}\\right\\rvert\nis either\n0\nor\n1\n1\n. Thus, we have the equality\n((43))\nğ’¥\n1\nâ€‹\n(\nu\n1\nâˆ—\nâ€‹\n(\nâ‹…\n)\n)\n=\nâˆ«\n0\nT\n|\nu\n1\nâˆ—\nâ€‹\n(\nt\n)\n|\nâ€‹\nd\nâ€‹\nt\n=\nâˆ«\nsupp\nâ€‹\n(\nu\n1\nâˆ—\n)\n1\nâ€‹\nd\nâ€‹\nt\n=\nÎ¼\nâ€‹\n(\nsupp\nâ€‹\n(\nu\n1\nâˆ—\n)\n)\n=\nğ’¥\n0\nâ€‹\n(\nu\n1\nâˆ—\nâ€‹\n(\nâ‹…\n)\n)\n\\displaystyle\\mathcal{J}_{1}\\bigl(u_{1}^{\\ast}(\\cdot)\\bigr)=\\int_{0}^{T}\\left\\lvert{u_{1}^{\\ast}(t)}\\right\\rvert\\mathop{}\\!\\mathrm{d}t=\\int_{\\mathrm{supp}(u_{1}^{\\ast})}1\\mathop{}\\!\\mathrm{d}t=\\mu\\bigl(\\mathrm{supp}(u_{1}^{\\ast})\\bigr)=\\mathcal{J}_{0}\\bigl(u_{1}^{\\ast}(\\cdot)\\bigr)\nNow let\nu\nâ€‹\n(\nâ‹…\n)\nâˆˆ\nğ’°\nad\nu(\\cdot)\\in\\mathcal{U}_{\\text{ad}}\nbe any feasible control trajectory. Then by design\n((44))\nğ’¥\n1\nâ€‹\n(\nu\nâ€‹\n(\nâ‹…\n)\n)\n=\nâˆ«\n0\nT\n|\nu\nâ€‹\n(\nt\n)\n|\nâ€‹\nd\nâ€‹\nt\n=\nâˆ«\nsupp\nâ€‹\n(\nu\n)\n|\nu\nâ€‹\n(\nt\n)\n|\nâ€‹\nd\nâ€‹\nt\nâ©½\nâˆ«\nsupp\nâ€‹\n(\nu\n)\n1\nâ€‹\nd\nâ€‹\nt\n=\nğ’¥\n0\nâ€‹\n(\nu\nâ€‹\n(\nâ‹…\n)\n)\n.\n\\displaystyle\\mathcal{J}_{1}\\bigl(u(\\cdot)\\bigr)=\\int_{0}^{T}\\left\\lvert{u(t)}\\right\\rvert\\mathop{}\\!\\mathrm{d}t=\\int_{\\mathrm{supp}(u)}\\left\\lvert{u(t)}\\right\\rvert\\mathop{}\\!\\mathrm{d}t\\leqslant\\int_{\\mathrm{supp}(u)}1\\mathop{}\\!\\mathrm{d}t=\\mathcal{J}_{0}\\bigl(u(\\cdot)\\bigr).\nThus, we have the chain\n((45))\nğ’¥\n0\nâ€‹\n(\nu\n1\nâˆ—\nâ€‹\n(\nâ‹…\n)\n)\n=\n(\nâ€ \n)\nğ’¥\n1\nâ€‹\n(\nu\n1\nâˆ—\nâ€‹\n(\nâ‹…\n)\n)\nâ©½\n(\nâ€¡\n)\nğ’¥\n1\nâ€‹\n(\nu\nâ€‹\n(\nâ‹…\n)\n)\nâ©½\n(\nâˆ˜\n)\nğ’¥\n0\nâ€‹\n(\nu\nâ€‹\n(\nâ‹…\n)\n)\n,\n\\displaystyle\\mathcal{J}_{0}\\bigl(u_{1}^{\\ast}(\\cdot)\\bigr)\\stackrel{{\\scriptstyle\\mathclap{({\\dagger})}}}{{=}}\\mathcal{J}_{1}\\bigl(u_{1}^{\\ast}(\\cdot)\\bigr)\\stackrel{{\\scriptstyle\\mathclap{({\\ddagger})}}}{{\\leqslant}}\\mathcal{J}_{1}\\bigl(u(\\cdot)\\bigr)\\stackrel{{\\scriptstyle\\mathclap{(\\circ)}}}{{\\leqslant}}\\mathcal{J}_{0}\\bigl(u(\\cdot)\\bigr),\nwhere the equality\n(\nâ€ \n)\n({\\dagger})\nfollows from (\n(43)\n), the inequality\n(\nâ€¡\n)\n({\\ddagger})\nfollows because\nu\n1\nâˆ—\nâ€‹\n(\nâ‹…\n)\nu_{1}^{\\ast}(\\cdot)\nis\nL\n1\n{L}^{1}\n-optimal, and the final inequality\n(\nâˆ˜\n)\n(\\circ)\nfollows from (\n(44)\n). Thus,\nğ’¥\n0\nâ€‹\n(\nu\n1\nâˆ—\nâ€‹\n(\nâ‹…\n)\n)\nâ©½\nğ’¥\n0\nâ€‹\n(\nu\nâ€‹\n(\nâ‹…\n)\n)\n\\mathcal{J}_{0}\\bigl(u_{1}^{\\ast}(\\cdot)\\bigr)\\leqslant\\mathcal{J}_{0}\\bigl(u(\\cdot)\\bigr)\nfor any feasible control\nu\nâ€‹\n(\nâ‹…\n)\nu(\\cdot)\n, therefore\nu\n1\nâˆ—\nâ€‹\n(\nâ‹…\n)\nâˆˆ\nğ’°\n0\nâˆ—\nu_{1}^{\\ast}(\\cdot)\\in\\mathcal{U}_{0}^{\\ast}\n.\nWe now prove the other direction\nğ’°\n0\nâˆ—\nâŠ‚\nğ’°\n1\nâˆ—\n\\mathcal{U}_{0}^{\\ast}\\subset\\mathcal{U}_{1}^{\\ast}\n. Let\nu\n0\nâˆ—\nâ€‹\n(\nâ‹…\n)\nâˆˆ\nğ’°\n0\nâˆ—\nu_{0}^{\\ast}(\\cdot)\\in\\mathcal{U}_{0}^{\\ast}\nand also choose independently\nu\n1\nâˆ—\nâ€‹\n(\nâ‹…\n)\nâˆˆ\nğ’°\n1\nâˆ—\nu_{1}^{\\ast}(\\cdot)\\in\\mathcal{U}_{1}^{\\ast}\n. Because\nu\n1\nâˆ—\nâ€‹\n(\nâ‹…\n)\nu_{1}^{\\ast}(\\cdot)\nis bang-off-bang, we have\n((46))\nğ’¥\n1\nâ€‹\n(\nu\n1\nâˆ—\nâ€‹\n(\nâ‹…\n)\n)\n=\nâˆ«\n0\nT\n|\nu\n1\nâˆ—\nâ€‹\n(\nt\n)\n|\nâ€‹\nd\nâ€‹\nt\n=\nâˆ«\nsupp\nâ€‹\n(\nu\n1\nâˆ—\n)\n1\nâ€‹\nd\nâ€‹\nt\n=\nğ’¥\n0\nâ€‹\n(\nu\n1\nâˆ—\nâ€‹\n(\nâ‹…\n)\n)\n,\n\\displaystyle\\mathcal{J}_{1}\\bigl(u_{1}^{\\ast}(\\cdot)\\bigr)=\\int_{0}^{T}\\left\\lvert{u_{1}^{\\ast}(t)}\\right\\rvert\\mathop{}\\!\\mathrm{d}t=\\int_{\\mathrm{supp}(u_{1}^{\\ast})}1\\mathop{}\\!\\mathrm{d}t=\\mathcal{J}_{0}\\bigl(u_{1}^{\\ast}(\\cdot)\\bigr),\nand thus using (\n(43)\n) we have\n((47))\nğ’¥\n0\nâ€‹\n(\nu\n1\nâˆ—\nâ€‹\n(\nâ‹…\n)\n)\n=\nğ’¥\n1\nâ€‹\n(\nu\n1\nâˆ—\nâ€‹\n(\nâ‹…\n)\n)\nâ©½\nğ’¥\n1\nâ€‹\n(\nu\n0\nâˆ—\nâ€‹\n(\nâ‹…\n)\n)\n.\n\\displaystyle\\mathcal{J}_{0}\\bigl(u_{1}^{\\ast}(\\cdot)\\bigr)=\\mathcal{J}_{1}\\bigl(u_{1}^{\\ast}(\\cdot)\\bigr)\\leqslant\\mathcal{J}_{1}\\bigl(u_{0}^{\\ast}(\\cdot)\\bigr).\nNow using the fact that\nğ’¥\n1\nâ€‹\n(\nu\n0\nâˆ—\nâ€‹\n(\nâ‹…\n)\n)\nâ©½\nğ’¥\n0\nâ€‹\n(\nu\n0\nâˆ—\nâ€‹\n(\nâ‹…\n)\n)\n\\mathcal{J}_{1}\\bigl(u_{0}^{\\ast}(\\cdot)\\bigr)\\leqslant\\mathcal{J}_{0}\\bigl(u_{0}^{\\ast}(\\cdot)\\bigr)\nand that\nu\n0\nâˆ—\nâ€‹\n(\nâ‹…\n)\nu_{0}^{\\ast}(\\cdot)\nis\nL\n0\n{L}^{0}\n-optimal, we have the inequalities\n((48))\nğ’¥\n1\nâ€‹\n(\nu\n0\nâˆ—\nâ€‹\n(\nâ‹…\n)\n)\nâ©½\nğ’¥\n0\nâ€‹\n(\nu\n0\nâˆ—\nâ€‹\n(\nâ‹…\n)\n)\nâ©½\nğ’¥\n0\nâ€‹\n(\nu\n1\nâˆ—\nâ€‹\n(\nâ‹…\n)\n)\n.\n\\displaystyle\\mathcal{J}_{1}\\bigl(u_{0}^{\\ast}(\\cdot)\\bigr)\\leqslant\\mathcal{J}_{0}\\bigl(u_{0}^{\\ast}(\\cdot)\\bigr)\\leqslant\\mathcal{J}_{0}\\bigl(u_{1}^{\\ast}(\\cdot)\\bigr).\nThen, with (\n(47)\n) and (\n(48)\n) we have the chain\n((49))\nğ’¥\n0\nâ€‹\n(\nu\n1\nâˆ—\nâ€‹\n(\nâ‹…\n)\n)\n=\nğ’¥\n1\nâ€‹\n(\nu\n1\nâˆ—\nâ€‹\n(\nâ‹…\n)\n)\nâ©½\nğ’¥\n1\nâ€‹\n(\nu\n0\nâˆ—\nâ€‹\n(\nâ‹…\n)\n)\nâ©½\nğ’¥\n0\nâ€‹\n(\nu\n0\nâˆ—\nâ€‹\n(\nâ‹…\n)\n)\nâ©½\nğ’¥\n0\nâ€‹\n(\nu\n1\nâˆ—\nâ€‹\n(\nâ‹…\n)\n)\n,\n\\displaystyle\\mathcal{J}_{0}\\bigl(u_{1}^{\\ast}(\\cdot)\\bigr)=\\mathcal{J}_{1}\\bigl(u_{1}^{\\ast}(\\cdot)\\bigr)\\leqslant\\mathcal{J}_{1}\\bigl(u_{0}^{\\ast}(\\cdot)\\bigr)\\leqslant\\mathcal{J}_{0}\\bigl(u_{0}^{\\ast}(\\cdot)\\bigr)\\leqslant\\mathcal{J}_{0}\\bigl(u_{1}^{\\ast}(\\cdot)\\bigr),\nwhich gives us\nğ’¥\n1\nâ€‹\n(\nu\n1\nâˆ—\nâ€‹\n(\nâ‹…\n)\n)\n=\nğ’¥\n1\nâ€‹\n(\nu\n0\nâˆ—\nâ€‹\n(\nâ‹…\n)\n)\n\\mathcal{J}_{1}\\bigl(u_{1}^{\\ast}(\\cdot)\\bigr)=\\mathcal{J}_{1}\\bigl(u_{0}^{\\ast}(\\cdot)\\bigr)\nand thus\nu\n0\nâˆ—\nâ€‹\n(\nâ‹…\n)\nâˆˆ\nğ’°\n1\nâˆ—\nu_{0}^{\\ast}(\\cdot)\\in\\mathcal{U}_{1}^{\\ast}\n. The proof is complete.\nâˆ\nRemark 3.7\n.\nTheorem\n3.6\nstates that, under normality and the nondegeneracy condition of Corollary\n3.4\n, the optimal solution sets of the robust\nL\n0\n{L}^{0}\nand robust\nL\n1\n{L}^{1}\nproblems coincide, i.e.,\nğ’°\n1\nâˆ—\n=\nğ’°\n0\nâˆ—\n\\mathcal{U}_{1}^{\\ast}=\\mathcal{U}_{0}^{\\ast}\n. The practical implication is that the intrinsically nonconvex and nonsmooth robust\nL\n0\n{L}^{0}\noptimal control problems can instead be solved by solving their convex robust\nL\n1\n{L}^{1}\nsurrogate, without loss of optimality, thereby enabling the use of a wide range of existing robust optimization solvers for numerical implementation; thatâ€™s the subject matter of Â§\n3.2\n.\n3.2.\nAlgorithmic developments\nLeveraging the equivalence result in Theorem\n3.6\n, we follow the scientific suggestions given in\n[\nVin05\n, Â§1. Introduction, p.3]\nto develop an algorithmic framework to solve the\nL\n1\n{L}^{1}\nrobust OCP (\n(8)\n). OCP (\n(8)\n) being an infinite-dimensional optimization problem over\nğ’°\nad\n\\mathcal{U}_{\\text{ad}}\nis numerically intractable in general, and towards this end, we parametrize the space of control actions\nğ’°\n\\mathcal{U}\nvia piecewise constant dictionaries, which is a standard approach in numerical optimal control\n[\nDGAC23\n,\nGDC24\n,\nGC24\n,\nGDA\n+\n25\n]\n.\nLet\nN\nâˆˆ\nâ„•\nâˆ—\nN\\in\\mathbb{N}^{*}\nand consider a dictionary\nğ’Ÿ\nâ‰”\n{\nÏ•\ni\nâ€‹\n(\nâ‹…\n)\n}\ni\nâˆˆ\nâ„•\nâˆ—\nâŠ‚\nğ–¯ğ–¢\nh\nâ€‹\n(\n[\n0\n,\nT\n]\n;\nâ„\n)\n\\mathcal{D}\\coloneqq\\{\\phi_{i}(\\cdot)\\}_{i\\in\\mathbb{N}^{*}}\\subset\\mathsf{PC}_{h}([0,T];\\mathbb{R})\nconsisting of piecewise constant functions that are linearly independent and normalized, i.e.,\nmax\ni\nâ¡\nmax\nt\nâ¡\n|\nÏ•\ni\nâ€‹\n(\nt\n)\n|\n=\n1\n.\n\\max_{i}\\max_{t}\\left\\lvert{\\phi_{i}(t)}\\right\\rvert=1.\nWe define the parametrized set of admissible control trajectories\nğ’°\nğ’Ÿ\nâŠ‚\nğ–¯ğ–¢\nh\nâ€‹\n(\n[\n0\n,\nT\n]\n;\nâ„\n)\n\\mathcal{U}_{\\mathcal{D}}\\subset\\mathsf{PC}_{h}([0,T];\\mathbb{R})\nby\nğ’°\nğ’Ÿ\nâ‰”\nspan\nâ¡\n{\nÏ•\ni\n:\n[\n0\n,\nT\n]\nâŸ¶\nâ„\n|\ni\n=\n1\n,\nâ€¦\n,\nN\n}\n.\n\\displaystyle\\mathcal{U}_{\\mathcal{D}}\\coloneqq\\operatorname{span}\\big\\{\\phi_{i}:[0,T]\\longrightarrow\\mathbb{R}\\;|\\;i=1,\\ldots,N\\big\\}.\nLet\nt\nâ†¦\nÎ¦\nâ€‹\n(\nt\n)\nâ‰”\n(\nÏ•\n1\nâ€‹\n(\nt\n)\nâ€‹\nÏ•\n2\nâ€‹\n(\nt\n)\nâ€‹\nâ€¦\nâ€‹\nÏ•\nN\nâ€‹\n(\nt\n)\n)\nâˆˆ\nâ„\nN\nt\\mapsto\\Phi(t)\\coloneqq\\bigl(\\phi_{1}(t)\\;\\phi_{2}(t)\\;\\ldots\\;\\phi_{N}(t)\\bigr)\\in\\mathbb{R}^{N}\n. Then, we define the parametrized control trajectory by\n((50))\n[\n0\n,\nT\n]\nâˆ‹\nt\nâ†¦\nu\nğ’Ÿ\nâ€‹\n(\nt\n)\n=\nâˆ‘\nj\n=\n1\nN\nÎ¸\nj\nâ€‹\nÏˆ\nj\nâ€‹\n(\nt\n)\n=\nÎ¸\nâ€‹\nÎ¦\nâ€‹\n(\nt\n)\n\\displaystyle[0,T]\\ni t\\mapsto u^{\\mathcal{D}}(t)=\\sum_{j=1}^{N}\\theta_{j}\\psi_{j}(t)=\\theta\\Phi(t)\nwhere\nÎ¸\nâˆˆ\nâ„\n1\nÃ—\nN\n\\theta\\in\\mathbb{R}^{1\\times N}\nare the control parameters. Using the parametrizations in (\n(50)\n) we express the solution to (\n(5)\n) as\n((51))\n[\n0\n,\nT\n]\nâˆ‹\nt\nâ†¦\nx\nÎ¸\nâ€‹\n(\nt\n;\nx\nÂ¯\n,\nÎ±\n)\n\\displaystyle[0,T]\\ni t\\mapsto x_{\\theta}(t;\\overline{x},\\alpha)\nâ‰”\ne\nA\nâ€‹\n(\nÎ±\n)\nâ€‹\nt\nâ€‹\nx\nÂ¯\n+\nâˆ«\n0\nt\ne\nA\nâ€‹\n(\nÎ±\n)\nâ€‹\n(\nt\nâˆ’\nÏ„\n)\nâ€‹\nb\nâ€‹\n(\nÎ±\n)\nâ€‹\nÎ¸\nâ€‹\nÎ¦\nâ€‹\n(\nÏ„\n)\nâ€‹\nd\nâ€‹\nÏ„\nâ€‹\nfor\nâ€‹\nÎ±\nâˆˆ\nğ–¯\n,\n\\displaystyle\\coloneqq\\mathrm{e}^{A(\\alpha)t}\\overline{x}+\\int_{0}^{t}\\mathrm{e}^{A(\\alpha)(t-\\tau)}b(\\alpha)\\theta\\Phi(\\tau)\\mathop{}\\!\\mathrm{d}\\tau\\text{ for }\\alpha\\in\\mathsf{P},\nand abusing notation we will write the trajectory (\n(51)\n) by\nt\nâ†¦\nx\nÎ¸\nâ€‹\n(\nt\n;\nÎ±\n)\nt\\mapsto x_{\\theta}(t;\\alpha)\n. The generating functions\nÏ•\nj\nâ€‹\n(\nâ‹…\n)\n\\phi_{j}(\\cdot)\nfor\nj\n=\n1\n,\nâ€¦\n,\nN\nj=1,\\ldots,N\nare piecewise constant and thus\n((52))\nâ„\nN\nâˆ‹\nÎ¦\nâ€‹\n(\nt\n)\n=\n{\nÎ¦\nk\nâˆ’\n1\nif\nt\nâˆˆ\n[\nt\nk\nâˆ’\n1\n,\nt\nk\n[\n,\nÎ¦\nK\nif\nâ€‹\nt\nâˆˆ\n[\nt\nK\n,\nT\n]\n,\n\\displaystyle\\mathbb{R}^{N}\\ni\\Phi(t)=\\begin{cases}\\Phi_{k-1}\\quad&\\text{if }t\\in[t_{k-1},t_{k}[,\\\\\n\\Phi_{K}&\\text{if }t\\in[t_{K},T],\\end{cases}\nwhere\nÎ¦\nk\nâˆ’\n1\n\\Phi_{k-1}\nfor\nk\n=\n1\n,\nâ€¦\n,\nK\nâˆ’\n1\nk=1,\\ldots,K-1\nand\nÎ¦\nK\n\\Phi_{K}\nare all vectors in\nâ„\nN\n\\mathbb{R}^{N}\n. The cost in (\n(8)\n) can therefore, be further simplified as\nğ’¥\n1\nâ€‹\n(\nÎ¸\nâ€‹\nÎ¦\nâ€‹\n(\nâ‹…\n)\n)\n=\n\\displaystyle\\mathcal{J}_{1}\\bigl(\\theta\\Phi(\\cdot)\\bigr)=\nâ‰”\nâˆ«\n0\nT\n|\nÎ¸\nâ€‹\nÎ¦\nâ€‹\n(\nt\n)\n|\nâ€‹\nd\nâ€‹\nt\n=\nâˆ‘\nk\n=\n1\nK\nâˆ«\nt\nk\nâˆ’\n1\nt\nk\n|\nÎ¸\nâ€‹\nÎ¦\nk\nâˆ’\n1\n|\nâ€‹\nd\nâ€‹\nt\n+\nâˆ«\nt\nK\nT\n|\nÎ¸\nâ€‹\nÎ¦\nK\n|\nâ€‹\nd\nâ€‹\nt\n\\displaystyle\\coloneqq\\int_{0}^{T}\\left\\lvert{\\theta\\Phi(t)}\\right\\rvert\\mathop{}\\!\\mathrm{d}t=\\sum_{k=1}^{K}\\int_{t_{k-1}}^{t_{k}}\\left\\lvert{\\theta\\Phi_{k-1}}\\right\\rvert\\mathop{}\\!\\mathrm{d}t+\\int_{t_{K}}^{T}\\left\\lvert{\\theta\\Phi_{K}}\\right\\rvert\\mathop{}\\!\\mathrm{d}t\n((53))\n=\nâˆ‘\nk\n=\n1\nK\nh\nâ€‹\n|\nÎ¸\nâ€‹\nÎ¦\nk\nâˆ’\n1\n|\n+\n(\nT\nâˆ’\nt\nK\n)\nâ€‹\n|\nÎ¸\nâ€‹\nÎ¦\nK\n|\n,\n\\displaystyle=\\sum_{k=1}^{K}h\\left\\lvert{\\theta\\Phi_{k-1}}\\right\\rvert+(T-t_{K})\\left\\lvert{\\theta\\Phi_{K}}\\right\\rvert,\nwhere\nh\n=\nt\nk\nâˆ’\nt\nk\nâˆ’\n1\n>\n0\nh=t_{k}-t_{k-1}>0\n.\nPutting everything together in (\n(8)\n), we obtain the following optimization problem:\n((54))\ninf\nÎ¸\n\\displaystyle\\hskip-11.38109pt\\inf_{\\theta}\nğ’¥\n1\nâ€‹\n(\nÎ¸\nâ€‹\nÎ¦\nâ€‹\n(\nâ‹…\n)\n)\n=\nâˆ‘\nk\n=\n1\nK\nh\nâ€‹\n|\nÎ¸\nâ€‹\nÎ¦\nk\nâˆ’\n1\n|\n+\n(\nT\nâˆ’\nt\nK\n)\nâ€‹\n|\nÎ¸\nâ€‹\nÎ¦\nK\n|\n\\displaystyle\\mathcal{J}_{1}\\bigl(\\theta\\Phi(\\cdot)\\bigr)=\\sum_{k=1}^{K}h\\left\\lvert{\\theta\\Phi_{k-1}}\\right\\rvert+(T-t_{K})\\left\\lvert{\\theta\\Phi_{K}}\\right\\rvert\nsubject\nâ€‹\nto\n\\displaystyle\\hskip-11.38109pt\\operatorname{subject\\ to}\n{\nÎ¸\nâ€‹\nÎ¦\nâ€‹\n(\nt\n)\nâˆˆ\nğ•Œ\n,\nÏˆ\nâ€‹\n(\nx\nÎ¸\nâ€‹\n(\nT\n;\nÎ±\n)\n)\nâ©½\n0\nâ€‹\nfor all\nâ€‹\nÎ±\nâˆˆ\nğ–¯\n.\n\\displaystyle\nRemark 3.8\n.\nThe optimal control problem (\n(54)\n) has been reformulated as a finite-dimensional optimization problem. However, it still involves a\ncompact, uncountable family of constraints\nindexed by\nÎ±\nâˆˆ\nğ–¯\n\\alpha\\in\\mathsf{P}\n. Standard discretize-then-optimize methods for optimal control\n[\nBet10\n,\nGRCB22\n,\nGDC24\n]\nare not suitable here, as they are unable to accommodate such an uncountable set of uncertainties. In the sequel, we develop and employ a robust optimization-based algorithm specifically designed to handle this class of problems.\nThe next proposition shows that (\n(54)\n) has nice qualitative properties.\n{myOCP}\nProposition 3.9\n.\nConsider the OCP (\n(8)\n) along with its problem data\n((\n(5)\n)-a)\nâ€“\n((\n(5)\n)-c)\n, the parametrization (\n(50)\n), and the OCP (\n(54)\n). Then, the set of admissible control parameters corresponding to the representation (\n(50)\n)\nâ„³\nâ‰”\n{\nÎ¸\nâˆˆ\nâ„\n1\nÃ—\nN\n|\nÎ¸\nâ€‹\nÎ¦\nâ€‹\n(\nt\n)\nâˆˆ\nğ•Œ\nâ€‹\nfor all\nâ€‹\nt\nâˆˆ\n[\n0\n,\nT\n]\n}\n,\n\\mathcal{M}\\coloneqq\\left\\{\\theta\\in\\mathbb{R}^{1\\times N}\\,\\middle|\\begin{array}[]{@{}l@{}}\\,\\theta\\Phi(t)\\in\\mathbb{U}\\;\\text{for all }t\\in[0,T]\\end{array}\\right\\},\nis compact and convex, moreover, if the feasible set of (\n(54)\n) is defined by\n((56))\nâ„±\nO\nâ‰”\n{\nÎ¸\nâˆˆ\nâ„³\n|\nÏˆ\nâ€‹\n(\nx\nÎ¸\nâ€‹\n(\nT\n;\nÎ±\n)\n)\nâ©½\n0\nâ€‹\nfor all\nâ€‹\nÎ±\nâˆˆ\nğ–¯\n}\n,\n\\displaystyle\\mathcal{F}_{O}\\coloneqq\\left\\{\\theta\\in\\mathcal{M}\\;\\middle|\\;\\begin{array}[]{@{}l@{}}\\psi\\bigl(x_{\\theta}(T;\\alpha)\\bigr)\\leqslant 0\\text{ for all }\\alpha\\in\\mathsf{P}\\end{array}\\right\\},\nthe program (\n(54)\n) admits a solution.\nProof.\nThe mapping\nÎ¸\nâ†¦\nÎ¸\nâ€‹\nÎ¦\nâ€‹\n(\nt\n)\n\\theta\\mapsto\\theta\\Phi(t)\nis linear and\nğ•Œ\n\\mathbb{U}\nis convex; thus convexity of\nâ„³\n\\mathcal{M}\nfollows readily. Moreover,\nğ•Œ\n\\mathbb{U}\nis closed and bounded and the mapping\nÎ¸\nâ†¦\nÎ¸\nâ€‹\nÎ¦\nâ€‹\n(\nt\n)\n\\theta\\mapsto\\theta\\Phi(t)\nis continuous, thus\nâ„³\n\\mathcal{M}\nis closed because it is the preimage of a closed set under a continuous map. The boundedness of\nâ„³\n\\mathcal{M}\nfollows immediately because\nğ•Œ\n\\mathbb{U}\nis bounded and\nÏ•\ni\nâ€‹\n(\nâ‹…\n)\n\\phi_{i}(\\cdot)\nare linearly independent. Thus\nâ„³\n\\mathcal{M}\nis compact and convex.\nThe set\nâ„±\nO\n\\mathcal{F}_{O}\nis compact. Indeed,\nâ„³\n\\mathcal{M}\nis compact and for a fixed\nÎ±\nâˆˆ\nğ–¯\n\\alpha\\in\\mathsf{P}\n(which is convex and compact), the mapping\nâ„³\nâˆ‹\nÎ¸\nâ†¦\nÏˆ\nâˆ˜\nx\nÎ¸\nâ€‹\n(\nT\n;\nÎ±\n)\n\\mathcal{M}\\ni\\theta\\mapsto\\psi\\circ x_{\\theta}(T;\\alpha)\nis continuous being composition of continuous maps\nÎ¾\nâ†¦\nÏˆ\nâ€‹\n(\nÎ¾\n)\n\\xi\\mapsto\\psi(\\xi)\nand\nâ„³\nâˆ‹\nÎ¸\nâ†¦\nx\nÎ¸\nâ€‹\n(\nT\n;\nÎ±\n)\n\\mathcal{M}\\ni\\theta\\mapsto x_{\\theta}(T;\\alpha)\n. Thus,\nâ„±\nO\n\\mathcal{F}_{O}\nis the intersection of\nâ„³\n\\mathcal{M}\nwith the preimage of\n]\nâˆ’\nâˆ\n,\n0\n]\n]-\\infty,0]\nunder\nâ„³\nâˆ‹\nÎ¸\nâ†¦\nÏˆ\nâˆ˜\nx\nÎ¸\nâ€‹\n(\nT\n;\nÎ±\n)\n\\mathcal{M}\\ni\\theta\\mapsto\\psi\\circ x_{\\theta}(T;\\alpha)\n((57))\nâ„±\nO\n=\nâ„³\nâˆ©\nâ‹‚\nÎ±\nâˆˆ\nğ–¯\n(\nÏˆ\nâˆ˜\nx\n(\nâ‹…\n)\n(\nT\n;\nÎ±\n)\n)\nâˆ’\n1\n(\n]\nâˆ’\nâˆ\n,\n0\n]\n)\n,\n\\displaystyle\\mathcal{F}_{O}=\\mathcal{M}\\cap\\bigcap_{\\alpha\\in\\mathsf{P}}\\bigl(\\psi\\circ x_{(\\cdot)}(T;\\alpha)\\bigr)^{-1}\\bigl(]-\\infty,0]\\bigr),\nwhich is compact, being an intersection of a closed and a compact set\n[\nRud76\n, Theorem 2.35, p. 37]\n. The convexity of\nâ„±\nO\n\\mathcal{F}_{O}\nalso follows immediately because\nÏˆ\nâ€‹\n(\nâ‹…\n)\n\\psi(\\cdot)\nis convex and\nâ„³\nâˆ‹\nÎ¸\nâ†¦\nÏˆ\nâ€‹\n(\nx\nÎ˜\nâ€‹\n(\nT\n;\nÎ±\n)\n)\n\\mathcal{M}\\ni\\theta\\mapsto\\psi\\bigl(x_{\\Theta}(T;\\alpha)\\bigr)\nis affine. Finally, noting that\nÎ¸\nâ†¦\nğ’¥\n1\nâ€‹\n(\nÎ¸\nâ€‹\nÎ¦\nâ€‹\n(\nâ‹…\n)\n)\n\\theta\\mapsto\\mathcal{J}_{1}\\bigl(\\theta\\Phi(\\cdot)\\bigr)\ndefined in (\n3.2\n) is continuous and convex, existence of solutions to (\n(54)\n) follows readily from Weierstrass theorem\n[\nRud76\n, Chapter 4, Theorem 4.16]\n.\nâˆ\nWe are ready to provide our main result concerning the SIP (\n(54)\n) and its algorithmic solution whose proof follows from standard results in variational analysis\n[\nDR14\n, Chapter 3]\n.\n{myOCP}\nTheorem 3.10\n.\nConsider the OCP (\n(54)\n) and suppose that it is strictly feasible.\n4\n4\n4\nThe OCP (\n(54)\n), satisfies a\nstrict feasibility condition\nif there exists a\nÎ¸\n\\theta\nsuch that\nÏˆ\nâ€‹\n(\nx\nâ€‹\n(\nT\n;\nÎ±\n)\n)\n<\n0\n\\psi\\bigl(x(T;\\alpha)\\bigr)<0\nfor all\nÎ±\nâˆˆ\nğ–¯\n\\alpha\\in\\mathsf{P}\n.\nFix\nx\nÂ¯\nâˆˆ\nâ„\nd\n\\overline{x}\\in\\mathbb{R}^{d}\nand let the optimal value of (\n(54)\n) be\nğ•\nT\nâˆ—\nâ€‹\n(\nx\nÂ¯\n)\n\\mathbb{V}_{T}^{*}(\\overline{x})\n. Denote the set of feasible initial states\nğ•\nT\n\\mathbb{X}_{T}\nfor (\n(54)\n) by\nğ•\nT\nâ‰”\n{\nx\nÂ¯\nâˆˆ\nâ„\nd\n|\nğ•\nT\nâˆ—\nâ€‹\n(\nx\nÂ¯\n)\n<\n+\nâˆ\n}\n\\mathbb{X}_{T}\\coloneqq\\big\\{\\overline{x}\\in\\mathbb{R}^{d}\\;\\big|\\;\\mathbb{V}_{T}^{*}(\\overline{x})<+\\infty\\big\\}\nand let\nğ•\nT\nâ‰ \nâˆ…\n\\mathbb{X}_{T}\\neq\\varnothing\n. Let\n((58))\nm\n^\nâ‰”\nN\n=\ndimension of the decision space of (\n(54)\n)\n,\n\\displaystyle\\widehat{m}\\coloneqq N=\\text{dimension of the decision space of \\eqref{eq:SR:pre_SIP}},\nand define\nğ’«\nâ‰”\n(\nÎ±\n1\n,\nâ€¦\n,\nÎ±\nm\n^\n)\nâˆˆ\nğ–¯\nm\n^\n\\mathcal{P}\\coloneqq(\\alpha^{1},\\ldots,\\alpha^{\\widehat{m}})\\in\\mathsf{P}^{\\widehat{m}}\n. For a fixed\nx\nÂ¯\nâˆˆ\nğ•\nT\n\\overline{x}\\in\\mathbb{X}_{T}\n, define the relaxed version\nğ–¯\nm\n^\nâˆ‹\nğ’«\nâ†¦\nğ’¢\nâ€‹\n(\nx\nÂ¯\n;\nğ’«\n)\nâˆˆ\nâ„\n\\mathsf{P}^{\\widehat{m}}\\ni\\mathcal{P}\\mapsto\\mathcal{G}(\\overline{x};\\mathcal{P})\\in\\mathbb{R}\n, of (\n(54)\n) by\n((59))\nğ’¢\nâ€‹\n(\nx\nÂ¯\n;\nğ’«\n)\nâ‰”\n\\displaystyle\\mathcal{G}(\\overline{x};\\mathcal{P})\\coloneqq\ninf\nÎ¸\nâˆˆ\nâ„³\n\\displaystyle\\inf_{\\theta\\in\\mathcal{M}}\nğ’¥\n1\nâ€‹\n(\nÎ¸\nâ€‹\nÎ¦\nâ€‹\n(\nâ‹…\n)\n)\n\\displaystyle\\mathcal{J}_{1}\\bigl(\\theta\\Phi(\\cdot)\\bigr)\nsubject\nâ€‹\nto\n\\displaystyle\\operatorname{subject\\ to}\n{\nÏˆ\nâ€‹\n(\nx\nÎ¸\nâ€‹\n(\nT\n;\nÎ±\ni\n)\n)\nâ©½\n0\nâ€‹\nfor\nâ€‹\ni\n=\n1\n,\nâ€¦\n,\nm\n^\n.\n\\displaystyle\nConsider the optimization problem\n((60))\nsup\nğ’«\n{\nğ’¢\nâ€‹\n(\nx\nÂ¯\n;\nğ’«\n)\n|\nğ’«\nâˆˆ\nğ–¯\nm\n^\n}\n.\n\\sup_{\\mathcal{P}}\\big\\{\\mathcal{G}(\\overline{x};\\mathcal{P})\\;\\big|\\;\\mathcal{P}\\in\\mathsf{P}^{\\widehat{m}}\\big\\}.\nThen\nğ–¯\nm\n^\nâˆ‹\nğ’«\nâ†¦\nğ’¢\nâ€‹\n(\nx\nÂ¯\n;\nğ’«\n)\n\\mathsf{P}^{\\widehat{m}}\\ni\\mathcal{P}\\mapsto\\mathcal{G}\\bigl(\\overline{x};\\mathcal{P}\\bigr)\nis continuous and there exists\nğ’«\nâˆ—\nâ€‹\n(\nx\nÂ¯\n)\n\\mathcal{P}^{\\ast}(\\overline{x})\nthat solves (\n(60)\n). Moreover, we have exact solutions, i.e.,\nğ•\nT\nâˆ—\nâ€‹\n(\nx\nÂ¯\n)\n=\nğ’¢\nâ€‹\n(\nx\nÂ¯\n;\nğ’«\nâˆ—\nâ€‹\n(\nx\nÂ¯\n)\n)\n\\mathbb{V}_{T}^{*}(\\overline{x})=\\mathcal{G}\\bigl(\\overline{x};\\mathcal{P}^{\\ast}(\\overline{x})\\bigr)\n.\nProof.\nFor a fixed\nx\nÂ¯\nâˆˆ\nğ•\nT\n\\overline{x}\\in\\mathbb{X}_{T}\n, to show the continuity of\nğ’¢\nâ€‹\n(\nx\nÂ¯\n;\nâ‹…\n)\n\\mathcal{G}(\\overline{x};\\cdot)\nwe will employ some standard results from variational analysis\n[\nDR14\n, Chapter 3]\n. To this end, notice that the feasible set mapping of (\n(59)\n) is nonempty and bounded, which follows from Proposition\n3.9\n. As the mapping\nÎ¸\nâ†¦\nğ’¥\n1\nâ€‹\n(\nÎ¸\nâ€‹\nÎ¦\nâ€‹\n(\nâ‹…\n)\n)\n\\theta\\mapsto\\mathcal{J}_{1}\\bigl(\\theta\\Phi(\\cdot)\\bigr)\nis convex and the constraint map\n(\nÎ¸\n,\nÎ±\n)\nâ†¦\nÏˆ\nâ€‹\n(\nx\nÎ¸\nâ€‹\n(\nT\n;\nÎ±\n)\n)\n(\\theta,\\alpha)\\mapsto\\psi\\bigl(x_{\\theta}(T;\\alpha)\\bigr)\nis jointly continuous, it follows that the feasible set mapping of (\n(59)\n) is continuous\n[\nDR14\n, Chapter 3, Example III.B]\nin the sense of PainlevÃ©-Kuratowski\n[\nDR14\n, Chapter 3, Â§3.2]\n. The preceding two properties imply that the mapping is Pompeiu-Hausdorff continuous\n[\nDR14\n, Chapter 3, Theorem 3B.3]\nat\nğ’«\nÂ¯\nâˆˆ\nğ–¯\nm\n^\n\\overline{\\mathcal{P}}\\in\\mathsf{P}^{\\widehat{m}}\n. Finally, employing\n[\nDR14\n, Chapter 3, Theorem 3B.5]\nwe conclude that\nğ’¢\nâ€‹\n(\nx\nÂ¯\n;\nâ‹…\n)\n\\mathcal{G}(\\overline{x};\\cdot)\nis continuous around the point\nğ’«\nÂ¯\n\\overline{\\mathcal{P}}\nwhich was arbitrary, and thus,\nğ’¢\nâ€‹\n(\nx\nÂ¯\n;\nâ‹…\n)\n\\mathcal{G}(\\overline{x};\\cdot)\nis continuous.\nContinuity of\nğ–¯\nm\n^\nâˆ‹\nğ’«\nâ†¦\nğ’¢\nâ€‹\n(\nx\nÂ¯\n;\nğ’«\n)\n\\mathsf{P}^{\\widehat{m}}\\ni\\mathcal{P}\\mapsto\\mathcal{G}(\\overline{x};\\mathcal{P})\nalong with the fact that\nğ–¯\nm\n^\n\\mathsf{P}^{\\widehat{m}}\nis compact immediately gives us existence of an optimizer\nğ’«\nâˆ—\nâ€‹\n(\nx\nÂ¯\n)\n\\mathcal{P}^{\\ast}(\\overline{x})\n.\nAs the optimization problem (\n(59)\n) is a strictly feasible convex program with a convex and continuous cost, convex and jointly continuous (in the pair\n(\nÎ¸\n,\nÎ±\n)\n(\\theta,\\alpha)\n) constraints, compact and convex decision space, and a compact uncertainty set, applying\n[\nDACC22\n, Theorem 1]\nwe readily obtain\nğ•\nT\nâˆ—\nâ€‹\n(\nx\nÂ¯\n)\n=\nğ’¢\nâ€‹\n(\nx\nÂ¯\n,\nğ’«\nâˆ—\nâ€‹\n(\nx\nÂ¯\n)\n)\n\\mathbb{V}_{T}^{*}(\\overline{x})=\\mathcal{G}\\bigl(\\overline{x},\\mathcal{P}^{\\ast}(\\overline{x})\\bigr)\nfor any\nx\nÂ¯\nâˆˆ\nğ•\nT\n\\overline{x}\\in\\mathbb{X}_{T}\n. The proof is complete.\nâˆ\nRemark 3.11\n.\nTheorem\n3.10\nforms the fundamental backbone of our algorithmic approach to solving (\n(8)\n). It introduces a relaxed optimal control problem (\n(59)\n) defined over a finite set of uncertainty realizations\nğ’«\nâ‰”\n(\nÎ±\n1\n,\nâ€¦\n,\nÎ±\nm\n^\n)\nâˆˆ\nğ–¯\nm\n^\n\\mathcal{P}\\coloneqq(\\alpha^{1},\\ldots,\\alpha^{\\widehat{m}})\\in\\mathsf{P}^{\\widehat{m}}\n, in contrast to the infinite family considered in (\n(54)\n). The first assertion, regarding the continuity of\nğ’¢\nâ€‹\n(\nx\nÂ¯\n;\nâ‹…\n)\n\\mathcal{G}(\\overline{x};\\cdot)\n, is crucial from a numerical standpoint, as it enables the use of numerous existing algorithms designed for global optimization problems with continuous objectives, such as (\n(60)\n). The second assertion guarantees the existence of at least one solution to problem (\n(60)\n). Most importantly, the final assertion precisely states that, by selecting\nm\n^\n\\widehat{m}\nuncertainty realizations and solving (\n(60)\n) globally over\nğ–¯\nm\n^\n\\mathsf{P}^{\\widehat{m}}\n, the optimal value\nğ’¢\nâ€‹\n(\nx\nÂ¯\n;\nğ’«\nâˆ—\nâ€‹\n(\nx\nÂ¯\n)\n)\n\\mathcal{G}\\bigl(\\overline{x};\\mathcal{P}^{\\ast}(\\overline{x})\\bigr)\nfor a fixed\nx\nÂ¯\nâˆˆ\nğ•\nT\n\\overline{x}\\in\\mathbb{X}_{T}\nmatches exactly the optimal value\nğ•\nT\nâˆ—\nâ€‹\n(\nx\nÂ¯\n)\n\\mathbb{V}_{T}^{*}(\\overline{x})\nof the original semi-infinite program (\n(54)\n). A wide range of global optimization algorithms are readily available to solve (\n(60)\n) efficiently, and our framework is algorithm-agnostic, provided that the chosen method complies with the conditions of Theorem\n3.10\n; see the architecture\nMaxHandsSol\nâ€‹\n(\nx\nÂ¯\n)\n\\textsf{MaxHandsSol}(\\overline{x})\nfor details.\n5\n5\n5\nA few well-known algorithms are the Simulated annealing\n[\nBÃ©l92\n]\n, differential evolution\n[\nSP97\n]\n, SequOOL (Sequential Optimistic Optimization with Levels)\n[\nBGV19\n]\n,\n[\nGVM15\n]\n, LIPO (Lipschitz Optimization based on Local Partitions)\n[\nMV17\n]\n. Also see Fig.\n2\nfor a schematic.\nData :\nStopping criterion\nSC\nâ€‹\n(\nâ‹…\n)\n\\text{SC}(\\cdot)\n, threshold for the stopping criterion\nÏ„\n\\tau\n, fix\nx\nÂ¯\nâˆˆ\nğ•\nT\n.\n\\overline{x}\\in\\mathbb{X}_{T}.\nInitialize :\ninitialize the constraint indices\n(\nÎ±\nin\n,\ni\n)\ni\n=\n1\nm\n^\nâˆˆ\nğ–¯\nm\n^\n\\bigl(\\alpha^{\\text{in},i}\\bigr)_{i=1}^{\\widehat{m}}\\in\\mathsf{P}^{\\widehat{m}}\n, initial guess for\nğ’¢\nmax\n\\mathcal{G}_{\\text{max}}\n, initial guess for the solution\nÎ¸\nÂ¯\n\\overline{\\theta}\n1\n2\nwhile\nSC\nâ€‹\n(\nm\n)\nâ©½\nÏ„\n\\text{SC}(m)\\leqslant\\tau\ndo\n3\n4\nSample the uncertainty set\n(\nÎ±\nm\n,\ni\n)\ni\n=\n1\nm\n^\nâˆˆ\nğ–¯\nm\n^\n\\bigl(\\alpha^{m,i}\\bigr)_{i=1}^{\\widehat{m}}\\in\\mathsf{P}^{\\widehat{m}}\n5\nSolve the\ninner-problem\nand evaluate\nğ’¢\nm\n=\nğ’¢\nâ€‹\n(\n(\nÎ±\nm\n,\ni\n)\ni\n=\n1\nm\n^\n;\nx\nÂ¯\n)\n\\mathcal{G}_{m}=\\mathcal{G}\\Bigl(\\bigl(\\alpha^{m,i}\\bigr)_{i=1}^{\\widehat{m}};\\overline{x}\\Bigr)\nas defined in (\n(59)\n)\n6\nRecover\nthe solution\nÎ¸\nm\nâˆˆ\narg\nâ€‹\nmin\nÎ¸\n~\nâ¡\n{\nğ’¥\n1\nâ€‹\n(\nÎ¸\n~\nâ€‹\nÎ¦\nâ€‹\n(\nâ‹…\n)\n)\n|\nconstraints in\n(\n(59)\n)\nhold at\nâ€‹\n(\nÎ±\nm\n,\ni\n)\ni\n=\n1\nm\n^\nâˆˆ\nğ–¯\nm\n^\n}\n\\theta^{m}\\in\\operatorname*{arg\\,min}_{\\widetilde{\\theta}}\\bigg\\{\\mathcal{J}_{1}\\bigl(\\widetilde{\\theta}\\Phi(\\cdot)\\bigr)\\;\\bigg|\\;\\text{ constraints in }\\eqref{eq:g_func}\\text{ hold at }\\bigl(\\alpha^{m,i}\\bigr)_{i=1}^{\\widehat{m}}\\in\\mathsf{P}^{\\widehat{m}}\\bigg\\}\n7\nUpdate\n(\nğ’¢\nmax\n,\nÎ¸\nÂ¯\n)\n(\\mathcal{G}_{\\text{max}},\\overline{\\theta})\nâŸµ\n\\longleftarrow\nIC\n(\nğ’¢\nm\n,\nÎ¸\nm\n)\n(\\mathcal{G}_{m},\\theta^{m})\n(\nI\nâ€‹\nC\n{IC}\nis an improvement rule depending upon the global optimization routine)\n8\nSolve for\nÎ¸\nm\n\\theta^{m}\nvia any convex solver;\n9\nUpdate\nm\nâ†\nm\n+\n1\nm\\leftarrow m+1\n10\n11\nend while\n12\nMaxHandsSol\nâ€‹\n(\nx\nÂ¯\n)\n\\textsf{MaxHandsSol}(\\overline{x})\n1\nA general architecture to solve (\n(60)\n)\nRemark 3.12\n.\nWe note that classical methods to solve SIPs such as\n[\nBF76\n]\nand methods in the spirit of Blankenshipâ€“Falk solve a sequence of finite relaxations by iteratively adding most violated constraints, so exactness is only achieved asymptotically (or depends on discretization/tolerances). In practice one must truncate after finitely many iterations, and these schemes typically provide no explicit bound on the error induced by truncation. In contrast, our framework yields an exact solution with finite â€” and reasonably sized â€” memory and computation: by Borweinâ€™s result\n[\nBor81\n, Theorem 4.1]\nand\n[\nDACC22\n]\n, only\nm\n^\n\\widehat{m}\nsamples of the uncertainty are required for exactness, and our algorithm returns them by solving a global optimization problem over\nm\n^\n\\widehat{m}\nuncertainty variables. As a result, no iterative constraint-generation loop or guess-and-refine sampling is needed, and no truncation/approximation error is incurred.\n\\lxSVG@picture\n(ii):\nMaxHandsSol\nâ€‹\n(\nx\nÂ¯\n)\n\\textsf{MaxHandsSol}({\\overline{x}})\nfor (\n(60)\n)\n(i): Input data\nx\nÂ¯\nâˆˆ\nğ•\nT\n\\overline{x}\\in\\mathbb{X}_{T}\n(iii):\nğ’«\nâˆ—\nâ€‹\n(\nx\nÂ¯\n)\n\\mathcal{P}^{\\ast}(\\overline{x})\nparametric in\nx\nÂ¯\n\\overline{x}\n(iv): OCP (\n(59)\n);\nparametric in\nx\nÂ¯\n\\overline{x}\n(v):\nt\nâ†¦\nu\nâˆ—\nâ€‹\n(\nt\n)\n=\nÎ¸\nâˆ—\nâ€‹\n(\nx\nÂ¯\n)\nâ€‹\nÎ¦\nâ€‹\n(\nt\n)\nt\\mapsto u^{\\ast}(t)=\\theta^{\\ast}(\\overline{x})\\Phi(t)\n\\endlxSVG@picture\nFigure 2\n.\nA birdâ€™s-eye view of our algorithmic architecture\nMaxHandsSol\nâ€‹\n(\nx\nÂ¯\n)\n\\textsf{MaxHandsSol}(\\overline{x})\n.\n4.\nDiscussion and numerical experiment\nThis section showcases a numerical simulation highlighting the effectiveness of our framework\nMaxHandsSol\nâ€‹\n(\nx\nÂ¯\n)\n\\textsf{MaxHandsSol}(\\overline{x})\napplied to an uncertain continuous-time benchmark spring-mass-damper system. The global optimization component in\nMaxHandsSol\nâ€‹\n(\nx\nÂ¯\n)\n\\textsf{MaxHandsSol}(\\overline{x})\nwas implemented using the simulated annealing algorithm\n[\nBÃ©l92\n]\n. All computations were performed in Julia version 1.1.14 on a laptop featuring an AMD Ryzen 5 5600H CPU and 8 GB of RAM.\n6\n6\n6\nS.G. thanks Ashwin Aravind for his assistance with the numerical simulations.\nConsider the spring-mass-damper system with parametric uncertainties\n((61))\nx\nË™\nâ€‹\n(\nt\n)\n=\n(\n0\n1\nâˆ’\n2\n+\nÎ±\n1\n0.6\n+\nÎ±\n2\n)\nâ€‹\nx\nâ€‹\n(\nt\n)\n+\n(\n0\n1\n+\nÎ±\n3\n)\nâ€‹\nu\nâ€‹\n(\nt\n)\nfor all\nâ€‹\nt\nâˆˆ\n[\n0\n,\nT\n]\n.\n\\displaystyle\\dot{x}(t)=\\begin{pmatrix}0&1\\\\\n-2+\\alpha_{1}&0.6+\\alpha_{2}\\end{pmatrix}x(t)+\\begin{pmatrix}0\\\\\n1+\\alpha_{3}\\end{pmatrix}u(t)\\quad\\text{for all }t\\in[0,T].\nLet\nÎ±\nâ‰”\n(\nÎ±\n1\n,\nÎ±\n2\n,\nÎ±\n3\n)\nâŠ¤\n\\alpha\\coloneqq(\\alpha_{1},\\alpha_{2},\\alpha_{3})^{\\top}\n. We have the following problem data\n((62))\n{\nT\n=\n5\n,\nx\nâ€‹\n(\n0\n)\nâ‰”\n(\nâˆ’\n1\n,\nâˆ’\n1\n)\nâŠ¤\n,\nu\nâ€‹\n(\nt\n)\nâˆˆ\n[\nâˆ’\n1\n,\n1\n]\n,\nÎ±\nâˆˆ\nğ–¯\nâ‰”\n[\nâˆ’\n0.1\n,\n0.1\n]\n3\nx\n(\nT\n;\nÎ±\n)\nâˆˆ\nC\nâ‰”\n{\n(\nÎ¾\n1\n,\nÎ¾\n2\n)\nâŠ¤\nâˆˆ\nâ„\n2\n|\nÎ¾\n1\nâ©½\n0.1\nâ€‹\nand\nÎ¾\n2\nâ©½\n0.1\n}\nfor all\nÎ±\nâˆˆ\nğ–¯\n.\n\\displaystyle\\hskip-5.69054pt\\begin{cases}T=5,\\,x(0)\\coloneqq(-1,-1)^{\\top},\\,u(t)\\in[-1,1],\\,\\alpha\\in\\mathsf{P}\\coloneqq[-0.1,0.1]^{3}\\\\\nx(T;\\alpha)\\in C\\coloneqq\\left\\{(\\xi_{1},\\xi_{2})^{\\top}\\in\\mathbb{R}^{2}\\;\\middle|\\;\\begin{array}[]{@{}l@{}}\\xi_{1}\\leqslant 0.1\\text{ and}\\\\\n\\xi_{2}\\leqslant 0.1\\end{array}\\right\\}\\text{ for all }\\alpha\\in\\mathsf{P}.\\end{cases}\nNote that the condition\n(\n3.2\n-b)\ncan be easily verified; indeed: let\nÎ¾\n1\nâ†¦\ng\n1\nâ€‹\n(\nÎ¾\n1\n)\nâ‰”\nÎ¾\n1\nâˆ’\n0.1\nâ©½\n0\n\\xi_{1}\\mapsto g_{1}(\\xi_{1})\\coloneqq\\xi_{1}-0.1\\leqslant 0\nand\nÎ¾\n2\nâ†¦\ng\n2\nâ€‹\n(\nÎ¾\n2\n)\n=\nÎ¾\n2\nâˆ’\n0.1\nâ©½\n0\n\\xi_{2}\\mapsto g_{2}(\\xi_{2})=\\xi_{2}-0.1\\leqslant 0\nand note that\nâˆ‡\ng\n1\nâ€‹\n(\nÎ¾\n1\n)\n=\ne\n1\n\\nabla g_{1}(\\xi_{1})=e_{1}\nand\nâˆ‡\ng\n2\nâ€‹\n(\nÎ¾\n2\n)\n=\ne\n2\n\\nabla g_{2}(\\xi_{2})=e_{2}\n, where\ne\ni\ne_{i}\nfor\ni\n=\n1\n,\n2\ni=1,2\nare the standard Euclidean basis vectors. Then for the active parameters,\nN\nC\nâ€‹\n(\nÎ¾\n)\n=\n{\nÎ¼\n1\nâ€‹\ne\n1\n+\nÎ¼\n2\nâ€‹\ne\n2\n|\nÎ¼\n1\nâ©¾\n0\n,\nÎ¼\n2\nâ©¾\n0\n}\nN_{C}(\\xi)=\\{\\mu_{1}e_{1}+\\mu_{2}e_{2}\\;|\\;\\mu_{1}\\geqslant 0,\\,\\mu_{2}\\geqslant 0\\}\nand thus\np\nâ€‹\n(\nT\n;\nÎ±\n)\n=\nÎ¼\n1\nâ€‹\n(\nÎ±\n)\nâ€‹\ne\n1\n+\nÎ¼\n2\nâ€‹\n(\nÎ±\n)\nâ€‹\ne\n2\np(T;\\alpha)=\\mu_{1}(\\alpha)e_{1}+\\mu_{2}(\\alpha)e_{2}\nfor\nÎ›\nact\n\\Lambda_{\\mathrm{act}}\n-a.e.\nÎ±\nâˆˆ\nğ–¯\nact\n\\alpha\\in\\mathsf{P}_{\\mathrm{act}}\n. Since\nd\n=\n2\nd=2\n, we focus on the integral\nâˆ«\nğ–¯\nact\nâŸ¨\nA\nâ€‹\n(\nÎ±\n)\nâ€‹\nb\nâ€‹\n(\nÎ±\n)\n,\np\nâ€‹\n(\nT\n;\nÎ±\n)\nâŸ©\nâ€‹\nÎ›\nact\nâ€‹\n(\nd\nâ€‹\nÎ±\n)\n\\int_{\\mathsf{P}_{\\mathrm{act}}}\\left\\langle{A(\\alpha)b(\\alpha)},\\,{p(T;\\alpha)}\\right\\rangle\\Lambda_{\\mathrm{act}}(\\mathop{}\\!\\mathrm{d}\\alpha)\nwhich is\nâˆ«\nğ–¯\nact\nâŸ¨\nA\nâ€‹\n(\nÎ±\n)\nâ€‹\nb\nâ€‹\n(\nÎ±\n)\n,\np\nâ€‹\n(\nT\n;\nÎ±\n)\nâŸ©\nâ€‹\nÎ›\nact\nâ€‹\n(\nd\nâ€‹\nÎ±\n)\n\\displaystyle\\int_{\\mathsf{P}_{\\mathrm{act}}}\\left\\langle{A(\\alpha)b(\\alpha)},\\,{p(T;\\alpha)}\\right\\rangle\\Lambda_{\\mathrm{act}}(\\mathop{}\\!\\mathrm{d}\\alpha)\n=\nâˆ«\nğ–¯\nact\n(\nÎ¼\n1\nâ€‹\nâŸ¨\nA\nâ€‹\n(\nÎ±\n)\nâ€‹\nb\nâ€‹\n(\nÎ±\n)\n,\ne\n1\nâŸ©\n+\nÎ¼\n2\nâ€‹\nâŸ¨\nA\nâ€‹\n(\nÎ±\n)\nâ€‹\nb\nâ€‹\n(\nÎ±\n)\n,\ne\n2\nâŸ©\n)\nâ€‹\nÎ›\nact\nâ€‹\n(\nd\nâ€‹\nÎ±\n)\n\\displaystyle=\\int_{\\mathsf{P}_{\\mathrm{act}}}\\hskip-8.53581pt\\bigl(\\mu_{1}\\left\\langle{A(\\alpha)b(\\alpha)},\\,{e_{1}}\\right\\rangle+\\mu_{2}\\left\\langle{A(\\alpha)b(\\alpha)},\\,{e_{2}}\\right\\rangle\\bigr)\\Lambda_{\\mathrm{act}}(\\mathop{}\\!\\mathrm{d}\\alpha)\nâ©¾\nâˆ«\nğ–¯\nact\n(\n0.9\nâ€‹\nÎ¼\n1\nâ€‹\n(\nÎ±\n)\n+\n0.45\nâ€‹\nÎ¼\n2\nâ€‹\n(\nÎ±\n)\n)\nâ€‹\nÎ›\nact\nâ€‹\n(\nd\nâ€‹\nÎ±\n)\n\\displaystyle\\geqslant\\int_{\\mathsf{P}_{\\mathrm{act}}}\\bigl(0.9\\mu_{1}(\\alpha)+0.45\\mu_{2}(\\alpha)\\bigr)\\Lambda_{\\mathrm{act}}(\\mathop{}\\!\\mathrm{d}\\alpha)\n((63))\nâ©¾\n0.45\nâ€‹\nâˆ«\nğ–¯\nact\n(\nÎ¼\n1\nâ€‹\n(\nÎ±\n)\n+\nÎ¼\n2\nâ€‹\n(\nÎ±\n)\n)\nâ€‹\nÎ›\nact\nâ€‹\n(\nd\nâ€‹\nÎ±\n)\n.\n\\displaystyle\\geqslant 0.45\\int_{\\mathsf{P}_{\\mathrm{act}}}(\\mu_{1}(\\alpha)+\\mu_{2}(\\alpha))\\Lambda_{\\mathrm{act}}(\\mathop{}\\!\\mathrm{d}\\alpha).\nIf\np\nâ€‹\n(\nT\n;\nÎ±\n)\nâ‰ \n0\np(T;\\alpha)\\neq 0\n, then the right-hand side of the inequality (\n4\n) is positive and hence the condition\n(\n3.2\n-b)\nholds.\nNow we focus on the numerical treatment. We parametrize the control trajectory\nu\nâ€‹\n(\nâ‹…\n)\nu(\\cdot)\nemploying piecewise constant functions with\nN\n=\n250\nN=250\n. With this parametrization, we considered the OCP\nmin\nÎ¸\n\\displaystyle\\min_{\\theta}\nğ’¥\n1\nâ€‹\n(\nÎ¸\nâ€‹\nÎ¦\nâ€‹\n(\nâ‹…\n)\n)\n\\displaystyle\\mathcal{J}_{1}(\\theta\\Phi(\\cdot))\n((64))\nsubject\nâ€‹\nto\n\\displaystyle\\operatorname{subject\\ to}\n{\ndynamics\n(\n(61)\n)\nand the data (\n(62)\n)\nfor all\nâ€‹\nÎ±\nâˆˆ\nğ–¯\n,\n\\displaystyle\\begin{cases}\\text{dynamics }\\eqref{eq:num:smd:par}\\text{ and the data \\eqref{eq:num:prob:par:data}}\\text{ for all }\\alpha\\in\\mathsf{P},\\end{cases}\nand employed the\nMaxHandsSol\nâ€‹\n(\nâ‹…\n)\n\\textsf{MaxHandsSol}(\\cdot)\narchitecture with the simulated annealing global optimization routine. The results of this numerical experiment are presented in Fig.\n3\n. The state trajectories of the spring-mass-damper system (\n(61)\n), subject to 10000 different realizations of the uncertain parameter, are shown in Fig.\n3(a)\n. The system is controlled using the sparse robust control computed by solvingÂ (\n4\n) via\nMaxHandsSol\nâ€‹\n(\n(\nâˆ’\n1\n,\nâˆ’\n1\n)\nâŠ¤\n)\n\\textsf{MaxHandsSol}\\bigl((-1,-1)^{\\top}\\bigr)\narchitecture. The figure illustrates the effectiveness of the proposed approach in generating sparse robust control inputs for the system with dataÂ (\n(62)\n). As observed from Fig.\n3(b)\n, the control input is sparse, i.e., being active only over a small portion of the time horizon. Despite the presence of parametric uncertainties, the resulting state trajectories satisfied both the state and terminal constraints, demonstrating the robustness of the proposed control scheme.\n(a)\nState trajectories.\n(b)\nControl trajectory.\nFigure 3\n.\nState and control trajectories obtained via\nMaxHandsSol\n.\nFor a baseline comparison, we present a few simulations based on the scenario robust optimization approach\n[\nCG18\n]\n; an widely used technique in control and optimization. For the illustrations we considered 1000 and 5000 scenarios for the experiments. It can be clearly observed from Fig.\n4\nthat multiple trajectories have violated the terminal constraints for all the scenarios presented here. Moreover, our algorithm, while employing finitary methods, achieves the true optimal values of CSIPs; see Table\n1\n.\nMethod\nvalue\n(\n\\big(\nfor\nx\nÂ¯\n=\n(\nâˆ’\n1\n,\n0\n)\n\\overline{x}=(-1,0)\n)\n\\big)\nMaxHandsSol\nâ€‹\n(\nx\nÂ¯\n)\n\\textsf{MaxHandsSol}(\\overline{x})\n89.01\nScenario optimization\n[\nCG18\n]\n(with\nN\n=\n200\nN=200\n)\n82.93\nScenario optimization (with\nN\n=\n500\nN=500\n)\n86.88\nScenario optimization (with\nN\n=\n1000\nN=1000\n)\n87.01\nTable 1\n.\nOptimal values for\nx\nÂ¯\nâ‰”\n(\nâˆ’\n1â€‰â€‰0\n)\nâŠ¤\n\\overline{x}\\coloneqq(-1\\,\\,0)^{\\top}\n, obtained via\nMaxHandsSol\nâ€‹\n(\nx\nÂ¯\n)\n\\textsf{MaxHandsSol}(\\overline{x})\nand the scenario optimization algorithm.\nFigure 4\n.\nState trajectories obtained via the scenario approach, with\nN\n=\n500\nN=500\nand\n1000\n1000\n.\n5.\nConclusion\nThis article developed both a theoretical and an algorithmic framework for solving a class of robust sparse optimal control problems. On the theoretical front, we established an equivalence between the\nL\n0\n{L}^{0}\nand the\nL\n1\n{L}^{1}\nformulations of the robust optimal control problem. On the algorithmic side, we designed a robust optimization-driven architecture that solves such problems accurately and efficiently. Several promising avenues remain open for future investigation. One direction involves developing equivalence-type results and algorithms for more general robust problems, where both parametric uncertainties and external disturbances are present, including the design of faster gradient-based methods that leverage the regularity properties of\nğ’¢\nâ€‹\n(\nâ‹…\n)\n\\mathcal{G}(\\cdot)\n.\nReferences\n[ABM25]\nA.Â Agrachev, I.Â Beschastnyi, and M.Â Motta,\nSingular extremals of optimal control problems with\nL\n1\n{L}^{1}\ncost\n, 2025, URL:\nhttps://arxiv.org/abs/2511.21527\n.\n[AF03]\nR.Â A. Adams and J.Â J.Â F. Fournier,\nSobolev Spaces\n, second ed., Pure and Applied Mathematics (Amsterdam), vol. 140, Elsevier/Academic Press, Amsterdam, 2003, doi:\nhttps://doi.org/10.1016/S0079-8169(03)80002-8\n.\n[AK25]\nA.Â Agrachev and B.Â Kazandjian,\nOptimal control for linear systems with\nL\n1\n{L}^{1}\n-norm cost\n, Journal of Optimization Theory and Applications\n204\n(2025), no.Â 3, 43, doi:\nhttps://doi.org/10.1007/s10957-024-02567-3\n.\n[BB11]\nS.Â Bhattacharya and T.Â BaÅŸar,\nSparsity based feedback design: A new paradigm in opportunistic sensing\n, Proceedings of the 2011 American Control Conference, IEEE, 2011, doi:\nhttps://doi.org/10.1109/ACC.2011.5991014\n, pp.Â 3704â€“3709.\n[BÃ©l92]\nC.Â J.Â P. BÃ©lisle,\nConvergence theorems for a class of simulated annealing algorithms on\nâ„\nd\n\\mathbb{R}^{d}\n, Journal of Applied Probability\n29\n(1992), no.Â 4, 885â€“895, doi:\nhttps://doi.org/10.2307/3214721\n.\n[Bet10]\nJ.Â T. Betts,\nPractical Methods for Optimal Control and Estimation Using Nonlinear Programming\n, Advances in Design and Control, vol.Â 1, SIAM, 2010, doi:\nhttps://doi.org/10.1137/1.9780898718577\n.\n[BF76]\nJ.Â W. Blankenship and J.Â E. Falk,\nInfinitely constrained optimization problems\n, Journal of Optimization Theory and Applications\n19\n(1976), 261â€“281, doi:\nhttps://doi.org/10.1007/BF00934096\n.\n[BGFB94]\nS.Â Boyd, L.Â El Ghaoui, E.Â Feron, and V.Â Balakrishnan,\nLinear Matrix Inequalities in System and Control Theory\n, SIAM Studies in Applied Mathematics, vol.Â 15, Society for Industrial and Applied Mathematics (SIAM), Philadelphia, PA, 1994, doi:\nhttps://doi.org/10.1137/1.9781611970777\n.\n[BGV19]\nP.Â L. Bartlett, V.Â Gabillon, and M.Â Valko,\nA simple parameter-free and adaptive approach to optimization under a minimal local smoothness assumption\n, Proceedings of the 30th International Conference on Algorithmic Learning Theory (AurÃ©lien Garivier and Satyen Kale, eds.), Proceedings of Machine Learning Research, vol.Â 98, PMLR, 22â€“24 Mar 2019, doi:\nhttps://proceedings.mlr.press/v98/bartlett19a.html\n, pp.Â 184â€“206.\n[Bor81]\nJ.Â M. Borwein,\nDirect theorems in semi-infinite convex programming\n, Mathematical Programming\n21\n(1981), no.Â 1, 301â€“318, doi:\nhttps://doi.org/10.1007/BF01584251\n.\n[CF14]\nE.Â Casas and F.TrÃ³ltzsch,\nSecond-order and stability analysis for state-constrained elliptic optimal control problems with sparse controls\n, SIAM Journal on Control and Optimization\n52\n(2014), no.Â 2, 1010â€“1033, doi:\nhttps://doi.org/10.1137/130917314\n.\n[CG18]\nM.Â C. Campi and S.Â Garatti,\nIntroduction to the Scenario Approach\n, MOS-SIAM Series on Optimization, vol.Â 26, SIAM, Philadelphia, PA, 2018, doi:\nhttps://doi.org/10.1137/1.9781611975444\n.\n[CHW12]\nE.Â Casas, R.Â Herzog, and G.Â Wachsmuth,\nApproximation of sparse controls in semilinear equations by piecewise linear functions\n, Numerische Mathematik\n122\n(2012), no.Â 4, 645â€“669, doi:\nhttps://doi.org/10.1007/s00211-012-0475-7\n.\n[CJL25]\nP.Â CavarÃ¨, M.Â Jungers, and J.Â LohÃ¨ac,\nL\n1\n{L}^{1}\n-optimal controls for driftless affine control systems\n, IEEE Control Systems Letters (2025), doi:\n10.1109/LCSYS.2025.3578988\n.\n[Cla13]\nF.Â Clarke,\nFunctional Analysis, Calculus of Variations and Optimal Control\n, Graduate Texts in Mathematics, vol. 264, Springer, London, 2013, doi:\nhttps://doi.org/10.1007/978-1-4471-4820-3\n.\n[DACC22]\nS.Â Das, A.Â Aravind, A.Â Cherukuri, and D.Â Chatterjee,\nNear-optimal solutions of convex semi-infinite programs via targeted sampling\n, Annals of Operations Research (2022), doi:\nhttps://doi.org/10.1007/s10479-022-04810-4\n.\n[DGAC23]\nS.Â Das, S.Â Ganguly, M.Â Anjali, and D.Â Chatterjee,\nTowards continuous-time MPC: A novel trajectory optimization algorithm\n, 2023 62nd IEEE Conference on Decision and Control (CDC), 2023, doi:\n10.1109/CDC49753.2023.10383236\n, pp.Â 3276â€“3281.\n[DMS25]\nG.Â Dirr and Michael M.Â SchÃ¶nlein,\nEnsemble controllability on various function spaces: Bounded and unbounded domains\n, Geometry, Topology, and Control System Design, Proceedings of a Banff International Research Station Workshop (2025), 1â€“369, URL:\nhttps://www.aimsciences.org/book/AM/volume/59\n.\n[Don06]\nD.Â L. Donoho,\nCompressed sensing\n, IEEE Transactions on Information Theory\n52\n(2006), no.Â 4, 1289â€“1306, doi:\nhttps://doi.org/10.1109/TIT.2006.871582\n.\n[DP13]\nG.Â E. Dullerud and F.Â Paganini,\nA Course in Robust Control Theory: A Convex Approach\n, Texts in Applied Mathematics, vol.Â 36, Springer Science & Business Media, 2013, doi:\nhttps://doi.org/10.1007/978-1-4757-3290-0\n.\n[DR14]\nA.Â L. Dontchev and R.Â T. Rockafellar,\nImplicit Functions and Solution Mappings\n, 2nd ed., Springer Series in Operations Research and Financial Engineering, Springer, New York, 2014, doi:\nhttps://doi.org/10.1007/978-1-4939-1037-3\n.\n[GC24]\nS.Â Ganguly and D.Â Chatterjee,\nExact solutions to minmax optimal control problems for constrained noisy linear systems\n, IEEE Control Systems Letters\n8\n(2024), 2063â€“2068, doi:\nhttps://doi.org/10.1109/LCSYS.2024.3439208\n.\n[GDA\n+\n25]\nS.Â Ganguly, S.Â Das, A.Â Aravind, M.Â Nagahara, and D.Â Chatterjee,\nSparse robust optimal control in continuous-time: a computationally viable approach\n, Submitted (2025).\n[GDC24]\nS.Â Ganguly, R.Â A. Dâ€™Silva, and D.Â Chatterjee,\nğ–°ğ—ğ–¨ğ–³ğ–®\n\\mathsf{QuITO}\nv.2\n: Trajectory optimization with uniform error guarantees under path constraints\n, 2024, doi:\nhttps://arxiv.org/abs/2404.13681\n.\n[GRCB22]\nS.Â Ganguly, N.Â Randad, D.Â Chatterjee, and R.Â Banavar,\nConstrained trajectory synthesis via quasi-interpolation\n, 2022 IEEE 61st Conference on Decision and Control (CDC), 2022, doi:\nhttps://doi.org/10.1109/CDC51059.2022.9992892\n, pp.Â 4533â€“4538.\n[GVM15]\nJ-B. Grill, M.Â Valko, and R.Â Munos,\nBlack-box optimization of noisy functions with unknown smoothness\n, Advances in Neural Information Processing Systems (C.Â Cortes, N.Â Lawrence, D.Â Lee, M.Â Sugiyama, and R.Â Garnett, eds.), vol.Â 28, Curran Associates, Inc., 2015, URL:\nhttps://proceedings.neurips.cc/paper_files/paper/2015/file/ab817c9349cf9c4f6877e1894a1faa00-Paper.pdf\n.\n[HGM13]\nE.Â N. Hartley, M.Â Gallieri, and J.Â M. Maciejowski,\nTerminal spacecraft rendezvous and capture with LASSO model predictive control\n, International Journal of Control\n86\n(2013), no.Â 11, 2104â€“2113, doi:\nhttps://doi.org/10.1080/00207179.2013.789608\n.\n[HS14]\nU.Â Helmke and M.Â SchÃ¶nlein,\nUniform ensemble controllability for one-parameter families of time-invariant linear systems\n, Systems & Control Letters\n71\n(2014), 69â€“77, doi:\nhttps://doi.org/10.1016/j.sysconle.2014.05.015\n.\n[HTW15]\nT.Â Hastie, R.Â Tibshirani, and M.Â Wainwright,\nStatistical Learning with Sparsity: The LASSO and Generalizations\n, Monographs on Statistics and Applied Probability\n143\n(2015), 8, doi:\nhttps://doi.org/10.1201/b18401\n.\n[IK19]\nT.Â Ikeda and K.Â Kashima,\nOn sparse optimal control for general linear systems\n, IEEE Transactions on Automatic Control\n64\n(2019), no.Â 5, 2077â€“2083, doi:\n10.1109/TAC.2018.2863220\n.\n[IN25]\nT.Â Ikeda and M.Â Nagahara,\nSparse optimal control for infinite-dimensional linear systems with applications to graphon control\n, 2025, URL:\nhttps://arxiv.org/abs/2507.18030\n.\n[KG23]\nB.Â A. Kristiansen and J.Â T. Gravdahl,\nMaximum hands-off attitude control of a spacecraft actuated by thrusters\n, IFAC-PapersOnLine\n56\n(2023), no.Â 2, 2026â€“2031, doi:\nhttps://doi.org/10.1016/j.ifacol.2023.10.1099\n.\n[LFJ13]\nF.Â Lin, M.Â Fardad, and M.Â R. JovanoviÄ‡,\nDesign of optimal sparse feedback gains via the alternating direction method of multipliers\n, IEEE Transactions on Automatic Control\n58\n(2013), no.Â 9, 2426â€“2431, doi:\nhttps://doi.org/10.1109/TAC.2013.2257618\n.\n[MV17]\nC.Â Malherbe and N.Â Vayatis,\nGlobal optimization of Lipschitz functions\n, Proceedings of Machine Learning Research (Doina Precup and YeeÂ Whye Teh, eds.), vol.Â 70, PMLR, 2017, URL:\nhttps://proceedings.mlr.press/v70/malherbe17a.html\n, pp.Â 2314â€“2323.\n[Nag20]\nM.Â Nagahara,\nSparsity Methods for Systems and Control\n, Now Publishers, 2020, doi:\nhttp://dx.doi.org/10.1561/9781680837254\n.\n[Nag23]\nby same author,\nSparse control for continuous-time systems\n, International Journal of Robust and Nonlinear Control\n33\n(2023), no.Â 1, 6â€“22, doi:\nhttps://doi.org/10.1002/rnc.5858\n.\n[NQN15]\nM.Â Nagahara, D.Â E. Quevedo, and D.Â NeÅ¡iÄ‡,\nMaximum hands-off control: a paradigm of control effort minimization\n, IEEE Transactions on Automatic Control\n61\n(2015), no.Â 3, 735â€“747, doi:\nhttps://doi.org/10.1109/TAC.2015.2452831\n.\n[NQÃ˜13]\nM.Â Nagahara, D.Â E. Quevedo, and J.Â Ã˜stergaard,\nSparse packetized predictive control for networked control over erasure channels\n, IEEE Transactions on Automatic Control\n59\n(2013), no.Â 7, 1899â€“1905, doi:\nhttps://doi.org/10.1109/TAC.2013.2294622\n.\n[PKS14]\nB.Â T. Polyak, M.Â V. Khlebnikov, and P.Â S. Shcherbakov,\nSparse feedback in linear control systems\n, Automation and Remote Control\n75\n(2014), 2099â€“2111, doi:\nhttps://doi.org/10.1134/S0005117914120029\n.\n[Rud76]\nWalter Rudin,\nPrinciples of Mathematical Analysis\n, third ed., International Series in Pure and Applied Mathematics, McGraw-Hill Book Co., New York-Auckland-DÃ¼sseldorf, 1976. MR 385023\n[Rud87]\nW.Â Rudin,\nReal and Complex Analysis\n, 3rd ed., McGraw-Hill, Inc., 1987.\n[San23]\nF.Â Santambrogio,\nA Course in the Calculus of Variations: Optimization, Regularity, and Modeling\n, Universitext, Springer Nature, 2023, doi:\nhttps://doi.org/10.1007/978-3-031-45036-5\n.\n[SH16]\nM.Â SchÃ¶nlein and U.Â Helmke,\nControllability of ensembles of linear dynamical systems\n, Mathematics and Computers in Simulation\n125\n(2016), 3â€“14, doi:\nhttps://doi.org/10.1016/j.matcom.2015.10.006\n.\n[SP97]\nR.Â Storn and K.Â Price,\nDifferential evolution â€” a simple and efficient heuristic for global optimization over continuous spaces\n, Journal of Global Optimization\n11\n(1997), no.Â 4, 341, doi:\nhttps://doi.org/10.1023/A:1008202821328\n.\n[TrÃ©24]\nE.Â TrÃ©lat,\nControl in Finite and Infinite Dimension\n, SpringerBriefs on PDEs and Data Science, vol.Â 1, Springer Singapore, 2024, doi:\nhttps://doi.org/10.1007/978-981-97-5948-4\n.\n[TrÃ¶10]\nF.Â TrÃ¶ltzsch,\nOptimal Control of Partial Differential Equations: Theory, Methods and Applications\n, Graduate Studies in Mathematics, vol. 112, American Mathematical Society, Providence, RI, 2010, doi:\nhttps://doi.org/10.1090/gsm/112\n.\n[UT14]\nM.Â Unser and P.Â D. Tafti,\nAn Introduction to Sparse Stochastic Processes\n, Cambridge University Press, 2014, doi:\nhttps://doi.org/10.1017/CBO9781107415805\n.\n[Vid19]\nM.Â Vidyasagar,\nAn Introduction to Compressed Sensing\n, SIAM, 2019, doi:\nhttps://doi.org/10.1137/1.9781611976120\n.\n[Vin05]\nR.Â B. Vinter,\nMinimax optimal control\n, SIAM journal on control and optimization\n44\n(2005), no.Â 3, 939â€“968, doi:\nhttps://doi.org/10.1137/S0363012902415244\n.\n[ZF22]\nZ.Â Zhang and Y.Â Fujisaki,\nSparse robust control design via scenario program\n, Proceedings of the ISCIE International Symposium on Stochastic Systems Theory and its Applications, 2022, doi:\nhttps://doi.org/10.5687/sss.2022.61\n, pp.Â 61â€“64.",
    "preview_text": "This work advances the maximum hands-off sparse control framework by developing a robust counterpart for constrained linear systems with parametric uncertainties. The resulting optimal control problem minimizes an $L^{0}$ objective subject to an uncountable, compact family of constraints, and is therefore a nonconvex, nonsmooth robust optimization problem. To address this, we replace the $L^{0}$ objective with its convex $L^{1}$ surrogate and, using a nonsmooth variant of the robust Pontryagin maximum principle, show that the $L^{0}$ and $L^{1}$ formulations have identical sets of optimal solutions -- we call this the robust hands-off principle. Building on this equivalence, we propose an algorithmic framework -- drawing on numerically viable techniques from the semi-infinite robust optimization literature -- to solve the resulting problems. An illustrative example is provided to demonstrate the effectiveness of the approach.\n\nRobust maximum hands-off optimal control: existence, maximum principle, and\nL\n0\n{L}^{0}\n-\nL\n1\n{L}^{1}\nequivalence\nSiddhartha Ganguly\nand\nKenji Kashima\nAbstract.\nThis work advances the maximum hands-off sparse control framework by developing a robust counterpart for constrained linear systems with parametric uncertainties. The resulting optimal control problem minimizes an\nL\n0\n{L}^{0}\nobjective subject to an uncountable, compact family of constraints, and is therefore a nonconvex, nonsmooth robust optimization problem. To address this, we replace the\nL\n0\n{L}^{0}\nobjective with its convex\nL\n1\n{L}^{1}\nsurrogate and, using a nonsmooth variant of the robust Pontryagin maximum principle, show that the\nL\n0\n{L}^{0}\nand\nL\n1\n{L}^{1}\nformulations have identical sets of optimal solutions â€” we call this\nthe robust hands-off principle\n. Building on this equivalence, we propose an algorithmic framework â€” drawing on numerically viable techniques from the semi-infinite robust optimization literature â€” to solve the resulting problems. An illustrative example is",
    "is_relevant": false,
    "relevance_score": 0.0,
    "extracted_keywords": [
        "optimal control",
        "robust optimization",
        "sparse control",
        "L0-L1 equivalence",
        "Pontryagin maximum principle"
    ],
    "one_line_summary": "è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§é’ˆå¯¹å‚æ•°ä¸ç¡®å®šçº¿æ€§ç³»ç»Ÿçš„é²æ£’æœ€å¤§æ‰‹ç¦»ç¨€ç–æ§åˆ¶æ¡†æ¶ï¼Œè¯æ˜äº†L0å’ŒL1ç›®æ ‡å‡½æ•°çš„æœ€ä¼˜è§£ç­‰ä»·æ€§ï¼Œå¹¶å¼€å‘äº†æ•°å€¼æ±‚è§£ç®—æ³•ã€‚",
    "detailed_summary": "",
    "qa_pairs": [],
    "is_hidden": false,
    "is_starred": false,
    "flag": true,
    "published_date": "2026-01-12T06:50:29Z",
    "created_at": "2026-01-21T12:09:08.523253",
    "updated_at": "2026-01-21T12:09:08.523260"
}