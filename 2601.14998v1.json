{
    "id": "2601.14998v1",
    "title": "Graph-Based Adaptive Planning for Coordinated Dual-Arm Robotic Disassembly of Electronic Devices (eGRAP)",
    "authors": [
        "Adip Ranjan Das",
        "Maria Koskinopoulou"
    ],
    "abstract": "电子废弃物快速增长，而回收率却持续低迷。我们提出一种基于电子设备图的自适应规划方法（eGRAP），该方法融合视觉感知、动态规划与双臂执行能力，实现自主拆解作业。系统通过搭载相机的机械臂识别零部件并估算其空间位姿，同时构建有向图编码零部件间的优先拆卸顺序。规划器基于该图的拓扑排序选择可行的后续步骤，并将任务分配给两台机械臂——允许独立任务并行执行。其中一台机械臂配备螺丝刀（集成手眼深度相机），另一台则负责抓持或搬运组件。我们在3.5英寸硬盘驱动器上验证了eGRAP系统：随着螺丝拆卸与零件移除，系统实时更新状态图并动态调整规划。实验表明，该系统能稳定完成每个硬盘的完整拆解流程，在保持高成功率的同时实现高效作业周期，展现了该方法实时自适应协调双臂任务的卓越能力。",
    "url": "https://arxiv.org/abs/2601.14998v1",
    "html_url": "https://arxiv.org/html/2601.14998v1",
    "html_content": "Graph-Based Adaptive Planning for Coordinated Dual-Arm Robotic Disassembly of Electronic Devices (eGRAP)\nAdip Ranjan Das\n1\nand Maria Koskinopoulou\n2\n*This work was not supported by any organization\n1\nAdip Ranjan Das, School of Engineering and Physical Sciences, Heriot-Watt University, Edinburgh, UK\nard2000@hw.ac.uk\n2\nMaria Koskinopoulou, School of Engineering and Physical Sciences, Heriot-Watt University, Edinburgh, UK\nM.Koskinopoulou@hw.ac.uk\nAbstract\nE-waste is growing rapidly while recycling rates remain low. We propose an electronic-device Graph-based Adaptive Planning (eGRAP) that integrates vision, dynamic planning, and dual-arm execution for autonomous disassembly. A camera-equipped arm identifies parts and estimates their poses, and a directed graph encodes which parts must be removed first. A scheduler uses topological ordering of this graph to select valid next steps and assign them to two robot arms, allowing independent tasks to run in parallel. One arm carries a screwdriver (with an eye-in-hand depth camera) and the other holds or handles components. We demonstrate eGRAP on\n3.5\nin\n3.5\\text{\\,}\\mathrm{i}\\mathrm{n}\nhard drives: as parts are unscrewed and removed, the system updates its graph and plan online. Experiments show consistent full disassembly of each HDD, with high success rates and efficient cycle times, illustrating the method’s ability to adaptively coordinate dual-arm tasks in real time.\n\\IEEEkeywords\nRobotic Disassembly,\nDual-Arm Manipulation, Task Planning,\nSustainable Manufacturing\nI\nIntroduction\nElectronic waste (e-waste) continues to grow while formal collection and recycling rates remain low. This leads to loss of valuable materials and increased environmental risk when hazardous substances enter the waste stream\n[\n7\n]\n[\n17\n]\n. Robotic disassembly offers a controlled alternative to shredding by taking devices apart in a defined order so parts and materials can be sorted and recovered.\nMany existing robotic cells are built for a single product and follow a fixed program. These systems work when the device and environment are tightly controlled, but they struggle when parts vary, fasteners are missing, or components are damaged. Industrial efforts illustrate both the potential and the limits of specialisation: Apple’s iPhone recycling robots and automated hard drive processing initiatives achieve high throughput by exploiting product uniformity\n[\n21\n]\n[\n2\n]\n[\n23\n,\n14\n]\n. However, such lines allow little adaptation and cannot easily exploit parallel work.\nFigure 1\n:\nDual-Arm testbed with a\nManipulation\narm (vacuum gripper) and a\nTooling\narm (screw-driving tool, RGB–D camera, and micro-camera). A\n3.5\nin\n3.5\\text{\\,}\\mathrm{i}\\mathrm{n}\nHDD is fixed on a passive holder at the workspace centre.\nA flexible system needs perception, planning, and execution that can change with the scene. After detecting parts, it is natural to model the device as a directed graph of components with edges for precedence and access, and to compute a valid order by topological reasoning\n[\n10\n]\n[\n5\n]\n[\n11\n]\n. Updating this graph online when observations change (for example, a missing or newly revealed fastener) allows the sequence to adapt during execution. Recent reviews on robotic assembly and disassembly motivate such integrated and adaptive approaches for sustainable manufacturing\n[\n19\n]\n. Using two robots further increases capability: one arm can hold or stabilise while the other operates, or both can work on independent targets to reduce idle time\n[\n4\n]\n[\n17\n]\n. At the action level, screw removal is sensitive to small pose errors and surface reflections, so close-range visual alignment and contact checks are needed before applying torque\n[\n24\n]\n.\nThis paper proposes\nelectronic-device Graph-based Adaptive Planning (eGRAP)\nfor autonomous disassembly. The method builds a directed part graph from live RGB-D detections, encodes precedence and access rules, and uses a topological scheduler to select the next valid actions. A coordination scheme assigns actions to two arms under collision and workspace limits and exposes safe parallel steps when dependencies allow it. The plan updates online after each step so the system can react to new observations or partial failures. The framework is device-agnostic: changing the object labels, detector training, and rules is sufficient to apply the same reasoning and scheduling to a new product. The proposed approach is tested in real-world experiments with two robotic arms on three different hard drive models (Figure\n1\n), completing full teardowns within an average of 22 mins per unit and demonstrating robust perception, adaptive planning, and reliable dual-arm execution.\nThe contributions address gaps in the state of the art. First, we present a unified formulation that links perception, graph construction, topological sequencing, and coordinated dual-arm execution in one loop. Second, we introduce online maintenance of the precedence graph from live detections and immediate rescheduling after each step, which provides adaptation to variation and missing parts. Third, we define a dual-arm scheduling and coordination scheme that respects access and collision constraints while enabling hold–operate behaviours and independent-step execution. Fourth, we include a fastener-engagement routine that combines close-range visual alignment with contact validation to address uncertainty in screw removal\n[\n24\n]\n. Compared to prior systems that are single-arm, device-specific, or rely on fixed scripts\n[\n17\n]\n, eGRAP targets autonomous disassembly of electronic devices with shared tasks across two arms and with adaptation driven by perception and graph reasoning. A full video demonstration of the complete Samsung HDD disassembly is available at:\nhttps://www.youtube.com/watch?v=7a6v7ff-EvU\n.\nII\nRelated Work\nRobotic disassembly has progressed along two complementary lines: concrete systems that dismantle real devices under sensing and control constraints, and process frameworks that formalize how to perceive, plan, and execute disassembly tasks under variability. A representative example of system-level integration is the vision-guided unscrewing cell by Díaz\net al.\n, which combines RGB-D detection of screw-head types with a mechatronic screwdriver and force-aware alignment to automate fastener removal on end-of-life products\n[\n6\n]\n. Kranz\net al.\ndocument lessons from the Robothon Grand Challenge, reporting a modular Sense-Plan-Act architecture, board localisation accuracy, and task execution time on real e-waste boards, with comparisons to human benchmarks\n[\n13\n]\n. In electric-vehicle battery recycling, Peng\net al.\nintroduce BEAM-1, a mobile manipulator that employs neuro-symbolic AI and heuristic search to plan and execute bolt-removal sequences; extensive trials show sustained autonomous disassembly of multi-bolt modules\n[\n16\n]\n. Complementary domain studies describe multi-robot battery-pack disassembly platforms with quantitative throughput and success metrics, demonstrating transfer to varied pack designs and fixtures\n[\n18\n]\n.\nSeveral works propose process and data frameworks for scalable automation. Saenz\net al.\nsurvey digital-twin and data-modelling requirements for automatic electronics disassembly, arguing for explicit representations of product states, skills, and step dependencies derived from both top-down analysis and bottom-up manual teardowns\n[\n22\n]\n. Asif\net al.\nreview task-and-motion planning (TAMP) for end-of-life products, emphasising that dynamic sequence generation and re-planning are required to cope with uncertain part condition and product variants, especially for EV batteries\n[\n3\n]\n. These perspectives converge on the need to link perception outputs to a structured task representation that can be updated online.\nHuman-robot collaboration and tele-robotics provide additional evidence that coordination and explicit scheduling improve robustness. Ameur\net al.\npresent a human-robot collaborative smartphone disassembly line in which operators can reassign tasks via voice/gesture control; simulated trials show reduced cycle time with low error rates when mixed-initiative task sharing is enabled\n[\n1\n]\n. For hazardous battery work, Hathaway\net al.\ncompare asymmetric haptic master-slave control to symmetric dual-cobot teleoperation during module unbolting and cutting, finding 22-57% time reductions for the symmetric setup at a modest cost to first-attempt success rates\n[\n8\n]\n. These studies highlight how coordinated multi-agent action and guarded control can sustain throughput under uncertainty.\nPerception for disassembly focuses on small, reflective, and densely packed targets. Yildiz\net al.\ndemonstrate a hybrid 2D/3D pipeline for HDDs that localizes screws, lid, and pry points, noting the value of close-range imaging for metallic surfaces\n[\n25\n]\n. In parallel, edge/IoT pipelines with modern detectors have been explored for PCB-level component detection to support online decision making in disassembly lines\n[\n15\n]\n. Across these efforts, reliable fastener engagement remains a critical step: uncertainty-aware routines combining visual alignment and contact checks help prevent slip and damage during unscrewing, which is now a frequent design feature of disassembly cells\n[\n6\n]\n.\nSequence generation is commonly formalised on graphs. Directed graphs with precedence and access edges enable topological ordering for feasible removal sequences, and they can be extended with objectives or uncertainty, as surveyed in recent TAMP and digital-twin literature\n[\n3\n]\n[\n22\n]\n. Competition and case-study reports also encode tasks as dependency graphs to expose parallelism and to support re-planning when detections change\n[\n13\n]\n[\n18\n]\n. This growing body of work motivates frameworks that (i) convert live detections into a part graph, (ii) compute precedence-feasible orders that expose independent work, and (iii) coordinate execution—potentially with two arms—to reduce idle time while respecting access and safety constraints.\nPrior studies provide strong components: close-range vision and contact-aware unscrewing\n[\n6\n]\n[\n25\n]\n, graph-based sequencing with re-planning hooks\n[\n3\n]\n[\n22\n]\n, and coordinated multi-agent execution for efficiency and safety\n[\n8\n]\n[\n1\n]\n. What remains less explored is a single, device-agnostic loop that tightly couples live perception to an online-updated precedence graph and a dual-arm scheduler that can both synchronise hold-operate behaviours and run independent steps in parallel, a gap that the present work addresses with eGRAP.\nIII\nElectronic-Device Graph-based Adaptive Planning (eGRAP) Framework\nThe eGRAP framework is a closed-loop system for robotic disassembly of electronic devices. It combines perception (to detect and identify parts), graph-based reasoning (to decide a removal order), and dual-arm execution (two robot arms coordinating to perform actions). The approach generalizes across devices and robot setups: to transfer to a new device family, one only updates the set of part types, a compact set of precedence/access rules, and a library of action templates; the core graph model, sequence generator, and scheduler remain unchanged.\nThe complete eGRAP framework, showing the vision module, graph-based reasoning, sequence generation, and dual-arm scheduler, is illustrated in Figure\n2\nand described in the following.\nIII-A\nVision Module\nThe perception pipeline has two stages that work together. First, the eye-in-hand RGB-D camera provides a global view of the device. On each frame, the visible parts are detected and classified based on the learned classes (for HDDs:\nscrew\n/\nfastener\n,\nlid\n,\nPCB\n), giving the confidence score, and the 2D pixel location of the detected part. Each 2D detection is projected into 3D by applying the calibrated camera intrinsics and sampling the corresponding depth value at the detection centroid\n[\n12\n]\n. The resulting 3D points are then transformed into the shared world coordinate frame using the hand–eye calibration, providing target poses that can be directly consumed by the planning and motion modules. This procedure is applied to all part types and supplies the coarse approach poses for the robots.\nThe second stage is a local, close-range refinement used only for screws. After the tooling arm reaches the coarse pose over a selected fastener, this fine manipulation process is employed. The same detection model runs on streams captured by a micro-camera to give a close view to detect screw-heads precisely. The pixel offset between the detected recess centre and the camera’s optical axis gives a small in-plane correction, which the arm applies before seating the driver.\nBecause screw heads are small, reflective, and depth can be noisy on metal, this two-stage approach with a global RGB-D for coarse positioning and a micro-camera for fine alignment, allows fine alignment and centres the driver bit in the T8 recess before torque is applied. Larger parts such as lids and PCBs are well handled with the RGB-D view, so they use only the first stage.\nThe dection model used in both cases is YOLOv11\n[\n9\n]\ntrained and fine-tuned on a custom dataset of 250 images that we manually annotated in Roboflow\n[\n20\n]\n. Augmentations including horizontal/vertical flips,\n±\n15\n​\n°\n\\pm$$\nrotations,\n±\n10\n​\n°\n\\pm$$\nshears,\n±\n20\n%\n\\pm 20\\%\nbrightness change, light blur\n≤\n\\leq\n1 px, and sparse noise\n≤\n0.97\n%\n\\leq 0.97\\%\npixels), were added\noffline in Roboflow\nand the augmented set was exported for training, yielding roughly 1,300 effective images. Images are auto-oriented and resized to\n640\n×\n640\n640\\times 640\nfor training and inference.\nTable\nI\nsummarises the configuration settings of the detection model.\nDetectors are trained per device family to remain sensitive to small or shiny parts. Across frames, we associate detections by simple class-consistent nearest-neighbour matching in image space; this maintains a short track for each physical item. When two detections refer to the same item in a frame (for example, due to overlapping boxes), we merge them if they fall within a small spatial gate and average their positions. The resulting 2D centroids are lifted to 3D by back-projecting with the calibrated camera intrinsics and using the depth map at the centroid (with a small neighbourhood median for robustness). Hand-eye calibration provides the transform from the eye-in-hand camera to the robot/world frame, so 3D poses are expressed in the shared world frame used by planning and execution. A light exponential moving average smooths the 3D positions over time to reduce jitter.\nThe perception output is a set of labelled part instances with 3D poses. When a previously unseen item appears (e.g., internals revealed after lid removal) or a known item disappears (e.g., a screw is extracted), the system updates the planning graph immediately. This keeps the plan consistent with the scene and allows the sequence to adapt as the disassembly progresses.\nTABLE I\n:\nYOLOv11 training data and augmentation settings\nBase images\n250 (manually labelled in Roboflow)\nEffective images (offline aug., exported)\n≈\n\\approx\n1,300\nAuto-orient\nApplied\nResize\nStretch to\n640\n×\n640\n640\\times 640\nAugmentations (offline, Roboflow)\nH/V flip; rotation\n±\n15\n∘\n\\pm 15^{\\circ}\n; shear\n±\n10\n∘\n\\pm 10^{\\circ}\n(H/V); brightness\n±\n20\n%\n\\pm 20\\%\n; blur\n≤\n1\n\\leq 1\npx; noise\n≤\n0.97\n%\n\\leq 0.97\\%\nof pixels\nFigure 2\n:\nBlock diagram of the eGRAP framework.\nPerception\noutputs labeled parts and 3D poses. The\nGraph\nblock encodes precedence and access rules. The\nSequence Generator\ntopologically orders ready parts and instantiates primitive actions. The\nScheduler\nassigns actions to two arms and updates the plan online from new observations. In the timeline,\nblue\noutlines denote the tooling (screwdriver) arm and\ngreen\noutlines denote the manipulation (gripper) arm; fill colors denote action types:\nyellow\n=\nunscrew\n,\npurple\n=\nremove\n,\norange\n=\ndrop\n.\nIII-B\nGraph-Based Reasoning and Sequencing\nThe\nPart Graph\nrepresents the current device state using common graph terms. Each detected item is a\nnode\n. A directed\nedge\nbetween two nodes encodes a rule that one part must be cleared before the other (precedence) or that one part blocks access to the other (access). A compact set of class-level rules automatically adds the correct edges; for example, “all\nfastener\nnodes point to their\nlid\nnode,” and “the\nlid\npoints to any internal components”. When a node is confirmed removed, it is dropped from the graph along with its incident edges, so the graph always reflects the visible, current device.\nGiven the graph, the sequence generator builds a\nprecedence-feasible order\nof parts to remove. It first collects the\nready set\nof nodes: these are parts that are still present and have no incoming edges, meaning nothing else is blocking them. If several nodes are ready at the same time, simple tie-breakers are applied: class priority (fasteners before lid, then internal components, then case bottom side parts) and a short-move preference so nearby targets are grouped. The ordered nodes are then turned into\naction primitives\nthat the robots can execute, such as\nunscrew\n,\nlift\n,\nremove\n, and\ndrop\n. Each action is created from a template with approach offsets, grasp/seat poses, nominal speeds, and tool parameters. Preconditions are checked against the graph—for example, a\nlift\naction for a lid is only issued when all its incident fasteners no longer appear in the graph.\nIII-C\nDual-Arm Calibration and Scheduling\nBefore execution, both arms are brought into the same world frame using a short, vision-based calibration. An ArUco marker is placed on the work surface. The eye-in-hand camera on the tooling arm is used to drive the tool centre point (TCP) to the marker centre, and small corrective motions are applied until the measured pose aligns with the known marker pose. The manipulation arm is then jogged to the same physical point and fine-tuned, so both arms agree on a common coordinate frame within a small tolerance.\nEach action declares the\ncapability\nit needs:\nunscrew\nrequires the tooling arm (screwdriver), while\nlift\n,\nremove\n, and\ndrop\nrequire the manipulation arm (gripper). The scheduler looks at the current ready actions, filters them by capability, and then selects a set that can run\nin parallel\nwithout spatial interference. Two actions are considered non-interfering when their workspaces do not overlap and they have no direct dependency in the graph. Non-interfering actions are dispatched concurrently to the two arms; overlapping or dependent actions are synchronised to realise safe\nhold-operate\nbehaviours and to minimise idle time.\nFastener handling includes a brief engagement check inside the\nunscrew\nprimitive. The driver is visually aligned over the screw head, a short guarded axial motion confirms seating, and only then is rotation started. If engagement is not confirmed, the action is re-queued with a small pose adjustment while other ready actions continue. When an action finishes successfully, its node is removed from the graph and newly unblocked nodes become ready immediately.\nIII-D\nExecution Loop\neGRAP runs in a fixed-rate loop: perception updates detections; the graph is refreshed from class rules; a topological pass exposes the next ready actions; actions are instantiated from templates and scheduled; execution feeds back state. As parts are removed or revealed, the ready set and schedule update immediately. Because the planner operates on abstract labels and capabilities, the same loop transfers across products and robot platforms: swapping detectors, adding device rules, or refining templates does not change the core pipeline of converting live detections to a precedence graph, generating a valid order, and executing it with coordinated dual-arm control.\nIV\nExperimental Results\nIV-A\nTestbed and System Configuration\nThe experimental setup consists of two collaborative robot arms operating within a shared workspace.\nThe\nTooling\narm\n, a 5-DoF xArm5, is equipped with a custom-made screw-driving end-effector and an Intel RealSense D435i in an eye-in-hand configuration. The RGB-D stream from this sensor is processed by eGRAP for part detection and close-range alignment prior to screw engagement. A micro-camera is embedded inside the tool body and aimed along the driver’s axis toward the screwdriver\nbit\n—that is, the removable Torx T8 screwdriver bit that engages the screw head. The camera has a resolution of\n640\n×\n480\n640{\\times}480\n(0.3 MP) at 30 fps, a\n∼\n67\n∘\n\\sim\\!67^{\\circ}\nfield of view, and a close-focus range of 3-10 cm. This placement gives a clear, close-up view of the screw and the Torx T8 bit during approach. The image is used to make small in-plane and axial corrections so the bit seats fully in the screw head, and to visually confirm contact before starting rotation for the unscrewing step.\nThe screw-driving tool is built on a commercial precision electric screwdriver by\nSoleilwear\n, mounted inside a 3D-printed housing case (Figure\n3\n). The housing provides the wrist-flange interface and keeps all auxiliary components rigid so that the bit axis is aligned to the tool frame. To avoid modifying the commercial driver electronics, two miniature servos press the driver’s physical buttons: one for the\nforward\n(screw) button and one for the\nreverse\n(unscrew) button. Short servo pulses emulate a human press, allowing the robot to switch modes and start/stop rotation without any internal changes to the driver.\nThe\nManipulation\narm\n, a 6-DoF UF850 with an electric vacuum gripper, stabilises the device during tooling, removes freed components such as the lid or PCB, and deposits them into collection bins. Coordination between the two arms is managed by the eGRAP scheduler, which enables parallel execution of independent tasks while ensuring safe hold-operate behaviours.\nThe complete testbed, including both robotic arms, end-effectors, sensors, and supporting hardware, is shown in Figure\n1\n. The device under test is a\n3.5\nin\n3.5\\text{\\,}\\mathrm{i}\\mathrm{n}\nhard drive.\nFigure 3\n:\nCustom end-effector with a\nSoleilwear\nprecision electric screwdriver, a 2D RGB micro-camera, two micro-servos for forward/reverse, and a controller. A Torx T8 bit is used.\n(a)\n(b)\nFigure 4\n:\nHDD brands and fasteners.\nThe hard drives used in our experiments are\n3.5\nin\n3.5\\text{\\,}\\mathrm{i}\\mathrm{n}\nunits from three major brands, i.e. Samsung, Western Digital, and Seagate, as shown in Figure\n4\na. Across these brands, the drives contain four variants of Torx T8 screws (Figure\n4\nb). These variants differ in head diameter and shank length, but all share the same T8 drive geometry. In a full teardown we encounter seven T8 screws on the lid (L1), twelve internal T8 screws (L2), and five T8 screws on the case bottom side (L3). Accordingly, the tool uses a single Torx T8 bit for all brands and all layers.\nFor all experiments, the HDD is mounted on a passive holder at the centre of the workbench. This fixture constrains the drive, exposes the top surface for access to lid screws, and provides sufficient clearance for the manipulation arm to lift components once released by the tooling arm.\nEach experiment runs the full eGRAP loop with the two robots coordinating to share tasks. The\nTooling arm\nmoves to a coarse pose from RGB-D perception, performs fine alignment on a Torx T8 screw using the embedded micro-camera, and actuates the screwdriver to unscrew, retrying if engagement is lost. Freed screws are carried to a drop location. In parallel, the\nManipulation arm\nholds or lifts components once all constraining fasteners are cleared and places them in designated bins. The planner maintains a live part graph, updating nodes and the ready set after each action, while the scheduler assigns non-conflicting tasks to the two arms. Disassembly proceeds across three layers: L1 (lid and seven screws), L2 (twelve internal screws, platter holder, platter, and actuator), and L3 (five case bottom side screws, PCB, and case). Completion is defined as all nodes cleared and all parts for each layer successfully disassembled. To evaluate accuracy and repeatability, we performed 10 full teardowns per HDD family, calculating metrics as reported in the following, including detection accuracy, screw-level success, disassembly layer times, total cycle time, and full-teardown completion rate.\nIV-B\nVision System Performance\nThe vision system was evaluated online during disassembly across the 10 iterations of the experiment for each three HDD families. Performance was measured using standard detection metrics, including precision (the proportion of correct detections), recall (the proportion of ground-truth instances detected), mean average precision at 0.5 IoU (mAP@0.5), and mean 2D localisation error in pixels on\n640\n×\n640\n640\\times 640\nframes. Each metric was averaged over ten complete trials for each HDD family. The results are summarised in Table\nII\n.\nTABLE II\n:\nYOLOv11 detection metrics\nModel\nPrecision\nRecall\nmAP@0.5\nLoc. Err. (px)\nSamsung\n0.92\n0.88\n0.91\n6.3\nSeagate\n0.89\n0.86\n0.88\n7.1\nWestern Digital\n0.93\n0.89\n0.92\n5.8\nThe vision detection module maintained consistently high performance across all three HDD families. Western Digital exhibited the most accurate localisation (5.8 px) and the highest mAP@0.5 (0.92), closely followed by Samsung (mAP@0.5: 0.91, localisation error: 6.3 px). Seagate showed slightly lower recall (0.86) and mAP@0.5 (0.88), with a modest increase in localisation error (7.1 px). In practice, these differences affect how many fine-alignment iterations are needed before the screwdriver seats, but they do not change the computed precedence graph or the chosen sequence.\nHigh precision limits false positives, which stabilises the part graph by avoiding spurious nodes. Recall near 0.9 means most fasteners and lid are detected early; any missed items are usually observed on the next view and inserted without violating precedence rules. The mean localisation error of about 6 px at\n640\n×\n640\n640\\times 640\nis within the capture range of the fine manipulation routine, which explains the observed behaviour in the lid layer: coarse positioning alone is fast but misses engagement on several screws; with fine manipulation, all screws are cleared at the cost of additional time (see Table\nIV\n).\nRare perception faults are linked to surface reflections on some lids. When this occurs, the plan pauses on the affected node, a short re-scan is triggered, and the graph is updated with the new detections. Because eGRAP separates coarse detection from contact-validated engagement, these transient errors have limited impact on overall success and do not require changes to the sequence.\nIV-C\nHDD Sequence Generation with eGRAP\nFigure 5\n:\nHDD sequence generation with eGRAP (L1 example). Top: the detector finds\nscrew\nand\nlid\n. Middle: detections become nodes; class rules add edges (e.g.,\nscrew\n→\n\\rightarrow\nlid\n). Bottom: a topological sort yields a valid order for lid removal. L2 and L3 follow the same pattern with different labels and rules.\nWe apply eGRAP to\n3.5\nin\n3.5\\text{\\,}\\mathrm{i}\\mathrm{n}\nhard drives from the three families using one shared list of part labels and a small set of rules. The labels are simply the part names the detector must find (e.g., screw, lid, PCB), and those same labels become the nodes that the planner reasons about in the graph. The same configuration is used across all three families; only geometry and layout differ. The framework builds and solves the sequence online as the scene changes so that small brand-specific differences are handled naturally.\nFigure\n5\nillustrates the process for the lid layer (L1). The detector runs on the eye-in-hand RGB-D stream and returns labelled boxes for\nscrew\nand\nlid\n. Detections are associated across frames, duplicates are merged by a small spatial gate, and 3D poses are estimated. Each confirmed instance becomes a node in the graph with class and pose.\nL1 (lid).\nFor the lid layer, eGRAP adds edges from each\nscrew\nto the\nlid\n(\nscrew\n→\n\\rightarrow\nlid\n) so that the lid is removable only after all incident screws are cleared. A topological sort computes a valid order. When several screws are ready, ties are broken by a fixed class priority (fasteners first) and a short move estimate so that nearby screws are serviced together. The ordered nodes are mapped to actions: each\nscrew\nbecomes an\nunscrew\naction on the tooling arm; the\nlid\nbecomes a guarded\nlift\non the manipulation arm once the graph confirms that all predecessor screws are gone. As actions succeed, their nodes are removed from the graph and successors become ready. Figure\n5\nshows this end-to-end flow for L1.\nL2 (internals).\nAfter lid removal, new parts become visible. The perception module adds nodes for\nplatter_holder_screw\n,\nactuator_screw\n,\nplatter_holder\n,\nplatter\n, and\nactuator\n. Class rules add edges from internal screws to their hosts (\nplatter_holder_screw\n→\n\\rightarrow\nplatter_holder\n,\nactuator_screw\n→\n\\rightarrow\nactuator\n) and edges from the\nlid\nto all internal parts to model access already satisfied by L1. The same topological procedure selects the next valid steps. Internal screws are cleared first, then\nplatter_holder\nand\nplatter\nare lifted in order, with the\nactuator\nremoved once its fasteners are cleared. As before,\nunscrew\nactions are assigned to the tooling arm, and\nlift\n/\nremove\nactions to the manipulation arm. Independent targets that do not overlap in the workspace are run in parallel.\nL3 (case bottom side).\nThe drive is then turned to expose the case bottom side. The detector adds nodes for\ncase_bottom_screw\n,\nPCB\n, and\ncase\n. Rules enforce\ncase_bottom_screw\n→\n\\rightarrow\nPCB\nand\nPCB\n→\n\\rightarrow\ncase\n. The scheduler again favours fasteners first and short moves. After all\ncase_bottom_screw\nnodes are cleared, the\nPCB\nis lifted, followed by the\ncase\n. As each action completes, the graph is updated and the ready set is recomputed, so the plan remains consistent with the current observations.\nAcross L1–L3, the logic is the same for all three HDD families: detections form nodes, class rules add edges, a topological sort yields a precedence-feasible order, and actions are issued to the two arms with capability and workspace checks. If an\nunscrew\naction reports a failed engagement, it is re-queued with a small pose offset while other ready actions proceed, and the graph continues to unlock new steps. This common process allows a single configuration of eGRAP to handle Samsung, Western Digital, and Seagate units without brand-specific scripts.\nIV-D\nHDD Disassembly Execution\nLid layer (L1).\nFigure\n6\nsummarises the execution for the first layer. For every\nscrew\nnode that becomes ready in the eGRAP plan, the scheduler issues an\nunscrew\naction to the tooling arm and keeps a guarded\nlid lift\nqueued for the manipulation arm.\nCoarse approach.\nThe tooling arm moves to an approach pose computed from the RGB-D detection and the calibrated eye-in-hand transform. The bit axis is aligned normal to the lid, and the arm stops a few millimetres above the target. This brings the tool into the neighbourhood of the screw head.\nEngage and unscrew.\nSmall in-plane and axial corrections are applied to centre and seat the screwdriver bit in the Torx head. A short guarded motion verifies contact; if contact is not confirmed or a slip is detected, the arm backs off, applies a small offset, and retries. Once engagement is confirmed, a servo presses the driver’s button to rotate. A light axial preload is maintained during release. When time or depth change indicates that the thread is free, rotation stops, and the screw, captured at the bit, is carried to a drop pose and released into a bin.\nThe cycle repeats until all seven lid screws are cleared. When the graph confirms that no incident screws remain on the\nlid\nnode, the scheduler dispatches the queued\nlid lift\n. The manipulation arm places the vacuum cup on a flat region, establishes suction, lifts the lid, and places it in the bin. L1 is completed, and the perception module exposes the internal parts, which are inserted into the graph for the next layer.\nFigure 6\n:\nExecution for the lid layer (L1) with Indicative external view snapshot from the process (Top Corner). (1) Coarse move to the screw pose from RGB-D detection; (2) Unscrew with contact-validated engagement; (3) Repeat until all screws are cleared; (4) Lift and remove the lid with the manipulation arm.\nInternal layer (L2).\nAfter the lid is removed, the detector reveals twelve internal screws and components. Figure\n7\nshows the same pattern applied to internal fasteners: coarse approach to each detected screw, contact-validated engagement and unscrewing, repetition until all internal screws are cleared, and then ordered removal of internal components. eGRAP enforces the graph rules so that the platter holder is lifted after its screws, followed by the platter and then the actuator. When targets are independent and their workspaces do not overlap, the scheduler runs actions in parallel to reduce idle time.\nFigure 7\n:\nExecution for the internal layer (L2) with Indicative external view snapshot from the process (Top Corner). (1) Coarse move to the detected internal screw pose; (2) Unscrew with contact-validated engagement; (3) Repeat until all internal screws are cleared; (4) Remove internal components in order (platter holder, platter, actuator) using the manipulation arm.\nCase bottom side (L3).\nThe final layer follows the same procedure. Case bottom five screws are cleared first using the engage-unscrew cycle, then the PCB is lifted, and then the case is removed. The same eGRAP loop continues until the graph is empty.\nIV-E\nDisassembly Performance\nWe evaluated eGRAP on three hard drive model families, performing ten full teardowns per family. The plan is organised into three layers: L1 (lid) removes seven screws and the lid; L2 (internals) removes twelve screws, the platter holder, the platter, and the actuator; L3 (case bottom side) removes five screws, the PCB, and the case. The scheduler issues parallel steps when targets are independent and their workspaces do not overlap. Table\nIII\nreports mean layer times with fine manipulation enabled on L1; all totals are within\n22\n22\nmins.\nTABLE III\n:\nLayer-wise time for fine manipulation (mins)\nModel\nL1\nL2\nL3\nTotal\nSamsung\n7.2\n9.9\n4.8\n21.9\nSeagate\n6.9\n9.7\n4.9\n21.5\nWestern Digital\n6.8\n9.2\n4.9\n20.9\nL1 and L2 dominate the cycle since they are fastener-heavy. Western Digital is slightly faster overall (20.9 mins), followed by Seagate (21.5 mins) and Samsung (21.9 mins). These small differences are consistent with minor variations in access and in the number of fine-alignment iterations needed before seating the bit.\nTo study the L1 speed-completeness trade-off, we compare coarse positioning only with fine manipulation using the micro-camera. Without fine manipulation, the tooling arm removes roughly three of seven screws quickly; with fine manipulation, all seven are cleared at the cost of extra time. Table\nIV\nreports the\nscrew clearance rate (%)\nand the time for each model family.\nTABLE IV\n:\nL1: coarse only vs. fine manipulation (mean)\nModel\nCoarse only\nFine manipulation\nClearance (%)\nTime (mins)\nClearance (%)\nTime (mins)\nSamsung\n42.9\n2.1\n100.0\n7.2\nSeagate\n42.9\n2.0\n100.0\n6.9\nWestern Digital\n42.9\n2.0\n100.0\n6.8\nTable\nIV\nshows that fine manipulation guarantees full L1 clearance, preventing later delays. The extra time on L1 is recovered in L2 and L3 because the plan proceeds without backtracking and the scheduler keeps both arms busy.\nCompletion statistics for each model family are given in Table\nV\n. We report the number of trials, the number of full teardowns completed, and the resulting success rate.\nTABLE V\n:\nFull teardown completion\nModel\nTrials\nSuccesses\nSuccess rate (%)\nSamsung\n10\n9\n90.0\nWestern Digital\n10\n7\n70.0\nSeagate\n10\n9\n90.0\nOverall\n30\n25\n83.3\nPrimary interruption causes were hardware or mechanical rather than planning-related. We observed safe aborts due to a transient vacuum-seal leak during a platter pick that led to part slip, intermittent reduction of tool-head illumination at the micro-camera that prevented reliable fine alignment during screw engagement, and instances where a lid screw was not fully disengaged before the guarded lid lift, triggering a resistance stop. In each case, the eGRAP plan remained valid; after correcting the condition or re-engaging the fastener, the same sequence executed to completion on re-run.\nTaken together, Tables\nIII\n-\nV\nshow consistent full teardowns within\n22\n22\nmins across all model families. The coarse-versus-fine comparison explains the L1 timing profile and aligns with the vision results: localisation errors of a few pixels are small enough for coarse approach but still benefit from fine alignment to guarantee first-pass screw removal. The scheduler’s parallelism reduces idle time by staging holds and lifts while the tool engages the next fastener, keeping totals tight across families and supporting stable end-to-end execution.\nV\nConclusion\nThis paper presents eGRAP, a perception-driven, graph-based planning framework for coordinated dual-arm robotic disassembly of electronic devices. The method represents detected parts and their constraints as a directed graph, generates precedence-feasible sequences by topological sorting, and assigns actions to two arms under simple capability and non-overlap constraints. The framework closes the loop from perception to execution: new observations update the graph, the ready set is recomputed, and the scheduler issues actions accordingly. This design separates device content (labels, rules, and action templates) from the core reasoning and thus supports reuse across products and robot platforms.\nWe validated the approach on\n3.5\nin\n3.5\\text{\\,}\\mathrm{i}\\mathrm{n}\nhard drives from three manufacturers. The system completed full teardowns within 22 mins per unit on average. The vision module, trained with modest data and targeted augmentations, maintained high precision and recall across families. The fine alignment routine, converted coarse visual poses into reliable screw engagement. The scheduler reads the precedence graph and each arm’s workspace to choose the next safe action. It assigns unscrew steps to the tooling arm and issues the matching hold or lift step to the manipulation arm only when the required conditions are met. Actions are sequenced so the arms never interfere and the device stays supported throughout.\nThe main contribution is a scalable disassembly pipeline that converts live detections into a precedence graph and applies simple rules to coordinate dual-arm actions. It generalises to new devices by updating part labels, retraining the detector, and redefining rules, while its instance-based reasoning allows it to handle missing or newly revealed parts without device-specific scripts.\nFuture work will expand the range of parts and products, including flexible elements like cables and gaskets, which need special perception and handling. A library of common part classes and subassemblies could be reused across devices, and using uncertainty estimates in the scheduler could help decide when to retry or reorder actions. eGRAP could also be integrated as a controller in larger recycling workflows, with support for job scheduling, traceability, and safety features to allow continuous operation. Finally, testing on standardized benchmarks with shared metrics would help compare systems and improve general robotic disassembly.\nReferences\n[1]\nS. Ameur, M. Tabaa, K. Karboub, M. Hamlich, and R. Bearee\n(2025)\nDesign and simulation of an interactive human–robot disassembly system for end-of-life phones\n.\nNote:\nPreprint\nExternal Links:\nDocument\n,\nLink\nCited by:\n§II\n,\n§II\n.\n[2]\nApple has a new iPhone recycling robot named ’Daisy’ | TechCrunch\n.\nExternal Links:\nLink\nCited by:\n§I\n.\n[3]\nM. E. Asif, A. Rastegarpanah, and R. Stolkin\n(2024)\nRobotic disassembly for end-of-life products focusing on task and motion planning: a comprehensive survey\n.\nJournal of Manufacturing Systems\n77\n,\npp. 483–524\n.\nExternal Links:\nDocument\n,\nLink\nCited by:\n§II\n,\n§II\n,\n§II\n.\n[4]\nJ. F. Buhl, R. Grønhøj, J. K. Jørgensen, G. Mateus, D. Pinto, J. K. Sørensen, S. Bøgh, and D. Chrysostomou\n(2019-01)\nA Dual-arm Collaborative Robot System for the Smart Factories of the Future\n.\nProcedia Manufacturing\n38\n,\npp. 333–340\n.\nExternal Links:\nISSN 2351-9789\n,\nLink\n,\nDocument\nCited by:\n§I\n.\n[5]\nJ. Cui, C. Yang, J. Zhang, S. Tian, J. Liu, and W. Xu\n(2023)\nRobotic disassembly sequence planning considering parts failure features\n.\nIET Collaborative Intelligent Manufacturing\n5\n(\n1\n),\npp. e12074\n(\nen\n).\nNote:\n_eprint: https://ietresearch.onlinelibrary.wiley.com/doi/pdf/10.1049/cim2.12074\nExternal Links:\nISSN 2516-8398\n,\nLink\n,\nDocument\nCited by:\n§I\n.\n[6]\nI. Díaz, D. Borro, O. Iparraguirre, M. Eizaguirre, F. A. Ricardo, N. Muñoz, and J. J. Gil\n(2025-10)\nRobotic system for automated disassembly of electronic waste: Unscrewing\n.\nRobotics and Computer-Integrated Manufacturing\n95\n,\npp. 103032\n.\nExternal Links:\nISSN 0736-5845\n,\nLink\n,\nDocument\nCited by:\n§II\n,\n§II\n,\n§II\n.\n[7]\newastemonitor\n(2024-03)\nThe Global E-waste Monitor 2024\n.\n(\nen-US\n).\nExternal Links:\nLink\nCited by:\n§I\n.\n[8]\nJ. Hathaway, A. Shaarawy, C. Akdeniz, A. Aflakian, R. Stolkin, and A. Rastegarpanah\nFrontiers | Towards reuse and recycling of lithium-ion batteries: tele-robotics for disassembly of electric vehicle batteries\n.\n(\nen\n).\nExternal Links:\nLink\n,\nDocument\nCited by:\n§II\n,\n§II\n.\n[9]\nUltralytics yolo11\nExternal Links:\nLink\nCited by:\n§\nIII-A\n.\n[10]\nJ. Jungbluth, W. Gerke, and P. Plapper\n(2017-09)\nAn intelligent agent-controlled and robot-based disassembly assistant\n.\n235\n(\n1\n),\npp. 012005\n.\nNote:\nPublisher: IOP Publishing\nExternal Links:\nISSN 1757-899X\n,\nLink\n,\nDocument\nCited by:\n§I\n.\n[11]\nT. Kiyokawa, K. Harada, W. Wan, T. Ishikura, N. Miyaji, and G. Matsuda\n(2024-01-03)\nMany-objective-optimized semi-automated robotic disassembly sequences\n.\narXiv\n.\nExternal Links:\nLink\n,\nDocument\n,\n2401.01817 [cs]\nCited by:\n§I\n.\n[12]\nS. Kobayashi, W. Wan, T. Kiyokawa, K. Koyama, and K. Harada\n(2022)\nObtaining an object’s 3d model using dual-arm robotic manipulation and stationary depth sensing\n.\nIEEE Transactions on Automation Science and Engineering\n20\n(\n3\n),\npp. 2075–2087\n.\nCited by:\n§\nIII-A\n.\n[13]\nP. Kranz, X. Sun, H. Phung, P. Wilson, W. Li, and G. Dissanayake\n(2023)\nTowards recycling e-waste using vision and robotic manipulation: lessons from the robothon grand challenge\n.\nIn\nProc. Australasian Conf. on Robotics and Automation (ACRA)\n,\nExternal Links:\nLink\nCited by:\n§II\n,\n§II\n.\n[14]\nMicrosoft uses automated robots to disassemble and recycle HDDs — company typically shreds two million hard drives per year | Tom’s Hardware\n.\nExternal Links:\nLink\nCited by:\n§I\n.\n[15]\nM. Mohsin, S. Rovetta, F. Masulli, and A. Cabri\n(2025)\nArtificial intelligence approach for waste-printed circuit boards: the role of edge computing and iot\n.\nComputers\n14\n(\n8\n),\npp. 304\n.\nExternal Links:\nDocument\n,\nLink\nCited by:\n§II\n.\n[16]\nY. Peng, Z. Wang, Y. Zhang, S. Zhang, N. Cai, F. Wu, and M. Chen\n(2024)\nRevolutionizing battery disassembly: the design and implementation of a battery disassembly autonomous mobile manipulator robot (beam-1)\n.\nIn\nProc. IEEE/RSJ Int. Conf. on Intelligent Robots and Systems (IROS)\n,\npp. 6367–6374\n.\nExternal Links:\nDocument\n,\nLink\nCited by:\n§II\n.\n[17]\nH. Poschmann, H. Brüggemann, and D. Goldmann\n(2020-03)\nDisassembly 4.0: A Review on Using Robotics in Disassembly Tasks as a Way of Automation\n.\nChemie Ingenieur Technik\n92\n.\nExternal Links:\nDocument\nCited by:\n§I\n,\n§I\n,\n§I\n.\n[18]\nM. Qu, D. T. Pham, F. Altumi, A. Gbadebo, N. Hartono, K. Jiang, M. Kerin, F. Lan, M. Micheli, S. Xu, and Y. Wang\n(2024)\nRobotic disassembly platform for disassembly of a plug-in hybrid electric vehicle battery: a case study\n.\nAutomation\n5\n(\n2\n),\npp. 50–67\n.\nExternal Links:\nDocument\n,\nLink\nCited by:\n§II\n,\n§II\n.\n[19]\nA. Ranjan Das and M. Koskinopoulou\n(2025)\nToward sustainable manufacturing: a review on innovations in robotic assembly and disassembly\n.\n13\n,\npp. 100149–100166\n.\nExternal Links:\nISSN 2169-3536\n,\nLink\n,\nDocument\nCited by:\n§I\n.\n[20]\nRoboflow, Inc.\n(2025)\nRoboflow: computer vision tools for data labeling, training, and deployment\n.\nNote:\nhttps://roboflow.com\nAccessed: 2025-09-15\nCited by:\n§\nIII-A\n.\n[21]\nC. Rujanavech, J. Lessard, S. Chandler, S. Shannon, J. Dahmus, and R. Guzzo\nLiam - An Innovation Story\n.\n(\nen\n).\nCited by:\n§I\n.\n[22]\nJ. Saenz, T. Meinhardt, M. Jung, D. Gsell,\net al.\n(2024)\nAutomated disassembly of electronic waste—requirements on data models and skills\n.\nFrontiers in Robotics and AI\n11\n,\npp. 1303279\n.\nExternal Links:\nDocument\n,\nLink\nCited by:\n§II\n,\n§II\n,\n§II\n.\n[23]\nSecure and sustainable disposal of hard disks\n(Website)\nExternal Links:\nLink\nCited by:\n§I\n.\n[24]\nR. Szewczyk, J. Szałatkiewicz, M. Nowicki, P. Gazda, A. Ostaszewska-Liżewska, P. T. Nowak, T. Charubin, W. Rogalski, M. Wiktorowicz, I. Patapenka, A. Siemiątkowski, and J. Zieliński\n(2024)\nUncertainty assessment of the screw removal system for robotic disassembly of hard disk drives during the recycling process\n.\n146\n(\n4\n).\nExternal Links:\nISSN 0587-4246\n,\nLink\n,\nDocument\nCited by:\n§I\n,\n§I\n.\n[25]\nE. Yildiz, T. Brinker, E. Renaudo, J. Hollenstein, S. M. Haller-Seeber, J. Piater, and F. Wörgötter\n(2020-11)\nA Visual Intelligence Scheme for Hard Drive Disassembly in Automated Recycling Routines\n.\nExternal Links:\nDocument\nCited by:\n§II\n,\n§II\n.",
    "preview_text": "E-waste is growing rapidly while recycling rates remain low. We propose an electronic-device Graph-based Adaptive Planning (eGRAP) that integrates vision, dynamic planning, and dual-arm execution for autonomous disassembly. A camera-equipped arm identifies parts and estimates their poses, and a directed graph encodes which parts must be removed first. A scheduler uses topological ordering of this graph to select valid next steps and assign them to two robot arms, allowing independent tasks to run in parallel. One arm carries a screwdriver (with an eye-in-hand depth camera) and the other holds or handles components. We demonstrate eGRAP on 3.5in hard drives: as parts are unscrewed and removed, the system updates its graph and plan online. Experiments show consistent full disassembly of each HDD, with high success rates and efficient cycle times, illustrating the method's ability to adaptively coordinate dual-arm tasks in real time.\n\nGraph-Based Adaptive Planning for Coordinated Dual-Arm Robotic Disassembly of Electronic Devices (eGRAP)\nAdip Ranjan Das\n1\nand Maria Koskinopoulou\n2\n*This work was not supported by any organization\n1\nAdip Ranjan Das, School of Engineering and Physical Sciences, Heriot-Watt University, Edinburgh, UK\nard2000@hw.ac.uk\n2\nMaria Koskinopoulou, School of Engineering and Physical Sciences, Heriot-Watt University, Edinburgh, UK\nM.Koskinopoulou@hw.ac.uk\nAbstract\nE-waste is growing rapidly while recycling rates remain low. We propose an electronic-device Graph-based Adaptive Planning (eGRAP) that integrates vision, dynamic planning, and dual-arm execution for autonomous disassembly. A camera-equipped arm identifies parts and estimates their poses, and a directed graph encodes which parts must be removed first. A scheduler uses topological ordering of this graph to select valid next steps and assign them to two robot arms, allowing independent tasks to run in parallel. One arm carries a screwdriver (with an eye-in-hand depth camera) and the other hol",
    "is_relevant": false,
    "relevance_score": 1.0,
    "extracted_keywords": [
        "vision",
        "dynamic planning",
        "dual-arm execution",
        "graph-based planning",
        "autonomous disassembly"
    ],
    "one_line_summary": "该论文提出了一种基于图的自适应规划方法，用于协调双臂机器人对电子设备进行自主拆卸，但未涉及强化学习、VLA、扩散模型、Flow Matching、运动控制、VLM或全身控制等关键词。",
    "detailed_summary": "",
    "qa_pairs": [],
    "is_hidden": false,
    "is_starred": false,
    "flag": true,
    "published_date": "2026-01-21T13:57:03Z",
    "created_at": "2026-01-27T15:53:21.051483",
    "updated_at": "2026-01-27T15:53:21.051490",
    "recommend": 0
}