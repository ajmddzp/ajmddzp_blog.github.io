{
    "id": "2601.15069v1",
    "title": "Influence of Operator Expertise on Robot Supervision and Intervention",
    "authors": [
        "Yanran Jiang",
        "Pavan Sikka",
        "Leimin Tian",
        "Dana Kuliic",
        "Cecile Paris"
    ],
    "abstract": "随着机器人自主性水平的提升，越来越多具备不同机器人专业知识背景的用户开始参与机器人监督工作。随着用户群体的日益多元化，理解不同专业水平的用户如何执行监督任务及其对人机协作效能的影响变得至关重要。本探索性研究调查了具有不同专业背景的操作者在监督远程机器人时如何感知信息并作出干预决策。我们开展了一项用户研究（样本量=27），参与者在模拟器中监督机器人自主探索四个未知隧道环境，并在认为机器人遇到困难时通过设置路径点进行干预。通过分析交互数据与问卷反馈，我们发现了新手、中级用户和专家用户在干预时机选择与决策策略上的差异化模式。",
    "url": "https://arxiv.org/abs/2601.15069v1",
    "html_url": "https://arxiv.org/html/2601.15069v1",
    "html_content": "Influence of Operator Expertise on Robot Supervision and Intervention\nYanran Jiang\n1,\n∗\n, Pavan Sikka\n1\n, Leimin Tian\n1\n, Dana Kulić\n1,2\nand Cécile Paris\n1\n1\nData 61, CSIRO,\nAustralia,\n2\nFaculty of Engineering,\nMonash University, Australia\n∗\nyanran.jiang@csiro.au\nAbstract\nAs autonomous robots are increasingly deployed in complex and high-risk environments, they are supervised by users with diverse levels of robotics expertise. As the diversity of the user population increases, it is important to understand how users with different expertise levels approach the supervision task and how this impacts performance of the human-robot team. This exploratory study investigates how operators with varying expertise levels perceive information and make intervention decisions when supervising a remote robot. We conducted a user study (\nN\n=\n27\nN=27\n) where participants supervised a robot autonomously exploring four unknown tunnel environments in a simulator, and provided waypoints to intervene when they believed the robot had encountered difficulties. By analyzing the interaction data and questionnaire responses, we identify differing patterns in intervention timing and decision-making strategies across novice, intermediate, and expert users.\n1\nINTRODUCTION\nThe integration of semi-autonomous remote robots into industrial, service, and field environments offers numerous benefits such as enhanced efficiency, reduced human labor, and increased safety\n[\n?\n]\n. However, the success of these robotic systems often depends on the ability of human operators to monitor and intervene when necessary\n[\n?\n;\n?\n]\n. This is especially crucial in complex environments where the semi-autonomous remote robot may encounter situations that challenge its autonomous capabilities, leading to suboptimal performance or failures\n[\n?\n]\n. One such complex environment is search and rescue, where a robot must deal with varying terrain, obstacles, and other dynamic factors, requiring remote human supervision\n[\n?\n;\n?\n]\n.\nHuman supervision of robots can involve operators with varying levels of knowledge and experience of robot capabilities or task understanding, i.e., operator’s expertise\n[\n?\n;\n?\n]\n. Comprehending how operators of varying expertise levels perceive information and make decisions is key to developing effective human-robot teaming (HRT) with shared autonomy\n[\n?\n]\n. By equipping robots with adaptive autonomy, these systems can adjust their behavior based on the operator’s expertise, providing more assistance to novices while allowing experts greater control\n[\n?\n;\n?\n]\n. To appropriately adapt to the operator’s expertise, robots need to be able to infer the operator’s level of expertise based on their interactions. However, to date there is limited research on how intervention strategies vary with the expertise levels of operators in remote HRT.\nWe conducted a user study recruiting participants with different expertise levels in a remote HRT task to characterize the strategies of user interventions, how they vary as a function of user expertise, and their impact on task performance. The HRT mission was generated in a custom simulator environment, using the same robot autonomy algorithms, data visualization, operator control interface, and realistic mission maps obtained from field deployment of the CSIRO Data61 team during the DARPA SubT challenge\n[\n?\n]\n. We aim to understand how operator expertise influences intervention behavior, providing insights on enhancing robot collaboration with users of diverse expertise levels. Our contributions are:\n•\nWe provide an empirical analysis of intervention behaviours (timing and waypoint placement) across operator expertise levels in remote human–robot supervision tasks.\n•\nPost-simulation analysis evaluates intervention efficiency, showing how expertise influences subsequent robot performance.\n•\nWe assess diverse operators’ perceptions and preferences in remote supervision of robots, demonstrating the need for both human-initiated intervention and robot-initiated help requests.\n2\nRelated Work\n2.1\nThe role of human supervisors in human-robot teaming\nHuman-robot teaming (HRT) research focuses on improving interaction and performance in complex, high-risk environments such as smart farming\n[\n?\n]\n, search and rescue\n[\n?\n]\n, and space exploration\n[\n?\n]\n. Human operators contribute significantly to HRT by providing foresight, contextual awareness, and advanced prioritization, ensuring that critical tasks are addressed during missions\n[\n?\n]\n. Operators typically assess the robot’s state, integrate visual information, and decide on the next steps to enhance task execution\n[\n?\n]\n. Where communication allows, they intervene through guidance or teleoperation to prevent critical incidents, such as robots becoming stuck or task inefficiency\n[\n?\n]\n.\nWhile operators can significantly enhance mission outcomes, they can also introduce errors and interruptions that affect performance\n[\n?\n]\n. Sheridan\n[\n?\n]\nhighlighted supervisory errors that undermine robot performance, while Wang et al.\n[\n?\n]\nexamined how task-switching increases errors and delays. Understanding when and how to best utilize operator intervention is crucial for optimizing human-robot collaboration. Robinson et al.\n[\n?\n]\nevaluated the impact of human operators on mission success and team performance in search and rescue missions. By comparing human-robot teams to fully autonomous teams in real-world scenarios, they identified scenarios where operator interventions were advantageous, such as redirecting robots to better cover ground or navigate challenging terrain. They also identified occasions where human intervention was disadvantageous or unneeded. However, this study was limited to expert operators. To develop more adaptive systems and facilitate wider adoption of HRT, it is critical to consider operators with different experience levels.\n2.2\nRobot adaptation to human expertise levels\nIdentifying and adapting to varying operator skill levels is essential for enhancing HRT\n[\n?\n]\n. Conlon\net al.\n[\n?\n]\nfound that robots communicating task proficiency without considering operator expertise led to trust and performance issues, especially in novices who ignored confidence levels. Their work highlights the difficulties novice operators face in controlling robots and reveals a significant gap: robots typically assess task feasibility based solely on their own performance metrics, which can lead to overconfidence in novices\n[\n?\n]\n. This emphasizes the need for robots to better understand human expertise in HRT.\nMost existing works classify novice and expert users with a pre-assessment of operator skill\n[\n?\n;\n?\n]\n. However, such static classifications may not fully reflect actual performance\n[\n?\n]\n. To address this, some studies dynamically adapt to user expertise based on real-time cues such as intent and task performance across manipulation and feedback-driven learning\n[\n?\n;\n?\n]\n. For instance, Lewis et al.\n[\n?\n]\nemploys an adjustable autonomy approach that classifies expertise using k-means clustering on teleoperation features like task completion time and command frequency. The system then adjusts autonomy to support weaker areas, enhancing performance. However, it does not account for increasing expertise as a user learns over time.\nUser expertise is often considered in robot learning from human input. For instance, Liang et al.\n[\n?\n]\nuse large language models (LLMs) to learn from iterative human feedback, classifying top-users based on the number of interactions needed to teach the robot. However, this approach risks conflating user skill with low standards, as users both guide and assess the robot. This highlights the need for a refined expertise assessment that considers both instruction efficiency and final task quality. In the field of robot learning from demonstration, participants’ performance is often evaluated using metrics focused on final task outcomes, such as task success, time spent on demonstrations, consistency in object handling, and the number of help requests\n[\n?\n;\n?\n]\n. These indicators reflect the effectiveness and skill of participants at task demonstration, which are only partially useful for assessing the operator expertise level in remote HRT, corresponding most closely to supervisor teleoperation.\nThere is a lack of research exploring user behaviours as expertise indicators in remote HRT beyond teleoperation. This exploratory study examines how expertise influences robot supervision and task performance. We conducted a user study in a realistic simulated search and rescue scenario, analyzing participants’ monitoring and intervention strategies during a tunnel exploration mission. Findings provide insights to enhance adaptive and effective HRT design.\n3\nExperiment\nTo investigate how operators with varying expertise levels perceive information and provide intervention in remote HRT, we conducted a user study, approved by the CSIRO Ethics Review Board. Related videos are in\nhttps://yanranjiang.github.io/Influence-of-Operator-Expertise/\n.\n3.1\nResearch Questions\nWe investigate the following research questions:\n•\nRQ1\n: How does the expertise level of human operators impact their intervention behaviours?\n–\nRQ1.1\n: Do operators with higher levels of expertise intervene at times closer to the pre-designed robot failures?\n–\nRQ1.2\n: Do operators with higher levels of expertise provide more effective interventions, such as positioning waypoints that better help the robot recover from failures and enhance exploration outcomes?\n•\nRQ2\n: Do operators, particularly novices, prefer a robot that explicitly requests help over relying on human observation to initiate intervention?\n3.2\nUser Study Design\nThe user study simulated an HRT mission where the aim was to explore as much of an unknown tunnel environment as possible within a time limit. The team was composed of one remote human operator and one simulated BIA5-tracked all-terrain robot (ATR). During the automated exploration phase, the robot may encounter various challenges that can result in reduced progress or complete immobilization. The key challenges the robot faces include identifying and avoiding redundant exploration of areas it has already visited, efficiently navigating through narrow tunnels, and safely traversing steep slopes (see details in Section\n3.3\n). We ask the operator to supervize the robot and intervene when necessary to help the robot explore the map efficiently. Participants are expected to intervene by providing waypoints to the robot (assist in navigating challenging terrain) when they deem it necessary. Only one intervention was allowed in each exploration mission to ensure consistency and comparability across participants. The robot’s actions in the simulator were pre-recorded, ensuring that each participant observed the exact same robot execution trajectory up to the point of intervention. This standardized the robot’s state and enabled systematic measurement of timing differences across expertise levels. The simulation was terminated as soon as the participant provided a waypoint. Participants’ intervention time and waypoint positions were recorded for data analysis and to enable forward simulation for assessing the effectiveness of the intervention.\n3.3\nSimulation Environment\nWe utilize the CSIRO NavStack simulator\n[\n?\n]\n, which accurately replicates the capabilities of the physical robot. The simulated robot was equipped with a multi-agent 3D Simultaneous Localisation and Mapping (SLAM) system\n[\n?\n]\n, along with multiple RGB and thermal cameras and a spinning lidar. The robot can autonomously explore and construct an accurate map of an unknown area for navigation and localization of artifacts, and communicate its progress to the base station (operator interface)\n[\n?\n]\n.\nThe operator interface (simulator) is segmented into four panels (see supplementary video for details): the Executive panel (left) allows the supervisor to select a robot and manually generate tasks for it to execute, namely a sequence of waypoints to navigate to, as well as an E-Stop panel for shutting down a selected robot in an emergency; the Map panel (center) displays a simulated ATR robot in a 3D map that is generated and updated continuously using SLAM and navigation data. The robot’s planned trajectory is also shown. On this 3D map, the supervisor can add waypoints to create supervisor-generated tasks for exploration, which are then added to the existing task list in the Executive panel for execution; the Robot Camera’s Feed panel (top right) streams the robot’s front and/or rear camera feeds; the Visualisation Manager panel (bottom right) displays status information of the robot, such as network connectivity and errors.\n((a))\n((b))\n((c))\n((d))\nFigure 1:\nFour scenarios with annotated challenging tunnel maps. The robot’s trajectory (red line) is extracted from recorded data. Red triangle marks trajectory start and red star marks the end. Dark blue annotations indicate points of robot delays. Predefined failure points, requiring human intervention, are marked at location c in scenarios 1-3 and b in scenario 4.\n3.4\nSimulator Scenario Design\nWe designed four simulator maps based on real-world challenges\n[\n?\n]\n, incorporating steep slopes, constrained tunnels, intersections, and sharp turns. These elements were arranged in feasible configurations to create diverse scenarios (Fig.\n1\n). The maps highlight key locations where robot progress is impeded.\nEach scenario introduces specific challenges, with intentionally designed robot failures at location c for Scenarios 1-3 and b for scenario 4:\n•\nScenario 1: The robot navigates an intersection, encounters obstacles, and gets stuck in a narrow tunnel.\n•\nScenario 2: The robot hesitates at an intersection, explores a U-turn, then becomes stuck at a dead end.\n•\nScenario 3: After a U-turn and intersection, the robot fails to proceed into an unexplored tunnel.\n•\nScenario 4: The robot struggles with a slope, attempts again, but becomes stuck near an obstacle.\nBaseline intervention timing is defined as the moment the robot reaches a failure point and remains stuck for 10 seconds (derived from scenario designer input). This controlled simulation ensures that every participant experiences an identical scene, eliminating extraneous variability (e.g., differences in lighting or object placement) that can occur in physical environments. Such consistency allows us to directly compare novice, intermediate, and expert intervention behaviors while still reflecting challenges derived from real-world scenarios.\n3.5\nParticipants Recruitment\nTwenty-seven participants (8 females, 19 males, age\n28.8\n±\n4.9\n28.8\\pm 4.9\n) with diverse backgrounds were recruited via email invitations to staff and PhD students at CSIRO and at Monash University. The participants represented varying levels of HRT expertise, as defined in Section\n4.1\n.\n3.6\nProcedure\nParticipants provided informed consent and reported their experience with human-robot collaboration via a questionnaire. They were seated in front of a laptop with a monitor displaying the simulated tunnel environment. Participants had a clear view of the exploration task interface and were comfortable with the input devices provided. Before interacting with the simulated robot, they watched a video explaining the steps of this user study, the task of the robot and participant, and the interface. A practice session followed, allowing them to familiarize themselves with the interface and how to place waypoints. Participants then completed two quizzes: one to confirm task understanding (with feedback) and another to assess expertise (without feedback). Each participant participated in all 4 scenarios (Fig.\n1\n). After each scenario, participants were asked to rate their intervention timing (timely, early, or late) and explain the reasons behind their interventions. A post-experiment questionnaire captured their overall experience and intervention preferences.\n3.7\nExperimental Measures\nWe collected several measures during and after the simulator experiments. These measures were designed to evaluate various aspects of the interaction, including intervention behaviours, robot performance, and user satisfaction.\nTask-related measures\nIntervention timing:\nIntervention timing refers to the specific moment during the task when participants chose to intervene and provide assistance to the robot. This metric is essential for understanding the decision-making process of human operators, as it reveals whether participants tend to intervene early as soon as they perceive the robot encountering an issue or late after the robot has already been grappling with a problem. Recorded as timestamps corresponding to each intervention, this metric enables analysis of intervention intervals and their correlation with task performance.\nWaypoint position:\nWaypoint position refers to the specific locations on the map where participants set waypoints to guide the robot. This metric provides insights into the spatial strategies employed by operators. Effective waypoint positioning is crucial for efficient navigation and task completion, as optimal waypoints help the robot avoid obstacles and take the shortest or safest path. Analyzing waypoint positions highlights strategic differences across expertise levels. Recorded as coordinates and orientations, they reveal variations in distribution, obstacle proximity, and path alignment, reflecting differences in planning and effectiveness.\nArea Covered Post-Intervention:\nArea covered post-intervention refers to the total area explored by the robot after a human intervention has occurred. The interface in the user study is not fully interactive. We terminated the simulation once the participant provided a waypoint. To examine the performance of the intervention, we subsequently run the simulation forward to see what would have happened as a result of that intervention. The metric captures the effectiveness of the intervention by measuring how much area the robot successfully explores after the operator intervened compared to autonomous behaviours without the intervention.\nQuestionnaire measures\nWe collected questionnaire measures to capture participants’ subjective experiences and perceptions during the experiment. The questions focused on\ntask evaluation\n,\nself-evaluation\n, and\ninteraction preferences\n. Participants were asked to rate task difficulty (1 = Not challenging at all, 10 = Extremely challenging), overall satisfaction (1 = Not satisfied at all, 10 = Extremely satisfied), and confidence in their interventions (1 = Not confident at all, 10 = Extremely confident). To evaluate interaction preferences, participants indicated whether they would assist if the robot explicitly asked for help and whether they preferred assistance to be initiated by the robot or at their own discretion. They were also asked to answer open-ended questions related to\nsystem performance\nand\noverall experience\n. These responses provided insights into how expertise levels influenced task perception, confidence, and help-seeking behavior.\n4\nResults Analysis\nWe analyzed intervention strategies across expertise levels using quantitative and qualitative data. Before conducting ANOVA, normality and homogeneity of variance assumptions were validated via Shapiro-Wilk (\np\n>\n0.05\np>0.05\nfor all groups) and Levene’s tests (\np\n>\n0.05\np>0.05\n), respectively.\n4.1\nLevel of Expertise\nWe categorized participants as three expertise levels: Novice, Intermediate, and Experienced, based on their background and experience. This classification was conducted post-study by reviewing self-reported survey on familiarity with AI, robotics, and similar HRT task or simulation.\n•\nNovice:\nParticipants (N=11) with little or no experience in AI, robotics, or relevant simulations.\n•\nIntermediate:\nParticipants (N=11) with moderate experience or knowledge in AI and robotics but new to this specific simulator and mission.\n•\nExperienced:\nParticipants (N=5) with substantial experience in using the simulator or in AI and robotics.\nExperienced participants had between one to five years of simulator experience, with usage frequency ranging from monthly to daily. Given the specialized nature of this domain and the proprietary NavStack simulator, expert operators are scarce, limiting the participant pool.\nTable 1:\nMixed-design ANOVA results of intervention behaviors: Shapiro-Wilk (\np\n>\n0.05\np>0.05\nfor all groups) and Levene’s tests (\np\n>\n0.05\np>0.05\n); Significance code:\n0\n<\n∗\n∗\n∗\n<\n0.001\n<\n∗\n∗\n<\n0.01\n<\n∗\n<\n0.05\n0<***<0.001<**<0.01<*<0.05\nData\nVariables\nSum of Squares\ndf\nF\np\nη\np\n2\n\\eta^{2}_{p}\nIntervention Timing\nC(scenario)\n5.29\n​\ne\n+\n05\n5.29e+05\n3\n14.6\n6.39\n​\ne\n−\n08\n∗\n⁣\n∗\n∗\n6.39e-08^{***}\n0.31\nC(expertise)\n1.29\n​\ne\n+\n05\n1.29e+05\n2\n5.35\n6.22\n​\ne\n−\n03\n∗\n∗\n6.22e-03^{**}\n0.10\nC(scenario):C(expertise)\n2.92\n​\ne\n+\n04\n2.92e+04\n6\n0.4\n8.75\n​\ne\n−\n01\n8.75e-01\n0.025\nResidual\n1.10\n​\ne\n+\n06\n1.10e+06\n96\n-\n-\n-\nIntervention Waypoint\nC(scenario)\n1597.33\n3\n35.97\n1.14\n​\ne\n−\n15\n∗\n⁣\n∗\n∗\n1.14e-15^{***}\n0.268\nC(expertise)\n334.73\n2\n3.40\n3.73\n​\ne\n−\n02\n∗\n3.73e-02^{*}\n0.071\nC(scenario):C(expertise)\n1116.29\n6\n0.12\n9.9\n​\ne\n−\n01\n9.9e-01\n0.004\nResidual\n4356.90\n96\n-\n-\n-\nArea Covered Post-Intervention\nC(scenario)\n2.75\n​\ne\n+\n06\n2.75e+06\n3\n38.42\n2.12\n​\ne\n−\n16\n∗\n⁣\n∗\n∗\n2.12e-16^{***}\n0.546\nC(group)\n2.14\n​\ne\n+\n05\n2.14e+05\n3\n2.97\n3.55\n​\ne\n−\n02\n∗\n3.55e-02^{*}\n0.085\nC(scenario):C(group)\n1.92\n​\ne\n+\n05\n1.92e+05\n9\n0.89\n5.36\n​\ne\n−\n01\n5.36e-01\n0.077\nResidual\n3.51\n​\ne\n+\n08\n3.51e+08\n96\n-\n-\n-\n4.2\nOperator Expertise and Intervention Behaviours -\nRQ1\nIntervention Timing by Expertise Level\nWe ran a mixed-design ANOVA with scenarios (4 scenarios) and expertise level (Novice vs Intermediate vs Experienced) as independent variables (Table\n1\n). Our analysis revealed significant main effects of the type of scenario (\nF\n​\n(\n3\n,\n96\n)\n=\n14.60\n,\np\n=\n6.39\n​\ne\n−\n08\n<\n0.001\n,\nη\np\n2\n=\n0.31\nF(3,96)=14.60,p=6.39e-08<0.001,\\eta^{2}_{p}=0.31\n) and expertise (\nF\n​\n(\n2\n,\n96\n)\n=\n5.35\n,\np\n=\n6.22\n​\ne\n−\n03\n<\n0.01\n,\nη\np\n2\n=\n0.10\nF(2,96)=5.35,p=6.22e-03<0.01,\\eta^{2}_{p}=0.10\n) on the intervention timing, but no interaction effect\nF\n​\n(\n6\n,\n96\n)\n=\n0.40\n,\np\n=\n8.75\n​\ne\n−\n01\n,\nη\np\n2\n=\n0.025\nF(6,96)=0.40,p=8.75e-01,\\eta^{2}_{p}=0.025\n. Tukey HSD revealed Scenario 3 differs significantly from others (\np\n<\n0.001\np<0.001\n). Significant differences are observed between Intermediate and Novice users (\np\n=\n1.6\n​\ne\n−\n03\n<\n0.005\np=1.6e-03<0.005\n), and between Experts and Novices (\np\n=\n2.80\n​\ne\n−\n03\n<\n0.005\np=2.80e-03<0.005\n)\nFig.\n2\nreveals distinct patterns of intervention timing among different expertise levels (addressing\nRQ1.1\n). The relative response time is computed as the participant’s intervention timing minus the baseline (i.e., 0s on the y-axis is the pre-defined robot failure point in each map). Novices intervene significantly earlier than intermediate and experienced users, with lower variance in timing. Participant reasoning (see Section\n4.4\n) provides insights into this trend — Novices rely on clear cues like stalling, obstacle proximity, or revisiting areas (e.g., ’The robot was stuck near a wall.’ - P3, Novice, Scenario 1), leading to lower variance in intervention timing. In contrast, Intermediate and Expert users intervene later, closer to predefined failure points. Their familiarity with the robot’s behaviour enables them to give it more time to resolve issues autonomously before stepping in. Similarly, Lewis et al.\n[\n?\n]\nfound that Novices issued stop commands more frequently, while Experts exercised more decisive control. Both studies suggest that Novices take a more conservative approach, while Experts intervene more strategically in remote HRT (answering\nRQ1\n).\nFigure 2:\nResponse Times by Scenario and Group\nIntervention Waypoint by Expertise Level\nA mixed-design ANOVA (Table\n1\n) found significant main effects of scenario type (\nF\n​\n(\n3\n,\n96\n)\n=\n35.97\n,\np\n=\n1.14\n​\ne\n−\n15\n<\n0.001\n,\nη\np\n2\n=\n0.268\nF(3,96)=35.97,p=1.14e-15<0.001,\\eta^{2}_{p}=0.268\n), and expertise level (\nF\n​\n(\n2\n,\n96\n)\n=\n3.40\n,\np\n=\n3.73\n​\ne\n−\n02\n<\n0.05\n,\nη\np\n2\n=\n0.071\nF(2,96)=3.40,p=3.73e-02<0.05,\\eta^{2}_{p}=0.071\n) on intervention waypoint positions, but no significant interaction effect (\nF\n​\n(\n6\n,\n96\n)\n=\n0.12\n,\np\n=\n9.9\n​\ne\n−\n01\n,\nη\np\n2\n=\n0.004\nF(6,96)=0.12,p=9.9e-01,\\eta^{2}_{p}=0.004\n). Post-hoc Tukey HSD tests confirmed that waypoint placement significantly differed between all scenario pairs (\np\n<\n0.01\np<0.01\n). Significant differences are observed between expert and novice users (\np\n=\n0.003\n<\n0.005\np=0.003<0.005\n).\nTo answer\nRQ1.2\n, we examined Fig.\n3\n, which illustrates the robot’s trajectory along with the mean positions and orientations of waypoints placed by participants and the corresponding robot positions at those times. Novices intervene early, while intermediates and experts wait until the robot encounters obstacles before intervening, aligning with findings from Fig.\n2\n.\nThe intervention positions of operators varied by expertise level across scenarios, as depicted in Fig.\n3\n. Most participants place waypoints near the robot’s current location, regardless of expertise. Experts, however, show a consistent intervention strategy, with low variance in placement. Beyond placement, waypoint orientation is key to success. Experts guide the robot away from failure points, while novices and intermediates often misalign waypoints, causing inefficient recovery and unnecessary detours. In Scenario 1, novices and intermediates direct the robot into a narrow tunnel, failing to recognize the challenge.\nFigure 3:\nUser intervention relating to robot trajectory. Waypoints by Novices, Intermediates, and Experts are marked as orange, green, and purple circles, respectively, with arrows indicating mean orientation. Corresponding robot positions are shown as squares in the same colors. Variance ellipses depict the spread of intervention points. The robot’s trajectory is plotted in red (arrow for start and X for end).\nArea Covered Post-Intervention\nTo further study\nRQ1.2\n, a forward simulation was conducted to examine the effectiveness of participant interventions. A mixed-design ANOVA results (Table\n1\n) show significant main effects of the type of scenario (\nF\n​\n(\n3\n,\n96\n)\n=\n38.42\n,\np\n=\n2.12\n​\ne\n−\n16\n<\n0.001\n,\nη\np\n2\n=\n0.546\nF(3,96)=38.42,p=2.12e-16<0.001,\\eta^{2}_{p}=0.546\n) and expertise group (Novice, Intermediate, Experienced, and Robot) (\nF\n​\n(\n3\n,\n96\n)\n=\n2.97\n,\np\n=\n3.55\n​\ne\n−\n02\n,\nη\np\n2\n=\n0.085\nF(3,96)=2.97,p=3.55e-02,\\eta^{2}_{p}=0.085\n) on the area covered, with no interaction effect (\nF\n​\n(\n9\n,\n96\n)\n=\n0.89\n,\np\n=\n5.36\n​\ne\n−\n01\n,\nη\np\n2\n=\n0.077\nF(9,96)=0.89,p=5.36e-01,\\eta^{2}_{p}=0.077\n). Post hoc Tukey’s HSD tests confirmed significant differences across all scenario comparisons (\np\n<\n0.001\np<0.001\n), with Scenario 3 deviating most from the others. For expertise groups, Experts and Intermediates significantly outperformed novices and robots (\np\n<\n0.001\np<0.001\n), but the difference between Experts and Intermediates was marginal (\np\n=\n0.05\np=0.05\n). Area covered following intervention by Novices compared to robots operating alone showed no significant difference (\np\n=\n0.13\np=0.13\n).\nFig.\n4\nshows the area covered by the robot before and after intervention, while Fig.\n5\npresents confidence intervals for each group’s mean area covered. Human intervention generally improves performance over autonomy in scenarios 1, 2, and 4, with Experienced operators achieving the highest coverage. However, variability among Novice and Intermediate participants suggests that not all interventions are effective. Intermediate participants initially outperformed the autonomous robot but plateaued, while some Novice interventions even reduced performance (Fig.\n4\n).\nIn scenario 3, the robot’s autonomous performance surpasses that of human intervention. In this scenario, the robot did not encounter significant challenges or become stuck until a critical point, where it chose to explore a longer, already traversed tunnel instead of a shorter, unexplored area at an intersection, which occurred much later close to mission completion (see Section\n3.4\n). Only a few participants recognized and corrected this behavior. This suggests that under specific conditions, such as tasks closely aligned with the robot’s programming, the robot’s autonomous exploration performance can be more advantageous.\nFigure 4:\nArea covered vs. time for the expertise group and the\nautonomous robot baseline. The plot compares area coverage over time for each novice, intermediate, and experienced users, along with the autonomous robot baseline.\n4.3\nConfidence in Intervention\nConfidence ratings were collected from 19 of 27 participants (5 Experts, 7 Intermediates, 7 Novices); data from 8 were missing due to incomplete responses. Experts reported high and consistent confidence (\nM\n=\n6.8\n,\nS\n​\nD\n=\n1.10\nM=6.8,SD=1.10\n). Intermediates had the lowest confidence (\nM\n=\n4.17\n,\nS\n​\nD\n=\n1.47\nM=4.17,SD=1.47\n), showing greater uncertainty and variability. Novices reported the highest confidence (\nM\n=\n7.0\n,\nS\n​\nD\n=\n1.41\nM=7.0,SD=1.41\n), but their variability suggests less consistent self-assessment. A one-way ANOVA confirmed a significant effect of expertise level on confidence (\nF\n​\n(\n2\n,\n16\n)\n=\n23.29\n,\np\n<\n0.001\nF(2,16)=23.29,p<0.001\n). Post-hoc Tukey’s HSD tests further showed that intermediates had significantly lower confidence than both Experts (\np\n=\n0.007\np=0.007\n) and Novices (\np\n=\n0.003\np=0.003\n), while no significant difference was found between Experts and Novices(\np\n=\n0.97\np=0.97\n). These results suggest that confidence does not increase linearly with expertise. Novices may overestimate their abilities, while Intermediates are more aware of their limitations.\nThis aligns with participant reasoning in Section\n4.4\n, where Novices initially hesitated but gradually gained confidence in their decisions on when to intervene. However, despite their confidence, Novice interventions performed worse than those of Experienced participants and even underperformed compared to the robot’s autonomous exploration in some scenarios (see Section\n4.2\n). These findings align with\n[\n?\n]\n, which highlights the tendency for overconfidence in Novice operators.\n4.4\nParticipants’ Intervention Strategies\nAfter each scenario, we asked each participant to give observations and reasons for their intervention behaviours. Based on what they could observe, participant interventions likely relied on the following factors:\nRobot Behaviour:\nMost participants observed the robot to decide when to intervene. Novices relied on clear signs like the robot stopping or failing to progress. For instance, one noted, “Since it did not move for some time, I could have intervened quicker.” (P5, Novice, Scenario 1). In contrast, experts allowed more time for autonomous operation and intervened only upon detecting inefficiencies or failures. “Provided enough time for the robot to explore autonomously but intervened due to inefficient navigation.” (P22, Experienced, Scenario 1). Another expert emphasized patience, noting they intervened for efficiency but recognized the system might have self-corrected: “If I had been more patient, the system looked like it would have reverted to the most efficient task.” (P22, Experienced, Scenario 2). Some novices adapted their approach over time, shifting towards efficiency-based interventions: “As soon as I saw continued difficulty, I intervened to redirect it.” (P5, Novice, Scenario 2).\nTiming Based Responses:\nTiming played a crucial role for many participants. “I waited 10-20 seconds when the robot became stuck against a wall before intervening, which I think is reasonable as it sometimes figures out an issue after that amount of time.” (P14, Intermediate, Scenario 3). This participant used a timing rule, allowing the robot some time to resolve the issue before stepping in.\nEnvironmental Cues:\nParticipants frequently recognized environmental factors, such as walls, narrow passages, or dead ends, as key indicators that the robot required intervention. These environmental cues often triggered decisions to intervene when the robot struggled to navigate or became stuck. For instance, one participant noted, “The robot has been stuck by an obstacle and returned to the travelled route.” (P16, Novice, Scenario 1). Similarly, another participant observed, “The robot was stuck near a wall.” (P3, Novice, Scenario 1). These participants responded to clear physical barriers that visibly hindered the robot’s progress.\n4.5\n“Ask for help” Preferences -\nRQ2\nTo answer\nRQ2\n, participants were asked about their interaction preferences after the experiment. In the post-experiment survey, all participants responded “Yes” to the question, “If the robot asks for help, would you be willing to provide assistance?” except for two individuals who expressed no preference.\nIn the subsequent question, “How do you prefer that help be initiated?”, a chi-square test confirmed a statistically significant difference in help initiation preferences (\nχ\n2\n​\n(\n2\n,\nN\n=\n27\n)\n=\n12.67\n,\np\n=\n0.0018\n\\chi^{2}(2,N=27)=12.67,p=0.0018\n), though expertise level had no significant effect.\nThe majority of participants expressed a preference for the robot explicitly asking for help, a trend that was particularly pronounced among novice operators. This finding suggests that less experienced users prefer that the robot provides clear cues for when assistance is needed. In contrast, participants with higher levels of experience were more likely to intervene and assist the robot without explicit requests. These responses indicate that experienced operators are more proactive and confident in their ability to identify when the robot requires help, leading to more efficient intervention behaviours.\n((a))\n((b))\n((c))\n((d))\nFigure 5:\nMean differences in area covered by groups. The x-axis shows the area covered. The y-axis lists Robot, Novice, Intermediate, and Experienced groups. Horizontal lines indicate confidence intervals, with central dots being mean values.\n5\nDiscussion\nThis study examined how operator expertise influences intervention behaviours, intervention timing, and help-seeking preferences in remote human-robot teaming.\nExpertise influences intervention timing and effectiveness.\nNovices intervened earlier and more consistently, relying on obvious visual cues (e.g., stalling, obstacles) but often overestimated their abilities (Section\n4.3\n). Experts delayed intervention, allowing for robot self-recovery, which enhanced efficiency. These differences are supported by statistically significant results (Table\n1\n).\nHuman intervention generally improves performance—but not always.\nHuman intervention generally improved performance (Scenarios 1, 2, and 4), especially among experienced users. However, Scenario 3 revealed that autonomous navigation outperformed human intervention, suggesting that robot autonomy can sometimes be more effective when well-aligned with task demands (Section\n3.4\n). These results, consistent with Robinson et al.\n[\n?\n]\n, show that our simulator captures the variability of human performance observed in real-world settings while isolating key decision points.\nMost participants preferred robot-initiated help requests\n, with novices relying on explicit cues, while experts preferred self-directed intervention. This suggests that novices need clearer guidance, whereas experts are more confident in assessing intervention needs. Future interfaces should adapt help prompts based on expertise, providing structured guidance for novices while minimizing interruptions for experts. Instead of trying to train all operators to behave like experts, adaptive robots could use real-time behavioural signals to estimate operator expertise and adjust their autonomy and communication accordingly.\nThis study has several limitations that should be considered\nwhen interpreting the results. The expert group was small (\nn\n=\n5\nn=5\n) due to the difficulty of recruiting operators with substantial robotic exploration experience, but we included all available experts to capture their behaviours. The single-intervention-per-scenario design was chosen to control variability and isolate the decision-making process for the first intervention, though it limits the natural expression of strategies. Although the simulated tunnels use realistic maps, they cannot fully capture field uncertainties. Future work will expand the expert pool, allow repeated interventions to observe the evolution of behavioural and mental models, refine expertise measures, and validate findings in field trials to inform adaptive shared autonomy.\n6\nCONCLUSIONS\nThis study examined how operator expertise influences intervention behavior in simulated missions, offering insights to enhance human-robot collaboration. Conducted in a high-fidelity simulator with realistic maps and robots, our findings highlight ways to lower entry barriers for non-roboticists while improving task success. By understanding how operator expertise affects intervention behaviour, we can inform the design of adaptive shared autonomy systems that collaborate effectively with users of diverse expertise levels.\nAcknowledgments\nThis project was funded by CSIRO’s CINTEL FSP program.\nReferences",
    "preview_text": "With increasing levels of robot autonomy, robots are increasingly being supervised by users with varying levels of robotics expertise. As the diversity of the user population increases, it is important to understand how users with different expertise levels approach the supervision task and how this impacts performance of the human-robot team. This exploratory study investigates how operators with varying expertise levels perceive information and make intervention decisions when supervising a remote robot. We conducted a user study (N=27) where participants supervised a robot autonomously exploring four unknown tunnel environments in a simulator, and provided waypoints to intervene when they believed the robot had encountered difficulties. By analyzing the interaction data and questionnaire responses, we identify differing patterns in intervention timing and decision-making strategies across novice, intermediate, and expert users.\n\nInfluence of Operator Expertise on Robot Supervision and Intervention\nYanran Jiang\n1,\n∗\n, Pavan Sikka\n1\n, Leimin Tian\n1\n, Dana Kulić\n1,2\nand Cécile Paris\n1\n1\nData 61, CSIRO,\nAustralia,\n2\nFaculty of Engineering,\nMonash University, Australia\n∗\nyanran.jiang@csiro.au\nAbstract\nAs autonomous robots are increasingly deployed in complex and high-risk environments, they are supervised by users with diverse levels of robotics expertise. As the diversity of the user population increases, it is important to understand how users with different expertise levels approach the supervision task and how this impacts performance of the human-robot team. This exploratory study investigates how operators with varying expertise levels perceive information and make intervention decisions when supervising a remote robot. We conducted a user study (\nN\n=\n27\nN=27\n) where participants supervised a robot autonomously exploring four unknown tunnel environments in a simulator, and provided waypoints to intervene when they believed the robot had encountered difficulties.",
    "is_relevant": false,
    "relevance_score": 0.0,
    "extracted_keywords": [
        "robot supervision",
        "operator expertise",
        "human-robot team",
        "intervention decisions",
        "user study"
    ],
    "one_line_summary": "这篇论文探讨了不同专业水平的操作员在监督远程机器人时的信息感知和干预决策模式，与强化学习、VLA、扩散模型等关键词无关。",
    "detailed_summary": "",
    "qa_pairs": [],
    "is_hidden": false,
    "is_starred": false,
    "flag": true,
    "published_date": "2026-01-21T15:14:23Z",
    "created_at": "2026-01-27T15:53:22.469397",
    "updated_at": "2026-01-27T15:53:22.469404"
}