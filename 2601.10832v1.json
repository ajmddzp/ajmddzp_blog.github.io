{
  "id": "2601.10832v1",
  "title": "IMU-based Real-Time Crutch Gait Phase and Step Detections in Lower-Limb Exoskeletons",
  "authors": [
    "Anis R. Shakkour",
    "David Hexner",
    "Yehuda Bitton",
    "Avishai Sintov"
  ],
  "abstract": "Lower limb exoskeletons and prostheses require precise, real time gait phase and step detections to ensure synchronized motion and user safety. Conventional methods often rely on complex force sensing hardware that introduces control latency. This paper presents a minimalist framework utilizing a single, low cost Inertial-Measurement Unit (IMU) integrated into the crutch hand grip, eliminating the need for mechanical modifications. We propose a five phase classification system, including standard gait phases and a non locomotor auxiliary state, to prevent undesired motion. Three deep learning architectures were benchmarked on both a PC and an embedded system. To improve performance under data constrained conditions, models were augmented with a Finite State Machine (FSM) to enforce biomechanical consistency. The Temporal Convolutional Network (TCN) emerged as the superior architecture, yielding the highest success rates and lowest latency. Notably, the model generalized to a paralyzed user despite being trained exclusively on healthy participants. Achieving a 94% success rate in detecting crutch steps, this system provides a high performance, cost effective solution for real time exoskeleton control.",
  "url": "https://arxiv.org/abs/2601.10832v1",
  "html_url": "https://arxiv.org/html/2601.10832v1",
  "html_content": "IMU-based Real-Time Crutch Gait Phase and Step Detections in Lower-Limb Exoskeletons\nAnis R. Shakkour, David Hexner, Yehuda Bitton and Avishai Sintov\nA. R. Shakkour and A. Sintov are with the School of Mechanical Engineering, Tel-Aviv University, Israel. E-mail: anisshakkour@mail.tau.ac.il; sintov1@tauex.tau.ac.il.D. Hexner is with LifeWard Ltd., Yokneam Ilit, Israel; Y. Bitton is with Binata Ltd. Yokneam Ilit, Israel. This research was supported by the Israel Innovation Authority (Grant No. 77857).\nAbstract\nLower limb exoskeletons and prostheses require precise, real time gait phase and step detections to ensure synchronized motion and user safety. Conventional methods often rely on complex force sensing hardware that introduces control latency. This paper presents a minimalist framework utilizing a single, low cost Inertial-Measurement Unit (IMU) integrated into the crutch hand grip, eliminating the need for mechanical modifications. We propose a five phase classification system, including standard gait phases and a non locomotor auxiliary state, to prevent undesired motion. Three deep learning architectures were benchmarked on both a PC and an embedded system. To improve performance under data constrained conditions, models were augmented with a Finite State Machine (FSM) to enforce biomechanical consistency. The Temporal Convolutional Network (TCN) emerged as the superior architecture, yielding the highest success rates and lowest latency. Notably, the model generalized to a paralyzed user despite being trained exclusively on healthy participants. Achieving a 94% success rate in detecting crutch steps, this system provides a high performance, cost effective solution for real time exoskeleton control.\nI\nIntroduction\nLower-limb exoskeletons are transformative robotic devices that either assist in rehabilitation\n[\n8\n]\nor restore standing and walking ability to individuals with severe mobility impairments, such as those resulting from spinal cord injury\n[\n2\n]\n.\nSimilarly, active lower-limb prostheses enable amputees to restore mobility and achieve a more natural gait\n[\n1\n]\n. These assistive devices are fundamentally designed to enhance user safety, promote smooth and natural motion, and maximize comfort. However, optimal performance is unattainable without a robust and functional gait phase detection method\n[\n19\n]\n. This detection unit is essential, as it provides the device‚Äôs main controller with real-time information about the user‚Äôs current gait phase. By accurately detecting the current phase (e.g., heel strike, swing), the device can produce the corresponding, temporally synchronized motion and actuation functionality. Consequently, integrating a highly accurate and low-latency gait detection strategy is paramount for improving the overall performance, responsiveness, and safety of the control system in the walking device.\nFigure 1:\nA participant walking with the ReWalk\n[\n6\n]\nlower limb exoskeleton and crutches. The right-hand side crutch is equipped with an Inertial Measurement Unit (IMU) for gait phase detection.\nCurrent methods for gait phase detection typically employ various sensor modalities. The detection strategies can be clearly separated based on the location of the sensing hardware. Sensors mounted directly on the robotic device commonly include joint encoders and torque sensors to measure the robot‚Äôs state, and force sensors integrated into the foot sole to detect ground contact\n[\n3\n,\n17\n]\n. While these provide direct kinematic and kinetic feedback, they primarily measure the current device state and do not interact with the user to capture intent\n[\n2\n]\n. This reliance on hindsight data precludes intent recognition, as the system only observes motion after sensing a shift in the body center of mass. Such reactive sensing fails to detect intent, resulting in sluggish coordination that lacks the proactive responsiveness required for natural walking. Furthermore, relying solely on foot sensors can lead to inconsistent performance across varied terrains or for users with atypical gait patterns. A comprehensive, yet challenging, approach involves Electro-Myography (EMG), which detects muscle activation to predict intent, but its real-world utility is limited by electrode placement sensitivity, signal noise, and inter-subject variability\n[\n11\n,\n9\n]\n.\nAn alternative and often more proactive approach utilizes sensors placed on the assistive devices, primarily the crutches, which the user manipulates to express walking intent\n[\n12\n,\n13\n]\n. In addition to assisting in balance, the crutch acts as the primary mechanical interface between the user‚Äôs intention and the ground. Instrumented crutches typically incorporate force sensors to directly quantify the axial load and shear forces exerted by the user onto the crutch, specifically measuring the interaction forces between the crutch tip and the ground\n[\n4\n,\n7\n]\n. An advanced and highly functional approach integrates these kinetic measurements with Inertial Measurement Units (IMUs)\n[\nNarv√°ez2022\n,\n15\n]\n. This sensor fusion provides a comprehensive dataset for accurately modeling the crutch‚Äôs state, providing a crucial predictive window for the exoskeleton controller\n[\n10\n]\n. Crucially, while IMUs are easy to deploy, the viability of relying solely on the crutch‚Äôs inertial data, without any supporting force sensors, for robust, multi-phase gait classification has not yet been thoroughly explored, presenting a significant opportunity for simplification and cost reduction.\nThis gap motivates our work. In this paper, we explore the use of an IMU on a crutch for cost-effective gait phase and step detections. We present a novel, minimalist, and computationally efficient framework for crutch gait detection tailored for real-time exoskeleton control (Figure\n1\n). Our key contribution lies in demonstrating that gait detection can be achieved using signals from a single, low-cost and standard IMU concealed within on the crutch hand grip, completely eliminating the need for force sensors or any mechanical modification to the crutch tip. While the common approach for control systems is to classify the standard four phases of the crutch gait cycle (i.e., stance, take-off, swing and strike\n[\n5\n]\n), a more robust controller requires the addition of a crucial functional phase. We extend the model to a five-phase system by adding the\nAuxiliary\nphase covering any non-gait activities such as standing, drinking, scratching or opening a door. This inclusion is vital for safety, as this phase allows the control system to enter a locked state, preventing undesired motion caused by incidental sensor readings during non-locomotor activities. We consider a temporal-based classification model to achieve accurate and low-latency performance. The resulting methodology offers a high-performance and cost-effective solution to significantly improve human-exoskeleton coordination and responsiveness.\nII\nMethod\nII-A\nSystem\nIn this work, the crutch system is the dedicated interface for the detection of user gait intent, utilizing a standard forearm crutch instrumented with a single, low-cost off-the-shelf IMU. The IMU was integrated within the hand grip of the right hand side crutch as seen in Figure\n2\n. Specifically, the\nz\nz\n-axis is oriented vertically upward, aligned with gravity during standing, the\nx\nx\n-axis is pointed horizontally toward the walking direction and the\ny\ny\n-axis is pointed perpendicular to the user‚Äôs walking direction. This specific alignment ensures that the output signals, such as forward pitch rotation about the\nx\nx\n-axis, directly and naturally correspond to key crutch motions like the swing phase.\nFigure 2:\nThe crutch with an integrated IMU within the hand grip.\nThe IMU sensor provides streaming at 100 Hz including all nine degrees of freedom: tri-axial linear acceleration (\na\nx\na_{x}\n,\na\ny\na_{y}\n,\na\nz\na_{z}\n), tri-axial angular velocity (\nœâ\nx\n\\omega_{x}\n,\nœâ\ny\n\\omega_{y}\n,\nœâ\nz\n\\omega_{z}\n) and tri-axial magnetic field strength (\nŒº\nx\n\\mu_{x}\n,\nŒº\ny\n\\mu_{y}\n,\nŒº\nz\n\\mu_{z}\n). Additionally, the IMU‚Äôs internal sensor fusion engine provides pre-processed orientation outputs in both Euler angles and quaternions, offering flexibility in choosing input features for the classification model. Consequently, a processed measurement vector at time\nt\nt\nis defined by\nùê±\nt\n‚àà\n‚Ñù\n9\n\\mathbf{x}_{t}\\in\\mathbb{R}^{9}\n. This vector is composed of the tri-axial raw linear acceleration, filtered angular velocity and fused orientation angles, represented as\nùê±\nt\n=\n(\na\n~\nx\n,\na\n~\ny\n,\na\n~\nz\n,\nœâ\n~\nx\n,\nœâ\n~\ny\n,\nœâ\n~\nz\n,\nœà\n,\nŒ∏\n,\nœï\n)\nT\n\\mathbf{x}_{t}=(\\tilde{a}_{x},\\tilde{a}_{y},\\tilde{a}_{z},\\tilde{\\omega}_{x},\\tilde{\\omega}_{y},\\tilde{\\omega}_{z},\\psi,\\theta,\\phi)^{T}\n(1)\nwhere\na\n~\nx\n\\tilde{a}_{x}\n,\na\n~\ny\n\\tilde{a}_{y}\nand\na\n~\nz\n\\tilde{a}_{z}\nare the unbiased accelerations acquired by rotating\na\nx\na_{x}\n,\na\ny\na_{y}\nand\na\nz\na_{z}\ninto the global coordinate system using the orientation quaternions. This transformation allows separation of gravity and motion components, producing the global unbiased accelerations. Similarly, velocity\nœâ\n~\nj\n\\tilde{\\omega}_{j}\ndenotes the angular velocity components (\nœâ\nj\n\\omega_{j}\n) after being smoothed by a low-pass filter to ensure a clean and robust signal for the model. Parameters\nœà\n\\psi\n,\nŒ∏\n\\theta\n, and\nœï\n\\phi\nrepresent the Euler angles derived from the IMU‚Äôs internal sensor fusion engine, which integrates gyroscope and magnetometer data. Utilizing these processed Euler angles instead of raw magnetometer signals significantly improves system reliability by mitigating the impact of local electromagnetic interference and magnetic anomalies.\nThe entire system is made portable by a rechargeable Li-Po battery, offering sufficient power for continuous operation for more than 6 hours on a single charge, which is adequate for typical testing or extended daily use sessions. Raw data stream from the IMU is wirelessly transmitted to a nearby computer over Bluetooth Low Energy (BLE), enabling easy data collection. In real-time operation, the data can be transmitted directly to the embedded exoskeleton controller for analysis and inference.\nII-B\nProblem Definition\nThe objective of this research is to formulate a real-time classifier of gait phases which imply about intent during crutch-assisted ambulation, specifically targeting lower-limb exoskeleton control. Given some IMU measurement\nùêà\nt\n\\mathbf{I}_{t}\nacquired at time\nt\nt\n, we aim to classify the user‚Äôs current gait status into one of\nm\n=\n5\nm=5\ndiscrete classes,\n{\nùíû\n1\n,\n‚Ä¶\n,\nùíû\n5\n}\n\\{\\mathcal{C}_{1},\\ldots,\\mathcal{C}_{5}\\}\n. These five functional classes collectively represent the full crutch-assisted gait cycle and all necessary non-locomotor states. The phases are defined as:\nùíû\n1\n\\mathcal{C}_{1}\n:\nStance\n, where the crutch is in full contact with the ground, bearing the user‚Äôs weight and maintaining stability;\nùíû\n2\n\\mathcal{C}_{2}\n:\nTake-off\n, which is the instant the crutch tip lifts off the ground, marking the end of the stance phase and preparation for movement;\nùíû\n3\n\\mathcal{C}_{3}\n:\nSwing\n, where the crutch is off the ground and moving forward toward the next contact point;\nùíû\n4\n\\mathcal{C}_{4}\n:\nStrike\n, the instant the crutch tip makes contact with the ground to initiate the load-bearing stance phase;\nùíû\n5\n\\mathcal{C}_{5}\n:\nAuxiliary\n, representing all non-locomotor states where the user has halted forward motion. This encompasses both active standing, where the user maintains a stable, stationary posture with grounded crutches, and the performance of static tasks unrelated to walking, such as drinking or hand washing. The first four phases are within the standard crutch gait cycle, and their detection enables the synchronization of the walking device based on the user‚Äôs upper-body intent. Phases\nùíû\n5\n\\mathcal{C}_{5}\nis essential to signal the control system to behave accordingly and not initiate undesired gait steps due to incidental crutch movements during non-locomotor activities.\nBeyond instantaneous phase classification, the core problem involves detecting entire completed steps and their corresponding temporal lengths. A step is identified through the successful sequential transition from\nùíû\n1\n\\mathcal{C}_{1}\nto\nùíû\n4\n\\mathcal{C}_{4}\n. By accurately predicting the start and end of these cycles, we can evaluate the system‚Äôs temporal precision, ensuring the exoskeleton mirrors the user‚Äôs actual step duration. Therefore, we aim to design and train a classifier\n‚Ñ±\n‚Äã\n(\nùêà\nt\n)\n\\mathcal{F}(\\mathbf{I}_{t})\nthat accurately outputs the current gait class\nùíû\ni\n\\mathcal{C}_{i}\nin real-time. The system must effectively distinguish between the similar kinematic patterns of the locomotion phases (\nùíû\n1\n\\mathcal{C}_{1}\n‚Äì\nùíû\n4\n\\mathcal{C}_{4}\n), identify critical non-locomotor states (\nùíû\n5\n\\mathcal{C}_{5}\n), and reliably segment entire steps to ensure the high-level control of the exoskeleton is both responsive and temporally accurate.\nII-C\nData Collection\nA dedicated dataset\n‚Ñã\n\\mathcal{H}\nwas collected for training and evaluating the gait phase recognition models. Several human subjects were recruited from two distinct groups to ensure the model‚Äôs generalizability: Healthy able-bodied subjects and an exoskeleton user who rely on the ReWalk device for mobility. To standardize the recordings, all subjects followed a 15 m path, turned, and walked back to the starting point, repeating this cycle until the session was complete. This design ensured each trial introduced natural variability into the dataset, encompassing straight walking, turning, and stopping phases, and incorporating diversity in crutch-assisted locomotion patterns. The subjects were also asked to arbitrary induce the auxiliary task (\nùíû\n5\n\\mathcal{C}_{5}\n) phase during the sessions. While no specific instructions were given to the subjects on how to walk, subjects employed multiple common crutch gait strategies, including Two-Point Gait (where the crutch swing preceded the contralateral leg step), Swing-To Gait (where both crutches were swung forward together, followed by advancing both legs to the level of the crutches), and Swing-Through Gait (where both crutches were swung forward, followed by moving both legs beyond the crutch tips). To maintain a robust and practical training resource, an effort was made to achieve a near-uniform distribution of samples across all five classes.\nFinally, the collected data was pre-processed to include labeled sequences. Sessions were truncated to multiple sequences where each sequence\nùêà\nt\n\\mathbf{I}_{t}\nis represented as a sliding window of length\nh\nh\n. This window aggregates the measurement vectors (\n1\n) over a specific temporal context, providing the model with the necessary dynamics to distinguish between gait phases. The sliding window at time\nt\nt\nis defined as a tensor:\nùêà\nt\n=\n[\nùê±\nt\n‚àí\nh\n+\n1\n,\nùê±\nt\n‚àí\nh\n+\n2\n,\n‚Ä¶\n,\nùê±\nt\n]\n.\n\\mathbf{I}_{t}=[\\mathbf{x}_{t-h+1},\\mathbf{x}_{t-h+2},\\ldots,\\mathbf{x}_{t}].\n(2)\nTensor\nùêà\nt\n‚àà\n‚Ñù\nh\n√ó\n9\n\\mathbf{I}_{t}\\in\\mathbb{R}^{h\\times 9}\nserves as the input for each inference step. This windowing approach allows the models to evaluate not just a static posture, but the kinematic trajectory of the crutch, which is essential for identifying transitional events like Strike or Take-off. Sequence tensor\nùêà\nt\n\\mathbf{I}_{t}\nwas manually labeled with the class\nc\ni\n‚àà\n{\n1\n,\n‚Ä¶\n,\n5\n}\nc_{i}\\in\\{1,\\ldots,5\\}\n. The labeling was performed off-line by an expert observing the cyclic signals and synchronized session videos. Consequently, the resulting training dataset is composed of synchronized, labeled time-series sequences of the form\n‚Ñã\n=\n{\n(\nùêà\ni\n,\nc\ni\n)\n}\ni\n=\n1\nN\n\\mathcal{H}=\\{(\\mathbf{I}_{i},c_{i})\\}_{i=1}^{N}\n, where\nùêà\ni\n\\mathbf{I}_{i}\nis the IMU data sequence\ni\ni\nand\nc\ni\nc_{i}\nis the corresponding gait phase label.\nII-D\nGait Phase Detection Model\nThe final stage of our methodology involves the sequence classification model\n‚Ñ±\n\\mathcal{F}\n, which is tasked with mapping a given IMU time-series feature window\nùêà\nt\n\\mathbf{I}_{t}\nto one of the five required gait phase classes in real-time. Since the system is designed for embedded real-time control where processing overhead and power consumption must be minimized, we prioritized lightweight, resource-efficient models. To identify the model that provides the optimal balance between classification accuracy and minimal inference latency, we performed a comparative benchmark across three low-complexity models: the Long Short-Term Memory (LSTM) network\n[\n20\n]\n, the Temporal Convolutional Network (TCN)\n[\n14\n]\n, and the Transformer\n[\n18\n]\n.\nThe LSTM network is evaluated as the baseline recurrent architecture, inherently designed to capture long-term temporal dependencies within the IMU sequence window. The TCN is selected for its demonstrated efficacy in time-series analysis, employing causal and dilated convolutions to efficiently model long-range temporal context with a large receptive field while benefiting from the parallelization capabilities of convolutions, making it computationally efficient. Finally, the Transformer network, leveraging its powerful self-attention mechanism, is included to assess its ability to identify global dependencies and weigh the importance of different time-steps across the entire input window. Each model was implemented with a consistent input structure receiving the feature tensor, followed by its respective sequence processing core, and culminating in a final dense layer with softmax activation.\nThe softmax activation generates a probability distribution across the five defined gait classes. To refine these raw predictions into a coherent gait trajectory, the decoded phase sequence is integrated with a Finite State Machine (FSM) designed to identify individual crutch steps and enforce biomechanical consistency. This FSM acts as a causal supervisor that monitors for the progression of a single step, specifically tracking the Take-off followed by a subsequent plausible sequence of gait phases. The FSM scheme for the crutch gait cycle is illustrated in Figure\n3\n. By operating casually in time, the FSM can be applied identically to the outputs of the LSTM, TCN or Transformer architectures, ensuring a standardized decoding layer across different model families.\nFigure 3:\nFinite State Machine (FSM) for crutch gait phase refinement and step event detection.\nTo maintain robustness against transient sensor noise or occasional misclassifications, the FSM ignores short, inconsistent phase fragments and segments labeled as auxiliary tasks. Its reliability is further enhanced by an internal step scoring mechanism that accumulates value based on the observation of a valid biomechanical sequence. In an ideal scenario, a complete sequence encompassing\nTake-off\n‚Üí\n\\to\nSwing\n‚Üí\n\\to\nStrike\n‚Üí\n\\to\nStance\nyields a maximal raw score of\n4.0\n4.0\n, while partial but plausible sequences receive proportionally lower scores. This value is subsequently normalized to a range of\n[\n0\n,\n1\n]\n[0,1]\n. A step event is only officially emitted when this normalized score exceeds a predefined threshold\nŒ±\n\\alpha\n, ensuring that the system requires sufficient cumulative evidence before declaring a step. When this threshold is reached, the FSM defines a discrete step interval,\nspanning from the first contributing phase to the final phase. This methodology makes the detection robust to isolated missing phases while preserving high temporal accuracy at the level of the overall step. Furthermore, the same FSM logic is utilized offline to process ground-truth labels, allowing for a direct and rigorous comparison between predicted step timelines and actual user intent during evaluation.\nIII\nExperiments\nTABLE I:\nClassification performance over three models\nModel\nPhase detection - success rate (%)\nStep detection -\nSuccess rate (%)\nRuntime\n(ms)\nw/o FSM\nw/ FSM\nTS1\nTS2\nTotal\nTS1\nTS2\nTotal\nTS1\nTS2\nTotal\nPC\nES\nTCN\n85\n61\n82\n95\n91\n93\n96\n91\n95\n0.98\n¬±\n\\pm\n0.253\n1.9\n¬±\n\\pm\n0.612\nLSTM\n80\n74\n81\n88\n84\n87\n90\n85\n89\n1.3\n¬±\n\\pm\n0.278\n11.7\n¬±\n\\pm\n1.52\nTransformer\n67\n74\n69\n94\n90\n93\n97\n92\n95\n1.1\n¬±\n\\pm\n0.366\n4.3\n¬±\n\\pm\n1.01\nIn this section, we evaluate the proposed approach for crutch-based gait detection and compare between the three models. The data collection and experiments were conducted with the approval of the ethics committee at Tel-Aviv University under application No. 0011588-2.\nHyperparameter tuning was performed using Optuna\n[\n16\n]\n, optimizing the model parameters across multiple configurations.\nIII-A\nDataset\nThe training dataset was compiled from four healthy adult subjects who were instructed to perform crutch-assisted walking using their voluntarily chosen technique without specific gait instructions. Each subject completed an average of four laps on a 15 m straight path, including turning motions, with each lap lasting approximately 40 seconds. Following the hyper-parameter optimization of the pre-processing temporal windows, distinct configurations were established for each model architecture to maximize classification performance: the TCN utilized a window size of\nh\n=\n8\nh=8\nwith a stride of\n2\n2\n, resulting in\nN\n=\n34\n,\n560\nN=34,560\nlabeled sequence samples; the LSTM employed a window size of\nh\n=\n7\nh=7\nwith a stride of\n5\n5\n, yielding\nN\n=\n13\n,\n830\nN=13,830\nsamples; and the Transformer utilized a window size of\nh\n=\n6\nh=6\nwith a stride of\n1\n1\n, producing a dataset of\nN\n=\n69\n,\n140\nN=69,140\nlabeled sequence samples. To evaluate the models‚Äô generalizability across different user profiles, a separate test set was collected from two distinct subjects: Test Subject 1 (TS1), a healthy able-bodied individual who completed six laps, and Test Subject 2 (TS2), an experienced exoskeleton subject with complete lower-limb paralysis who is functionally dependent on the ReWalk device for mobility and completed four laps.\nIII-B\nModels Architectures\nTo identify the architecture providing the optimal balance between classification accuracy and minimal inference latency, we compared between TCN, LSTM and a Transformer. The hyperparameter optimization for all models was performed to identify the configurations that minimize categorical cross-entropy loss. The TCN configuration utilizes two residual blocks with 96 feature channels, a kernel size of 2, and a spatial dropout of 0.255, optimized with a learning rate of\n8.9\n√ó\n10\n‚àí\n4\n8.9\\times 10^{-4}\n, totaling 67,398 trainable parameters. In contrast, the LSTM architecture consists of three bidirectional layers with 64 hidden units per direction, a dropout rate of 0.313, and a learning rate of\n2.5\n√ó\n10\n‚àí\n4\n2.5\\times 10^{-4}\n, totaling 233,734 trainable parameters. For the Transformer model, which contains 201,350 trainable parameters, the embedding maps into a\n128\n128\n-dimensional space followed by two encoder layers, each with two attention heads and a 128-unit feed-forward network.\nTo map the extracted features to gait phase probabilities, all models incorporate a series of dense layers followed by a Softmax activation layer. Specifically, the TCN includes a fully connected layer with 96 units, while the Transformer utilizes a 64-unit dense head. To refine these predictions, an FSM is integrated at the output of all models to enforce biomechanically valid phase sequences. The FSM utilizes an internal normalized score to evaluate the progression of a step; a step is only officially registered if this score exceeds a predefined threshold of\nŒ±\n=\n0.6\n\\alpha=0.6\n, ensuring robustness against transient misclassifications or isolated sensor noise.\nIII-C\nModels Evaluation\nIII-C\n1\nModel Accuracy\nWe first provide a performance comparison between the three classification models with and without including the FSM. Table\nI\npresents the success rate results for phase and step detection over the test data. The results show individual success rates for TS1 and TS2, along with the total rates. First, we observe the phase detection accuracy. The results show a clear benefit of using the FSM, where it is able to significantly improve the detection accuracy of the five classes even for an ill-trained classification model. This is highlighted in the results for all three models, where they provide a rather poor predictions while the FSM significantly leveraged the detection accuracy. This performance discrepancy is elucidated by the confusion matrix in Figure\n4\n. The data reveals a clear classification bias where the models frequently misidentify the auxiliary phase as near-static locomotor phases, such as strike or stance. This suggests that the kinematic signatures of a stationary user performing auxiliary tasks share significant similarities with the grounded phases of active walking. To mitigate this overlap, future work should prioritize the inclusion of a more diverse and extensive auxiliary dataset to better refine the pattern boundaries between stationary activities and active locomotion. Nevertheless, the FSM is able to filter-out the non-locomotor phase and focus on gait phases. All three models demonstrate high accuracy in identifying the five gait phases, with the TCN and Transformer exhibiting a slight advantage in overall success rate.\nFigure 4:\nConfusion matrix for detecting the five crutch gait phases using the TCN and without using the FSM.\nA primary application of the proposed approach is the synchronization of an assistive walking device‚Äôs control cycle with user intent by monitoring crutch kinematics. Table\nI\nalso shows the success rates for detecting entire steps using the FSM. The results demonstrate that the system achieves strong temporal alignment, accurately capturing step occurrence and the specific timing of initiation and termination. A representative segment of this session is visualized in Figure\n5\n. An analysis of missed detections reveals that the majority of classification errors occurred during gait initiation, specifically the first step taken from a static standing position. While the training set included labeled instances of these transitions, the model consistently struggled to recognize them compared to steady state walking cycles. This discrepancy suggests that the kinematic characteristics of the transition from static stance to locomotion differ significantly from those of continuous gait. Furthermore, the training data appears to lack sufficient volume of these first step samples to achieve high fidelity recognition. Consequently, a potential refinement for future iterations should involve adding initiation samples.\nFigure 5:\nReal versus predicted steps of TS2 (exoskeleton user) based on observing crutch gait cycles.\nWhile training datasets were composed exclusively of data from healthy subjects, the performance for TP2 underscores the model high degree of cross domain generalizability. The architecture successfully identified the gait phases of an exoskeleton user with complete lower limb paralysis, demonstrating the potential for zero shot transfer to clinical populations. This can eliminate the need for intensive, patient specific retraining. Nevertheless, while current zero shot transfer is effective, including training data from paralyzed populations in future iterations is expected to further refine decision boundaries and maximize classification accuracy.\nIII-C\n2\nComputational Efficiency\nTable\nI\ndetails the computational runtime benchmarks for the models across two environments: a high-performance PC and an Embedded System (ES) representative of the target hardware for the walking device. The PC setup featured an Intel Core Ultra 7 (2.20 GHz) CPU with 32.0 GB of RAM. To evaluate the practical feasibility of real-time deployment on a walking device, runtimes were also measured on an ES, specifically the NVIDIA Jetson AGX Orin. To establish a baseline for processor-bound performance and simulate power-constrained operating conditions, inference was executed exclusively on the CPU in both instances, with no GPU acceleration utilized. The results highlight the TCN as the most advantageous architecture, as it simultaneously achieves the highest classification fidelity and the lowest inference latency across all tested platforms. Hence, we use the TCN for further analysis.\nIII-C\n3\nData Efficiency\nTo determine the data requirements for the TCN model, we conducted an analysis on the size of the training population. This was performed through a cross-validation procedure where the TCN was iteratively trained using data from a varying number of subjects. For each size, the model was retrained across four unique subject combinations to compute an average success rate of phase and step detection, ensuring the results were not biased by a specific individual‚Äôs gait characteristics. All resulting models were evaluated using the same test data from the two test subjects. As illustrated in Figure\n6\n, the average detection accuracy exhibits a positive correlation with the number of training subjects. However, a significant finding is the impact of the FSM on data efficiency. While the raw model accuracy improves with additional data, the integration of the FSM markedly lowers the data threshold required for effective operation; even with a single training subject, the FSM-augmented model achieves sufficient performance for practical use. Despite this baseline robustness, the results indicate that classification accuracy continues to scale with the inclusion of more diverse data, suggesting that further performance gains can be acquired by training with more subjects.\nFigure 6:\nClassification success rate with regard to the number of subjects included in the training data, evaluated on the test data with the TCN model.\nIV\nConclusions\nThis research validates an approach for gait phase and step detection in lower limb walking devices using a single crutch mounted IMU. By identifying a five phase gait cycle without force sensing hardware, we provide a scalable, cost effective method for human exoskeleton coordination. The TCN emerged as the optimal architecture for embedded deployment, offering superior accuracy and minimal computational runtime. A core finding is the efficacy of the FSM as an augmentation layer, which significantly enhances accuracy and lowers the data threshold, achieving sufficient performance even with a single training subject. Furthermore, the model demonstrated high generalizability by accurately classifying the gait of a paralyzed user despite being trained solely on healthy subjects. This suggests that crutch kinematics provide a universal signature for intent recognition, facilitating clinical deployment without intensive patient specific retraining.\nFuture work should focus on enhancing gait initiation detection by introducing specialized phase labels to capture the unique kinematic transitions from standing to locomotion. In addition, one can aim to implement a high-level control loop that synchronizes leg gait phases with crutch motion, ensuring that mechanical assistance is perfectly phased with user intent. To facilitate this, future work may pursue full real-time embedded integration into a mobile walking device, optimizing the TCN architecture for power-constrained environments. Finally, systematic clinical trials are necessary to quantify objective improvements in gait stability, user experience, and safety compared to baseline exoskeleton operation.\nReferences\n[1]\nM. Asif, M. I. Tiwana, U. S. Khan, W. S. Qureshi, J. Iqbal, N. Rashid, and N. Naseer\n(2021)\nAdvancements, trends and future prospects of lower limb prosthesis\n.\nIEEE Access\n9\n(\n),\npp.¬†85956‚Äì85977\n.\nCited by:\n¬ßI\n.\n[2]\nR. Baud, A. R. Manzoori, A. J. Ijspeert, and M. Bouri\n(2021)\nReview of control strategies for lower-limb exoskeletons to restore gait\n.\nJournal of NeuroEngineering and Rehabilitation\n18\n(\n1\n),\npp.¬†119\n.\nCited by:\n¬ßI\n,\n¬ßI\n.\n[3]\nR. Caldas, M. Mundt, W. Potthast, F. B. de Lima Neto, and B. Markert\n(2017)\nA systematic review of gait analysis methods based on inertial sensors and adaptive algorithms\n.\nGait & Posture\n57\n,\npp.¬†204‚Äì210\n.\nCited by:\n¬ßI\n.\n[4]\nG. Chamorro-Moriana, J. L. Sevillano, and C. Ridao-Fern√°ndez\n(2016)\nA compact forearm crutch based on force sensors for aided gait: reliability and validity\n.\nSensors\n16\n(\n6\n).\nCited by:\n¬ßI\n.\n[5]\nE. Costamagna, S. Thies, L. Kenney, D. Howard, A. Liu, and D. Ogden\n(2017-07)\nA generalisable methodology for stability assessment of walking aid users\n.\nMedical Engineering & Physics\n47\n,\npp.\n.\nCited by:\n¬ßI\n.\n[6]\nA. Esquenazi, M. Talaty, A. Packel, and M. Saulino\n(2012)\nThe rewalk powered exoskeleton to restore ambulatory function to individuals with thoracic-level motor-complete spinal cord injury\n.\nAmerican journal of physical medicine & rehabilitation\n91\n(\n11\n),\npp.¬†911‚Äì921\n.\nCited by:\nFigure 1\n,\nFigure 1\n.\n[7]\nT. A. Fong, J. Alarcon, C. Yang,\net al.\n(2022)\nExploring the utility of crutch force sensors to predict user intent in assistive lower limb exoskeletons\n.\nIn\nInt. Conf. on Rehabilitation Rob.\n,\npp.¬†1‚Äì6\n.\nCited by:\n¬ßI\n.\n[8]\nA. Foroutannia and M. Mohammadian\n(2026)\nA comprehensive survey of lower limb assistive exoskeleton robots: models, dynamics, mechanics, and control\n.\nRob. and Aut. Systems\n195\n,\npp.¬†105232\n.\nCited by:\n¬ßI\n.\n[9]\nB. M. V. Guerra, M. Schmid, S. Sozzi, S. Pizzocaro, A. M. De Nunzio, and S. Ramat\n(2024)\nA recurrent deep network for gait phase identification from EMG signals during exoskeleton-assisted walking\n.\nSensors\n24\n(\n20\n).\nCited by:\n¬ßI\n.\n[10]\nJ. Jung, I. Jang, R. Riener, and H. Park\n(2012)\nWalking intent detection algorithm for paraplegic patients using a robotic exoskeleton walking assistant with crutches\n.\nInternational Journal of Control, Automation and Systems\n10\n,\npp.¬†1169‚Äì1177\n.\nCited by:\n¬ßI\n.\n[11]\nJ. Kim, Y. Kim, and S. Kim\n(2022)\nBiomechanical task-based gait analysis suggests ReWalk gait resembles crutch gait\n.\nApplied Sciences\n12\n(\n24\n).\nCited by:\n¬ßI\n.\n[12]\nM. Lancini, M. Serpelloni, S. Pasinetti, and E. Guanziroli\n(2016)\nHealthcare sensor system exploiting instrumented crutches for force measurement during assisted gait of exoskeleton users\n.\nIEEE Sensors Journal\n16\n(\n23\n),\npp.¬†8228‚Äì8237\n.\nCited by:\n¬ßI\n.\n[13]\nH. Li, H. Yu, Y. Chen, Q. Du, D. Wang, and Q. Meng\n(2021)\nDesign of a crutch-exoskeleton assisted gait for reducing upper extremity loads\n.\nMechatronics\n80\n,\npp.¬†102680\n.\nExternal Links:\nISSN 0957-4158\nCited by:\n¬ßI\n.\n[14]\nA. Mizrahi and A. Sintov\n(2024)\nTeleFMG: a wearable force-myography device for natural teleoperation of multi-finger robotic hands\n.\nIEEE Robotics and Automation Letters\n9\n(\n3\n),\npp.¬†2933‚Äì2940\n.\nCited by:\n¬ß\nII-D\n.\n[15]\nM. Narvaez Dorado, M. Salazar, and J. Aranda\n(2024)\nAssessment of gait patterns during crutch assisted gait through spatial and temporal analysis\n.\nSensors\n24\n(\n11\n).\nCited by:\n¬ßI\n.\n[16]\nY. Ozaki, S. Watanabe, and T. Yanase\n(2025)\nOptunaHub: a platform for black-box optimization\n.\narXiv preprint arXiv:2510.02798\n.\nCited by:\n¬ßIII\n.\n[17]\nJ. S. Park, C. M. Lee, S. Koo, and C. H. Kim\n(2020)\nGait phase detection using force sensing resistors\n.\nIEEE Sensors Journal\n20\n(\n12\n),\npp.¬†6516‚Äì6523\n.\nCited by:\n¬ßI\n.\n[18]\nA. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, ≈Å. Kaiser, and I. Polosukhin\n(2017)\nAttention is all you need\n.\nIn\nInt. Conf. on Neural Information Processing Systems\n,\npp.¬†6000‚Äì6010\n.\nExternal Links:\nISBN 9781510860964\nCited by:\n¬ß\nII-D\n.\n[19]\nH. Vu, D. Dong, H. Cao,\net al.\n(2020)\nA review of gait phase detection algorithms for lower-limb prostheses and exoskeletons\n.\nSensors\n20\n(\n14\n),\npp.¬†3972\n.\nCited by:\n¬ßI\n.\n[20]\nY. Yu, X. Si, C. Hu, and J. Zhang\n(2019)\nA review of recurrent neural networks: LSTM cells and network architectures\n.\nNeural Computation\n31\n(\n7\n),\npp.¬†1235‚Äì1270\n.\nCited by:\n¬ß\nII-D\n.",
  "preview_text": "Lower limb exoskeletons and prostheses require precise, real time gait phase and step detections to ensure synchronized motion and user safety. Conventional methods often rely on complex force sensing hardware that introduces control latency. This paper presents a minimalist framework utilizing a single, low cost Inertial-Measurement Unit (IMU) integrated into the crutch hand grip, eliminating the need for mechanical modifications. We propose a five phase classification system, including standard gait phases and a non locomotor auxiliary state, to prevent undesired motion. Three deep learning architectures were benchmarked on both a PC and an embedded system. To improve performance under data constrained conditions, models were augmented with a Finite State Machine (FSM) to enforce biomechanical consistency. The Temporal Convolutional Network (TCN) emerged as the superior architecture, yielding the highest success rates and lowest latency. Notably, the model generalized to a paralyzed user despite being trained exclusively on healthy participants. Achieving a 94% success rate in detecting crutch steps, this system provides a high performance, cost effective solution for real time exoskeleton control.\n\nIMU-based Real-Time Crutch Gait Phase and Step Detections in Lower-Limb Exoskeletons\nAnis R. Shakkour, David Hexner, Yehuda Bitton and Avishai Sintov\nA. R. Shakkour and A. Sintov are with the School of Mechanical Engineering, Tel-Aviv University, Israel. E-mail: anisshakkour@mail.tau.ac.il; sintov1@tauex.tau.ac.il.D. Hexner is with LifeWard Ltd., Yokneam Ilit, Israel; Y. Bitton is with Binata Ltd. Yokneam Ilit, Israel. This research was supported by the Israel Innovation Authority (Grant No. 77857).\nAbstract\nLower limb exoskeletons and prostheses require precise, real time gait phase and step detections to ensure synchronized motion and user safety. Conventional methods often rely on complex force sensing hardware that introduces control latency. This paper presents a ",
  "is_relevant": false,
  "relevance_score": 1.0,
  "extracted_keywords": [
    "IMU",
    "gait phase detection",
    "exoskeleton",
    "real-time",
    "deep learning",
    "TCN",
    "Finite State Machine"
  ],
  "one_line_summary": "ËØ•ËÆ∫ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éIMUÁöÑÂÆûÊó∂ÊãêÊùñÊ≠•ÊÄÅÁõ∏‰ΩçÂíåÊ≠•ÊÄÅÊ£ÄÊµãÊñπÊ≥ïÔºåÁî®‰∫é‰∏ãËÇ¢Â§ñÈ™®È™ºÊéßÂà∂Ôºå‰∏çÊ∂âÂèäÂº∫ÂåñÂ≠¶‰π†„ÄÅVLA„ÄÅÊâ©Êï£Ê®°Âûã„ÄÅFlow Matching„ÄÅÂÖ®Ë∫´ÊéßÂà∂ÊàñVLM„ÄÇ",
  "detailed_summary": "",
  "qa_pairs": [],
  "is_hidden": false,
  "is_starred": false,
  "flag": "",
  "published_date": "2026-01-15T20:07:54Z",
  "created_at": "2026-01-20T17:49:57.827249",
  "updated_at": "2026-01-20T17:49:57.827260"
}