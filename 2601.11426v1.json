{
    "id": "2601.11426v1",
    "title": "Learning-Based Shrinking Disturbance-Invariant Tubes for State- and Input-Dependent Uncertainty",
    "authors": [
        "Abdelrahman Ramadan",
        "Sidney Givigi"
    ],
    "abstract": "æˆ‘ä»¬å¼€å‘äº†ä¸€ç§åŸºäºå­¦ä¹ çš„æ¡†æ¶ï¼Œç”¨äºåœ¨çŠ¶æ€å’Œè¾“å…¥ç›¸å…³çš„ä¸ç¡®å®šæ€§ä¸‹æ„å»ºæ”¶ç¼©å‹æ‰°åŠ¨ä¸å˜ç®¡ï¼Œæ—¨åœ¨ä½œä¸ºç®¡æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆMPCï¼‰çš„åŸºç¡€æ¨¡å—ï¼Œå¹¶é€šè¿‡ä¸€ä¸ªæå‡çš„ã€ä¿åºï¼ˆä¿æŒé¡ºåºï¼‰çš„ä¸åŠ¨ç‚¹æ˜ å°„æ¥ç¡®ä¿å®‰å…¨æ€§ã€‚é«˜æ–¯è¿‡ç¨‹ï¼ˆGPï¼‰åéªŒè¢«è½¬åŒ–ä¸º$(1-Î±)$å¯ä¿¡æ¤­çƒï¼Œè¿›è€Œé€šè¿‡ç¡®å®šæ€§é›†åˆæ“ä½œå¾—åˆ°å¤šé¢ä½“å¤–é›†ã€‚æˆ‘ä»¬é‡‡ç”¨åŒæ—¶é—´å°ºåº¦æ–¹æ¡ˆï¼Œå°†å­¦ä¹ é˜¶æ®µï¼ˆå…¶ä¸­è¿™äº›å¤šé¢ä½“ä¿æŒå›ºå®šï¼‰ä¸ä¸€ä¸ªç”±å¤–è‡³å†…çš„å†…éƒ¨è¿­ä»£åˆ†ç¦»ï¼Œè¯¥è¿­ä»£æ”¶æ•›äºä¸€ä¸ªç´§è‡´ä¸åŠ¨ç‚¹$Z^\\star\\!\\subseteq\\!\\mathcal G$ï¼›å…¶çŠ¶æ€æŠ•å½±å¯¹äºè¢«æ§å¯¹è±¡æ˜¯é²æ£’æ­£ä¸å˜çš„ã€‚éšç€æ•°æ®ç§¯ç´¯ï¼Œæ‰°åŠ¨å¤šé¢ä½“é€æ¸æ”¶ç´§ï¼Œç›¸å…³ç®¡é›†åˆå•è°ƒåµŒå¥—ï¼Œä»è€Œè§£å†³äº†å¾…éªŒè¯é›†åˆä¸æ‰°åŠ¨æ¨¡å‹ä¹‹é—´çš„å¾ªç¯ä¾èµ–é—®é¢˜ï¼ŒåŒæ—¶ä¿æŒç¡¬çº¦æŸä¸å˜ã€‚é€šè¿‡åŒç§¯åˆ†å™¨æ¡ˆä¾‹ç ”ç©¶ï¼Œå±•ç¤ºäº†åœ¨æ•°æ®ä¸°å¯ŒåŒºåŸŸä¸­ç®¡æˆªé¢æ”¶ç¼©çš„åŒæ—¶ä¿æŒä¸å˜æ€§çš„ç‰¹æ€§ã€‚",
    "url": "https://arxiv.org/abs/2601.11426v1",
    "html_url": "https://arxiv.org/html/2601.11426v1",
    "html_content": "Learning-Based Shrinking Disturbance-Invariant Tubes for State- and Input-Dependent Uncertainty\nAbdelrahman Ramadan\n\\IEEEmembership\nGraduate Student Member, IEEE\n1\nSidney Givigi\n\\IEEEmembership\nSenior Member, IEEE\n2\n1\nA. Ramadan is with Electrical and Computer Engineering (ECE), Smith Engineering and with Ingenuity Labs Research Institute, Queenâ€™s University, Kingston, ON K7L 3N6 Canada, 20amr3@queensu.ca\n2\nS. Givigi is with the School of Computing and with Ingenuity Labs Research Institute, Queenâ€™s University, Kingston, ON K7L 3N6 Canada, sidney.givigi@queensu.ca\nAbstract\nWe develop a learning-based framework for constructing shrinking disturbance-invariant tubes under state- and input-dependent uncertainty, intended as a building block for tube Model Predictive Control (MPC), and certify safety via a lifted,\nisotone\n(order-preserving) fixed-point map. Gaussian Process (GP) posteriors become\n(\n1\nâˆ’\nÎ±\n)\n(1-\\alpha)\ncredible ellipsoids, then polytopic outer sets for deterministic set operations. A two-time-scale scheme separates\nlearning epochs\n, where these polytopes are frozen, from an inner, outside-in iteration that converges to a compact fixed point\nZ\nâ‹†\nâŠ†\nğ’¢\nZ^{\\star}\\!\\subseteq\\!\\mathcal{G}\n; its state projection is RPI for the plant. As data accumulate, disturbance polytopes tighten, and the associated tubes nest monotonically, resolving the circular dependence between the set to be verified and the disturbance model while preserving hard constraints. A double-integrator study illustrates shrinking tube cross-sections in data-rich regions while maintaining invariance.\nkeywords:\nData-driven control, set invariance, MPC.\n1\nIntroduction\nRobust Model Predictive Control (MPC) fundamentally relies on set-theoretic invariance to guaranty safety. Classical results provide disturbance-invariant and Robust Positively Invariant (RPI) sets, as well as practical computation for\nfixed\n, state-independent bounds\n[\n2\n,\n8\n]\n. While these constructions are mature, they rely on worst-case bounds, and are therefore conservative. To reduce this conservatism, tube MPC has evolved to\nstate-dependent\ncross-sections that adapt to local state disturbance characteristics\n[\n4\n,\n15\n]\n, to formulations that capture stateâ€“input dependent effects in practice\n[\n9\n]\n, and to parametric RPI sets that represent input-scaled uncertainty\n[\n3\n]\n. Recent work improves computational tooling for state-/input-dependent invariance\n[\n17\n]\n.\nIn parallel, learning-based MPC approaches have been gaining a lot of traction, particularly those based on Gaussian Processes (GPs) that model unknown dynamics and infer residual disturbances from data. GPs provide nonparametric posteriors over model mismatch\n[\n14\n]\n; GPâ€“MPC has leveraged these posteriors for safe exploration\n[\n7\n]\n, to translate confidence sets into constraint tightenings\n[\n6\n]\n, and to develop numerically tractable controllers\n[\n12\n]\n. Extensions consider distributionally robust treatments\n[\n10\n]\nand adaptive/online updates\n[\n1\n]\n. However, most GPâ€“MPC approaches reason via chance constraints or tightenings: they do not deliver an invariant-set synthesis that\n(i)\ntreats joint\n(\nx\n,\nu\n)\n(x,u)\n-dependent,\nlearned\ndisturbance sets and\n(ii)\nyields tubes that nest monotonically across learning epochs with explicit control of representation complexity. Relatedly, while reachability for LTI systems with moving (state- and input-dependent) disturbance sets is well recognized\n[\n13\n]\n, available relaxations (e.g., state-/input-dependent tubes and tools\n[\n4\n,\n17\n]\n) do not offer a convergent invariant-set iteration beyond low dimensionâ€”precisely the gap we target.\nMotivation for state and input dependence.\nMany ubiquitous effects scale with\nboth\nstate and input: aerodynamic drag and lift vary with velocity (and angle), actuator efficiency and rate limits scale with the commanded input, and friction/contact forces depend on pose and normal load. A single worst-case bound is thus overly conservative; locally sized, state-/input-dependent sets tighten where data are informative.\nFollowing the work in\n[\n13\n]\n, other works show continued relevance through state-dependent tubes\n[\n15\n]\n, input-scaled/parametric RPI sets\n[\n3\n]\n. We follow this line but replace hard-specified dependence with\nlearned\n(\nx\n,\nu\n)\n(x,u)\n-dependent bounds.\nIn line with GPâ€“MPC practice, we adopt an LTI nominal model and learn the residual with a GP\n[\n7\n,\n6\n]\n.\nHowever, extending the state- and input-dependent invariant-set computation to fully non-linear plants would require non-convex reachable-set propagation or differential-inclusion machinery with stronger regularity and substantially higher computational load. We leave this for future work (LPV/local-linear variants fit naturally into our pipeline).\nNovelty in context.\nRelative to state- and input-dependent tubes, invariance tools\n[\n4\n,\n15\n,\n9\n,\n3\n]\nand GPâ€“MPC tightenings\n[\n7\n,\n6\n,\n12\n,\n11\n,\n18\n,\n1\n]\n, we:\n(i)\nwrap GP posteriors into polytopic\n(\n1\nâˆ’\nÎ±\n)\n(1-\\alpha)\nconfidence sets that are frozen per epoch to avoid circularity;\n(ii)\nlift the plant into a fixed-graph space and show a monotone outsideâ€“in iteration whose state projection yields RPI tubes; and\n(iii)\ntreat scalability via support-function approximations and anchor grids that bound facet growth, ensuring tubes nest as data contract the learned bounds. This complements GPâ€“MPC: we certify safety by invariant sets under learned\n(\nx\n,\nu\n)\n(x,u)\n-dependent uncertainty rather than solely by chance-constrained tightenings.\nThis letter is organized as follows: Section\n2\ndevelops our approach for RPI sets computation under learned state- and input-dependent disturbances. Section\n3\npresents our control synthesis. Sections\n4\nand\n5\npresent simulation results and conclusions respectively.\n2\nRPI Computation under Learned State- and Input-Dependent Disturbances\nThe computation of RPI sets for LTI systems with state- and input-dependent uncertain unmodeled dynamics (henceforth referred to as â€œ\ndisturbances\nâ€) represents a fundamental challenge in safe autonomy as traditional robust control methods assume fixed, state-independent disturbance sets.\nIn this section, we consider RPI sets for disturbances that depend on the system state and input.\n2.1\nState- and Input-Dependent Disturbances\nLet us consider a general discrete-time LTI system with state- and input-dependent disturbances:\nğ±\nâ€‹\n(\nk\n+\n1\n)\n=\nğ€ğ±\nâ€‹\n(\nk\n)\n+\nğğ®\nâ€‹\n(\nk\n)\n+\nğ°\nâ€‹\n(\nğ±\nâ€‹\n(\nk\n)\n,\nğ®\nâ€‹\n(\nk\n)\n)\n,\n\\mathbf{x}(k+1)=\\mathbf{A}\\mathbf{x}(k)+\\mathbf{B}\\mathbf{u}(k)+\\mathbf{w}(\\mathbf{x}(k),\\mathbf{u}(k)),\n(1)\nwhere\nğ±\nâ€‹\n(\nk\n)\nâˆˆ\nğ•\nâŠ†\nâ„\nn\n\\mathbf{x}(k)\\in\\mathbb{X}\\subseteq\\mathbb{R}^{n}\nis the system state,\nğ®\nâ€‹\n(\nk\n)\nâˆˆ\nğ•Œ\nâŠ†\nâ„\nm\n\\mathbf{u}(k)\\in\\mathbb{U}\\subseteq\\mathbb{R}^{m}\nis the control input, with\nğ•\n\\mathbb{X}\nand\nğ•Œ\n\\mathbb{U}\nbeing compact convex constraint sets,\nğ€\nâˆˆ\nâ„\nn\nÃ—\nn\n\\mathbf{A}\\in\\mathbb{R}^{n\\times n}\nand\nğ\nâˆˆ\nâ„\nn\nÃ—\nm\n\\mathbf{B}\\in\\mathbb{R}^{n\\times m}\nare the known system matrices, and\nğ°\nâ€‹\n(\nğ±\n,\nğ®\n)\nâˆˆ\nâ„\nn\n\\mathbf{w}(\\mathbf{x},\\mathbf{u})\\in\\mathbb{R}^{n}\nrepresents the state- and input-dependent disturbance\n[\n13\n]\n.\nThe component\nğ°\nâ€‹\n(\nğ±\n,\nğ®\n)\n\\mathbf{w}(\\mathbf{x},\\mathbf{u})\nintroduces coupling between the state trajectory and the command input in a stochastic fashion. Since the true disturbance function\nğ°\nâ€‹\n(\nğ±\n,\nğ®\n)\n\\mathbf{w}(\\mathbf{x},\\mathbf{u})\nis unknown, we employ a data-driven approach to learn this mapping from observed system behavior. The disturbance uncertainty set will be specified in Section\n2.2\nfrom the GP posterior (mean and covariance) at\n(\nğ±\n,\nğ®\n)\n(\\mathbf{x},\\mathbf{u})\n, where\nğ\n^\nğ°\nâ€‹\n(\nğ±\n,\nğ®\n)\n\\hat{\\bm{\\mu}}_{\\mathbf{w}}(\\mathbf{x},\\mathbf{u})\nand\nğšº\n^\nğ°\nâ€‹\n(\nğ±\n,\nğ®\n)\n\\hat{\\bm{\\Sigma}}_{\\mathbf{w}}(\\mathbf{x},\\mathbf{u})\nare data-driven estimates of the disturbance mean and covariance at state-input pair\n(\nğ±\n,\nğ®\n)\n(\\mathbf{x},\\mathbf{u})\n, and\nÎ±\n\\alpha\ncontrols the confidence level of the uncertainty set.\n2.2\nLearning-Based Disturbance Modeling\nWe employ GPs to learn the unknown state- and input-dependent disturbance mapping\nğ°\nâ€‹\n(\nğ±\n,\nğ®\n)\n\\mathbf{w}(\\mathbf{x},\\mathbf{u})\nfrom observed system trajectories. GPs provide a framework for uncertainty quantification, yielding posterior distributions that naturally capture both aleatoric uncertainty (measurement noise) and epistemic uncertainty (model uncertainty). This enables adaptive confidence bounds that shrink in data-rich regions while maintaining conservative estimates in unexplored areas, a property essential for our shrinking tube MPC framework.\nWe begin by collecting system trajectory data to construct the disturbance dataset.\nData Collection:\nUsing system trajectories, we compute the disturbance at each time step as the model mismatch:\nğ°\n(\nj\n)\n=\nğ±\n(\nj\n+\n1\n)\nâˆ’\nğ€ğ±\n(\nj\n)\nâˆ’\nğğ®\n(\nj\n)\n,\nj\n=\n1\n,\nâ€¦\n,\nN\ndata\n.\n\\mathbf{w}^{(j)}=\\mathbf{x}^{(j+1)}-\\mathbf{A}\\mathbf{x}^{(j)}-\\mathbf{B}\\mathbf{u}^{(j)},\\quad j=1,\\ldots,N_{\\mathrm{data}}.\n(2)\nIf we define\nğ³\n=\n(\nğ±\n,\nğ®\n)\n\\mathbf{z}=(\\mathbf{x},\\mathbf{u})\n, this yields a dataset\nğ’Ÿ\n=\n{\n(\nğ³\n(\nj\n)\n,\nğ°\n(\nj\n)\n)\n}\nj\n=\n1\nN\ndata\n\\mathcal{D}=\\{(\\mathbf{z}^{(j)},\\mathbf{w}^{(j)})\\}_{j=1}^{N_{\\mathrm{data}}}\nof state-input-disturbance triplets.\nGP Model Structure:\nWe model each component of the disturbance vector independently to maintain computational tractability:\nw\ni\nâ€‹\n(\nğ±\n,\nğ®\n)\nâˆ¼\nğ’¢\nâ€‹\nğ’«\nâ€‹\n(\n0\n,\nk\ni\nâ€‹\n(\n(\nğ±\n,\nğ®\n)\n,\n(\nğ±\nâ€²\n,\nğ®\nâ€²\n)\n)\n)\n,\ni\n=\n1\n,\nâ€¦\n,\nn\nw_{i}(\\mathbf{x},\\mathbf{u})\\sim\\mathcal{GP}\\bigl(0,k_{i}((\\mathbf{x},\\mathbf{u}),(\\mathbf{x}^{\\prime},\\mathbf{u}^{\\prime}))\\bigr),\\quad i=1,\\ldots,n\nwhere\nğ’¢\nâ€‹\nğ’«\nâ€‹\n(\nÎ¼\nâ€‹\n(\nâ‹…\n)\n,\nk\nâ€‹\n(\nâ‹…\n,\nâ‹…\n)\n)\n\\mathcal{GP}(\\mu(\\cdot),k(\\cdot,\\cdot))\ndenotes a Gaussian Process with mean function\nÎ¼\nâ€‹\n(\nâ‹…\n)\n\\mu(\\cdot)\nand covariance function\nk\nâ€‹\n(\nâ‹…\n,\nâ‹…\n)\nk(\\cdot,\\cdot)\n, with\nk\ni\nâ€‹\n(\nâ‹…\n,\nâ‹…\n)\nk_{i}(\\cdot,\\cdot)\nas the covariance kernel for the\ni\ni\n-th component.\nAssumption 1\n(Component Independence)\n.\nThe disturbance components are conditionally independent given the state-input pair, i.e.,\nCov\nâ€‹\n[\nğ°\ni\nâ€‹\n(\nğ±\n,\nğ®\n)\n,\nğ°\nj\nâ€‹\n(\nğ±\n,\nğ®\n)\n]\n=\n0\n\\text{Cov}[\\mathbf{w}_{i}(\\mathbf{x},\\mathbf{u}),\\mathbf{w}_{j}(\\mathbf{x},\\mathbf{u})]=0\nfor\ni\nâ‰ \nj\ni\\neq j\n.\nThis assumption simplifies computation while often providing reasonable approximations for many physical systems where coupling between disturbance components is weak.\nKernel Function:\nFor each disturbance component\nw\ni\nw_{i}\nwe use the product kernel â€œRBF\nÃ—\n\\times\nExpSineSquaredâ€ with white noise, written concisely as\nk\ni\nâ€‹\n(\n(\nğ±\n,\nğ®\n,\nt\n)\n,\n(\nğ±\nâ€²\n,\nğ®\nâ€²\n,\nt\nâ€²\n)\n)\n=\nÏƒ\nf\n,\ni\n2\nâ€‹\nk\nSE\nâ€‹\n(\nğ³\n,\nğ³\nâ€²\n;\nâ„“\ni\n)\nâ€‹\nk\nPER\nâ€‹\n(\nt\n,\nt\nâ€²\n;\np\ni\n,\nâ„“\np\n,\ni\n)\n+\nÏƒ\nn\n,\ni\n2\nâ€‹\nÎ´\n(\nğ±\n,\nğ®\n,\nt\n)\n,\n(\nğ±\nâ€²\n,\nğ®\nâ€²\n,\nt\nâ€²\n)\nk_{i}\\big((\\mathbf{x},\\mathbf{u},t),(\\mathbf{x}^{\\prime},\\mathbf{u}^{\\prime},t^{\\prime})\\big)=\\sigma_{f,i}^{2}\\,k_{\\mathrm{SE}}(\\mathbf{z},\\mathbf{z}^{\\prime};\\ell_{i})\\,k_{\\mathrm{PER}}(t,t^{\\prime};p_{i},\\ell_{p,i})+\\sigma_{n,i}^{2}\\,\\delta_{(\\mathbf{x},\\mathbf{u},t),(\\mathbf{x}^{\\prime},\\mathbf{u}^{\\prime},t^{\\prime})}\n,\nwhere\nğ³\n=\n[\nğ±\nâŠ¤\n,\nğ®\nâŠ¤\n]\nâŠ¤\n\\mathbf{z}=[\\mathbf{x}^{\\top},\\mathbf{u}^{\\top}]^{\\top}\n,\nk\nSE\nâ€‹\n(\nğ³\n,\nğ³\nâ€²\n;\nâ„“\ni\n)\n=\nexp\nâ¡\n(\nâˆ’\nâ€–\nğ³\nâˆ’\nğ³\nâ€²\nâ€–\n2\n/\n(\n2\nâ€‹\nâ„“\ni\n2\n)\n)\nk_{\\mathrm{SE}}(\\mathbf{z},\\mathbf{z}^{\\prime};\\ell_{i})=\\exp(-\\|\\mathbf{z}-\\mathbf{z}^{\\prime}\\|^{2}/(2\\ell_{i}^{2}))\nis the squaredâ€“exponential (RBF) over\n(\nğ±\n,\nğ®\n)\n(\\mathbf{x},\\mathbf{u})\n,\nk\nPER\nâ€‹\n(\nt\n,\nt\nâ€²\n;\np\ni\n,\nâ„“\np\n,\ni\n)\n=\nexp\nâ¡\n(\nâˆ’\n2\nâ€‹\nsin\n2\nâ¡\n(\nÏ€\nâ€‹\n(\nt\nâˆ’\nt\nâ€²\n)\n/\np\ni\n)\n/\nâ„“\np\n,\ni\n2\n)\nk_{\\mathrm{PER}}(t,t^{\\prime};p_{i},\\ell_{p,i})=\\exp\\!\\big(-2\\sin^{2}(\\pi(t-t^{\\prime})/p_{i})/\\ell_{p,i}^{2}\\big)\nis the ExpSineSquared factor on the scalar periodic feature\nt\nt\n,\nÏƒ\nf\n,\ni\n2\n\\sigma_{f,i}^{2}\nis the signal variance,\nâ„“\ni\n\\ell_{i}\nthe isotropic lengthâ€“scale on\n(\nğ±\n,\nğ®\n)\n(\\mathbf{x},\\mathbf{u})\n,\np\ni\np_{i}\nthe period,\nâ„“\np\n,\ni\n\\ell_{p,i}\nits smoothness scale,\nÏƒ\nn\n,\ni\n2\n\\sigma_{n,i}^{2}\nthe i.i.d. whiteâ€“noise variance, and\nÎ´\nâ‹…\n,\nâ‹…\n\\delta_{\\cdot,\\cdot}\nthe Kronecker delta.\nFrom Data to GP Model:\nGiven observed trajectories, we compute disturbances as inÂ (\n2\n),\nyielding the dataset\nğ’Ÿ\n=\n{\n(\nğ±\n(\nj\n)\n,\nğ®\n(\nj\n)\n,\nğ°\n(\nj\n)\n)\n}\nj\n=\n1\nN\ndata\n\\mathcal{D}=\\{(\\mathbf{x}^{(j)},\\mathbf{u}^{(j)},\\mathbf{w}^{(j)})\\}_{j=1}^{N_{\\mathrm{data}}}\n.\nWe model each disturbance component independently as\nw\ni\nâ€‹\n(\nğ±\n,\nğ®\n)\nâˆ¼\nğ’¢\nâ€‹\nğ’«\nâ€‹\n(\n0\n,\nk\ni\n)\nw_{i}(\\mathbf{x},\\mathbf{u})\\sim\\mathcal{GP}(0,k_{i})\n, resulting in posterior mean\nğ\n^\nğ°\nâ€‹\n(\nğ±\n,\nğ®\n)\n:\nğ•\nÃ—\nğ•Œ\nâ†’\nâ„\nn\n\\hat{\\bm{\\mu}}_{\\mathbf{w}}(\\mathbf{x},\\mathbf{u}):\\mathbb{X}\\times\\mathbb{U}\\rightarrow\\mathbb{R}^{n}\nwhere each component\ni\ni\nis\nÎ¼\n^\nw\n,\ni\nâ€‹\n(\nğ³\n)\n=\nğ¤\ni\nâ€‹\n(\nğ³\n,\nZ\n)\nâŠ¤\nâ€‹\n(\nğŠ\ni\n+\nÏƒ\nn\n,\ni\n2\nâ€‹\nğˆ\n)\nâˆ’\n1\nâ€‹\nğ°\ni\n,\n\\hat{\\mu}_{w,i}(\\mathbf{z})=\\mathbf{k}_{i}(\\mathbf{z},Z)^{\\top}\\bigl(\\mathbf{K}_{i}+\\sigma^{2}_{n,i}\\mathbf{I}\\bigr)^{-1}\\mathbf{w}_{i},\nwhere\nZ\n=\n{\nğ³\n(\nj\n)\n}\nj\n=\n1\nN\ndata\n,\nğ°\ni\n=\n[\nw\ni\n(\n1\n)\n,\nâ€¦\n,\nw\ni\n(\nN\ndata\n)\n]\nâŠ¤\n,\nğ¤\ni\nâ€‹\n(\nğ³\n,\nZ\n)\n=\n[\nk\ni\nâ€‹\n(\nğ³\n,\nğ³\n(\n1\n)\n)\n,\nâ€¦\n,\nk\ni\nâ€‹\n(\nğ³\n,\nğ³\n(\nN\ndata\n)\n)\n]\nâŠ¤\nZ=\\{\\mathbf{z}^{(j)}\\}_{j=1}^{N_{\\mathrm{data}}},\\quad\\mathbf{w}_{i}=[w_{i}^{(1)},\\dots,w_{i}^{(N_{\\mathrm{data}})}]^{\\top},\\ \\mathbf{k}_{i}(\\mathbf{z},Z)=[k_{i}(\\mathbf{z},\\mathbf{z}^{(1)}),\\dots,k_{i}(\\mathbf{z},\\mathbf{z}^{(N_{\\mathrm{data}})})]^{\\top}\nand\nğŠ\ni\n\\mathbf{K}_{i}\nis the Gram matrix with entries\n[\nğŠ\ni\n]\np\nâ€‹\nq\n=\nk\ni\nâ€‹\n(\nğ³\n(\np\n)\n,\nğ³\n(\nq\n)\n)\n,\n[\\mathbf{K}_{i}]_{pq}=k_{i}(\\mathbf{z}^{(p)},\\mathbf{z}^{(q)}),\nand the (diagonal) covariance is\nğšº\n^\nğ°\nâ€‹\n(\nğ±\n,\nğ®\n)\n=\ndiag\nâ¡\n(\nğˆ\n^\nğ°\n,\n1\n2\nâ€‹\n(\nğ±\n,\nğ®\n)\n,\nâ€¦\n,\nğˆ\n^\nğ°\n,\nn\n2\nâ€‹\n(\nğ±\n,\nğ®\n)\n)\n\\hat{\\bm{\\Sigma}}_{\\mathbf{w}}(\\mathbf{x},\\mathbf{u})=\\operatorname{diag}(\\hat{\\bm{\\sigma}}_{\\mathbf{w},1}^{2}(\\mathbf{x},\\mathbf{u}),\\ldots,\\hat{\\bm{\\sigma}}_{\\mathbf{w},n}^{2}(\\mathbf{x},\\mathbf{u}))\nat any query point\n(\nğ±\n,\nğ®\n)\n(\\mathbf{x},\\mathbf{u})\n.\nDeterministic abstraction:\nRather than propagating GP uncertainty via chance constraints, we wrap GP posteriors in deterministic confidence sets\n[\n5\n]\n.\nWe distinguish three uncertainty types:\n(i)\nstateâ€“independent aleatoric\n(fixed noise law),\n(ii)\nstateâ€“dependent epistemic\n(unknown deterministic\ng\nâ€‹\n(\nğ±\n,\nğ®\n)\ng(\\mathbf{x},\\mathbf{u})\n), and\n(iii)\nstateâ€“dependent aleatoric\n(noise law\nğ’Ÿ\nğ±\n,\nğ®\n\\mathcal{D}_{\\mathbf{x},\\mathbf{u}}\nvaries with\n(\nğ±\n,\nğ®\n)\n(\\mathbf{x},\\mathbf{u})\n). Most probabilistic invariance assumes\n(i)\n, and learningâ€“robust control typically addresses\n(ii)\nby setâ€“wrapping GP posteriors. We target\n(iii)\n: tubes/invariant sets when the distribution changes with\n(\nx\n,\nu\n)\n(x,u)\n, using an epistemic shrinkâ€“wrap plus a local chance operator to obtain\nğ•\nGP\nâ€‹\n(\nğ±\n,\nğ®\n)\n\\displaystyle\\mathbb{W}_{\\text{GP}}(\\mathbf{x},\\mathbf{u})\n=\n{\nğ°\nâˆˆ\nâ„\nn\n:\n(\nğ°\nâˆ’\nğ\n^\nğ°\n(\nğ±\n,\nğ®\n)\n)\nâŠ¤\n\\displaystyle=\\bigl\\{\\mathbf{w}\\in\\mathbb{R}^{n}:\\,(\\mathbf{w}-\\hat{\\bm{\\mu}}_{\\mathbf{w}}(\\mathbf{x},\\mathbf{u}))^{\\top}\n(3)\nğšº\n^\nğ°\n(\nğ±\n,\nğ®\n)\nâˆ’\n1\n(\nğ°\nâˆ’\nğ\n^\nğ°\n(\nğ±\n,\nğ®\n)\n)\nâ‰¤\nÏ‡\nn\n,\n1\nâˆ’\nÎ±\n2\n}\n,\n\\displaystyle\\hat{\\bm{\\Sigma}}_{\\mathbf{w}}(\\mathbf{x},\\mathbf{u})^{-1}(\\mathbf{w}-\\hat{\\bm{\\mu}}_{\\mathbf{w}}(\\mathbf{x},\\mathbf{u}))\\leq\\chi^{2}_{n,1-\\alpha}\\bigr\\},\nwhich encloses the true disturbance with probability\n1\nâˆ’\nÎ±\n1-\\alpha\nwhile enabling standard robust set operations. Here\nÏ‡\nn\n,\n1\nâˆ’\nÎ±\n2\n\\chi^{2}_{n,1-\\alpha}\ndenotes the\n(\n1\nâˆ’\nÎ±\n)\n(1-\\alpha)\nquantile of the\nÏ‡\n2\n\\chi^{2}\ndistribution with\nn\nn\ndegrees of freedom, i.e., the smallest\nc\n>\n0\nc>0\nsuch that\nâ„™\nâ€‹\n{\nÎ·\nâŠ¤\nâ€‹\nÎ·\nâ‰¤\nc\n}\n=\n1\nâˆ’\nÎ±\n\\mathbb{P}\\{\\mathbf{\\eta}^{\\top}\\mathbf{\\eta}\\leq c\\}=1-\\alpha\nfor\nÎ·\nâˆ¼\nğ’©\nâ€‹\n(\n0\n,\nI\nn\n)\n\\mathbf{\\eta}\\sim\\mathcal{N}(0,I_{n})\n. Equivalently,\n(\nğ°\nâˆ’\nÎ¼\n^\n)\nâŠ¤\nâ€‹\nÎ£\n^\nâˆ’\n1\nâ€‹\n(\nğ°\nâˆ’\nÎ¼\n^\n)\nâ‰¤\nÏ‡\nn\n,\n1\nâˆ’\nÎ±\n2\n(\\mathbf{w}-\\hat{\\mu})^{\\top}\\hat{\\Sigma}^{-1}(\\mathbf{w}-\\hat{\\mu})\\leq\\chi^{2}_{n,1-\\alpha}\nis a highest-density credible ellipsoid under the Gaussian posterior.\n2.3\nRPI for State- and Input-Dependent Disturbances\nThe fundamental challenge in computing RPI sets for LTI systems with state- and input-dependent disturbances lies in the circularity of the invariance condition. Consider a control law of the form\nğ®\nâ€‹\n(\nk\n)\n=\nğŠğ±\nâ€‹\n(\nk\n)\n+\nğ¯\nâ€‹\n(\nk\n)\n\\mathbf{u}(k)=\\mathbf{K}\\mathbf{x}(k)+\\mathbf{v}(k)\n, where\nğŠ\nâˆˆ\nâ„\nm\nÃ—\nn\n\\mathbf{K}\\in\\mathbb{R}^{m\\times n}\nis a stabilizing feedback gain and\nğ¯\nâ€‹\n(\nk\n)\nâˆˆ\nğ•\nâŠ†\nâ„\nm\n\\mathbf{v}(k)\\in\\mathbb{V}\\subseteq\\mathbb{R}^{m}\nis an auxiliary control input. This results in the closed-loop dynamics:\nğ±\nâ€‹\n(\nk\n+\n1\n)\n\\displaystyle\\mathbf{x}(k+1)\n=\n(\nğ€\n+\nğğŠ\n)\nâ€‹\nğ±\nâ€‹\n(\nk\n)\n+\nğğ¯\nâ€‹\n(\nk\n)\n\\displaystyle=(\\mathbf{A}+\\mathbf{BK})\\mathbf{x}(k)+\\mathbf{B}\\mathbf{v}(k)\n(4)\n+\nğ°\nâ€‹\n(\nğ±\nâ€‹\n(\nk\n)\n,\nğŠğ±\nâ€‹\n(\nk\n)\n+\nğ¯\nâ€‹\n(\nk\n)\n)\n.\n\\displaystyle+\\mathbf{w}(\\mathbf{x}(k),\\mathbf{K}\\mathbf{x}(k)+\\mathbf{v}(k)).\nFor traditional RPI sets with fixed disturbance sets, the invariance condition has the simple form\nğ€\ncl\nâ€‹\nÎ©\nâŠ•\nğ•\nâŠ†\nÎ©\n\\mathbf{A_{\\text{cl}}}\\Omega\\oplus\\mathbb{W}\\subseteq\\Omega\n[\n8\n]\n, where\nğ€\ncl\n=\nğ€\n+\nğğŠ\n\\mathbf{A_{\\text{cl}}}=\\mathbf{A}+\\mathbf{BK}\nis the closed-loop system matrix and\nâŠ•\n\\oplus\nis the Minkowski sum, allowing straightforward fixed-point iterations that converge monotonically.\n2.3.1\nFixed-Point Circularity\nWith state- and input-dependent disturbances, the RPI condition becomes:\nâˆ€\nğ±\nâˆˆ\nÎ©\n,\nâˆƒ\nğ¯\nâˆˆ\nğ•\n,\n\\displaystyle\\forall\\mathbf{x}\\in\\Omega,\\exists\\mathbf{v}\\in\\mathbb{V},\n(5)\nâˆ€\nğ°\nâˆˆ\nğ•\nâ€‹\n(\nğ±\n,\nğŠğ±\n+\nğ¯\n)\n:\nğ€\ncl\nâ€‹\nğ±\n+\nğğ¯\n+\nğ°\nâˆˆ\nÎ©\n.\n\\displaystyle\\forall\\mathbf{w}\\in\\mathbb{W}(\\mathbf{x},\\mathbf{Kx}+\\mathbf{v}):\\mathbf{A_{\\text{cl}}x}+\\mathbf{Bv}+\\mathbf{w}\\in\\Omega.\nThis introduces a fundamental logical circularity: to verify if\nÎ©\n\\Omega\nis an RPI set, we need to evaluate\nF\nâ€‹\n(\nÎ©\n)\nâŠ†\nÎ©\nF(\\Omega)\\subseteq\\Omega\n, where\nF\nâ€‹\n(\nÎ©\n)\n=\nâ‹ƒ\nğ±\nâˆˆ\nÎ©\nâ‹ƒ\nğ¯\nâˆˆ\nğ•\n{\nğ€\ncl\nâ€‹\nğ±\n+\nğğ¯\n+\nğ°\n:\nğ°\nâˆˆ\nğ•\nâ€‹\n(\nğ±\n,\nğŠğ±\n+\nğ¯\n)\n}\nF(\\Omega)=\\bigcup_{\\mathbf{x}\\in\\Omega}\\bigcup_{\\mathbf{v}\\in\\mathbb{V}}\\{\\mathbf{A_{\\text{cl}}x}+\\mathbf{Bv}+\\mathbf{w}:\\mathbf{w}\\in\\mathbb{W}(\\mathbf{x},\\mathbf{Kx}+\\mathbf{v})\\}\n. The circularity stems from the fact that\nF\nF\nitself depends on\nÎ©\n\\Omega\nthrough the mapping\nF\nâ€‹\n(\nÎ©\n)\n=\nF\nâ€‹\n(\nÎ©\n,\nğ•\nâ€‹\n(\nÎ©\n)\n)\nF(\\Omega)=F(\\Omega,\\mathbb{W}(\\Omega))\n, where\nğ•\nâ€‹\n(\nÎ©\n)\n=\nâ‹ƒ\nğ±\nâˆˆ\nÎ©\n,\nğ¯\nâˆˆ\nğ•\nğ•\nâ€‹\n(\nğ±\n,\nğŠğ±\n+\nğ¯\n)\n\\mathbb{W}(\\Omega)=\\bigcup_{\\mathbf{x}\\in\\Omega,\\mathbf{v}\\in\\mathbb{V}}\\mathbb{W}(\\mathbf{x},\\mathbf{Kx}+\\mathbf{v})\n.\nThis self-referential dependency breaks the monotonicity property critical for standard fixed-point iterations. Unlike the state-independent case where\nÎ©\ni\n+\n1\n=\nğ€\ncl\nâ€‹\nÎ©\ni\nâŠ•\nğ•\n\\Omega_{i+1}=\\mathbf{A_{\\text{cl}}}\\Omega_{i}\\oplus\\mathbb{W}\nguarantees\nÎ©\ni\nâŠ†\nÎ©\nj\nâŸ¹\nÎ©\ni\n+\n1\nâŠ†\nÎ©\nj\n+\n1\n\\Omega_{i}\\subseteq\\Omega_{j}\\implies\\Omega_{i+1}\\subseteq\\Omega_{j+1}\n, with state-dependent disturbances we have\nÎ©\ni\n+\n1\n=\nğ€\ncl\nâ€‹\nÎ©\ni\nâŠ•\nğ•\nâ€‹\n(\nÎ©\ni\n)\n\\Omega_{i+1}=\\mathbf{A_{\\text{cl}}}\\Omega_{i}\\oplus\\mathbb{W}(\\Omega_{i})\n, which may expand or contract non-monotonically between iterations. This undermines convergence guarantees of traditional fixed-point methods and potentially leads to multiple distinct fixed-point solutions for different initial estimates\nÎ©\n0\n\\Omega_{0}\n.\nPast works\n[\n4\n,\n15\n,\n13\n]\naddress this circularity by\nlifting\nthe system into an extended space that explicitly includes both the state and the disturbance (or disturbance parameters). Following\n[\n4\n]\n, we define the control increment\nğœ¹\nâ€‹\nğ¯\nâ€‹\n(\nk\n)\n=\nğ¯\nâ€‹\n(\nk\n)\nâˆ’\nğ¯\nâ€‹\n(\nk\nâˆ’\n1\n)\n\\bm{\\delta}\\mathbf{v}(k)=\\mathbf{v}(k)-\\mathbf{v}(k-1)\nand construct an augmented state vector:\nğƒ\nâ€‹\n(\nk\n)\n=\n[\nğ±\nâ€‹\n(\nk\n)\nğ¯\nâ€‹\n(\nk\nâˆ’\n1\n)\nğ°\nâ€‹\n(\nk\nâˆ’\n1\n)\n]\nâˆˆ\nâ„\n2\nâ€‹\nn\n+\nm\n.\n\\bm{\\xi}(k)=\\begin{bmatrix}\\mathbf{x}(k)\\\\\n\\mathbf{v}(k-1)\\\\\n\\mathbf{w}(k-1)\\end{bmatrix}\\in\\mathbb{R}^{2n+m}.\n(6)\nThe augmented dynamics in this lifted space become:\nğƒ\nâ€‹\n(\nk\n+\n1\n)\n\\displaystyle\\small\\bm{\\xi}(k+1)\n=\n[\nğ±\nâ€‹\n(\nk\n+\n1\n)\nğ¯\nâ€‹\n(\nk\n)\nğ°\nâ€‹\n(\nk\n)\n]\n\\displaystyle=\\begin{bmatrix}\\mathbf{x}(k+1)\\\\\n\\mathbf{v}(k)\\\\\n\\mathbf{w}(k)\\end{bmatrix}\n(7)\n=\n[\nğ€\ncl\nâ€‹\nğ±\nâ€‹\n(\nk\n)\n+\nğğ¯\nâ€‹\n(\nk\n)\n+\nğ°\nâ€‹\n(\nk\n)\nğ¯\nâ€‹\n(\nk\nâˆ’\n1\n)\n+\nğœ¹\nâ€‹\nğ¯\nâ€‹\n(\nk\n)\nğ°\nâ€‹\n(\nk\n)\n]\n\\displaystyle=\\begin{bmatrix}\\mathbf{A_{\\text{cl}}x}(k)+\\mathbf{Bv}(k)+\\mathbf{w}(k)\\\\\n\\mathbf{v}(k-1)+\\bm{\\delta}\\mathbf{v}(k)\\\\\n\\mathbf{w}(k)\\end{bmatrix}\nThis can be written in compact form as:\nğƒ\nâ€‹\n(\nk\n+\n1\n)\n\\displaystyle\\small\\bm{\\xi}(k+1)\n=\n[\nğ€\ncl\nğ\nğŸ\nğŸ\nğˆ\nğŸ\nğŸ\nğŸ\nğŸ\n]\nâŸ\nğ€\n~\nâ€‹\nğƒ\nâ€‹\n(\nk\n)\n\\displaystyle=\\underbrace{\\begin{bmatrix}\\mathbf{A}_{\\text{cl}}&\\mathbf{B}&\\mathbf{0}\\\\\n\\mathbf{0}&\\mathbf{I}&\\mathbf{0}\\\\\n\\mathbf{0}&\\mathbf{0}&\\mathbf{0}\\end{bmatrix}}_{\\widetilde{\\mathbf{A}}}\\bm{\\xi}(k)\\;\n(8)\n+\n[\nğ\nğˆ\nğŸ\n]\nâŸ\nğ\n~\nâ€‹\nğœ¹\nâ€‹\nğ¯\nâ€‹\n(\nk\n)\n+\n[\nğˆ\nğŸ\nğˆ\n]\nâŸ\nğƒ\n~\nâ€‹\nğ°\nâ€‹\n(\nk\n)\n,\n\\displaystyle+\\;\\underbrace{\\begin{bmatrix}\\mathbf{B}\\\\\n\\mathbf{I}\\\\\n\\mathbf{0}\\end{bmatrix}}_{\\widetilde{\\mathbf{B}}}\\bm{\\delta}\\mathbf{v}(k)\\;+\\;\\underbrace{\\begin{bmatrix}\\mathbf{I}\\\\\n\\mathbf{0}\\\\\n\\mathbf{I}\\end{bmatrix}}_{\\widetilde{\\mathbf{D}}}\\,\\mathbf{w}(k),\nwhere\nğƒ\nâ€‹\n(\nk\n)\n\\bm{\\xi}(k)\ndenotes the lifted (augmented) state vector, the augmented system matrix is denoted as\nğ€\n~\nâˆˆ\nâ„\n(\n2\nâ€‹\nn\n+\nm\n)\nÃ—\n(\n2\nâ€‹\nn\n+\nm\n)\n\\widetilde{\\mathbf{A}}\\in\\mathbb{R}^{(2n+m)\\times(2n+m)}\n,\nğ\n~\nâˆˆ\nâ„\n(\n2\nâ€‹\nn\n+\nm\n)\nÃ—\nm\n\\widetilde{\\mathbf{B}}\\in\\mathbb{R}^{(2n+m)\\times m}\nis the augmented control input matrix, and\nğƒ\n~\nâˆˆ\nâ„\n(\n2\nâ€‹\nn\n+\nm\n)\nÃ—\nn\n\\widetilde{\\mathbf{D}}\\in\\mathbb{R}^{(2n+m)\\times n}\ninjects the current disturbance\nğ°\nâ€‹\n(\nk\n)\n\\mathbf{w}(k)\ninto the\nx\nx\n-update (top block) and stores it in the disturbance memory (bottom block).\nIn this augmented system, the state and input dependency of the disturbance is captured by defining the constraint set:\nğ’¢\n=\n{\n(\nğ±\n,\nğ¯\n,\nğ°\n)\nâˆˆ\nâ„\n2\nâ€‹\nn\n+\nm\n:\nğ°\nâˆˆ\nğ•\nâ€‹\n(\nğ±\n,\nğŠğ±\n+\nğ¯\n)\n}\n,\n\\mathcal{G}\\;=\\;\\bigl\\{(\\mathbf{x},\\mathbf{v},\\mathbf{w})\\in\\mathbb{R}^{2n+m}:\\ \\mathbf{w}\\in\\mathbb{W}(\\mathbf{x},\\mathbf{Kx}+\\mathbf{v})\\bigr\\},\n(9)\nwhich encodes the stateâ€“disturbance coupling explicitly within the state space of the augmented system. It is important to note that while the disturbance\nğ°\n\\mathbf{w}\nremains state- and input-dependent, the set\nğ’¢\n\\mathcal{G}\nitself is a fixed subset of the extended state space. This insight allows us to reformulate the problem in a space where standard RPI computation techniques become applicable.\nThe key advantage of this formulation is that we can now compute an RPI set\nZ\nâŠ‚\nğ’¢\nZ\\subset\\mathcal{G}\nfor the augmented system,\nwhere the invariance condition becomes:\n(\nğ€\n~\nâ€‹\nZ\nâŠ•\nğ\n~\nâ€‹\nÎ”\nâ€‹\nğ•\nâŠ•\nğƒ\n~\nâ€‹\nğ•\nâ€‹\n(\nProj\nğ±\n,\nğ¯\nâ¡\n(\nZ\n)\n)\n)\nâˆ©\nğ’¢\nâŠ†\nZ\n,\n\\bigl(\\,\\widetilde{\\mathbf{A}}Z\\;\\oplus\\;\\widetilde{\\mathbf{B}}\\,\\Delta\\mathbb{V}\\;\\oplus\\;\\widetilde{\\mathbf{D}}\\,\\mathbb{W}(\\operatorname{Proj}_{\\mathbf{x},\\mathbf{v}}(Z))\\,\\bigr)\\ \\cap\\ \\mathcal{G}\\ \\subseteq\\ Z,\n(10)\nwhere\nÎ”\nâ€‹\nğ•\n=\n{\nğ¯\n1\nâˆ’\nğ¯\n2\n:\nğ¯\n1\n,\nğ¯\n2\nâˆˆ\nğ•\n}\n\\Delta\\mathbb{V}=\\{\\mathbf{v}_{1}-\\mathbf{v}_{2}:\\mathbf{v}_{1},\\mathbf{v}_{2}\\in\\mathbb{V}\\}\nis the set of feasible control increments,\nProj\nğ±\n,\nğ¯\nâ¡\n(\nZ\n)\n\\operatorname{Proj}_{\\mathbf{x},\\mathbf{v}}(Z)\ndenotes the projection of\nZ\nZ\nonto the\n(\nğ±\n,\nğ¯\n)\n(\\mathbf{x},\\mathbf{v})\ncomponents, and\nğ•\nâ€‹\n(\nProj\nğ±\n,\nğ¯\nâ¡\n(\nZ\n)\n)\n\\mathbb{W}(\\operatorname{Proj}_{\\mathbf{x},\\mathbf{v}}(Z))\nrepresents the collection of disturbance sets for all stateâ€“input pairs in the projection. While this condition still incorporates the state- and input-dependent disturbance set, the formulation within the augmented state space allows us to apply fixed-point methods in a well-defined manner.\nTo implement this approach, a two-stage approximation process is employed: first, we convert GP predictions to confidence ellipsoids, as described in Section\n2.2\n; then, we approximate these ellipsoids with polytopes to enable efficient set operations. Our method transitions systematically from worst-case to data-driven disturbance bounds. Initially, we employ conservative bounds to ensure safety in poorly explored regions. As the GP model refines with additional data, posterior variance reduction enables dynamic shrinking of these bounds, maintaining formal safety guarantees while progressively reducing conservatism\n[\n7\n]\n.\n3\nLearning-Based Robust Control Synthesis\nThis section presents our integrated methodology, building on the GP-based disturbance modeling framework established in Section\n2\n, we develop a comprehensive control synthesis approach that addresses the circular dependency in RPI computations while leveraging learned uncertainty bounds for reduced conservatism.\n3.1\nFrom GP Ellipsoids to Polytopic Control Constraints\nThe GP framework from Section\n2\nyields confidence ellipsoids\nğ•\nGP\n\\mathbb{W}_{\\text{GP}}\ninÂ (\n3\n)\nthat provide probabilistic guarantees but are incompatible with standard MPC optimization frameworks. Robust control synthesis commonly requires deterministic polytopic bounds that enable linear constraint formulations and efficient set operations (Minkowski sums, intersections, projections) essential for RPI computation\n[\n16\n]\n.\nWe address this through polytopic outer approximation: for each ellipsoid\nğ•\nGP\nâ€‹\n(\nğ±\n,\nğ®\n)\n\\mathbb{W}_{\\text{GP}}(\\mathbf{x},\\mathbf{u})\n, we construct a polytope\nğ•\npoly\nâ€‹\n(\nğ±\n,\nğ®\n)\n=\n{\nğ°\nâˆˆ\nâ„\nn\n:\nğ‡\nğ°\nâ€‹\nğ°\nâ‰¤\nğ¡\nğ°\n}\n\\mathbb{W}_{\\text{poly}}(\\mathbf{x},\\mathbf{u})=\\{\\mathbf{w}\\in\\mathbb{R}^{n}:\\mathbf{H_{w}w}\\leq\\mathbf{h_{w}}\\}\nsuch that\nğ•\nGP\nâ€‹\n(\nğ±\n,\nğ®\n)\nâŠ†\nğ•\npoly\nâ€‹\n(\nğ±\n,\nğ®\n)\n\\mathbb{W}_{\\text{GP}}(\\mathbf{x},\\mathbf{u})\\subseteq\\mathbb{W}_{\\text{poly}}(\\mathbf{x},\\mathbf{u})\n, where\nğ‡\nğ°\nâˆˆ\nâ„\nn\nf\nÃ—\nn\n\\mathbf{H_{w}}\\in\\mathbb{R}^{n_{f}\\times n}\nand\nğ¡\nğ°\nâˆˆ\nâ„\nn\nf\n\\mathbf{h_{w}}\\in\\mathbb{R}^{n_{f}}\ndefine the polytopic constraints with\nn\nf\nn_{f}\nfacets. This conversion preserves the original probabilistic guarantees while enabling computational tractability: if\nâ„™\nâ€‹\n[\nğ°\nâ€‹\n(\nğ±\n,\nğ®\n)\nâˆˆ\nğ•\nGP\nâ€‹\n(\nğ±\n,\nğ®\n)\n]\n=\n1\nâˆ’\nÎ±\n\\mathbb{P}[\\mathbf{w}(\\mathbf{x},\\mathbf{u})\\in\\mathbb{W}_{\\text{GP}}(\\mathbf{x},\\mathbf{u})]=1-\\alpha\n, then\nâ„™\nâ€‹\n[\nğ°\nâ€‹\n(\nğ±\n,\nğ®\n)\nâˆˆ\nğ•\npoly\nâ€‹\n(\nğ±\n,\nğ®\n)\n]\nâ‰¥\n1\nâˆ’\nÎ±\n\\mathbb{P}[\\mathbf{w}(\\mathbf{x},\\mathbf{u})\\in\\mathbb{W}_{\\text{poly}}(\\mathbf{x},\\mathbf{u})]\\geq 1-\\alpha\n.\nCritically, the polytopic approximation preserves the adaptive sizing properties of GP uncertainty quantification. In data-dense regions where\nğšº\n^\nğ°\nâ€‹\n(\nğ±\n,\nğ®\n)\n\\hat{\\bm{\\Sigma}}_{\\mathbf{w}}(\\mathbf{x},\\mathbf{u})\nis small, the resulting polytopes\nğ•\npoly\nâ€‹\n(\nğ±\n,\nğ®\n)\n\\mathbb{W}_{\\text{poly}}(\\mathbf{x},\\mathbf{u})\nare correspondingly tight, reducing conservatism. In unexplored regions where\nğšº\n^\nğ°\nâ€‹\n(\nğ±\n,\nğ®\n)\n\\hat{\\bm{\\Sigma}}_{\\mathbf{w}}(\\mathbf{x},\\mathbf{u})\napproaches prior values, larger polytopes maintain robust safety margins.\n3.2\nLiftâ€“andâ€“Project Framework for RPI Computation\nStateâ€“ and inputâ€“dependent disturbances make the RPI test circular: the set to be verified depends on itself. We break this by a liftâ€“andâ€“project formulation that augments the state with disturbance variables and encodes the coupling as a fixed graph constraint\nğ’¢\n\\mathcal{G}\nin the extended space; the RPI search then reduces to a standard fixed-point computation under this static constraint.\nTwo nested time scales:\nWe separate\n(i)\nlearning epochs\nq\nq\n, where the GP posterior and its polytope\nğ•\n^\n(\nq\n)\n\\widehat{\\mathbb{W}}^{(q)}\nare frozen, from\n(ii)\nan\ninner fixed-point iteration\nk\n=\n0\n,\n1\n,\nâ€¦\nk=0,1,\\dots\nthat computes the RPI set for that frozen description. The index\nk\nk\nis not physical time. When new data arrive, GP variance contracts so\nğ•\n^\n(\nq\n+\n1\n)\nâŠ†\nğ•\n^\n(\nq\n)\n\\widehat{\\mathbb{W}}^{(q+1)}\\subseteq\\widehat{\\mathbb{W}}^{(q)}\n; we warm-start a fresh fixed-point run from the previous solution. This separation preserves rigor while accommodating evolving uncertainty. The liftâ€“andâ€“project framework is summarized in Algorithm\n1\n.\n3.2.1\nInvariance in the Lifted Space\nWe work with the closed-loop dynamicsÂ (\n4\n) and the augmented state\nğƒ\n=\n[\nğ±\nâŠ¤\n,\nğ¯\nâŠ¤\n,\nğ°\nâŠ¤\n]\nâŠ¤\n\\bm{\\xi}=\\bigl[\\mathbf{x}^{\\top},\\;\\mathbf{v}^{\\top},\\;\\mathbf{w}^{\\top}\\bigr]^{\\top}\nofÂ (\n6\n). The algebraic coupling\nğ°\nâˆˆ\nğ•\nâ€‹\n(\nğ±\n,\nğ®\n)\n\\mathbf{w}\\in\\mathbb{W}(\\mathbf{x},\\mathbf{u})\nis encoded by the fixed graph set\nğ’¢\n=\n{\n(\nğ±\n,\nğ¯\n,\nğ°\n)\n:\nğ°\nâˆˆ\nğ•\nâ€‹\n(\nğ±\n,\nğŠğ±\n+\nğ¯\n)\n}\n.\n\\mathcal{G}\\!=\\!\\bigl\\{(\\mathbf{x},\\mathbf{v},\\mathbf{w}):\\mathbf{w}\\!\\in\\!\\mathbb{W}(\\mathbf{x},\\mathbf{K}\\mathbf{x}+\\mathbf{v})\\bigr\\}.\nAssumptions & Regularity\n1.\n(Asm. 2)\nDomain/constraints:\nğ•\nâŠ‚\nâ„\nn\n\\mathbb{X}\\subset\\mathbb{R}^{n}\n,\nğ•Œ\n,\nğ•\nâŠ‚\nâ„\nm\n\\mathbb{U},\\mathbb{V}\\subset\\mathbb{R}^{m}\nare non-empty, compact, convex;\nK\nK\nrenders\nA\n+\nB\nâ€‹\nK\nA{+}BK\nSchur.\n2.\n(Asm. 3)\nDisturbance map:\n(\nx\n,\nu\n)\nâ†¦\nğ•\n^\nâ€‹\n(\nx\n,\nu\n)\n(x,u)\\mapsto\\widehat{\\mathbb{W}}(x,u)\nis non-empty, compact-valued, upper hemicontinuous, with closed graph; its polyhedralization preserves closed graph.\n3.\n(Asm. 4)\nLifted graph:\nğ’¢\n=\n{\n(\nx\n,\nv\n,\nw\n)\n:\nw\nâˆˆ\nğ•\n^\nâ€‹\n(\nx\n,\nK\nâ€‹\nx\n+\nv\n)\n}\n\\mathcal{G}=\\{(x,v,w):w\\in\\widehat{\\mathbb{W}}(x,Kx{+}v)\\}\nis closed, and all lifted images under\nA\n~\n,\nB\n~\n,\nD\n~\n\\tilde{A},\\tilde{B},\\tilde{D}\nremain bounded in\nğ’¢\n\\mathcal{G}\n.\n4.\n(Asm. 5)\nAuxiliary input set:\nğ•\nâŠ†\nâ„\nm\n\\mathbb{V}\\subseteq\\mathbb{R}^{m}\nis compact and convex, and we denote\nÎ”\nâ€‹\nğ•\n=\n{\nğ¯\n1\nâˆ’\nğ¯\n2\n:\nğ¯\n1\n,\n2\nâˆˆ\nğ•\n}\n\\Delta\\mathbb{V}=\\{\\mathbf{v}_{1}-\\mathbf{v}_{2}:\\mathbf{v}_{1,2}\\in\\mathbb{V}\\}\n.\n5.\nSupports:\nsupport directions\nğ’®\n\\mathcal{S}\nare fixed, finite, and bounded.\nForward outside-in operator.\nFor any\nZ\nâŠ†\nğ’¢\nZ\\subseteq\\mathcal{G}\ndefine\nâ„±\nâ€‹\n(\nZ\n)\n:=\n(\nğ€\n~\nâ€‹\nZ\nâŠ•\nğ\n~\nâ€‹\nÎ”\nâ€‹\nğ•\nâŠ•\nğƒ\n~\nâ€‹\nW\nâ€‹\n(\nZ\n)\n)\nâˆ©\nğ’¢\n,\n\\mathcal{F}(Z)\\;:=\\;\\bigl(\\widetilde{\\mathbf{A}}Z\\,\\oplus\\,\\widetilde{\\mathbf{B}}\\,\\Delta\\mathbb{V}\\,\\oplus\\,\\widetilde{\\mathbf{D}}\\,W(Z)\\bigr)\\;\\cap\\;\\mathcal{G},\n(11)\nwith\nW\nâ€‹\n(\nZ\n)\n=\nâ‹ƒ\n(\nğ±\n,\nğ¯\n)\nâˆˆ\nProj\nğ±\n,\nğ¯\nâ¡\n(\nZ\n)\nğ•\nâ€‹\n(\nğ±\n,\nğŠğ±\n+\nğ¯\n)\n.\nW(Z)=\\!\\bigcup\\limits_{(\\mathbf{x},\\mathbf{v})\\in\\operatorname{Proj}_{\\mathbf{x},\\mathbf{v}}(Z)}\\mathbb{W}(\\mathbf{x},\\mathbf{K}\\mathbf{x}+\\mathbf{v}).\nA set\nZ\nâ‹†\nZ^{\\star}\nis RPI for the lifted system iff\nâ„±\nâ€‹\n(\nZ\nâ‹†\n)\nâŠ†\nZ\nâ‹†\n\\mathcal{F}(Z^{\\star})\\subseteq Z^{\\star}\n. Because we enforce\nâ„±\nâ€‹\n(\nZ\n0\n)\nâŠ†\nZ\n0\n\\mathcal{F}(Z_{0})\\subseteq Z_{0}\nat the start of every epoch, the sequence\nZ\nk\n+\n1\n=\nâ„±\nâ€‹\n(\nZ\nk\n)\nZ_{k+1}=\\mathcal{F}(Z_{k})\nshrinks\n, i.e.\nZ\nk\n+\n1\nâŠ†\nZ\nk\nZ_{k+1}\\subseteq Z_{k}\n, hence â€œoutside-inâ€.\nMonotonicity\nLemma 1\n(Monotonicity property)\n.\nIf\nZ\n1\nâŠ†\nZ\n2\nâŠ†\nğ’¢\nZ_{1}\\subseteq Z_{2}\\subseteq\\mathcal{G}\n, then\nâ„±\nâ€‹\n(\nZ\n1\n)\nâŠ†\nâ„±\nâ€‹\n(\nZ\n2\n)\n\\mathcal{F}(Z_{1})\\subseteq\\mathcal{F}(Z_{2})\n.\nProof.\nAssume\nZ\n1\nâŠ†\nZ\n2\nZ_{1}\\subseteq Z_{2}\n. Since\nğ€\n~\n\\widetilde{\\mathbf{A}}\nis linear,\nğ€\n~\nâ€‹\nZ\n1\nâŠ†\nğ€\n~\nâ€‹\nZ\n2\n\\widetilde{\\mathbf{A}}Z_{1}\\subseteq\\widetilde{\\mathbf{A}}Z_{2}\nfollows immediately.\nThe projection satisfies\nProj\nğ±\n,\nğ¯\nâ¡\n(\nZ\n1\n)\nâŠ†\nProj\nğ±\n,\nğ¯\nâ¡\n(\nZ\n2\n)\n\\operatorname{Proj}_{\\mathbf{x},\\mathbf{v}}(Z_{1})\\subseteq\\operatorname{Proj}_{\\mathbf{x},\\mathbf{v}}(Z_{2})\n;\nhence every pair\n(\nğ±\n,\nğ¯\n)\n(\\mathbf{x},\\mathbf{v})\nthat contributes to\nW\nâ€‹\n(\nZ\n1\n)\nW(Z_{1})\nalso contributes to\nW\nâ€‹\n(\nZ\n2\n)\nW(Z_{2})\n,\ngiving\nW\nâ€‹\n(\nZ\n1\n)\nâŠ†\nW\nâ€‹\n(\nZ\n2\n)\nW(Z_{1})\\subseteq W(Z_{2})\n. Because\nğƒ\n~\n\\widetilde{\\mathbf{D}}\nis linear,\nğƒ\n~\nâ€‹\nW\nâ€‹\n(\nZ\n1\n)\nâŠ†\nğƒ\n~\nâ€‹\nW\nâ€‹\n(\nZ\n2\n)\n\\widetilde{\\mathbf{D}}W(Z_{1})\\subseteq\\widetilde{\\mathbf{D}}W(Z_{2})\nfollows.\nThe Minkowski sum preserves inclusions:\nğ€\n~\nâ€‹\nZ\n1\nâŠ•\nğ\n~\nâ€‹\nÎ”\nâ€‹\nğ•\nâŠ•\nğƒ\n~\nâ€‹\nW\nâ€‹\n(\nZ\n1\n)\nâŠ†\nğ€\n~\nâ€‹\nZ\n2\nâŠ•\nğ\n~\nâ€‹\nÎ”\nâ€‹\nğ•\nâŠ•\nğƒ\n~\nâ€‹\nW\nâ€‹\n(\nZ\n2\n)\n.\n\\displaystyle\\widetilde{\\mathbf{A}}Z_{1}\\,\\oplus\\,\\widetilde{\\mathbf{B}}\\Delta\\mathbb{V}\\,\\oplus\\,\\widetilde{\\mathbf{D}}W(Z_{1})\\subseteq\\widetilde{\\mathbf{A}}Z_{2}\\,\\oplus\\,\\widetilde{\\mathbf{B}}\\Delta\\mathbb{V}\\,\\oplus\\,\\widetilde{\\mathbf{D}}W(Z_{2}).\nIntersecting both sides with\nğ’¢\n\\mathcal{G}\npreserves the inclusion, yielding\nâ„±\nâ€‹\n(\nZ\n1\n)\nâŠ†\nâ„±\nâ€‹\n(\nZ\n2\n)\n\\mathcal{F}(Z_{1})\\subseteq\\mathcal{F}(Z_{2})\n.\nâˆ\nOutside-in convergence (single epoch)\nLemma 2\n(Cantorâ€“Bolzano fixed point)\n.\nChoose\nZ\n0\nâŠ†\nğ’¢\nZ_{0}\\subseteq\\mathcal{G}\nnon-empty, compact and such that\nâ„±\nâ€‹\n(\nZ\n0\n)\nâŠ†\nZ\n0\n\\mathcal{F}(Z_{0})\\subseteq Z_{0}\n.\nThen the decreasing chain\nZ\nk\n+\n1\n=\nâ„±\nâ€‹\n(\nZ\nk\n)\nZ_{k+1}=\\mathcal{F}(Z_{k})\nsatisfies\n1.\nZ\nk\n+\n1\nâŠ†\nZ\nk\nZ_{k+1}\\subseteq Z_{k}\nfor all\nk\nk\n(outside-in),\n2.\nZ\nâˆ\n:=\nâ‹‚\nk\n=\n0\nâˆ\nZ\nk\nZ_{\\infty}:=\\bigcap_{k=0}^{\\infty}Z_{k}\nis non-empty and compact, and\n3.\nZ\nâˆ\n=\nâ„±\nâ€‹\n(\nZ\nâˆ\n)\nZ_{\\infty}=\\mathcal{F}(Z_{\\infty})\n.\nProof.\nItem 1:\nWe have\nZ\n1\n=\nâ„±\nâ€‹\n(\nZ\n0\n)\nâŠ†\nZ\n0\nZ_{1}=\\mathcal{F}(Z_{0})\\subseteq Z_{0}\nby assumption.\nBy Lemma\n1\n,\nZ\n2\n=\nâ„±\nâ€‹\n(\nZ\n1\n)\nâŠ†\nâ„±\nâ€‹\n(\nZ\n0\n)\n=\nZ\n1\nZ_{2}=\\mathcal{F}(Z_{1})\\subseteq\\mathcal{F}(Z_{0})=Z_{1}\n.\nBy induction,\nZ\nk\n+\n1\n=\nâ„±\nâ€‹\n(\nZ\nk\n)\nâŠ†\nZ\nk\nZ_{k+1}=\\mathcal{F}(Z_{k})\\subseteq Z_{k}\nfor all\nk\nâ‰¥\n0\nk\\geq 0\n.\nItem 2:\nThe sequence\nZ\n0\nâŠ‡\nZ\n1\nâŠ‡\nZ\n2\nâŠ‡\nâ€¦\nZ_{0}\\supseteq Z_{1}\\supseteq Z_{2}\\supseteq\\ldots\nis a decreasing chain of non-empty compact sets. By Cantorâ€™s intersection theorem,\nZ\nâˆ\n=\nâ‹‚\nk\n=\n0\nâˆ\nZ\nk\nZ_{\\infty}=\\bigcap_{k=0}^{\\infty}Z_{k}\nis non-empty and compact.\nItem 3:\nTo show\nZ\nâˆ\n=\nâ„±\nâ€‹\n(\nZ\nâˆ\n)\nZ_{\\infty}=\\mathcal{F}(Z_{\\infty})\n, we prove both inclusions.\nFor\nâ„±\nâ€‹\n(\nZ\nâˆ\n)\nâŠ†\nZ\nâˆ\n\\mathcal{F}(Z_{\\infty})\\subseteq Z_{\\infty}\n: Since\nZ\nâˆ\nâŠ†\nZ\nk\nZ_{\\infty}\\subseteq Z_{k}\nfor all\nk\nk\n, Lemma\n1\ngives\nâ„±\nâ€‹\n(\nZ\nâˆ\n)\nâŠ†\nâ„±\nâ€‹\n(\nZ\nk\n)\n=\nZ\nk\n+\n1\n\\mathcal{F}(Z_{\\infty})\\subseteq\\mathcal{F}(Z_{k})=Z_{k+1}\nfor all\nk\nk\n. Hence\nâ„±\nâ€‹\n(\nZ\nâˆ\n)\nâŠ†\nâ‹‚\nk\n=\n0\nâˆ\nZ\nk\n+\n1\n=\nZ\nâˆ\n\\mathcal{F}(Z_{\\infty})\\subseteq\\bigcap_{k=0}^{\\infty}Z_{k+1}=Z_{\\infty}\n. For\nZ\nâˆ\nâŠ†\nâ„±\nâ€‹\n(\nZ\nâˆ\n)\nZ_{\\infty}\\subseteq\\mathcal{F}(Z_{\\infty})\n: Take any\nğƒ\nâˆˆ\nZ\nâˆ\n\\bm{\\xi}\\in Z_{\\infty}\n. Then\nğƒ\nâˆˆ\nZ\nk\n+\n1\n=\nâ„±\nâ€‹\n(\nZ\nk\n)\n\\bm{\\xi}\\in Z_{k+1}=\\mathcal{F}(Z_{k})\nfor all\nk\nâ‰¥\n0\nk\\geq 0\n. For each\nk\nk\n, there exists\nğœ»\nk\nâˆˆ\nZ\nk\n\\bm{\\zeta}_{k}\\in Z_{k}\nsuch that\nğƒ\nâˆˆ\nâ„±\nâ€‹\n(\n{\nğœ»\nk\n}\n)\n\\bm{\\xi}\\in\\mathcal{F}(\\{\\bm{\\zeta}_{k}\\})\n. Since\n{\nğœ»\nk\n}\nk\n=\n0\nâˆ\nâŠ†\nZ\n0\n\\{\\bm{\\zeta}_{k}\\}_{k=0}^{\\infty}\\subseteq Z_{0}\n(compact), by Bolzanoâ€“Weierstrass, a subsequence\n{\nğœ»\nk\nj\n}\n\\{\\bm{\\zeta}_{k_{j}}\\}\nconverges to some\nğœ»\nâˆ—\nâˆˆ\nZ\nâˆ\n\\bm{\\zeta}^{*}\\in Z_{\\infty}\n. By the closed-graph property of\nâ„±\n\\mathcal{F}\n(guaranteed by upper hemicontinuity of\nğ•\n\\mathbb{W}\nand compactness), as\nğœ»\nk\nj\nâ†’\nğœ»\nâˆ—\n\\bm{\\zeta}_{k_{j}}\\to\\bm{\\zeta}^{*}\nwith\nğƒ\nâˆˆ\nâ„±\nâ€‹\n(\n{\nğœ»\nk\nj\n}\n)\n\\bm{\\xi}\\in\\mathcal{F}(\\{\\bm{\\zeta}_{k_{j}}\\})\n, we have\nğƒ\nâˆˆ\nâ„±\nâ€‹\n(\n{\nğœ»\nâˆ—\n}\n)\nâŠ†\nâ„±\nâ€‹\n(\nZ\nâˆ\n)\n\\bm{\\xi}\\in\\mathcal{F}(\\{\\bm{\\zeta}^{*}\\})\\subseteq\\mathcal{F}(Z_{\\infty})\n.\nâˆ\nProjection back to the plant coordinates\nLemma 3\n(RPI via measurable selector)\n.\nLet\nZ\nâ‹†\nâŠ†\nğ’¢\nZ^{\\star}\\subseteq\\mathcal{G}\nbe a lifted fixed point for a frozen epoch and define\nâ„¤\nâ‹†\n:=\nProj\nx\nâ€‹\n(\nZ\nâ‹†\n)\n\\mathbb{Z}^{\\star}:=\\mathrm{Proj}_{x}(Z^{\\star})\n. Suppose\n(\nx\n,\nu\n)\nâ†¦\nğ•\n^\nâ€‹\n(\nx\n,\nu\n)\n(x,u)\\mapsto\\widehat{\\mathbb{W}}(x,u)\nhas closed graph and compact values. Then there exists a Borel-measurable selector\nÎº\n:\nâ„¤\nâ‹†\nâ†’\nğ•\n\\kappa:\\mathbb{Z}^{\\star}\\to\\mathbb{V}\nsuch that\n(\nA\n+\nB\nâ€‹\nK\n)\nâ€‹\nx\n+\nB\nâ€‹\nÎº\nâ€‹\n(\nx\n)\n+\nw\nâˆˆ\nâ„¤\nâ‹†\nâˆ€\nx\nâˆˆ\nâ„¤\nâ‹†\n,\nâˆ€\nw\nâˆˆ\nğ•\n^\nâ€‹\n(\nx\n,\nK\nâ€‹\nx\n+\nÎº\nâ€‹\n(\nx\n)\n)\n.\n(\\!A{+}BK\\!)x+B\\,\\kappa(x)+w\\in\\mathbb{Z}^{\\star}\\quad\\forall x\\in\\mathbb{Z}^{\\star},\\ \\forall w\\in\\widehat{\\mathbb{W}}(x,Kx{+}\\kappa(x)).\nHence\nâ„¤\nâ‹†\n\\mathbb{Z}^{\\star}\nis RPI for the plant.\nProof.\nLet\nT\nâ€‹\n(\nğ±\n)\n:=\n{\nğ¯\nâˆˆ\nğ•\n:\nâˆƒ\nğ°\nâ€‹\ns.t.\nâ€‹\n(\nğ±\n,\nğ¯\n,\nğ°\n)\nâˆˆ\nZ\nâ‹†\n}\nT(\\mathbf{x}):=\\{\\,\\mathbf{v}\\in\\mathbb{V}:\\ \\exists\\,\\mathbf{w}\\ \\text{s.t.}\\ (\\mathbf{x},\\mathbf{v},\\mathbf{w})\\in Z^{\\star}\\,\\}\n; then\nT\nT\nhas non-empty compact values and closed (hence Borel) graph\nGraph\nâ¡\n(\nT\n)\n=\nProj\nx\n,\nv\nâ¡\n(\nZ\nâ‹†\n)\n\\operatorname{Graph}(T)=\\operatorname{Proj}_{x,v}(Z^{\\star})\n. By the Kuratowskiâ€“Ryll-Nardzewski measurable selection theorem, there exists a Borel selector\nğœ¿\nâ€‹\n(\nğ±\n)\nâˆˆ\nT\nâ€‹\n(\nğ±\n)\n\\bm{\\kappa}(\\mathbf{x})\\in T(\\mathbf{x})\n. For any\nğ±\n\\mathbf{x}\nand any\nğ°\nâˆˆ\nğ•\n^\nâ€‹\n(\nğ±\n,\nğŠğ±\n+\nğœ¿\nâ€‹\n(\nğ±\n)\n)\n\\mathbf{w}\\in\\widehat{\\mathbb{W}}(\\mathbf{x},\\mathbf{K}\\mathbf{x}+\\bm{\\kappa}(\\mathbf{x}))\n, taking\nğœ¹\nâ€‹\nğ’—\n=\nğŸ\n\\bm{\\delta v}=\\mathbf{0}\nand using\nZ\nâ‹†\n=\nâ„±\nâ€‹\n(\nZ\nâ‹†\n)\nZ^{\\star}=\\mathcal{F}(Z^{\\star})\nyields\n(\n(\nğ€\n+\nğğŠ\n)\nâ€‹\nğ±\n+\nğ\nâ€‹\nğœ¿\nâ€‹\n(\nğ±\n)\n+\nğ°\n,\nğœ¿\nâ€‹\n(\nğ±\n)\n,\nğ°\n)\nâˆˆ\nZ\nâ‹†\n\\big((\\mathbf{A}{+}\\mathbf{B}\\mathbf{K})\\mathbf{x}+\\mathbf{B}\\bm{\\kappa}(\\mathbf{x})+\\mathbf{w},\\ \\bm{\\kappa}(\\mathbf{x}),\\ \\mathbf{w}\\big)\\in Z^{\\star}\n, hence\n(\nğ€\n+\nğğŠ\n)\nâ€‹\nğ±\n+\nğ\nâ€‹\nğœ¿\nâ€‹\n(\nğ±\n)\n+\nğ°\nâˆˆ\nâ„¤\nâ‹†\n(\\mathbf{A}{+}\\mathbf{B}\\mathbf{K})\\mathbf{x}+\\mathbf{B}\\bm{\\kappa}(\\mathbf{x})+\\mathbf{w}\\in\\mathbb{Z}^{\\star}\n.\nâˆ\nMaintaining Uniform Safety through\nÎµ\n\\varepsilon\n-nets\nLemma 4\n(Uniform safety of Anchors)\n.\nLet\nâ„›\nx\n,\nv\nâŠ‚\nğ•\nÃ—\nğ•\n\\mathcal{R}_{x,v}\\subset\\mathbb{X}\\times\\mathbb{V}\nbe compact and let\nğ’œ\nx\n,\nv\n\\mathcal{A}_{x,v}\nbe an\nÎµ\n\\varepsilon\n-net (finite grid covering) of\nâ„›\nx\n,\nv\n\\mathcal{R}_{x,v}\n.\nFor\n(\nğ±\n,\nğ¯\n)\nâˆˆ\nâ„›\nx\n,\nv\n(\\mathbf{x},\\mathbf{v})\\in\\mathcal{R}_{x,v}\nset\nğ®\n=\nğŠğ±\n+\nğ¯\n\\mathbf{u}=\\mathbf{K}\\mathbf{x}+\\mathbf{v}\nand\nğ³\n=\n(\nğ±\n,\nğ®\n)\n\\mathbf{z}=(\\mathbf{x},\\mathbf{u})\n; for each anchor\n(\nğ±\na\n,\nğ¯\na\n)\nâˆˆ\nğ’œ\nx\n,\nv\n(\\mathbf{x}_{a},\\mathbf{v}_{a})\\in\\mathcal{A}_{x,v}\nset\nğ®\na\n=\nğŠğ±\na\n+\nğ¯\na\n\\mathbf{u}_{a}=\\mathbf{K}\\mathbf{x}_{a}+\\mathbf{v}_{a}\nand\nğ³\na\n=\n(\nğ±\na\n,\nğ®\na\n)\n\\mathbf{z}_{a}=(\\mathbf{x}_{a},\\mathbf{u}_{a})\n.\nFix\nÎ±\nanc\nâˆˆ\n(\n0\n,\n1\n)\n\\alpha_{\\mathrm{anc}}\\in(0,1)\nand define\nc\nn\n,\nÎ±\n:=\nÏ‡\nn\n,\n1\nâˆ’\nÎ±\n2\nc_{n,\\alpha}:=\\sqrt{\\chi^{2}_{n,\\,1-\\alpha}}\n.\nLet\nğ’®\nâŠ‚\nâ„\nn\n\\mathcal{S}\\subset\\mathbb{R}^{n}\nbe the fixed finite set of support directions (unit vectors) used to define the disturbance polytopes. For each\nğ¬\nâˆˆ\nğ’®\n\\mathbf{s}\\in\\mathcal{S}\ndefine\nh\nâ€‹\n(\nğ³\n;\nğ¬\n)\n=\nğ¬\nâŠ¤\nâ€‹\nğ›\n^\nğ°\nâ€‹\n(\nğ³\n)\n+\nc\nn\n,\nÎ±\nanc\nâ€‹\nÏƒ\nğ¬\nâ€‹\n(\nğ³\n)\n,\nÏƒ\nğ¬\nâ€‹\n(\nğ³\n)\n:=\nğ¬\nâŠ¤\nâ€‹\nğšº\n^\nğ°\nâ€‹\n(\nğ³\n)\nâ€‹\nğ¬\n.\nh(\\mathbf{z};\\mathbf{s})=\\mathbf{s}^{\\top}\\hat{\\bm{\\mu}}_{\\mathbf{w}}(\\mathbf{z})\\;+\\;c_{n,\\alpha_{\\mathrm{anc}}}\\ \\sigma_{\\mathbf{s}}(\\mathbf{z}),\\ \\sigma_{\\mathbf{s}}(\\mathbf{z}):=\\sqrt{\\mathbf{s}^{\\top}\\hat{\\bm{\\Sigma}}_{\\mathbf{w}}(\\mathbf{z})\\,\\mathbf{s}}.\nAssume\nğ›\n^\nğ°\n\\hat{\\bm{\\mu}}_{\\mathbf{w}}\nis\nL\nÎ¼\nL_{\\mu}\nâ€“Lipschitz and, for each fixed\nğ¬\nâˆˆ\nğ’®\n\\mathbf{s}\\in\\mathcal{S}\n,\nÏƒ\nğ¬\n\\sigma_{\\mathbf{s}}\nis\nL\nÏƒ\nL_{\\sigma}\nâ€“Lipschitz on\nâ„›\nx\n,\nu\n=\n{\n(\nğ±\n,\nğŠğ±\n+\nğ¯\n)\n:\n(\nğ±\n,\nğ¯\n)\nâˆˆ\nâ„›\nx\n,\nv\n}\n\\mathcal{R}_{x,u}=\\{(\\mathbf{x},\\mathbf{K}\\mathbf{x}+\\mathbf{v}):(\\mathbf{x},\\mathbf{v})\\in\\mathcal{R}_{x,v}\\}\n.\nDefine the anchor envelope with Lipschitz inflation\nh\nÂ¯\nâ€‹\n(\nğ¬\n)\n\\displaystyle\\overline{h}(\\mathbf{s})\n:=\nmax\n(\nğ±\na\n,\nğ¯\na\n)\nâˆˆ\nğ’œ\nx\n,\nv\nâ¡\n[\nğ¬\nâŠ¤\nâ€‹\nğ\n^\nğ°\nâ€‹\n(\nğ³\na\n)\n+\nc\nn\n,\nÎ±\nanc\nâ€‹\nÏƒ\nğ¬\nâ€‹\n(\nğ³\na\n)\n]\nâŸ\nanchor supports\n\\displaystyle=\\ \\underbrace{\\max_{(\\mathbf{x}_{a},\\mathbf{v}_{a})\\in\\mathcal{A}_{x,v}}\\Bigl[\\mathbf{s}^{\\top}\\hat{\\bm{\\mu}}_{\\mathbf{w}}(\\mathbf{z}_{a})+c_{n,\\alpha_{\\mathrm{anc}}}\\ \\sigma_{\\mathbf{s}}(\\mathbf{z}_{a})\\Bigr]}_{\\text{anchor supports}}\n(12)\n+\n(\nâ€–\nğ¬\nâ€–\nâ€‹\nL\nÎ¼\n+\nc\nn\n,\nÎ±\nanc\nâ€‹\nL\nÏƒ\n)\nâ€‹\nÎµ\nâŸ\nLipschitz inflation\n.\n\\displaystyle+\\;\\underbrace{\\bigl(\\|\\mathbf{s}\\|L_{\\mu}+c_{n,\\alpha_{\\mathrm{anc}}}L_{\\sigma}\\bigr)\\,\\varepsilon}_{\\text{Lipschitz inflation}}.\nThen, for all\n(\nğ±\n,\nğ¯\n)\nâˆˆ\nâ„›\nx\n,\nv\n(\\mathbf{x},\\mathbf{v})\\in\\mathcal{R}_{x,v}\n(hence\nğ³\nâˆˆ\nâ„›\nx\n,\nu\n\\mathbf{z}\\in\\mathcal{R}_{x,u}\n) and all\nğ¬\nâˆˆ\nğ’®\n\\mathbf{s}\\in\\mathcal{S}\n,\nh\nâ€‹\n(\nğ³\n;\nğ¬\n)\nâ‰¤\nh\nÂ¯\nâ€‹\n(\nğ¬\n)\n.\nh(\\mathbf{z};\\mathbf{s})\\;\\leq\\;\\overline{h}(\\mathbf{s}).\nMoreover, if each anchor ellipsoid is\n(\n1\nâˆ’\nÎ±\nanc\n)\n(1-\\alpha_{\\mathrm{anc}})\n-credible under the GP posterior, then by the union bound the probability that\nsome\nanchor ellipsoid fails to contain the true disturbance is at most\nÎ±\nuniform\n:=\n|\nğ’œ\nx\n,\nv\n|\nâ€‹\nÎ±\nanc\n.\n\\alpha_{\\mathrm{uniform}}\\;:=\\;|\\mathcal{A}_{x,v}|\\ \\alpha_{\\mathrm{anc}}.\nConsequently, using\nÎµ\ncov\nâ€‹\n(\nğ¬\n)\n=\n(\nâ€–\nğ¬\nâ€–\nâ€‹\nL\nÎ¼\n+\nc\nn\n,\nÎ±\nanc\nâ€‹\nL\nÏƒ\nâ€‹\n(\nğ¬\n)\n)\nâ€‹\nÎµ\n\\varepsilon_{\\mathrm{cov}}(\\mathbf{s})=\\bigl(\\|\\mathbf{s}\\|L_{\\mu}+c_{n,\\alpha_{\\mathrm{anc}}}L_{\\sigma}(\\mathbf{s})\\bigr)\\,\\varepsilon\nin Algorithm\n1\nyields a uniform outer wrapper whose probability of excluding the true disturbance at some anchor (in some\nğ¬\nâˆˆ\nğ’®\n\\mathbf{s}\\in\\mathcal{S}\n) is at most\nÎ±\nuniform\n\\alpha_{\\mathrm{uniform}}\n.\nProof sketch.\nClaim follows directly from the perâ€“anchor\n(\n1\nâˆ’\nÎ±\nanc\n)\n(1-\\alpha_{\\mathrm{anc}})\ncredibility of the GP ellipsoids, the union bound over the finite net\nğ’œ\nx\n,\nv\n\\mathcal{A}_{x,v}\n, and the Lipschitz bounds on\nğ\n^\nğ°\n\\hat{\\bm{\\mu}}_{\\mathbf{w}}\nand\nÏƒ\nğ¬\n\\sigma_{\\mathbf{s}}\n; the detailed derivation is therefore omitted for brevity.\nâˆ\n3.3\nMain Result for a Single Learning Epoch\nTheorem 1\n(RPI existence, projection, and per-epoch uniform safety)\n.\nFix an epoch\nq\nq\nwith a frozen wrapper\nğ•\n^\n(\nq\n)\nâ€‹\n(\nâ‹…\n)\n\\widehat{\\mathbb{W}}^{(q)}(\\cdot)\nconstructed from GP posteriors as in Section\n2\n, polyhedralized on a fixed finite set of supports, and uniformized as in Lemma\n4\nwith risk budget\nÎ±\nepoch\nâˆˆ\n(\n0\n,\n1\n)\n\\alpha_{\\mathrm{epoch}}\\in(0,1)\nover a compact design domain\nâ„›\nx\n,\nv\n\\mathcal{R}_{x,v}\n.\nLet\nğ’¢\n=\n{\n(\nğ±\n,\nğ¯\n,\nğ°\n)\n:\nğ°\nâˆˆ\nğ•\n^\n(\nq\n)\nâ€‹\n(\nğ±\n,\nğŠğ±\n+\nğ¯\n)\n}\n\\mathcal{G}=\\{(\\mathbf{x},\\mathbf{v},\\mathbf{w}):\\ \\mathbf{w}\\in\\widehat{\\mathbb{W}}^{(q)}(\\mathbf{x},\\mathbf{K}\\mathbf{x}+\\mathbf{v})\\}\nand define the isotone outsideâ€“in operator in (\n11\n)\nW\nâ€‹\n(\nZ\n)\n\\displaystyle W(Z)\n=\nâ‹ƒ\n(\nğ±\n,\nğ¯\n)\nâˆˆ\nProj\nğ±\n,\nğ¯\nâ¡\n(\nZ\n)\nğ•\n^\n(\nq\n)\nâ€‹\n(\nğ±\n,\nğŠğ±\n+\nğ¯\n)\n.\n\\displaystyle=\\!\\!\\!\\bigcup_{(\\mathbf{x},\\mathbf{v})\\in\\operatorname{Proj}_{\\mathbf{x},\\mathbf{v}}(Z)}\\!\\!\\!\\!\\!\\widehat{\\mathbb{W}}^{(q)}(\\mathbf{x},\\mathbf{K}\\mathbf{x}+\\mathbf{v}).\nAssume\nğ€\n+\nğğŠ\n\\mathbf{A}{+}\\mathbf{B}\\mathbf{K}\nis Schur,\nğ•\n,\nğ•Œ\n,\nğ•\n\\mathbb{X},\\mathbb{U},\\mathbb{V}\nare compact convex, and\n(\nğ±\n,\nğ®\n)\nâ†¦\nğ•\n^\n(\nq\n)\nâ€‹\n(\nğ±\n,\nğ®\n)\n(\\mathbf{x},\\mathbf{u})\\mapsto\\widehat{\\mathbb{W}}^{(q)}(\\mathbf{x},\\mathbf{u})\nhas compact values and closed graph on\nâ„›\nx\n,\nu\n\\mathcal{R}_{x,u}\n. Pick a non-empty compact\nZ\n0\nâŠ†\nğ’¢\nZ_{0}\\subseteq\\mathcal{G}\nwith\nâ„±\nâ€‹\n(\nZ\n0\n)\nâŠ†\nZ\n0\n\\mathcal{F}(Z_{0})\\subseteq Z_{0}\n. Then: (\nExistence and convergence\n) The sequence\nZ\nk\n+\n1\n=\nâ„±\nâ€‹\n(\nZ\nk\n)\nZ_{k+1}=\\mathcal{F}(Z_{k})\nis decreasing,\nZ\nk\n+\n1\nâŠ†\nZ\nk\nZ_{k+1}\\subseteq Z_{k}\n, and converges (in the PainlevÃ©â€“Kuratowski sense) to a non-empty compact fixed point\nZ\nâ‹†\n=\nâ„±\nâ€‹\n(\nZ\nâ‹†\n)\nâŠ†\nğ’¢\nZ^{\\star}=\\mathcal{F}(Z^{\\star})\\subseteq\\mathcal{G}\n. (\nPlant-level invariance\n) There exists a Borel-measurable selector\nğ›‹\n:\nâ„¤\nâ‹†\nâ†’\nğ•\n\\bm{\\kappa}:\\mathbb{Z}^{\\star}\\to\\mathbb{V}\nsuch that, with\nâ„¤\nâ‹†\n:=\nProj\nğ±\nâ¡\n(\nZ\nâ‹†\n)\n\\mathbb{Z}^{\\star}:=\\operatorname{Proj}_{\\mathbf{x}}(Z^{\\star})\n,\n(\nğ€\n+\nğğŠ\n)\nâ€‹\nğ±\n+\nğ\nâ€‹\nğ›‹\nâ€‹\n(\nğ±\n)\n+\nğ°\nâˆˆ\nâ„¤\nâ‹†\nâ€‹\nâˆ€\nğ±\nâˆˆ\nâ„¤\nâ‹†\n,\nâˆ€\nğ°\nâˆˆ\nğ•\n^\n(\nq\n)\nâ€‹\n(\nğ±\n,\nğŠğ±\n+\nğ›‹\nâ€‹\n(\nğ±\n)\n)\n.\n(\\mathbf{A}{+}\\mathbf{B}\\mathbf{K})\\mathbf{x}+\\mathbf{B}\\,\\bm{\\kappa}(\\mathbf{x})+\\mathbf{w}\\ \\in\\ \\mathbb{Z}^{\\star}\\\\\n\\forall\\mathbf{x}\\in\\mathbb{Z}^{\\star},\\ \\forall\\mathbf{w}\\in\\widehat{\\mathbb{W}}^{(q)}\\bigl(\\mathbf{x},\\mathbf{K}\\mathbf{x}+\\bm{\\kappa}(\\mathbf{x})\\bigr).\nHence\nâ„¤\nâ‹†\n\\mathbb{Z}^{\\star}\nis RPI for the plant with respect to the epoch outer wrapper\nğ•\n^\n(\nq\n)\nâ€‹\n(\nâ‹…\n)\n\\widehat{\\mathbb{W}}^{(q)}(\\cdot)\n. (Per-epoch uniform safety) With probability at least\n1\nâˆ’\nÎ±\nepoch\n1-\\alpha_{\\mathrm{epoch}}\n(over the GP posterior within epoch\nq\nq\n), the true disturbance satisfies\nğ°\nâ€‹\n(\nğ±\n,\nğ®\n)\nâˆˆ\nğ•\n^\n(\nq\n)\nâ€‹\n(\nğ±\n,\nğ®\n)\n\\mathbf{w}(\\mathbf{x},\\mathbf{u})\\in\\widehat{\\mathbb{W}}^{(q)}(\\mathbf{x},\\mathbf{u})\nsimultaneously for all\n(\nğ±\n,\nğ®\n)\nâˆˆ\nâ„›\nx\n,\nu\n(\\mathbf{x},\\mathbf{u})\\in\\mathcal{R}_{x,u}\n; consequently, with the same probability,\nâ„¤\nâ‹†\n\\mathbb{Z}^{\\star}\nis RPI for the true plant disturbances throughout the epoch. (Epoch nesting) If the next-epoch wrapper tightens,\nğ•\n^\n(\nq\n+\n1\n)\nâŠ†\nğ•\n^\n(\nq\n)\n\\widehat{\\mathbb{W}}^{(q+1)}\\subseteq\\widehat{\\mathbb{W}}^{(q)}\n, then the corresponding fixed points satisfy\nZ\nâ‹†\n,\n(\nq\n+\n1\n)\nâŠ†\nZ\nâ‹†\n,\n(\nq\n)\nZ^{\\star,(q+1)}\\subseteq Z^{\\star,(q)}\nand\nProj\nğ±\nâ¡\n(\nZ\nâ‹†\n,\n(\nq\n+\n1\n)\n)\nâŠ†\nProj\nğ±\nâ¡\n(\nZ\nâ‹†\n,\n(\nq\n)\n)\n\\operatorname{Proj}_{\\mathbf{x}}(Z^{\\star,(q+1)})\\subseteq\\operatorname{Proj}_{\\mathbf{x}}(Z^{\\star,(q)})\n.\nProof.\nConvergence.\nBy Lemma\n1\n,\nâ„±\n\\mathcal{F}\nis isotone. The initialization\nâ„±\nâ€‹\n(\nZ\n0\n)\nâŠ†\nZ\n0\n\\mathcal{F}(Z_{0})\\subseteq Z_{0}\nmakes the sequence\nZ\nk\n+\n1\n=\nâ„±\nâ€‹\n(\nZ\nk\n)\nZ_{k+1}=\\mathcal{F}(Z_{k})\ndecreasing. The sets are nonempty and uniformly bounded (compactness of\nğ•\n,\nğ•\n\\mathbb{X},\\mathbb{V}\nand of the values of\nğ•\n^\n(\nq\n)\n\\widehat{\\mathbb{W}}^{(q)}\n, plus Schur stability of\nğ€\n+\nğğŠ\n\\mathbf{A}{+}\\mathbf{B}\\mathbf{K}\nensure bounded images), hence by Cantorâ€™s theorem the intersection\nZ\nâ‹†\n:=\nâ‹‚\nk\nZ\nk\nZ^{\\star}:=\\bigcap_{k}Z_{k}\nis nonempty and compact. Closedness of the graph of\nâ„±\n\\mathcal{F}\n(induced by linearity, Minkowski sums, and the closed graph of\nğ•\n^\n(\nq\n)\n\\widehat{\\mathbb{W}}^{(q)}\n) yields\nZ\nâ‹†\n=\nâ„±\nâ€‹\n(\nZ\nâ‹†\n)\nZ^{\\star}=\\mathcal{F}(Z^{\\star})\nas in Lemma\n2\n.\nPlant-level invariance.\nBy Lemma\n3\n, closed-graph and compact-valuedness of\n(\nğ±\n,\nğ®\n)\nâ†¦\nğ•\n^\n(\nq\n)\nâ€‹\n(\nğ±\n,\nğ®\n)\n(\\mathbf{x},\\mathbf{u})\\mapsto\\widehat{\\mathbb{W}}^{(q)}(\\mathbf{x},\\mathbf{u})\nimply the existence of a Borel selector\nÎº\nâ€‹\n(\nâ‹…\n)\n\\kappa(\\cdot)\nso that the projection\nâ„¤\nâ‹†\n\\mathbb{Z}^{\\star}\nis RPI for the lifted disturbance wrapper, establishing the claim.\nPer-epoch uniform safety.\nBy Lemma\n4\nand the choice\nÎ±\nanc\n=\nÎ±\nepoch\n/\n|\nğ’œ\nx\n,\nv\n|\n\\alpha_{\\mathrm{anc}}=\\alpha_{\\mathrm{epoch}}/|\\mathcal{A}_{x,v}|\n, with probability at least\n1\nâˆ’\nÎ±\nepoch\n1-\\alpha_{\\mathrm{epoch}}\nwe have the\nsimultaneous\ninclusion\nğ°\nâ€‹\n(\nğ±\n,\nğ®\n)\nâˆˆ\nğ•\n^\n(\nq\n)\nâ€‹\n(\nğ±\n,\nğ®\n)\n\\mathbf{w}(\\mathbf{x},\\mathbf{u})\\in\\widehat{\\mathbb{W}}^{(q)}(\\mathbf{x},\\mathbf{u})\nfor all\n(\nğ±\n,\nğ®\n)\nâˆˆ\nâ„›\nx\n,\nu\n(\\mathbf{x},\\mathbf{u})\\in\\mathcal{R}_{x,u}\nduring epoch\nq\nq\n. The fixed-point\nZ\nâ‹†\nZ^{\\star}\nwas computed against this (outer) wrapper; by monotonicity, invariance for the outer wrapper implies invariance for the true (smaller) disturbances, uniformly over\nâ„›\nx\n,\nv\n\\mathcal{R}_{x,v}\nwithin the epoch.\nEpoch nesting.\nIf\nğ•\n^\n(\nq\n+\n1\n)\nâŠ†\nğ•\n^\n(\nq\n)\n\\widehat{\\mathbb{W}}^{(q+1)}\\subseteq\\widehat{\\mathbb{W}}^{(q)}\n, then for any\nZ\nZ\nwe have\nâ„±\nq\n+\n1\nâ€‹\n(\nZ\n)\nâŠ†\nâ„±\nq\nâ€‹\n(\nZ\n)\n\\mathcal{F}_{q+1}(Z)\\subseteq\\mathcal{F}_{q}(Z)\n. Applying Lemma\n1\nto the two operators yields\nZ\nâ‹†\n,\n(\nq\n+\n1\n)\nâŠ†\nZ\nâ‹†\n,\n(\nq\n)\nZ^{\\star,(q+1)}\\subseteq Z^{\\star,(q)}\nand the corresponding inclusion of state projections.\nâˆ\n4\nSimulation and Results\nWe evaluate on a 2D double integrator with\nx\n=\n[\np\nx\n,\np\ny\n,\nv\nx\n,\nv\ny\n]\nâŠ¤\nx=[p_{x},p_{y},v_{x},v_{y}]^{\\top}\n,\nu\n=\n[\na\nx\n,\na\ny\n]\nâŠ¤\nu=[a_{x},a_{y}]^{\\top}\n, and additive, state- and inputâ€“dependent disturbances on acceleration,\n[\nw\nx\nw\ny\n]\n=\nâˆ’\nÎ²\n1\nm\nâ€‹\nâ€–\nğ¯\nâ€–\nâ€‹\n[\nv\nx\nv\ny\n]\nâˆ’\nÎ²\n2\nm\nâ€‹\n[\nu\nx\nu\ny\n]\n+\nÏ‘\n,\n\\begin{bmatrix}w_{x}\\\\\nw_{y}\\end{bmatrix}=-\\frac{\\beta_{1}}{m}\\|\\mathbf{v}\\|\\!\\begin{bmatrix}v_{x}\\\\\nv_{y}\\end{bmatrix}-\\frac{\\beta_{2}}{m}\\!\\begin{bmatrix}u_{x}\\\\\nu_{y}\\end{bmatrix}+\\mathbf{\\vartheta},\nwhere\nâ€–\nğ¯\nâ€–\n\\|\\mathbf{v}\\|\nis the magnitude of the velocity vector in meters per second (m/s),\nm\nm\nis the mass of the system in kg,\nÎ²\n1\n\\beta_{1}\nis the aerodynamic drag coefficient in kg/m,\nÎ²\n2\n\\beta_{2}\nis the actuator efficiency coefficient in kg, and\nÏ‘\n=\n[\nÏ‘\nx\n,\nÏ‘\ny\n]\nT\n\\mathbf{\\vartheta}=[\\vartheta_{x},\\vartheta_{y}]^{T}\nis the process noise vector in m/s\n2\n.\nDisturbance learning.\nFigures\n1\n(a,b) illustrate representative slices: velocity-dependent drag in\n(\nv\nx\n,\nu\nx\n)\n(v_{x},u_{x})\nand input coupling in\n(\nu\nx\n,\nu\ny\n)\n(u_{x},u_{y})\n.\nThese learned structures tighten the local disturbance polytopes where data are informative, reducing conservatism while preserving hard safety via the fixed-point tube. In our bounded domain these coincide; we report\nZ\nâ‹†\nZ^{\\star}\n. Figures\n1\n(c,d) show the contraction to\nZ\nâ‹†\nZ^{\\star}\n(yellow) entirely within the graph constraint (blue).\nProjecting back gives\nProj\nx\nâ¡\n(\nZ\nâ‹†\n)\n\\operatorname{Proj}_{x}(Z^{\\star})\n, which is RPI for the plant and provides tube cross-sections for MPC. Our verifiably safe learning approach demonstrates 22.9\nÃ—\n\\times\nimproved accuracy over traditional fixed bounds, reducing overall conservatism by 55.4% compared to worst-case methods while maintaining safety guarantees.\n(a)\nw\nx\nw_{x}\nover\n(\nv\nx\n,\nu\nx\n)\n(v_{x},u_{x})\n(b)\nw\ny\nw_{y}\nover\n(\nu\nx\n,\nu\ny\n)\n(u_{x},u_{y})\n(c)\n(\nv\nx\n,\nu\nx\n,\nw\nx\n)\n(v_{x},u_{x},w_{x})\nslice\n(d)\n(\np\nx\n,\nu\nx\n,\nw\nx\n)\n(p_{x},u_{x},w_{x})\nslice\nFigure 1:\nGPâ€“learned disturbance structure and liftedâ€“space RPI.\n(a,b)\nGP posteriors expose state- and inputâ€“dependent effects used to size local disturbance sets.\n(c,d)\nThe liftâ€“andâ€“project iteration converges to a compact invariant set (yellow) contained in the graph constraint\nğ’¢\n\\mathcal{G}\n(blue). The final projected RPI facet count is\nProj\nğ±\n(\nZ\nâ‹†\n,\n(\nq\n)\n)\nn\nf\n=\n1466\n{\\operatorname{Proj}_{\\mathbf{x}}(Z^{\\star,(q)})}_{n_{f}}=1466\n, convergence metric: Hausdorff distance\nAlgorithm 1\nSTMPC epoch loop\n1:\ndataset\nğ’Ÿ\nq\n\\mathcal{D}_{q}\n, nominal\n(\nğ€\n,\nğ\n)\n(\\mathbf{A},\\mathbf{B})\n, sets\n(\nğ•\n,\nğ•Œ\n,\nğ•\n)\n(\\mathbb{X},\\mathbb{U},\\mathbb{V})\n, gain\nğŠ\n\\mathbf{K}\n, warm start\nZ\nâ‹†\n,\n(\nq\nâˆ’\n1\n)\nZ^{\\star,(q-1)}\n(optional)\n2:\nTrain GP:\nfit independent GPs for\nğ°\nâ€‹\n(\nâ‹…\n,\nâ‹…\n)\n\\mathbf{w}(\\cdot,\\cdot)\non\nğ’Ÿ\nq\n\\mathcal{D}_{q}\nto get\nğ\n^\nğ°\nâ€‹\n(\nğ±\n,\nğ®\n)\n\\hat{\\bm{\\mu}}_{\\mathbf{w}}(\\mathbf{x},\\mathbf{u})\n,\nğšº\n^\nğ°\nâ€‹\n(\nğ±\n,\nğ®\n)\n\\hat{\\bm{\\Sigma}}_{\\mathbf{w}}(\\mathbf{x},\\mathbf{u})\n.\n3:\nEllipsoid\nâ†’\n\\to\nPolytope:\nform\nğ”¼\nâ€‹\n(\nğ±\n,\nğ®\n)\n\\mathbb{E}(\\mathbf{x},\\mathbf{u})\nat level\n1\nâˆ’\nÎ±\n1-\\alpha\n; outer-approximate by\nğ•\n^\nâ€‹\n(\nğ±\n,\nğ®\n)\n\\widehat{\\mathbb{W}}(\\mathbf{x},\\mathbf{u})\n(facet-limited).\n4:\nLifted graph:\nset\nğ’¢\n=\n{\n(\nğ±\n,\nğ¯\n,\nğ°\n)\n:\nğ°\nâˆˆ\nğ•\n^\nâ€‹\n(\nğ±\n,\nğŠğ±\n+\nğ¯\n)\n}\n\\mathcal{G}=\\{(\\mathbf{x},\\mathbf{v},\\mathbf{w}):\\,\\mathbf{w}\\in\\widehat{\\mathbb{W}}(\\mathbf{x},\\mathbf{K}\\mathbf{x}+\\mathbf{v})\\}\n; initialize\nZ\n0\nâŠ†\nğ’¢\nZ_{0}\\subseteq\\mathcal{G}\n(warm-start\nZ\nâ‹†\n,\n(\nq\nâˆ’\n1\n)\nZ^{\\star,(q-1)}\n).\n5:\nOutside-in:\niterate\nZ\nk\n+\n1\n=\n(\nğ€\n~\nâ€‹\nZ\nk\nâŠ•\nğ\n~\nâ€‹\nÎ”\nâ€‹\nğ•\nâŠ•\nğƒ\n~\nâ€‹\nW\nâ€‹\n(\nZ\nk\n)\n)\nâˆ©\nğ’¢\nZ_{k+1}=\\big(\\widetilde{\\mathbf{A}}Z_{k}\\oplus\\widetilde{\\mathbf{B}}\\,\\Delta\\mathbb{V}\\oplus\\widetilde{\\mathbf{D}}\\,W(Z_{k})\\big)\\cap\\mathcal{G}\nuntil gap\n<\nÎµ\n<\\varepsilon\n.\n6:\nProjection:\nset\nZ\nâ‹†\n,\n(\nq\n)\n=\nfix\nâ€‹\n(\nZ\nk\n)\nZ^{\\star,(q)}=\\mathrm{fix}(Z_{k})\nand\nâ„¤\nâ‹†\n,\n(\nq\n)\n=\nProj\nğ±\nâ¡\n(\nZ\nâ‹†\n,\n(\nq\n)\n)\n\\mathbb{Z}^{\\star,(q)}=\\operatorname{Proj}_{\\mathbf{x}}(Z^{\\star,(q)})\n; choose measurable selector\nğœ¿\nâ€‹\n(\nğ±\n)\nâˆˆ\nğ•\n\\bm{\\kappa}(\\mathbf{x})\\in\\mathbb{V}\n.\n7:\nMPC:\ntighten with\nâ„¤\nâ‹†\n,\n(\nq\n)\n\\mathbb{Z}^{\\star,(q)}\nand apply\nğ®\n=\nğŠğ±\n+\nğœ¿\nâ€‹\n(\nğ±\n)\n\\mathbf{u}=\\mathbf{K}\\mathbf{x}+\\bm{\\kappa}(\\mathbf{x})\n.\n8:\nRepeat:\nacquire new data, update\nğ’Ÿ\nq\n+\n1\n\\mathcal{D}_{q+1}\n; set\nq\nâ†\nq\n+\n1\nq\\!\\leftarrow\\!q{+}1\nand repeat from StepÂ 1 (warm-start\nZ\n0\nâ†\nZ\nâ‹†\n,\n(\nq\nâˆ’\n1\n)\nZ_{0}\\!\\leftarrow\\!Z^{\\star,(q-1)}\n).\n5\nConclusion\nWe presented a learning-based shrinking disturbance invariant scheme that couples with tube MPCs, which learns state- and input-dependent disturbances with GPs and certifies safety through a lifted, orderâ€“preserving outsideâ€“in fixedâ€“point. Two-time-scale operation (frozen â€œepochsâ€ for learning versus inner fixed-point iterations) resolves circularity and yields\nepoch-to-epoch nesting\nof tubes as uncertainty contracts. A double-integrator study illustrates how data tighten local disturbance polytopes and shrink tube cross-sections without relaxing hard constraints. We also detailed a uniform-safety construction over anchor grids. Future work should address the practical computation of the guaranteed measurable selector policy and the robust estimation of Lipschitz constants for uniform safety bounds. A key extension is to handle temporally correlated (colored) disturbances, requiring an augmented state to model disturbance dynamics.\nReferences\n[1]\nT. Benciolini, C. Tang, M. Leibold, C. Weaver, M. Tomizuka, and W. Zhan\n(2025)\nActive exploration in iterative gaussian process regression for uncertainty modeling in autonomous racing\n.\nIEEE Transactions on Control Systems Technology\n33\n(\n4\n),\npp.Â 1301â€“1316\n.\nExternal Links:\nDocument\nCited by:\nÂ§1\n,\nÂ§1\n.\n[2]\nF. Blanchini and S. Miani\n(2008)\nSet-theoretic methods in control\n.\nBirkhÃ¤user\n,\nBoston\n.\nExternal Links:\nISBN 978-0-8176-3255-7\n,\nDocument\nCited by:\nÂ§1\n.\n[3]\nM. S. Darup, R. M. Schaich, and M. Cannon\n(2016)\nParametric robust positively invariant sets for linear systems with scaled disturbances\n.\nIn\n2016 IEEE 55th Conference on Decision and Control (CDC)\n,\npp.Â 1496â€“1501\n.\nExternal Links:\nDocument\nCited by:\nÂ§1\n,\nÂ§1\n,\nÂ§1\n.\n[4]\nR. Ghaemi, W. Xie, and J. Sun\n(2011)\nRobust control of linear systems with disturbances bounded in a state-dependent set\n.\nIEEE Transactions on Automatic Control\n56\n(\n12\n),\npp.Â 2944â€“2950\n.\nExternal Links:\nDocument\nCited by:\nÂ§1\n,\nÂ§1\n,\nÂ§1\n,\nÂ§2.3.1\n.\n[5]\nL. Hewing, A. Carron, K. P. Wabersich, and M. N. Zeilinger\n(2018)\nOn a correspondence between probabilistic and robust invariant sets for linear systems\n.\nIn\n2018 European Control Conference (ECC)\n,\npp.Â 1642â€“1647\n.\nExternal Links:\nDocument\nCited by:\nÂ§2.2\n.\n[6]\nL. Hewing, J. Kabzan, and M. N. Zeilinger\n(2020)\nCautious model predictive control using gaussian process regression\n.\nIEEE Transactions on Control Systems Technology\n28\n(\n6\n),\npp.Â 2736â€“2743\n.\nExternal Links:\nDocument\nCited by:\nÂ§1\n,\nÂ§1\n,\nÂ§1\n.\n[7]\nT. Koller, F. Berkenkamp, M. Turchetta, and A. Krause\n(2018)\nLearning-based model predictive control for safe exploration\n.\nIn\n2018 IEEE Conference on Decision and Control (CDC)\n,\npp.Â 6059â€“6066\n.\nExternal Links:\nDocument\nCited by:\nÂ§1\n,\nÂ§1\n,\nÂ§1\n,\nÂ§2.3.1\n.\n[8]\nI. Kolmanovsky and E. G. Gilbert\n(1998)\nTheory and computation of disturbance invariant sets for discrete-time linear systems\n.\nMathematical Problems in Engineering\n4\n(\n4\n),\npp.Â 317â€“367\n.\nExternal Links:\nDocument\nCited by:\nÂ§1\n,\nÂ§2.3\n.\n[9]\nD. Malyuta, B. AÃ§ikmeÅŸe, and M. Cacan\n(2019)\nRobust model predictive control for linear systems with state and input dependent uncertainties\n.\nIn\n2019 American Control Conference (ACC)\n,\nVol.\n,\npp.Â 1145â€“1151\n.\nExternal Links:\nDocument\nCited by:\nÂ§1\n,\nÂ§1\n.\n[10]\nR. D. McAllister and P. M. Esfahani\n(2025)\nDistributionally robust model predictive control: closed-loop guarantees and scalable algorithms\n.\nIEEE Transactions on Automatic Control\n70\n(\n5\n),\npp.Â 2963â€“2978\n.\nExternal Links:\nDocument\nCited by:\nÂ§1\n.\n[11]\nF. Micheli, T. Summers, and J. Lygeros\n(2022)\nData-driven distributionally robust mpc for systems with uncertain dynamics\n.\nIn\n2022 IEEE 61st Conference on Decision and Control (CDC)\n,\nVol.\n,\npp.Â 4788â€“4793\n.\nExternal Links:\nDocument\nCited by:\nÂ§1\n.\n[12]\nM. Prajapat, A. Lahr, J. KÃ¶hler, A. Krause, and M. N. Zeilinger\n(2024)\nTowards safe and tractable gaussian process-based mpc: efficient sampling within a sequential quadratic programming framework\n.\nIn\n2024 IEEE 63rd Conference on Decision and Control (CDC)\n,\nVol.\n,\npp.Â 7458â€“7465\n.\nExternal Links:\nDocument\nCited by:\nÂ§1\n,\nÂ§1\n.\n[13]\nS. V. RakoviÄ‡, E. C. Kerrigan, and D. Q. Mayne\n(2003)\nReachability computations for constrained discrete-time systems with state- and input-dependent disturbances\n.\nIn\n42nd IEEE International Conference on Decision and Control (CDC)\n,\nVol.\n4\n,\npp.Â 3905â€“3910\n.\nExternal Links:\nDocument\nCited by:\nÂ§1\n,\nÂ§2.1\n,\nÂ§2.3.1\n.\n[14]\nC. E. Rasmussen and C. K. I. Williams\n(2006)\nGaussian processes for machine learning\n.\nMIT Press\n,\nCambridge, MA\n.\nExternal Links:\nISBN 978-0-262-18253-9\nCited by:\nÂ§1\n.\n[15]\nR. M. Schaich and M. Cannon\n(2015)\nRobust positively invariant sets for state dependent disturbances\n.\nIFAC-PapersOnLine\n48\n(\n23\n),\npp.Â 284â€“289\n.\nExternal Links:\nDocument\nCited by:\nÂ§1\n,\nÂ§1\n,\nÂ§1\n,\nÂ§2.3.1\n.\n[16]\nP. Trodden\n(2016)\nA one-step approach to computing a polytopic robust positively invariant set\n.\nIEEE Transactions on Automatic Control\n61\n(\n12\n),\npp.Â 4100â€“4105\n.\nExternal Links:\nDocument\nCited by:\nÂ§3.1\n.\n[17]\nK. P. Wabersich and M. N. Zeilinger\n(2021)\nNonlinear learning-based model predictive control supporting state and input dependent model uncertainty estimates\n.\nInternational Journal of Robust and Nonlinear Control\n31\n(\n18\n),\npp.Â 8897â€“8915\n.\nExternal Links:\nDocument\n,\nLink\n,\nhttps://onlinelibrary.wiley.com/doi/pdf/10.1002/rnc.5688\nCited by:\nÂ§1\n,\nÂ§1\n.\n[18]\nK. Wang, S. Zhang, S. Gros, and S. V. RakoviÄ‡\n(2024)\nTube mpc with time-varying cross-sections\n.\nIEEE Transactions on Automatic Control\n.\nExternal Links:\nDocument\nCited by:\nÂ§1\n.",
    "preview_text": "We develop a learning-based framework for constructing shrinking disturbance-invariant tubes under state- and input-dependent uncertainty, intended as a building block for tube Model Predictive Control (MPC), and certify safety via a lifted, isotone (order-preserving) fixed-point map. Gaussian Process (GP) posteriors become $(1-Î±)$ credible ellipsoids, then polytopic outer sets for deterministic set operations. A two-time-scale scheme separates learning epochs, where these polytopes are frozen, from an inner, outside-in iteration that converges to a compact fixed point $Z^\\star\\!\\subseteq\\!\\mathcal G$; its state projection is RPI for the plant. As data accumulate, disturbance polytopes tighten, and the associated tubes nest monotonically, resolving the circular dependence between the set to be verified and the disturbance model while preserving hard constraints. A double-integrator study illustrates shrinking tube cross-sections in data-rich regions while maintaining invariance.\n\nLearning-Based Shrinking Disturbance-Invariant Tubes for State- and Input-Dependent Uncertainty\nAbdelrahman Ramadan\n\\IEEEmembership\nGraduate Student Member, IEEE\n1\nSidney Givigi\n\\IEEEmembership\nSenior Member, IEEE\n2\n1\nA. Ramadan is with Electrical and Computer Engineering (ECE), Smith Engineering and with Ingenuity Labs Research Institute, Queenâ€™s University, Kingston, ON K7L 3N6 Canada, 20amr3@queensu.ca\n2\nS. Givigi is with the School of Computing and with Ingenuity Labs Research Institute, Queenâ€™s University, Kingston, ON K7L 3N6 Canada, sidney.givigi@queensu.ca\nAbstract\nWe develop a learning-based framework for constructing shrinking disturbance-invariant tubes under state- and input-dependent uncertainty, intended as a building block for tube Model Predictive Control (MPC), and certify safety via a lifted,\nisotone\n(order-preserving) fixed-point map. Gaussian Process (GP) posteriors become\n(\n1\nâˆ’\nÎ±\n)\n(1-\\alpha)\ncredible ellipsoids, then polytopic outer sets for deterministic set operation",
    "is_relevant": false,
    "relevance_score": 2.0,
    "extracted_keywords": [
        "Learning-Based",
        "Tube MPC",
        "Gaussian Process",
        "Safety Certification",
        "Uncertainty"
    ],
    "one_line_summary": "è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºå­¦ä¹ çš„æ–¹æ³•ï¼Œç”¨äºæ„å»ºåœ¨çŠ¶æ€å’Œè¾“å…¥ç›¸å…³ä¸ç¡®å®šæ€§ä¸‹çš„æ”¶ç¼©æ‰°åŠ¨ä¸å˜ç®¡ï¼Œä½œä¸ºç®¡æ¨¡å‹é¢„æµ‹æ§åˆ¶çš„åŸºç¡€æ¨¡å—ï¼Œå¹¶é€šè¿‡å›ºå®šç‚¹æ˜ å°„ç¡®ä¿å®‰å…¨æ€§ã€‚",
    "detailed_summary": "",
    "qa_pairs": [],
    "is_hidden": false,
    "is_starred": false,
    "flag": true,
    "published_date": "2026-01-16T16:47:04Z",
    "created_at": "2026-01-20T17:50:01.745786",
    "updated_at": "2026-01-20T17:50:01.745795",
    "recommend": 0
}