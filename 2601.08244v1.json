{
  "id": "2601.08244v1",
  "title": "A brain-inspired information fusion method for enhancing robot GPS outages navigation",
  "authors": [
    "Yaohua Liu",
    "Hengjun Zhang",
    "Binkai Ou"
  ],
  "abstract": "Low-cost inertial navigation systems (INS) are prone to sensor biases and measurement noise, which lead to rapid degradation of navigation accuracy during global positioning system (GPS) outages. To address this challenge and improve positioning continuity in GPS-denied environments, this paper proposes a brain-inspired GPS/INS fusion network (BGFN) based on spiking neural networks (SNNs). The BGFN architecture integrates a spiking Transformer with a spiking encoder to simultaneously extract spatial features from inertial measurement unit (IMU) signals and capture their temporal dynamics. By modeling the relationship between vehicle attitude, specific force, angular rate, and GPS-derived position increments, the network leverages both current and historical IMU data to estimate vehicle motion. The effectiveness of the proposed method is evaluated through real-world field tests and experiments on public datasets. Compared to conventional deep learning approaches, the results demonstrate that BGFN achieves higher accuracy and enhanced reliability in navigation performance, particularly under prolonged GPS outages.",
  "url": "https://arxiv.org/abs/2601.08244v1",
  "html_url": "https://arxiv.org/html/2601.08244v1",
  "html_content": "A brain-inspired information fusion method for enhancing robot GPS outages navigation\nYaohua Liu\nHengjun Zhang\nBinkai Ou\nAbstract\nLow-cost inertial navigation systems (INS) are prone to sensor biases and measurement noise, which lead to rapid degradation of navigation accuracy during global positioning system (GPS) outages. To address this challenge and improve positioning continuity in GPS-denied environments, this paper proposes a brain-inspired GPS/INS fusion network (BGFN) based on spiking neural networks (SNNs). The BGFN architecture integrates a spiking Transformer with a spiking encoder to simultaneously extract spatial features from inertial measurement unit (IMU) signals and capture their temporal dynamics. By modeling the relationship between vehicle attitude, specific force, angular rate, and GPS-derived position increments, the network leverages both current and historical IMU data to estimate vehicle motion. The effectiveness of the proposed method is evaluated through real-world field tests and experiments on public datasets. Compared to conventional deep learning approaches, the results demonstrate that BGFN achieves higher accuracy and enhanced reliability in navigation performance, particularly under prolonged GPS outages.\nkeywords:\nRobot localization, spike neural network, inertial measurement unit, GPS outages.\n‚Ä†\n‚Ä†\njournal:\nInformation Fusion\n\\affiliation\n[label1]organization=Guangdong Institute of Intelligence Science and Technology,addressline=Hengqin,\ncity=Zhuhai,\npostcode=519031,\nstate=Guangdong,\ncountry=China\n\\affiliation\n[label2]organization=School of Electronic Engineering and Automation, Guilin University of Electronic Technology,city=Guilin,\npostcode=541000,\nstate=Guangxi,\ncountry=China\n\\affiliation\n[label3]organization=Innovation and Research and Development Department, BoardWare Information System Company Ltd,city=Macau,\npostcode=999078,\ncountry=China\n1\nIntroduction\nThe integration of the inertial navigation system (INS) and global positioning system (GPS) provides a high-precision navigation solution that is widely used in ground vehicles and unmanned aerial vehicles (UAVs) when GPS signals are available\n[\n1\n]\n. However, when these vehicles travel through environments with weak GPS signals, such as areas surrounded by tall buildings or inside tunnels, the GPS reception is often blocked. As a result, the integrated system operates in standalone INS mode. In this case, navigation accuracy deteriorates rapidly due to errors in the inertial measurement unit (IMU), including bias drift and scale factor instability\n[\n2\n]\n. Therefore, it is essential to develop integrated navigation systems that can maintain reliable performance in a variety of complex and challenging environments.\nTo mitigate the adverse effects of GPS signal interruptions, a range of fusion strategies have been proposed for enhancing GPS/INS navigation performance. These can generally be categorized into two main approaches. The first involves incorporating auxiliary sensing technologies‚Äîsuch as lidar\n[\n3\n]\n, vision systems\n[\n4\n]\n, or wheel odometry\n[\n5\n]\n‚Äîto compensate for the absence of GPS updates. While effective in improving accuracy, this approach increases both the system‚Äôs cost and its structural complexity. The second relies on machine learning (ML) techniques, including ensemble learning\n[\n6\n]\n, support vector machines (SVMs)\n[\n7\n]\n, and random forest regression (RFR)\n[\n8\n]\n, to emulate the error propagation behavior of standalone INS. By leveraging datasets where GPS measurements are available, these models learn the relationship between vehicle dynamics and INS error states, enabling error prediction during GPS outages.\nThe advancement of artificial intelligence (AI) has led to widespread use of artificial neural networks (ANNs) for improving navigation accuracy. Early studies, such as those by Rashad et al.\n[\n9\n]\n, employed radial basis function neural networks (RBFNNs) to map the relationship between INS-derived positions and the associated errors using GPS data. Similarly, El-Sheimy et al.\n[\n10\n]\ndeveloped an ANN-based INS/GPS integration approach to fuse uncompensated INS outputs with differential GPS measurements. Later work by Zhang et al.\n[\n11\n]\nintroduced a dual optimization framework that combined cubature Kalman filtering (CKF) with multilayer perceptron (MLP) networks, enhancing model precision by adaptively tuning network weights. Doostdar et al.\n[\n12\n]\nfurther explored recurrent fuzzy wavelet neural networks (RFWNNs) to model the connection between INS motion parameters and GNSS/INS discrepancies, enabling more precise corrections during GNSS outages. More recently, Belhajem et al.\n[\n13\n]\nproposed robust INS/GPS fusion methods integrating extended Kalman filters (EKFs) with ML algorithms such as neural networks and SVMs, yielding improved stability and accuracy.\nDespite their promise, most of these approaches are based on static neural network architectures that rely only on current and immediate past INS data, without leveraging a broader history of vehicle dynamics. The absence of long-term temporal context limits localization accuracy during extended GPS interruptions. In recent years, deep learning (DL) techniques have shown superior performance in time-series prediction tasks, including natural language processing and speech recognition\n[\n14\n]\n. Recurrent neural networks (RNNs) are particularly well-suited to modeling sequential data and nonlinear system behavior, offering advantages over traditional ML methods\n[\n15\n,\n16\n,\n17\n,\n18\n]\n. For example, RNNs combined with unscented Kalman filters (UKFs) have been used to estimate and compensate for MEMS gyroscope drift in real time. However, conventional RNNs often suffer from vanishing or exploding gradients when handling long sequences. Long short-term memory (LSTM) networks have been developed to address these issues, enabling denoising of MEMS IMU signals and improved estimation of INS errors using both present and past outputs\n[\n19\n]\n,\n[\n20\n]\n. Hybrid architectures combining convolutional neural networks (CNNs) with gated recurrent units (GRUs) have also been explored for extracting IMU features from noisy measurements\n[\n21\n]\n.\nWhile these DL-based methods demonstrate notable improvements, their dependence on CNNs and RNNs constrains their ability to capture long-term dependencies and extract motion-relevant patterns from IMU sequences heavily affected by random noise. Transformer-based models, such as the bidirectional encoder proposed by Guyard et al.\n[\n22\n]\n, have shown potential in modeling extended temporal patterns for INS/GPS fusion during GPS outages. Nonetheless, these methods typically require large, high-quality datasets to generalize effectively, which limits their applicability in low-data scenarios.\nSpiking neural networks (SNNs), regarded as the third generation of neural network models, have emerged as a promising alternative. SNNs can match the performance of conventional DL models in various time-series applications while offering greater computational efficiency and robustness in temporal feature extraction\n[\n23\n,\n24\n,\n25\n]\n. Their event-driven processing paradigm enables effective handling of low-cost MEMS IMU data with minimal energy consumption, making them well-suited for embedded and resource-constrained navigation systems.\nThis paper proposes an advanced fusion strategy that integrates the Kalman Filter (KF) with a novel brain-inspired GPS/INS fusion network (BGFN) to maintain high navigation accuracy during periods of GPS signal loss. Within the BGFN framework, a spiking encoder is utilized to transform IMU inputs into a high-dimensional spiking representation, facilitating more effective extraction of IMU features from noisy sensor data. Additionally, a spiking Transformer architecture is introduced to capture and model the dynamic motion patterns of mobile robots over time. To support the INS during GPS outages while minimizing computational overhead, a hybrid fusion mechanism leveraging the spiking Transformer is designed. The key contributions of this work are summarized as follows:\n1.\nA novel brain-inspired GPS/INS fusion network, termed BGFN, is introduced to enhance the accuracy of integrated GPS/INS navigation. To the best of the authors‚Äô knowledge, this work represents the first application of a spiking Transformer in the context of GPS/INS fusion. Unlike conventional deep learning-based approaches that primarily rely on current sensor inputs, the proposed hybrid fusion strategy within BGFN incorporates both real-time INS errors and historical inertial data. This enables more accurate modeling of INS error evolution and improved estimation of vehicle dynamic states, particularly during extended GPS outages.\n2.\nA hybrid fusion strategy is proposed to model the nonlinear relationship between sensor measurements and GPS position increments during periods of GPS signal loss. Specifically, during periods of GPS availability, the KF is employed to fuse INS and GPS data, yielding accurate and reliable position and velocity estimates. Concurrently, the synchronized INS and GPS measurements are stored onboard for training the BGFN model. When GPS signals become unavailable, the pre-trained BGFN is activated to predict the GPS position increments, which are then integrated into the navigation solution to sustain high positioning accuracy.\n3.\nIn comparison to conventional neural network models, the proposed BGFN demonstrates superior capability in extracting meaningful spatial features from IMU data amidst sensor noise, thereby improving measurement accuracy. Moreover, thanks to its spiking neural network architecture, BGFN achieves these enhancements with significantly lower computational energy consumption. The performance of the proposed method is comprehensively evaluated through a series of experiments using publicly available datasets as well as real-world field tests, demonstrating its effectiveness and robustness in practical navigation scenarios.\nThe remainder of the paper is organized as follows. In Section II, the mathematical model of the GPS/INS integrated system and KF is explained in detail. Section III describes a process of establishing a navigation model based on BGFN in GPS denied scenarios. Dataset experiments and real field tests are performed and discussed in Section IV. The conclusion is provided in Section V.\n2\nGPS/INS Integrated Navigation System Model\n2.1\nINS Error Model\nThe INS serves as a fundamental component in both INS/GPS and INS/ML integration frameworks, delivering estimates of a vehicle‚Äôs attitude, velocity, and position by double-integrating inertial sensor data from the IMU. However, due to inherent sensor biases and cumulative integration errors, the position and velocity solutions from standalone INS tend to drift rapidly over time. To mitigate this limitation, INS is commonly fused with GPS using a KF to improve overall navigation accuracy and reliability. The architecture of GPS/INS integration can be categorized into three main configurations: loosely coupled, tightly coupled, and ultra-tightly coupled. Among these, loosely coupled integration is widely adopted in vehicle and UAV navigation applications due to its simplicity, ease of implementation, and robust performance under normal operating conditions.\nA loosely coupled GPS/INS integrated navigation system is illustrated in Fig.\n1\n. In this configuration, GPS and INS operate independently, each generating its own navigation solution. To enhance accuracy, the position and velocity outputs from both systems are fed into a KF, which computes their differences and estimates the INS errors based on a predefined error model. These estimated errors are then used to correct the INS solution, resulting in a refined, integrated navigation output that provides improved estimates of position, velocity, and attitude.\nFigure 1:\nA block diagram of a loosely coupled GPS/INS integration.\nAccurate navigation for vehicles and UAVs relies on the proper selection of coordinate systems, particularly the body-fixed frame and the navigation frame. The navigation frame is typically defined as the local geographic coordinate system, which aligns with the north, east, and down (NED) directions and follows the right-hand coordinate rule. This reference frame is widely used in inertial navigation due to its intuitive alignment with geographic directions. A comprehensive derivation of the dynamic error model for the INS is presented in the next section. By omitting higher-order small terms and certain sensor non-idealities, the attitude error equation of the INS can be formulated as,\nœï\nÀô\n=\nœï\n√ó\nœâ\ni\n‚Äã\nn\nn\n+\nŒ¥\n‚Äã\nœâ\ni\n‚Äã\nn\nn\n‚àí\nŒµ\nn\n\\dot{\\phi}=\\phi\\times\\omega_{in}^{n}+\\delta\\omega_{in}^{n}-{\\varepsilon^{n}}\n(1)\nwhere\nœï\n\\phi\nis the attitude angle error;\nœâ\ni\n‚Äã\nn\nn\n\\omega_{in}^{n}\nand\nŒ¥\n‚Äã\nœâ\ni\n‚Äã\nn\nn\n\\delta\\omega_{in}^{n}\nare the angular velocity of the rotation of the navigation coordinate frame relative to the inertial coordinate frame and its error;\nŒµ\nn\n\\varepsilon^{n}\nis the gyroscope drift vector of the navigation coordinate frame.\nThe INS velocity error equation is described as,\nŒ¥\n‚Äã\nV\nÀô\nn\n=\n‚àí\nœï\nn\n√ó\nf\nn\n+\nŒ¥\n‚Äã\nV\nn\n√ó\n(\n2\n‚Äã\nœâ\ni\n‚Äã\ne\nn\n+\nœâ\ne\n‚Äã\nn\nn\n)\n+\nV\nn\n√ó\n(\n2\n‚Äã\nŒ¥\n‚Äã\nœâ\ni\n‚Äã\ne\nn\n+\nŒ¥\n‚Äã\nœâ\ne\n‚Äã\nn\nn\n)\n+\n‚àá\nn\n\\begin{array}[]{c}\\delta{\\dot{V}^{n}}=-{\\phi^{n}}\\times{f^{n}}+\\delta{V^{n}}\\times(2\\omega_{ie}^{n}+\\omega_{en}^{n})+{V^{n}}\\\\\n\\times(2\\delta\\omega_{ie}^{n}+\\delta\\omega_{en}^{n})+{\\nabla^{n}}\\\\\n\\end{array}\n(2)\nwhere\nŒ¥\n‚Äã\nV\nn\n\\delta{V^{n}}\nand\nV\nn\nV^{n}\nare the velocity error and velocity in the east, north and upward, respectively;\nf\nn\nf^{n}\nis the specific force;\nœâ\ni\n‚Äã\ne\nn\n\\omega_{ie}^{n}\nand\nœâ\ne\n‚Äã\nn\nn\n\\omega_{en}^{n}\nare the earth self-rotation rate and the angle rate relative to the earth in the navigation coordinate system, respectively;\n‚àá\nn\n{\\nabla^{n}}\nis the accelerometers‚Äô bias of the navigation frame.\nThe INS position error equation can be expressed as,\n{\nŒ¥\n‚Äã\nL\nÀô\n=\nŒ¥\n‚Äã\nV\nN\nR\nM\n+\nh\n‚àí\nŒ¥\n‚Äã\nh\n‚Äã\nV\nN\n(\nR\nM\n+\nh\n)\n2\nŒ¥\n‚Äã\nŒª\nÀô\n=\nŒ¥\n‚Äã\nV\nE\n‚Äã\nsec\n‚Å°\nL\nR\nN\n+\nh\n+\nŒ¥\n‚Äã\nL\n‚Äã\nV\nE\n‚Äã\ntan\n‚Å°\nL\n‚Äã\nsec\n‚Å°\nL\nR\nN\n+\nh\n‚àí\nŒ¥\n‚Äã\nh\n‚Äã\nV\nE\n‚Äã\nsec\n‚Å°\nL\n(\nR\nN\n+\nh\n)\n2\nŒ¥\n‚Äã\nh\nÀô\n=\nŒ¥\n‚Äã\nV\nU\n\\left\\{\\begin{array}[]{l}\\delta\\dot{L}=\\frac{{\\delta{V_{N}}}}{{{R_{M}}+h}}-\\frac{{\\delta h{V_{N}}}}{{{{({R_{M}}+h)}^{2}}}}\\\\\n\\delta\\dot{\\lambda}=\\frac{{\\delta{V_{E}}\\sec L}}{{{R_{N}}+h}}+\\frac{{\\delta L{V_{E}}\\tan L\\sec L}}{{{R_{N}}+h}}-\\frac{{\\delta h{V_{E}}\\sec L}}{{{{({R_{N}}+h)}^{2}}}}\\\\\n\\delta\\dot{h}=\\delta{V_{U}}\\end{array}\\right.\n(3)\nwhere\nŒ¥\n‚Äã\nL\n\\delta L\n,\nŒ¥\n‚Äã\nŒª\n\\delta\\lambda\nand\nŒ¥\n‚Äã\nh\n\\delta h\nare the errors of latitude, longitude and height;\nŒ¥\n‚Äã\nV\nN\n\\delta V_{N}\n,\nŒ¥\n‚Äã\nV\nU\n\\delta V_{U}\nand\nŒ¥\n‚Äã\nV\nE\n\\delta V_{E}\ndenote the velocity errors in north, east and upward directions respectively;\nR\nM\nR_{M}\nand\nR\nN\nR_{N}\nare the radiuses of the curvature in the meridian and prime vertical.\n2.2\nThe Information fusion model based on Kalman filter\nThe KF is a well-established algorithm in control theory, also referred to as a linear quadratic estimator (LQE), renowned for its ability to estimate unobserved system states with higher accuracy than methods relying on individual measurements\n[\n26\n]\n,\n[\n27\n]\n. To apply the KF for state estimation, the system should first be described by a set of state and measurement equations. Assuming that the true system state at the\nk\nt\n‚Äã\nh\n{{\\rm{k}}^{th}}\ntime step evolves from the state at step\nk\n‚àí\n1\nk-1\n, the discrete-time state transition can be expressed as,\nx\nk\n=\nF\nk\n‚Äã\nx\nk\n‚àí\n1\n+\nB\nk\n‚Äã\nu\nk\n+\nw\nk\n{x_{k}}={F_{k}}{x_{k-1}}+{B_{k}}{u_{k}}+{w_{k}}\n(4)\nwhere\nx\nk\nx_{k}\nis the state vector at the\nk\nt\n‚Äã\nh\n{{\\rm{k}}^{th}}\nmoment;\nF\nk\nF_{k}\nis the state transition model applied to the previous state\nx\nk\n‚àí\n1\nx_{k-1}\n;\nB\nk\nB_{k}\nis the coefficient vector related to the control vector\nu\nk\nu_{k}\n;\nw\nk\nw_{k}\nis the process noise assumed as a zero mean with normal distribution and covariance matrix\nQ\nk\nQ_{k}\n.\nThe measurement equation can be defined as,\nz\nk\n=\nH\nk\n‚Äã\nx\nk\n+\nv\nk\n{z_{k}}={H_{k}}{x_{k}}+{v_{k}}\n(5)\nwhere\nz\nk\nz_{k}\nis the measurement vector;\nH\nk\nH_{k}\nis the observation model which maps the actual state space into the observed space;\nv\nk\nv_{k}\nis the observation noise assumed to be zero mean Gaussian white noise with covariance\nR\nk\nR_{k}\n.\nIf the estimated state vector\nx\nk\nx_{k}\nand measurement vector\nz\nk\nz_{k}\ncan be written in the form of Eq.\n4\nand Eq.\n5\n, and the noise variance\nw\nk\nw_{k}\nand\nv\nk\nv_{k}\nfollow the zero mean Gaussian white noise distribution, the process of KF algorithm can be divided into two parts:\n(i) Time update:\nx\n^\nk\n‚àí\n=\nF\nk\n‚Äã\nx\n^\nk\n‚àí\n1\n+\nB\nk\n‚Äã\nu\nk\nP\nk\n‚àí\n=\nF\nk\n‚Äã\nP\nk\n‚àí\n1\n‚Äã\nF\nk\nT\n+\nQ\n{\\begin{array}[]{*{20}{c}}\\hat{x}_{k}^{-}={F_{k}}{\\hat{x}_{k-1}}+{B_{k}}{u_{k}}\\\\\nP_{k}^{-}={F_{k}}{P_{k-1}}{F_{k}^{T}}+Q\\\\\n\\end{array}}\n(6)\n(ii) Measurement update:\nK\nk\n=\nP\nk\n‚àí\n‚Äã\nH\nk\nT\n‚Äã\n(\nH\nk\n‚Äã\nP\nk\n‚àí\n‚Äã\nH\nk\nT\n+\nR\n)\n‚àí\n1\nx\n^\nk\n=\nx\n^\nk\n‚àí\n+\nK\nk\n‚Äã\n(\nz\nk\n‚àí\nH\nk\n‚Äã\nx\n^\nk\n‚àí\n)\nP\nk\n=\n(\nI\n‚àí\nK\nk\n‚Äã\nH\nk\n)\n‚Äã\nP\nk\n‚àí\n{\\begin{array}[]{*{20}{c}}{K_{k}}=P_{k}^{-}{H_{k}^{T}}{(H_{k}P_{k}^{-}{H_{k}^{T}}+R)^{-1}}\\\\\n{\\hat{x}_{k}}=\\hat{x}_{k}^{-}+{K_{k}}({z_{k}}-H_{k}\\hat{x}_{k}^{-})\\\\\n{P_{k}}=(I-{K_{k}}H_{k})P_{k}^{-}\\\\\n\\end{array}}\n(7)\nIn Eq.\n6\n,\nx\n^\nk\n‚àí\n\\hat{x}_{k}^{-}\ndenotes the a priori estimate of the system state at time step\nk\nk\n, and\nP\nk\n‚àí\nP_{k}^{-}\nrepresents the corresponding a priori error covariance matrix. In Eq.\n7\n,\nP\nk\nP_{k}\nis the updated (a posteriori) state covariance matrix, and\nK\nk\nK_{k}\nis the Kalman gain matrix, which determines the weight given to the measurement residual in correcting the state estimate. The core mechanism of the KF involves the iterative execution of two phases: prediction (time update) and correction (measurement update). Through this recursive process, the optimal state estimate\nx\n^\nk\n\\hat{x}_{k}\nis computed at each time step, provided that initial values for the state vector\nx\n0\nx_{0}\nand the error covariance matrix\nP\n0\nP_{0}\nare available.\nThe INS error model in Section II is suitable for vehicle stop and motion. The KF with a 15-state vector\nx\ncan be employed to correct the INS errors, and the system state vector\nx\nis defined as,\nx\n=\n[\nœÜ\nE\nœÜ\nN\nœÜ\nD\nŒ¥\n‚Äã\nV\nE\nŒ¥\n‚Äã\nV\nN\nŒ¥\n‚Äã\nV\nD\nŒ¥\n‚Äã\nL\nŒ¥\n‚Äã\nŒª\nŒ¥\n‚Äã\nh\n‚àá\nx\n‚àá\ny\n‚àá\nz\nŒµ\nx\nŒµ\ny\nŒµ\nz\n]\n\\begin{array}[]{*{20}{c}}{\\textbf{x}}=[{\\varphi_{E}}&{\\varphi_{N}}&{\\varphi_{D}}&{\\delta{V_{E}}}&{\\delta{V_{N}}}&{\\delta{V_{D}}}&{\\delta L}&{\\delta\\lambda}\\\\\n&{\\delta h}&{\\nabla_{x}}&{\\nabla_{y}}&{\\nabla_{z}}&{\\varepsilon_{x}}&{\\varepsilon_{y}}&{\\varepsilon_{z}}]\\end{array}\n(8)\nwhere\n(\nœÜ\nE\n,\nœÜ\nN\n,\nœÜ\nD\n)\n({\\varphi_{E}},{\\varphi_{N}},{\\varphi_{D}})\nare the misalignment angles of the calculated platform in the east-north-up navigation coordinate system;\n(\nŒ¥\n‚Äã\nV\nN\n,\nŒ¥\n‚Äã\nV\nE\n,\nŒ¥\n‚Äã\nV\nD\n)\n(\\delta{V_{N}},\\delta{V_{E}},\\delta{V_{D}})\nare the velocity errors.\nŒ¥\n‚Äã\nL\n\\delta L\n,\nŒ¥\n‚Äã\nŒª\n\\delta\\lambda\nand\nŒ¥\n‚Äã\nh\n\\delta h\nare the latitude, longitude and height errors, respectively.\n‚àá\nx\n,\n‚Äã\ny\n,\n‚Äã\nz\n{\\nabla_{{{\\rm{x}}_{,}}{y_{,}}z}}\nand\nŒµ\nx\n,\n‚Äã\ny\n,\n‚Äã\nz\n{\\varepsilon_{{{\\rm{x}}_{,}}{y_{,}}z}}\ndenote the accelerometer biases and gyro biases in the body coordinate system.\nThe measurement vector\nz\nz\nis defined as the difference in position between the INS and GPS solutions. Under normal operating conditions, the GPS/INS integrated system operates continuously by fusing data through the KF, as governed by the previously described equations. However, during GPS outages, the KF loses access to external position updates, preventing it from effectively estimating and correcting the accumulating INS errors. As a result, the navigation solution becomes increasingly degraded over time due to unbounded error growth in the standalone INS.\n2.3\nSpiking Neurons and Surrogate Gradient\nIn contrast to conventional deep neural networks (DNNs), the proposed method employs SNNs whose basic computational unit is the leaky integrate-and-fire (LIF) neuron\n[\n28\n]\n, a model that more closely mimics biological neuronal behavior. As depicted in Fig.\n2\n, the LIF neuron accumulates incoming synaptic inputs over time in the form of spikes. When the membrane potential reaches a predefined threshold, the neuron generates an output spike and resets its potential. Between spikes, the membrane potential gradually decays, reflecting the ‚Äùleaky‚Äù nature of the integration process. The dynamics of the membrane potential can be formally expressed as,\nU\n‚Äã\n(\nt\n)\n=\nH\n‚Äã\n(\nt\n‚àí\nŒî\n‚Äã\nt\n)\n+\nI\n‚Äã\n(\nt\n)\n,\nI\n‚Äã\n(\nt\n)\n=\nf\n‚Äã\n(\nx\n;\nŒ∏\n)\n,\nH\n‚Äã\n(\nt\n)\n=\nV\nreset\n‚Äã\nS\n‚Äã\n(\nt\n)\n+\n(\n1\n‚àí\nS\n‚Äã\n(\nt\n)\n)\n‚Äã\nŒ≤\n‚Äã\nU\n‚Äã\n(\nt\n)\n,\nS\n‚Äã\n(\nt\n)\n=\n{\n1\n,\nif\n‚Äã\nU\n‚Äã\n(\nt\n)\n‚â•\nU\nthr\n,\n0\n,\nif\n‚Äã\nU\n‚Äã\n(\nt\n)\n<\nU\nthr\n\\begin{array}[]{l}U(t)=H(t-\\Delta t)+I(t),\\quad I(t)=f(x;\\theta),\\\\\nH(t)=V_{\\text{reset }}S(t)+(1-S(t))\\beta U(t),\\\\\nS(t)=\\left\\{\\begin{array}[]{ll}1,&\\text{ if }U(t)\\geq U_{\\text{thr }},\\\\\n0,&\\text{ if }U(t)<U_{\\text{thr }}\\end{array}\\right.\\end{array}\n(9)\nFigure 2:\nThe structure illustration of the LIF neuron.\nIn the context of the LIF neuron model, the spatial input\nI\n‚Äã\n(\nt\n)\nI(t)\nat time step\nt\nt\nis computed by applying a learnable function\nf\nf\nto the input\nùê±\n\\bf{x}\n, parameterized by\nŒ∏\n\\theta\n. The temporal output\nH\n‚Äã\n(\nt\n)\nH(t)\nis governed by a discretization constant\nŒî\n‚Äã\nt\n\\Delta t\n, which controls the resolution of the LIF dynamics. The spike response\nS\n‚Äã\n(\nt\n)\nS(t)\nis defined using a Heaviside step function, triggered when the membrane potential\nU\n‚Äã\n(\nt\n)\nU(t)\nexceeds a predefined threshold\nU\nthr\nU_{\\text{thr }}\n. Upon firing, the neuron emits a spike and the membrane potential is reset to\nV\nr\n‚Äã\ne\n‚Äã\ns\n‚Äã\ne\n‚Äã\nt\nV_{reset}\n. If the threshold is not reached, no spike is generated, and the membrane potential decays toward\nH\n‚Äã\n(\nt\n)\nH(t)\nat a rate determined by the decay rate\nŒ≤\n\\beta\n. This formulation enables the neuron to capture temporal dependencies and sparse activation patterns, which are crucial for efficient spatiotemporal feature extraction.\nWithin the LIF neuron framework, the spatial input\nI\n‚Äã\n(\nt\n)\nI(t)\nat time step\nt\nt\nis obtained by applying a learnable mapping\nf\nŒ∏\n{f_{\\theta}}\nto the input vector\nx\nx\n, where\nŒ∏\n\\theta\nrepresents the trainable parameters. The temporal dynamics of the neuron are discretized using a time step\nŒî\n‚Äã\nt\n\\Delta t\n, which determines the resolution of the simulation. The spiking behavior\nS\n‚Äã\n(\nt\n)\nS(t)\nis modeled via a Heaviside step function, activated when the membrane potential\nU\n‚Äã\n(\nt\n)\nU(t)\nexceeds a fixed threshold\nU\nthr\nU_{\\text{thr }}\n. Upon spiking, a pulse is emitted and\nU\n‚Äã\n(\nt\n)\nU(t)\nis reset to\nV\nr\n‚Äã\ne\n‚Äã\ns\n‚Äã\ne\n‚Äã\nt\nV_{reset}\n. In the absence of a spike, the potential gradually decays toward the resting state\nH\n‚Äã\n(\nt\n)\nH(t)\n, governed by a decay factor\nŒ≤\n\\beta\n. This dynamic enables the LIF neuron to effectively capture temporal correlations and sparse, event-driven activation patterns‚Äîkey characteristics for efficient spatiotemporal representation learning in spiking neural networks.\nThrough a spiking neuron layer\nS\n‚Äã\nN\n‚Äã\n(\n‚ãÖ\n)\nSN(\\cdot)\n, the spike trains\nS\nS\nare generated by iterating over\nT\n‚Ä≤\n{T^{\\prime}}\ndiscrete time steps, where each of the\nN\nN\ninput currents\nI\nI\nis processed by a corresponding LIF neuron. Formally, this can be expressed as,\nS\n=\nS\n‚Äã\nN\n‚Äã\n(\nI\n)\n{S}=SN(I)\n(10)\nwhere the arctangent-like surrogate gradients\n[\n29\n]\nare used\nto approximate the gradients of the spiking neurons during the backpropagation\nprocess. The surrogate gradient is defined as follows,\nS\n‚Äã\n(\nt\n)\n‚âà\n1\nœÄ\n‚Äã\narctan\n‚Å°\n(\nœÄ\n2\n‚Äã\nŒ±\n‚Äã\nU\n‚Äã\n(\nt\n)\n)\n+\n1\n2\nS(t)\\approx\\frac{1}{\\pi}\\arctan(\\frac{\\pi}{2}\\alpha U(t))+\\frac{1}{2}\n(11)\nwhere\nŒ±\n\\alpha\nis a hyperparameter that controls the steepness of the surrogate\ngradient. Therefore, the comprehensive model can be trained using an end-to-end\napproach, facilitated by backpropagation through time (BPTT)\n[\n30\n]\n, which enables efficient\nlearning and optimization.\n3\nA Brain-inspired GPS/INS fusion Method\n3.1\nThe hybrid GPS/INS navigation structure\nThe proposed GPS/INS integrated navigation system employs an SNN to model the relationship between navigation information and the outputs of the INS, including velocity, attitude, specific force, and angular rate. This approach maintains high navigation accuracy even during GPS outages. Navigation information generally refers to either the position difference between the INS and GPS solutions or the GPS position increment. The main motivation for using SNNs stems from the highly nonlinear and complex nature of the GPS/INS system, which is difficult to describe with a precise mathematical model. Traditional filter-based methods depend heavily on accurate system modeling, and their performance deteriorates when sensor data is missing or degraded, such as during GPS signal loss. In contrast, SNN-based methods are capable of capturing temporal patterns and extracting meaningful spatial features from noisy measurements. Compared to conventional machine learning-aided approaches, the SNN method demonstrates enhanced robustness and lower energy consumption, making it particularly suitable for navigation in challenging environments where GPS signals are unavailable.\nRecently, numerous ML-aided models have been proposed to capture the relationship between navigation information and INS outputs, which can generally be classified into three categories based on their target variables:\nO\nI\n‚Äã\nN\n‚Äã\nS\n‚àí\nŒ¥\n‚Äã\nP\nI\n‚Äã\nN\n‚Äã\nS\nO_{INS}-\\delta P_{INS}\n,\nO\nI\n‚Äã\nN\n‚Äã\nS\n‚àí\nX\nk\nO_{INS}-X_{k}\nand\nO\nI\n‚Äã\nN\n‚Äã\nS\n‚àí\nŒî\n‚Äã\nP\nG\n‚Äã\nP\n‚Äã\nS\nO_{INS}-\\Delta P_{GPS}\n. The\nO\nI\n‚Äã\nN\n‚Äã\nS\n‚àí\nŒ¥\n‚Äã\nP\nI\n‚Äã\nN\n‚Äã\nS\nO_{INS}-\\delta P_{INS}\nmodel aims to learn the relationship between INS measurements and the position error of the integrated GPS/INS system, effectively estimating the deviation of the INS solution from the GPS reference. The\nO\nI\n‚Äã\nN\n‚Äã\nS\n‚àí\nX\nk\nO_{INS}-X_{k}\napproach focuses on establishing a mapping from INS data to the Kalman filter state vector\nX\nk\nX_{k}\n, which typically includes navigation errors and sensor biases. In contrast, the\nO\nI\n‚Äã\nN\n‚Äã\nS\n‚àí\nŒî\n‚Äã\nP\nG\n‚Äã\nP\n‚Äã\nS\nO_{INS}-\\Delta P_{GPS}\nmodel uses INS outputs as input and predicts the GPS-derived position increment over a given time interval. Notably, the first two models incorporate both INS and GPS information in their target outputs, which may introduce coupling errors due to GPS noise or filter artifacts. In comparison, the\n(\n(\nO\nI\n‚Äã\nN\n‚Äã\nS\n‚àí\nŒî\n‚Äã\nP\nG\n‚Äã\nP\n‚Äã\nS\nO_{INS}-\\Delta P_{GPS}\n)\n)\nmodel relies solely on short-term GPS position changes, reducing dependency on long-term GPS accuracy and minimizing error propagation, thereby offering greater robustness during GPS outages. The GPS position increment in this model can be expressed as\n[\n31\n]\n,\nŒî\n‚Äã\nP\nG\n‚Äã\nP\n‚Äã\nS\n=\n‚à¨\nV\nÀô\nn\n‚Äã\n(\nt\n)\n‚Äã\nùëë\nt\n‚Äã\nùëë\nt\n=\n‚à¨\n(\nC\nb\nn\n‚Äã\nf\ni\n‚Äã\nb\nb\n‚Äã\n(\nt\n)\n‚àí\n(\n2\n‚Äã\nœâ\ni\n‚Äã\ne\nn\n‚Äã\n(\nt\n)\n+\nœâ\ne\n‚Äã\nn\nn\n‚Äã\n(\nt\n)\n)\n√ó\nV\nn\n‚Äã\n(\nt\n)\n+\nG\nn\n)\n‚Äã\nùëë\nt\n‚Äã\nùëë\nt\n\\begin{array}[]{l}\\begin{array}[]{l}\\Delta{P_{GPS}}=\\iint{{{\\dot{V}}_{n}}(t)}dtdt\\end{array}\\\\\n=\\begin{array}[]{l}\\iint{(C_{b}^{n}f_{ib}^{b}(t)-(2\\omega_{ie}^{n}(t)+\\omega_{en}^{n}(t))\\times{V_{n}}(t)+G_{n})dtdt}\\end{array}\\end{array}\n(12)\nwhere\nC\nb\nn\nC_{b}^{n}\nis the direction cosine matrix of the transformation from body frame to the navigation frame;\nf\ni\n‚Äã\nb\nf_{ib}\nis the output of the accelerometer;\nœâ\ni\n‚Äã\ne\nn\n\\omega_{ie}^{n}\nis the angular rate of earth frame\ne\ne\nto the inertial frame\ni\ni\n;\nœâ\ne\n‚Äã\nn\nn\n\\omega_{en}^{n}\nis the angular rate of the navigation frame\nn\nn\nto the earth frame\ne\ne\n;\nV\nn\nV_{n}\nis the velocity of the vehicle in the navigation frame\nn\nn\nand\nG\nn\nG_{n}\nis the gravity vector.\nIn Eq.\n(\n(\n12\n)\n)\n, the terms\nœâ\ni\n‚Äã\ne\nn\n\\omega_{ie}^{n}\nand\nG\nn\nG_{n}\ndepend on the longitude and latitude, while\nœâ\ne\n‚Äã\nn\nn\n\\omega_{en}^{n}\nis a function of the velocity vector\nV\nn\nV_{n}\n. However, in practical navigation scenarios, the variations in longitude and latitude are typically small over short time intervals. As a result, the dominant factors influencing the GPS position increment\nŒî\n‚Äã\nP\nG\n‚Äã\nP\n‚Äã\nS\n\\Delta P_{GPS}\nare the attitude matrix\nC\nb\nn\nC_{b}^{n}\n, the specific force measurements\nf\ni\n‚Äã\nb\nf_{ib}\n, and the velocity vector\nV\nn\nV_{n}\n. Among these, the transformation matrix\nC\nb\nn\nC_{b}^{n}\n, which maps vectors from the body frame to the navigation frame, plays a critical role and can be expressed as,\n[\ncos\n‚Å°\nŒ∏\n‚Äã\ncos\n‚Å°\nœà\n‚àí\ncos\n‚Å°\nŒ≥\n‚Äã\nsin\n‚Å°\nœà\n+\nsin\n‚Å°\nŒ≥\n‚Äã\nsin\n‚Å°\nŒ∏\n‚Äã\ncos\n‚Å°\nœà\nsin\n‚Å°\nŒ≥\n‚Äã\nsin\n‚Å°\nœà\n+\ncos\n‚Å°\nŒ≥\n‚Äã\nsin\n‚Å°\nŒ∏\n‚Äã\ncos\n‚Å°\nœà\ncos\n‚Å°\nŒ∏\n‚Äã\nsin\n‚Å°\nœà\ncos\n‚Å°\nŒ≥\n‚Äã\ncos\n‚Å°\nœà\n+\nsin\n‚Å°\nŒ≥\n‚Äã\nsin\n‚Å°\nŒ∏\n‚Äã\nsin\n‚Å°\nœà\n‚àí\nsin\n‚Å°\nŒ≥\n‚Äã\ncos\n‚Å°\nœà\n+\ncos\n‚Å°\nŒ≥\n‚Äã\nsin\n‚Å°\nŒ∏\n‚Äã\nsin\n‚Å°\nœà\n‚àí\nsin\n‚Å°\nŒ∏\nsin\n‚Å°\nŒ≥\n‚Äã\ncos\n‚Å°\nŒ∏\ncos\n‚Å°\nŒ≥\n‚Äã\ncos\n‚Å°\nŒ∏\n]\n\\scriptsize\\left[{\\begin{array}[]{*{20}{c}}{\\cos\\theta\\cos\\psi}&{-\\cos\\gamma\\sin\\psi+\\sin\\gamma\\sin\\theta\\cos\\psi}&{\\sin\\gamma\\sin\\psi+\\cos\\gamma\\sin\\theta\\cos\\psi}\\\\\n{\\cos\\theta\\sin\\psi}&{\\cos\\gamma\\cos\\psi+\\sin\\gamma\\sin\\theta\\sin\\psi}&{-\\sin\\gamma\\cos\\psi+\\cos\\gamma\\sin\\theta\\sin\\psi}\\\\\n{-\\sin\\theta}&{\\sin\\gamma\\cos\\theta}&{\\cos\\gamma\\cos\\theta}\\end{array}}\\right]\n(13)\nwhere\nŒ∏\n\\theta\n,\nŒ≥\n\\gamma\nand\nœà\n\\psi\nare the pitch, roll and yaw, respectively. The attitude angles are mostly obtained by integrating the gyroscope outputs\nœâ\ni\n‚Äã\nb\nb\n\\omega_{ib}^{b}\n. In summary,\nŒî\n‚Äã\nP\nG\n‚Äã\nP\n‚Äã\nS\n\\Delta P_{GPS}\nis mainly determined by\nf\ni\n‚Äã\nb\nf_{ib}\n,\nœâ\ni\n‚Äã\nb\nb\n\\omega_{ib}^{b}\n,\nŒ∏\n\\theta\n,\nŒ≥\n\\gamma\nand\nœà\n\\psi\n, which are selected as the inputs of BGFN model to mimic the mathematical relationship of the position increments of the GPS/INS integrated system when GPS signals are available.\nThe output is the GPS position increments\nŒî\n‚Äã\nP\nG\n‚Äã\nP\n‚Äã\nS\n\\Delta P_{GPS}\n, and the input and output can be expressed as,\nI\n‚Äã\nn\n‚Äã\np\n‚Äã\nu\n‚Äã\nt\n:\n[\nœï\nf\nb\nœâ\nb\n]\n=\n[\nŒ≥\nŒ∏\nœà\nf\nx\nb\nf\ny\nb\nf\nz\nb\nœâ\nx\nb\nœâ\ny\nb\nœâ\nz\nb\n]\nO\n‚Äã\nu\n‚Äã\nt\n‚Äã\np\n‚Äã\nu\n‚Äã\nt\n:\n[\nŒî\n‚Äã\nP\nG\n‚Äã\nP\n‚Äã\nS\n]\n=\n[\nŒî\n‚Äã\nP\nG\n‚Äã\nP\n‚Äã\nS\nn\nŒî\n‚Äã\nP\nG\n‚Äã\nP\n‚Äã\nS\ne\n]\n\\begin{array}[]{l}Input:[\\begin{array}[]{*{20}{c}}{\\phi}&{{f^{b}}}&{{\\omega^{b}}}\\end{array}]\\\\\n=[\\begin{array}[]{*{20}{c}}{\\gamma}&{\\theta}&{\\psi}&{{f_{x}^{b}}}&{{f_{y}^{b}}}&{{f_{z}^{b}}}&{{\\omega_{x}^{b}}}&{{\\omega_{y}^{b}}}&{{\\omega_{z}^{b}}}\\end{array}]\\\\\nOutput:[\\begin{array}[]{*{20}{c}}{\\Delta P_{GPS}}\\end{array}]=[\\begin{array}[]{*{20}{c}}{\\Delta{P_{GPS}^{n}}}&{\\Delta{P_{GPS}^{e}}}\\end{array}]\\end{array}\n(14)\nAt the initial stage, the pre-trained BGFN is deployed on the mobile vehicle. Once the vehicle begins motion, the GPS/INS integrated navigation system based on BGFN operates in two distinct modes. As illustrated in Fig.\n3\n, when GPS signals are available, the system enters the online-training mode. In this mode, the INS-provided velocity\nV\nI\n‚Äã\nN\n‚Äã\nS\nV_{INS}\n, position\nP\nI\n‚Äã\nN\n‚Äã\nS\nP_{INS}\n, and attitude\nA\nI\n‚Äã\nN\n‚Äã\nS\nA_{INS}\nare fused with the GPS position\nP\nG\n‚Äã\nP\n‚Äã\nS\nP_{GPS}\nwithin a KF. The KF estimates the velocity error\nŒ¥\n‚Äã\nV\n\\delta V\n, position error\nŒ¥\n‚Äã\nP\n\\delta P\n, and attitude error\nŒ¥\n‚Äã\nA\n\\delta A\n, which are then fed back to correct the INS solutions and mitigate position drift. Concurrently, the synchronized GPS/INS data are logged on the onboard computer to further train the BGFN. Since GPS outages typically occupy only a small fraction of the total operation time, the BGFN remains in training mode for most of the mission. During this extended period, IMU data are continuously fed into the network, enabling the BGFN to accumulate sufficient representative data for comprehensive training. Through this process, the synaptic weights in the hidden layers are iteratively adjusted to accurately capture the underlying input-output dynamics between inertial measurements and navigation increments.\nFigure 3:\nThe GPS/INS integrated navigation system based on BGFN.\nOnce GPS signals become unavailable, the BGFN-based GPS/INS navigation system transitions into prediction mode. During GPS outages, no new external position updates are available, and the KF estimates are held at their last valid values, preventing further correction of INS errors. As a result, the system effectively operates as a standalone INS, which is prone to accumulating errors over time. The architecture of this prediction mode is illustrated by the dashed-line components in Fig.\n3\n. In this mode, the pre-trained BGFN predicts the GPS position increments\nŒî\n‚Äã\nP\nG\n‚Äã\nP\n‚Äã\nS\n\\Delta P_{GPS}\n, which are then accumulated to generate a pseudo-GPS position. This synthetic position solution is computed by integrating all predicted increments according to Eq.\n15\n.\nP\nG\n‚Äã\nP\n‚Äã\nS\n‚Äã\n(\nk\n)\n=\nP\nG\n‚Äã\nP\n‚Äã\nS\n0\n+\n‚àë\ni\n=\n0\nk\nŒî\n‚Äã\nP\nG\n‚Äã\nP\n‚Äã\nS\ni\nP_{GPS}(k)=P_{GPS_{0}}+\\mathop{\\sum}\\limits_{i=0}^{k}\\Delta P_{GPS_{i}}\n(15)\nwhere\nP\nG\n‚Äã\nP\n‚Äã\nS\n0\nP_{GPS_{0}}\nis the initial position when GPS fails at the\nk\nt\n‚Äã\nh\n{\\rm{k}}^{th}\nmoment. This estimated position\nP\nG\n‚Äã\nP\n‚Äã\nS\n‚Äã\n(\nk\n)\nP_{GPS}(k)\nis then used instead of the missing GPS position increments and fused with INS by KF. The hybrid structure of GPS/INS will maintain navigation continuously when GPS signals are lost.\n3.2\nThe BGFN Architecutre\nAs illustrated in Fig.\n4\n, the BGFN consists primarily of spike encoder layers and spiking Transformer layers. The spike encoder aligns the temporal resolution between the IMU time-series data and the spiking neural network while converting the continuous sensor measurements into meaningful spike trains. The spiking Transformer layers then process these spike sequences to capture the dynamic motion patterns of the mobile vehicle from historical IMU data. The input to the network is represented as a time series vector\nS\nt\n=\n(\nu\n1\n,\nu\n2\n,\n‚Ä¶\n,\nu\ni\n,\n‚Ä¶\n‚Äã\nu\nk\n)\n{S_{t}}=({u_{1}},{u_{2}},\\ldots,{u_{i}},\\ldots{u_{k}})\n, where each\nu\ni\n{u_{i}}\ncontains nine-dimensional measurements from the accelerometer, gyroscope, and attitude sensors at time step\ni\ni\n, and\nk\nk\ndenotes the size of the time window. The network predicts the GPS position increment\nŒî\n‚Äã\nP\nG\n‚Äã\nP\n‚Äã\nS\nk\n+\n1\n\\Delta P_{GPS}^{k{\\rm{+}}1}\nat the next time step\nk\n+\n1\n{k+1}\nbased on the preceding\nk\nk\nIMU observations. Thus, the navigation-aiding prediction task can be formulated as,\nFigure 4:\nThe architecture of the BGFN.\nŒî\n‚Äã\nP\nG\n‚Äã\nP\n‚Äã\nS\nk\n+\n1\n=\nB\n‚Äã\nG\n‚Äã\nF\n‚Äã\nN\n‚Äã\n(\nS\n1\n,\nS\n2\n,\n‚Ä¶\n,\nS\nk\n)\n\\Delta P_{GPS}^{k{\\rm{+}}1}=BGFN({S_{1}},{S_{2}},\\ldots,{S_{k}})\n(16)\nTo fully exploit the temporal processing capabilities of SNNs, it is crucial to align the time scale of the IMU time-series data with the dynamics of the SNN. As shown in Fig.\n4\n, the key strategy in this work involves capturing fine-grained temporal patterns of spike activity within the sensor data at each time step. To achieve this alignment, each time step\nŒî\n‚Äã\nT\n\\Delta T\nof the input sequence is divided into\nT\ns\nT_{s}\ndiscrete segments, each of duration\nŒî\n‚Äã\nt\n\\Delta t\n, such that\nŒî\n‚Äã\nT\n=\nT\ns\n‚Äã\nŒî\n‚Äã\nt\n\\Delta T={T_{s}}\\Delta t\n. This relationship establishes a direct correspondence between the time resolution of the IMU data and the internal time step of the SNN. As a result, the independent variable\nt\nt\n, which is used in both the time-series signal\nX\n‚Äã\n(\nt\n)\nX(t)\nand the SNN state variables such as membrane potential\nU\n‚Äã\n(\nt\n)\nU(t)\n, input current\nI\n‚Äã\n(\nt\n)\nI(t)\n, hidden state\nH\n‚Äã\n(\nt\n)\nH(t)\nand spike activity\nS\n‚Äã\n(\nt\n)\nS(t)\n, acquires a unified temporal meaning across the network. Inspired by the recent work of Qu et al.\n[\n32\n]\n, which demonstrated that such temporal patterns can be effectively captured using convolutional kernels, a one-dimensional convolutional layer is employed as a temporal encoder to transform raw IMU inputs into spike-compatible representations. Given the\nk\nt\n‚Äã\nh\nk_{th}\nhistorical IMU sequence\nS\nt\n{S_{t}}\n, it is passed through the convolutional layer followed by batch normalization to generate the corresponding spike trains as,\nS\n=\nS\n‚Äã\nN\n‚Äã\n(\nB\n‚Äã\nN\n‚Äã\n(\nC\n‚Äã\no\n‚Äã\nn\n‚Äã\nv\n‚Äã\n(\nS\nk\n)\n)\n)\n{S}=SN(BN(Conv(S_{k})))\n(17)\nBy passing through the convolutional-based spike encoder, the dimension of the input\nS\nk\nS_{k}\nis expanded to\nT\ns\n√ó\nT\n√ó\nC\n{T_{s}}\\times T\\times C\n, where\nC\nC\ndenotes the number of sensor channels, specifically nine, corresponding to the three-axis angular velocity, three-axis linear acceleration, and three attitude angles. The convolutional spike encoder effectively captures the intrinsic temporal patterns within the input data, including dynamic changes in magnitude and waveform shape over time. This rich temporal representation enhances the robustness of the encoded features and accurately reflects the time-varying nature of the IMU signals. As a result, the encoded spike tensor is well-suited for subsequent spiking layers, enabling efficient event-driven processing and facilitating accurate modeling of motion dynamics in the spiking neural network.\nGiven the high sampling frequency of the IMU, typically 100 Hz, and the presence of substantial nonlinear noise in the sensor data, the spiking neural network need learn temporal features over long time windows. Traditional neural networks such as RNNs and CNNs often struggle to capture long-term dependencies due to the vanishing gradient problem. To address this challenge, we employ a spiking Transformer as the backbone of the SNN, which is capable of modeling long-range temporal dependencies and extracting discriminative temporal patterns from IMU measurements. In the proposed architecture, the spiking Transformer is adapted from SpikeFormer v2\n[\n33\n]\n, which has achieved state-of-the-art performance on large-scale vision benchmarks including ImageNet-1K and CIFAR-10. This strong representational capability motivates its application to inertial navigation, where accurate modeling of dynamic motion over time is critical.\nInspired by Spikformer v2, the spiking self-attention (SSA) mechanism is employed to construct the spiking Transformer blocks. The SSA mechanism is specifically designed to capture temporal dependencies and long-range relationships within the input spike sequences, which is crucial for accurately modeling the dynamic characteristics of IMU measurements under high-frequency sampling and noise interference. To enable effective feature learning, a channel-wise spiking embedding layer is first applied to transform the input spike trains into a latent continuous representation. This embedded feature sequence is then processed by a series of spiking Transformer blocks, each leveraging the SSA mechanism to propagate and refine temporal information across the sequence. The overall transformation can be expressed as follows,\nS\ne\n‚Äã\nm\n‚Äã\nb\n=\nS\n‚Äã\nN\n‚Äã\n(\nL\n‚Äã\ni\n‚Äã\nn\n‚Äã\ne\n‚Äã\na\n‚Äã\nr\n‚Äã\n(\nS\n)\n)\n{S_{emb}}=SN(Linear(S))\n(18)\nwhere\nS\ne\n‚Äã\nm\n‚Äã\nb\nS_{emb}\nis the spiking embedding of the input spike trains\nS\nS\n, and the linear layer is used to project the spike trains into a higher-dimensional\nspace.\nThe spiking Transformer blocks consist of multiple stacked layers, each containing spiking self-attention and spiking feed-forward network modules. These components are designed to capture both local temporal features and long-range dependencies in the input spike sequences. The output sequence from the final spiking Transformer block is passed through a projection layer, such as a fully connected network, to map the learned spatiotemporal features to the final output of the BGFN, which is the predicted GPS position increment\nŒî\n‚Äã\nP\nG\n‚Äã\nP\n‚Äã\nS\nk\n+\n1\n\\Delta P_{GPS}^{k{\\rm{+}}1}\n. This method enables gradient computation across time steps and supports effective learning of dynamic motion patterns from sequential IMU data.\n4\nExperimental Results and Analysis\n4.1\nDataset tests\nTo evaluate the performance of the proposed algorithm, numerical experiments are conducted using a publicly available dataset from NaveGo\n[\n34\n]\n, provided by Gonzalez and Dabove. The dataset is collected by driving a vehicle equipped with an Ekinox-D IMU and a GNSS receiver through the urban environment of Turin. Four different methods are compared: (1) standalone INS, (2) multilayer perceptron (MLP), (3) attention-based LSTM (AT-LSTM)\n[\n35\n]\n, and (4) the proposed BGFN. Two 30-second GPS outages are selected from the dataset to assess the effectiveness of BGFN in aiding the INS during outages. The 3D trajectory of the NaveGo dataset is illustrated in Fig.\n5\n, with the positions of the two outages indicated by red lines.\nFigure 5:\nThe Navego dataset trajectory.\nThe proposed method is implemented using PyTorch and SpikingJelly\n[\n29\n]\n. Training is performed for 1000 epochs using the BPTT algorithm with an NVIDIA RTX A6000 GPU and a batch size of 8. To enable the network to capture sufficient temporal dynamics, the BGFN is configured with a sliding time window of\nN\n=\n200\nN=200\n, meaning it uses the most recent 200 IMU measurements to predict the next GPS position increment. The embedding layer and the feed-forward network within the spiking Transformer both have a feature dimension of 256. The multi-head self-attention mechanism employs 6 attention heads, and the overall architecture consists of 4 spiking Transformer blocks. The output layer contains 2 neurons, corresponding to the two-dimensional GPS position increment\nŒî\n‚Äã\nP\nG\n‚Äã\nP\n‚Äã\nS\n\\Delta P_{GPS}\nin the local horizontal plane.\nAs illustrated in Fig.\n6\nand Table\n1\n, the east and north position errors of four methods, namely pure INS, MLP, AT-LSTM, and BGFN, are compared. The results are shown using red, yellow, black, and blue curves, respectively. Due to the absence of external GPS corrections, the position errors of all methods gradually increase over time. The standalone INS exhibits the largest drift, with maximum east and north errors reaching 23.1 m and 23.2 m, respectively. The MLP model shows improved performance, reducing the maximum errors to 11.0 m in the east and 15.4 m in the north. The AT-LSTM further reduces the errors to 7.9 m and 7.7 m, demonstrating the benefit of modeling temporal dependencies with attention mechanisms. The proposed BGFN achieves the best performance among all methods, effectively suppressing error growth. Compared to standalone INS, the maximum errors are reduced by 79.7\n%\n\\%\nin the east and 79.3\n%\n\\%\nin the north, highlighting its superior capability in aiding inertial navigation during GPS outages.\nTable 1:\nThe max position error(\nm\nm\n) among different algorithms in the dataset test\nMax Position Error (m)\nINS\nMLP\nAT-LSTM\nBGFN\nEast\nNorth\nEast\nNorth\nEast\nNorth\nEast\nNorth\nOutage 1\n23.1\n23.2\n11.0\n15.4\n7.9\n7.7\n4.7\n4.8\nOutage 2\n10.6\n19.6\n5.6\n9.3\n2.9\n6.0\n1.8\n4.2\nFigure 6:\nThe position errors among different algorithms during the first outage in the dataset test. (a) The east position error. (b) The north position error.\nFig.\n7\nand Table\n1\npresent the performance of the four methods during the second GPS outage. The results follow a similar trend to those observed in the first outage. The standalone INS exhibits the largest position drift, with maximum errors of 10.6 m in the east and 19.6 m in the north. Both MLP and AT-LSTM show improved accuracy compared to the standalone INS. Specifically, MLP achieves maximum errors of 5.6 m (east) and 9.3 m (north), while AT-LSTM reduces them to 2.9 m (east) and 6.0 m (north). The proposed BGFN demonstrates the best overall performance, with maximum errors further reduced to 1.8 m in the east and 4.2 m in the north. These results confirm that BGFN outperforms the pure INS, MLP, and AT-LSTM across multiple outage scenarios, demonstrating its superior ability to accurately predict GPS position increments and effectively assist inertial navigation under signal-denied conditions.\nFigure 7:\nThe position errors among different algorithms during the second outage in the dataset test. (a) The east position error. (b) The north position error.\n4.2\nField tests\nTo further validate the proposed method, real-world field tests are conducted using a custom-built mobile car platform, as shown in Fig.\n8\n(a). This platform is designed to collect realistic driving data under various environmental conditions and real-world sensor noise. The system integrates a Pixhawk autopilot, a high-performance embedded flight controller suitable for a wide range of robotic platforms, including fixed-wing aircraft, multi-rotor drones, helicopters, ground vehicles, and marine vessels. The primary inertial sensors are the Invensense MPU-6000 and STMicroelectronics LSM303D, providing gyroscope and accelerometer measurements with a typical gyroscope bias of 5¬∞/s and accelerometer bias of 60 mg. To obtain accurate position reference data, a u-blox NEO-M9N GNSS receiver is installed. The position estimates are generated by fusing the GNSS and INS data using an EKF, providing a reliable ground truth trajectory for performance evaluation.\nFigure 8:\nThe mobile robot and trajectory. (a) The mobile vehicle. (b) The vehicle trajectory\nA mobile car driving experiment is conducted in Hengqin, Guangdong Province, China. The vehicle trajectory, shown in blue in Fig.\n8\n(b), covers a realistic urban environment, and two 30-second GPS outages are indicated by red lines. To ensure reliable baseline navigation performance, the experiment is carried out in an open playground where GPS signals from at least seven satellites are consistently available throughout the normal operation periods. The GPS outages is artificially introduced using a signal shielding device to simulate signal-denied conditions, enabling a controlled evaluation of the proposed BGFN under realistic yet repeatable scenarios.\nFig.\n9\nillustrates the east and north position errors estimated by different algorithms during the first GPS outage, with the maximum errors in both directions summarized in Table\n2\n. When GPS signals are interrupted, the KF loses external position updates, causing the integrated navigation system to operate in standalone INS mode. In this mode, position errors accumulate rapidly over time due to unbounded drift from sensor biases and noise. When MLP, AT-LSTM, or the proposed BGFN is employed to aid the INS, the error growth is mitigated to varying degrees. During the first outage, the maximum east position errors for standalone INS, MLP, AT-LSTM, and BGFN are 289.4 m, 103.0 m, 47.3 m, and 35.0 m, respectively, while the corresponding north errors are 175.1 m, 64.2 m, 33.8 m, and 16.2 m. Comparative analysis shows that the BGFN-based method achieves the smallest position errors among all approaches. These results demonstrate that the BGFN effectively enhances navigation accuracy during GPS outages and exhibits superior capability in suppressing inertial navigation drift compared to traditional deep learning models such as MLP and AT-LSTM.\nFigure 9:\nThe position errors among different algorithms during the first outage in the field test. (a) The east position error. (b) The north position error\nTo further evaluate the performance of BGFN-assisted integrated navigation under dynamic motion conditions, the second GPS outage is selected during a vehicle maneuvering phase characterized by significant changes in direction. As shown in Fig.\n10\n, the east and north position errors of the standalone INS, MLP, AT-LSTM, and BGFN methods are compared during the second outage period, with quantitative results summarized in Table\n2\n. At the end of the outage, the BGFN-based method reduces the position error by 90.0\n%\n\\%\nin the east and 85.5\n%\n\\%\nin the north compared to standalone INS. These results demonstrate that the proposed BGFN maintains high prediction accuracy even during large-scale maneuvers, effectively constraining inertial drift and significantly improving navigation robustness under challenging, dynamic conditions.\nFigure 10:\nThe position errors among different algorithms during the second outage in the field test. (a) The east position error. (b) The north position error.\nThe results from the mobile robot real-world driving experiments demonstrate that the BGFN-based integrated navigation method effectively suppresses position error growth and achieves higher navigation accuracy compared to traditional neural network approaches. Furthermore, when deployed on a 45 nm neuromorphic hardware platform\n[\n36\n]\n, the proposed spiking Transformer architecture achieves a theoretical energy reduction of 66.3\n%\n\\%\nrelative to conventional Transformer-based models\n[\n23\n]\n. This significant improvement underscores the energy efficiency of the bio-inspired design, making it well suited for edge computing applications where power consumption is a critical constraint.\nTable 2:\nThe max position error among different algorithms in the real field test\nMax Position Error (m)\nINS\nMLP\nAT-LSTM\nBGFN\nEast\nNorth\nEast\nNorth\nEast\nNorth\nEast\nNorth\nOutage 1\n289.4\n175.1\n103.0\n64.2\n47.3\n33.8\n35.0\n16.2\nOutage 2\n477.5\n226.0\n258.7\n103.0\n112.3\n62.1\n47.6\n32.7\n5\nConclusion\nThis paper proposes a novel spiking neural network-based method for aiding INS during GPS signal outages by effectively mitigating the accumulation of navigation errors. The key advantage of the proposed BGFN lies in its ability to not only extract robust feature representations from noisy sensor measurements but also to automatically correlate current inputs with historical model states, enabling accurate temporal modeling. To evaluate its performance, both experiments on numerical public datasets and real-world field tests are conducted, and the results demonstrate that BGFN significantly improves navigation accuracy under GPS-denied conditions. The proposed brain-inspired GPS/INS fusion architecture is capable of capturing the inherent nonlinear relationship between INS outputs and GPS position increments, thereby providing reliable and precise navigation solutions during prolonged signal outages. Although the method shows strong performance, there remains room for improvement: future work will focus on deploying BGFN onto neuromorphic or brain-inspired hardware platforms to leverage its energy efficiency, as well as exploring an end-to-end trainable spiking neural network for the GPS/INS integrated system to further enhance accuracy and robustness in complex environments.\nReferences\n[1]\nD.¬†Wang, Y.¬†Dong, Z.¬†Li, Q.¬†Li, J.¬†Wu, Constrained mems-based gnss/ins tightly coupled system with robust kalman filter for accurate land vehicular navigation, IEEE Transactions on Instrumentation and Measurement 69¬†(7) (2019) 5138‚Äì5148.\n[2]\nY.¬†Kim, J.¬†An, J.¬†Lee, Robust navigational system for a transporter using gps/ins fusion, IEEE Transactions on Industrial Electronics 65¬†(4) (2017) 3346‚Äì3354.\n[3]\nW.¬†Wang, Q.¬†Zhang, Y.¬†Hu, M.¬†Gallay, W.¬†Zheng, J.¬†Guo, Recent advances in slam for degraded environments a review, IEEE Sensors Journal (2025).\n[4]\nT.¬†E. Tabassum, I.¬†Petrunin, Z.¬†A. Rana, A comparative analysis of hybrid sensor fusion schemes for visual‚Äìinertial navigation, IEEE Transactions on Instrumentation and Measurement (2025).\n[5]\nZ.¬†Li, Q.¬†Meng, Z.¬†Shen, L.¬†Wang, L.¬†Li, H.¬†Jia, Resilient factor graph-based gnss/imu/vision/odo integrated navigation scheme enhanced by noise approximate gaussian estimation in challenging environments, Remote Sensing 16¬†(12) (2024) 2176.\n[6]\nJ.¬†Li, N.¬†Song, G.¬†Yang, M.¬†Li, Q.¬†Cai, Improving positioning accuracy of vehicular navigation system during gps outages utilizing ensemble learning algorithm, Information Fusion 35 (2017) 1‚Äì10.\n[7]\nD.¬†Bhatt, P.¬†Aggarwal, V.¬†Devabhaktuni, P.¬†Bhattacharya, A novel hybrid fusion algorithm to bridge the period of gps outages using low-cost ins, Expert Systems with Applications 41¬†(5) (2014) 2166‚Äì2173.\n[8]\nS.¬†Adusumilli, D.¬†Bhatt, H.¬†Wang, P.¬†Bhattacharya, V.¬†Devabhaktuni, A low-cost ins/gps integration methodology based on random forest regression, Expert Systems with Applications 40¬†(11) (2013) 4653‚Äì4659.\n[9]\nR.¬†Sharaf, A.¬†Noureldin, A.¬†Osman, N.¬†El-Sheimy, Online ins/gps integration with a radial basis function neural network, IEEE Aerospace and Electronic Systems Magazine 20¬†(3) (2005) 8‚Äì14.\n[10]\nN.¬†El-Sheimy, K.-W. Chiang, A.¬†Noureldin, The utilization of artificial neural networks for multisensor system integration in navigation and positioning instruments, IEEE Transactions on instrumentation and measurement 55¬†(5) (2006) 1606‚Äì1615.\n[11]\nY.¬†Zhang, C.¬†Shen, J.¬†Tang, J.¬†Liu, Hybrid algorithm based on mdf-ckf and rf for gps/ins system during gps outages (april 2018), IEEE Access 6 (2018) 35343‚Äì35354.\n[12]\nP.¬†Doostdar, J.¬†Keighobadi, M.¬†A. Hamed, Ins/gnss integration using recurrent fuzzy wavelet neural networks, GPS solutions 24¬†(1) (2020) 29.\n[13]\nI.¬†Belhajem, Y.¬†B. Maissa, A.¬†Tamtaoui, Improving low cost sensor based vehicle positioning with machine learning, Control Engineering Practice 74 (2018) 168‚Äì176.\n[14]\nJ.¬†Li, C.¬†Li, Y.¬†Wu, Y.¬†Qian, Unified cross-modal attention: robust audio-visual speech recognition and beyond, IEEE/ACM Transactions on Audio, Speech, and Language Processing 32 (2024) 1941‚Äì1953.\n[15]\nJ.¬†Liu, G.¬†Guo, Vehicle localization during gps outages with extended kalman filter and deep learning, IEEE Transactions on Instrumentation and Measurement 70 (2021) 1‚Äì10.\n[16]\nS.¬†Zhao, Y.¬†Zhou, T.¬†Huang, A novel method for ai-assisted ins/gnss navigation system based on cnn-gru and ckf during gnss outage, Remote Sensing 14¬†(18) (2022) 4494.\n[17]\nY.¬†Xu, K.¬†Wang, C.¬†Jiang, Z.¬†Li, C.¬†Yang, D.¬†Liu, H.¬†Zhang, Motion-constrained gnss/ins integrated navigation method based on bp neural network, Remote sensing 15¬†(1) (2022) 154.\n[18]\nW.¬†Fang, J.¬†Jiang, S.¬†Lu, Y.¬†Gong, Y.¬†Tao, Y.¬†Tang, P.¬†Yan, H.¬†Luo, J.¬†Liu, A lstm algorithm estimating pseudo measurements for aiding ins during gnss signal outages, Remote sensing 12¬†(2) (2020) 256.\n[19]\nD.¬†Li, J.¬†Zhou, Y.¬†Liu, Recurrent-neural-network-based unscented kalman filter for estimating and compensating the random drift of mems gyroscopes in real time, Mechanical Systems and Signal Processing 147 (2021) 107057.\n[20]\nC.¬†Chen, X.¬†Pan, Deep learning for inertial positioning: A survey, IEEE transactions on intelligent transportation systems 25¬†(9) (2024) 10506‚Äì10523.\n[21]\nY.¬†Liu, Q.¬†Luo, Y.¬†Zhou, Deep learning-enabled fusion to bridge gps outages for ins/gps integrated navigation, IEEE Sensors Journal 22¬†(9) (2022) 8974‚Äì8985.\n[22]\nK.¬†C. Guyard, J.¬†Bertolaccini, S.¬†Montavon, M.¬†Deriaz, A transformer encoder approach for localization reconstruction during gps outages from an imu and gps-based sensor, Sensors 25¬†(2) (2025) 522.\n[23]\nC.¬†Lv, Y.¬†Wang, D.¬†Han, X.¬†Zheng, X.¬†Huang, D.¬†Li, Efficient and effective time-series forecasting with spiking neural networks, arXiv preprint arXiv:2402.01533 (2024).\n[24]\nB.¬†Candelori, G.¬†Bardella, I.¬†Spinelli, S.¬†Ramawat, P.¬†Pani, S.¬†Ferraina, S.¬†Scardapane, Spatio-temporal transformers for decoding neural movement control, Journal of Neural Engineering 22¬†(1) (2025) 016023.\n[25]\nX.¬†Li, X.¬†Chen, R.¬†Guo, Y.¬†Wu, Z.¬†Zhou, F.¬†Yu, H.¬†Lu, Neurove: Brain-inspired linear-angular velocity estimation with spiking neural networks, IEEE Robotics and Automation Letters (2025).\n[26]\nY.¬†Peng, G.¬†Zhang, J.¬†Shi, B.¬†Xu, L.¬†Zheng, Srai-lstm: A social relation attention-based interaction-aware lstm for human trajectory prediction, Neurocomputing 490 (2022) 258‚Äì268.\n[27]\nG.¬†Zhang, H.¬†Zhou, C.¬†Wang, H.¬†Xue, J.¬†Wang, H.¬†Wan, Time series high-resolution land surface albedo estimation based on the ensemble kalman filter algorithm, Remote Sensing 11¬†(7) (2019) 753.\n[28]\nW.¬†Maass, Networks of spiking neurons: the third generation of neural network models, Neural networks 10¬†(9) (1997) 1659‚Äì1671.\n[29]\nW.¬†Fang, Y.¬†Chen, J.¬†Ding, Z.¬†Yu, T.¬†Masquelier, D.¬†Chen, L.¬†Huang, H.¬†Zhou, G.¬†Li, Y.¬†Tian, Spikingjelly: An open-source machine learning infrastructure platform for spike-based intelligence, Science Advances 9¬†(40) (2023) eadi1480.\n[30]\nA.¬†Gruslys, R.¬†Munos, I.¬†Danihelka, M.¬†Lanctot, A.¬†Graves, Memory-efficient backpropagation through time, Advances in neural information processing systems 29 (2016).\n[31]\nY.¬†Yao, X.¬†Xu, A rls-svm aided fusion methodology for ins during gps outages, Sensors 17¬†(3) (2017) 432.\n[32]\nE.¬†Qu, Y.¬†Wang, X.¬†Luo, W.¬†He, K.¬†Ren, D.¬†Li, Cnn kernels can be the best shapelets, in: The Twelfth International Conference on Learning Representations, 2024.\n[33]\nZ.¬†Zhou, K.¬†Che, W.¬†Fang, K.¬†Tian, Y.¬†Zhu, S.¬†Yan, Y.¬†Tian, L.¬†Yuan, Spikformer v2: Join the high accuracy club on imagenet with an snn ticket, arXiv preprint arXiv:2401.02020 (2024).\n[34]\nR.¬†Gonzalez, J.¬†I. Giribet, H.¬†D. Patino, Navego: A simulation framework for low-cost integrated navigation systems, Journal of Control Engineering and Applied Informatics 17¬†(2) (2015) 110‚Äì120.\n[35]\nS.¬†Chen, M.¬†Xin, F.¬†Yang, X.¬†Zhang, J.¬†Liu, G.¬†Ren, S.¬†Kong, Error compensation method of gnss/ins integrated navigation system based on at-lstm during gnss outages, IEEE Sensors Journal 24¬†(12) (2024) 20188‚Äì20199.\n[36]\nM.¬†Horowitz, 1.1 computing‚Äôs energy problem (and what we can do about it), in: 2014 IEEE international solid-state circuits conference digest of technical papers (ISSCC), IEEE, 2014, pp. 10‚Äì14.\nAcknowledgments\nThis work is supported by the Science and Technology Development Fund, Macau, SAR, under Grant 0005/2023/EIB1.",
  "preview_text": "Low-cost inertial navigation systems (INS) are prone to sensor biases and measurement noise, which lead to rapid degradation of navigation accuracy during global positioning system (GPS) outages. To address this challenge and improve positioning continuity in GPS-denied environments, this paper proposes a brain-inspired GPS/INS fusion network (BGFN) based on spiking neural networks (SNNs). The BGFN architecture integrates a spiking Transformer with a spiking encoder to simultaneously extract spatial features from inertial measurement unit (IMU) signals and capture their temporal dynamics. By modeling the relationship between vehicle attitude, specific force, angular rate, and GPS-derived position increments, the network leverages both current and historical IMU data to estimate vehicle motion. The effectiveness of the proposed method is evaluated through real-world field tests and experiments on public datasets. Compared to conventional deep learning approaches, the results demonstrate that BGFN achieves higher accuracy and enhanced reliability in navigation performance, particularly under prolonged GPS outages.\n\nA brain-inspired information fusion method for enhancing robot GPS outages navigation\nYaohua Liu\nHengjun Zhang\nBinkai Ou\nAbstract\nLow-cost inertial navigation systems (INS) are prone to sensor biases and measurement noise, which lead to rapid degradation of navigation accuracy during global positioning system (GPS) outages. To address this challenge and improve positioning continuity in GPS-denied environments, this paper proposes a brain-inspired GPS/INS fusion network (BGFN) based on spiking neural networks (SNNs). The BGFN architecture integrates a spiking Transformer with a spiking encoder to simultaneously extract spatial features from inertial measurement unit (IMU) signals and capture their temporal dynamics. By modeling the relationship between vehicle attitude, specific force, angular rate, and GPS-derived position increments, the network leverages",
  "is_relevant": false,
  "relevance_score": 1.0,
  "extracted_keywords": [
    "GPS",
    "INS",
    "spiking neural networks",
    "navigation",
    "fusion"
  ],
  "one_line_summary": "ËØ•ËÆ∫ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éËÑâÂÜ≤Á•ûÁªèÁΩëÁªúÁöÑËÑëÂêØÂèëÂºèGPS/INSËûçÂêàÊñπÊ≥ïÔºåÁî®‰∫éÊèêÈ´òÊú∫Âô®‰∫∫Âú®GPS‰∏≠Êñ≠ÁéØÂ¢É‰∏ãÁöÑÂØºËà™ÊÄßËÉΩ„ÄÇ",
  "detailed_summary": "",
  "qa_pairs": [],
  "is_hidden": false,
  "is_starred": false,
  "flag": "",
  "published_date": "2026-01-13T06:02:17Z",
  "created_at": "2026-01-20T17:49:41.079400",
  "updated_at": "2026-01-20T17:49:41.079407"
}